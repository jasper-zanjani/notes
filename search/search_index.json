{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"Coding/","title":"Overview","text":""},{"location":"Coding/#text","title":"Text","text":""},{"location":"Coding/#hello-world","title":"Hello, world!","text":"Hello, world!ParameterizedInteractiveCLI framework <pre><code>\"Hello, world!\"\n</code></pre> <pre><code>Console.WriteLine(\"Hello World!\");\n</code></pre> <pre><code>import sys\n\n\ndef main():\n    name : str = sys.argv[1]\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <pre><code>using System.CommandLine;\nusing System.CommandLine.Invocation;\n\nstatic int Main(string[] args)\n{\nvar cmd = new RootCommand\n{\nnew Argument&lt;string&gt;(\"name\"),//, \"Your name\"),\nnew Option&lt;string?&gt;(new[] {\"--greeting\", \"-g\" },\"The greeting to use\"),\n};\n\ncmd.Handler = CommandHandler.Create&lt;string, string?&gt;(HandleGreeting);\n\nreturn cmd.Invoke(args);\n}\n\nstatic void HandleGreeting(string? greeting, string name)\n{\nConsole.WriteLine($\"{greeting}, {name}\");\n}\n</code></pre> <pre><code>def main():\n    name: str = input(\"What is your name? \")\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> argparse <pre><code>import argparse\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Say hello\")\n    parser.add_argument(\n        dest=\"name\",metavar=\"name\", default=\"World\", help=\"Name to greet\"\n    )\n    args = parser.parse_args()\n    print(f\"Hello, {args.name}!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> clap"},{"location":"Coding/#numbers","title":"Numbers","text":"Weight on MarsDouble array <pre><code>def main():\n    weight = input(\"Enter weight in kilograms:\\n\")\n    try:\n        mars_weight = (int(weight)/9.81) * 3.711\n    except ValueError:\n        mars_weight = 0.0\n    print(\"Weight on Mars: {} kg\".format(mars_weight))\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> List comprehensionmap() <pre><code>[ 2 * el for el in primes ]\n</code></pre> <pre><code>primes = [1, 2, 3, 5, 7, 11, 13, 17, 19, 23]\ndouble = lambda x: 2*x\nlist(map(double, primes))\n</code></pre> <p>Parse a date string</p> <code>TryParse</code><code>try/catch</code> <pre><code>namespace Program\n{\nclass Program\n{\nstatic void Main()\n{\nstring rawDate = \"07/04/1776\";\nDateTime.TryParse(rawDate, out parsedDate);\nConsole.WriteLine(parsedDate.ToLongDateString()); // =&gt; \"July 4, 1776\"\n}\n}\n}\n</code></pre> <pre><code>namespace Program\n{\nclass Program\n{\nstatic void Main()\n{\nstring rawDate = \"07/04/1776\";\ntry {\nDateTime parsedDate = DateTime.Parse(rawDate);\n}\ncatch (FormatException)\n{\nConsole.WriteLine(\"Unparsable!\")\n}\n}\n}\n}\n</code></pre>"},{"location":"Coding/#file-operations","title":"File operations","text":"Create Read Copy Move <pre><code>using (StreamWriter writer = File.CreateText(\"test.txt\"))\n{\nwriter.WriteLine(\"Hello, world!\");\n}\n</code></pre> <pre><code>with open('text', 'w') as f:\n    f.write('Hello, world!')\n</code></pre> ReadAllTextReadAllLines <pre><code>using System.IO;\n\nstring raven = File.ReadAllText(\"raven\");\n</code></pre> <pre><code>using System.IO;\n\nstring[] raven = File.ReadAllLines(\"raven\");\n</code></pre> <p>Using <code>StreamReader</code> objects</p> ReadToEndLoop <pre><code>using System.IO;\n\nusing (StreamReader reader = File.OpenText(\"raven\"))\n{\nreader.ReadToEnd();\n}\n</code></pre> <pre><code>using System.IO;\n\nusing (StreamReader reader = File.OpenText(\"raven\"))\n{\nstring s;\nwhile ((s = sr.ReadLine()) != null)\n{\nConsole.WriteLine(s);\n}\n}\n</code></pre> <p> </p> <pre><code>with open('raven') as f:\n    f.readlines()\n</code></pre> <pre><code>using System.IO;\n\nFile.Copy('raven', 'raven.bak', true)\n</code></pre> <p> </p> <pre><code>import shutil\n\nshutil.copyfile('raven', 'raven.bak')\n</code></pre> <pre><code>using System.IO;\n\nFile.Move('raven', 'raven.bak');\n</code></pre>"},{"location":"Coding/#text-output","title":"Text output","text":"<pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet filename = &amp;args[1];\n\nlet contents = std::fs::read_to_string(filename)\n.expect(\"Couldn't read file\");\n\nprintln!(\"{}\", contents);\n}\n</code></pre>"},{"location":"Coding/#data-file-formats","title":"Data file formats","text":"CSVJSON <pre><code>import csv\n\nwith open (\"greeks.csv\") as f:\n    r = csv.reader(f)\n    headers = next(r)\n    data = [row for row in r]\n</code></pre> <pre><code>using System;\nusing System.IO;\nusing CsvHelper;\n\nstruct Greek\n{\npublic string name { get; set; }\npublic string city { get; set; }\npublic string dob { get; set; }\n}\n\nclass Program\n{\nstatic void Main(string[] args)\n{\nusing (StreamReader reader = new StreamReader(\"greeks.csv\"))\n{\nCsvReader csvreader = new CsvReader(reader, System.Globalization.CultureInfo.InvariantCulture);\n\nvar data = csvreader.GetRecords&lt;Greek&gt;();\n\nforeach (Greek item in data)\n{\nConsole.WriteLine($\"{item.name,-15} {item.city,-15} {item.dob,-15}\");\n}\n}\n}\n}\n</code></pre> <pre><code>using (var stream = await storageFile.OpenAsync(FileAccessMode.Read))\n{\nusing (var dataReader = new DataReader(stream))\n{\nawait dataReader.LoadAsync((uint)stream.Size);\nvar json = dataReader.ReadString((uint)stream.Size);\ncustomerList = JsonConvert.DeserializeObject&lt;List&lt;Customer&gt;&gt;(json);\n}\n}\n</code></pre>"},{"location":"Coding/#random-numbers","title":"Random numbers","text":"IntegerReal number <pre><code>Random r = new System.Random();\nint result = r.Next(1, 6);\n</code></pre> <pre><code>import random\nrandom.randrange(1,6)\n</code></pre> <pre><code>Random r = new System.Random();\nint result = r.NextDouble();\n</code></pre> <pre><code>import random\nrandom.random()\n</code></pre>"},{"location":"Coding/#string-formatting","title":"String formatting","text":"<pre><code>Socrates   Athens         470 BC\nPlato      Athens         428 BC\nAristotle  Stagira        384 BC\nEuclid     Alexandria     325 BC\nPythagoras Samos          570 BC\n</code></pre> <p>In C#, multidimensional arrays cannot be traversed with the <code>foreach</code> loops which appear to flatten its structure.</p> <pre><code>for (int i = 0; i &lt;= greeks.GetUpperBound(0); i++)\n{\nConsole.WriteLine(\"{0,-10} {1,-10} {2,10}\", greeks[i,0], greeks[i,1], greeks[i,2]);\n}\n</code></pre> <p> </p> <pre><code>for r in greeks:\n    print(\"{0:10} {1:10} {2:&gt;10}\".format(r[0],r[1],r[2]))\n</code></pre> <p>Currency formatting</p> <pre><code>Console.WriteLine($\"{123456.789:C }\");          //  $123,456.79\nConsole.WriteLine(123456.789d.ToString(\"C\"));   //  $123,456.79\n</code></pre> <p> </p> f-stringlocale module <pre><code>f\"${123456.789:,.2f}\"                           #   $123,456.79\n</code></pre> <p>Formatting a number in currency requires use of the locale module, and for the locale environment variables to be set.</p> <pre><code>import locale\n\nlocale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\nlocale.currency(123456.789)                 #   $123456.79\n</code></pre>"},{"location":"Coding/#network","title":"Network","text":"<p>Berkeley sockets  have formed the basis of modern network communication since their introduction in the early 1980s.  The use of the term \"socket\" to refer to an endpoint for communication began as early as 1971  with ARPANET. As a concept it belongs in the Session layer of the OSI model.</p> <p>The original Berkeley sockets API, written in C, has been maintained in implementations of other languages</p> <ul> <li>Python's socket module </li> <li>Rust's net module </li> </ul> <p>The API:</p> <ul> <li>socket() creates a new socket in the operating system, identified by an integer. It returns a file descriptor</li> <li>bind() associates a socket with an address structure: IP address and port number</li> <li>listen() blocks for incoming connections</li> <li>accept() creates a new TCP connection from the remote client</li> </ul>"},{"location":"Coding/#echo-server","title":"Echo server","text":"<p>An echo server simply reflects text sent to it over a TCP connection</p> <ul> <li>Both Python's socket object and Rust's TcpListener object expose a <code>bind()</code> method, although in Rust host and port are combined in a string, whereas in Python they are passed as a <code>(str,int)</code> tuple.</li> <li>Both implementations expose an <code>accept()</code> method that returns a tuple, but in Python the tuple returned contains the socket (named \"conn\") object and a nested tuple that contains the address of the client. In Rust, the equivalent to the connection object seems to be a TcpStream object ...<ul> <li>This object contains binary data which must be put into a buffer.  In Rust the buffer is passed as a mutable reference to the <code>read()</code> method (i.e. <code>read(&amp;mut buffer)</code>). The buffer size is determined by the size of the initialized buffer.</li> <li>In Python the binary information is assigned to a variable using the <code>recv()</code> method, which does take an integer argument specifying the buffer size.</li> </ul> </li> </ul> <pre><code>echo \"Hello, world!\" | netcat localhost 8080\n</code></pre> <p> </p> <pre><code>use std::net::TcpListener;\nuse std::io::Read;\n\nfn main() {\nlet server = Server::new(\"127.0.0.1:8000\".to_string());\nserver.run();\n}\n\npub struct Server {\naddr: String,\n}\n\nimpl Server {\npub fn new(addr: String) -&gt; Self {\nSelf { addr }\n}\n\npub fn run(self) {\nprintln!(\"Listening on {}\", self.addr);\n\nlet listener = TcpListener::bind(&amp;self.addr).unwrap();\n\nloop {\nmatch listener.accept() {\nOk((mut stream, _)) =&gt; {\nlet mut buffer = [0; 1024];\nmatch stream.read(&amp;mut buffer) {\nOk(_) =&gt; {\nprintln!(\"Received request: {}\", String::from_utf8_lossy(&amp;buffer));\n},\nErr(e) =&gt; println!(\"Failed to read from connection: {}\", e),\n}\n}\nErr(e) =&gt; println!(\"Failed to establish a connection: {}\", e), }\n}\n}\n}\n</code></pre> <p> </p> <pre><code>import socket\n\n\nclass Echo_Server:\n    def __init__(self, address: str):\n        self.addr = address\n\n    def run(self):\n        HOST = self.addr[: self.addr.find(\":\")]\n        PORT = int(self.addr[self.addr.find(\":\") + 1 :])\n\n        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n            s.bind((HOST, PORT))\n            s.listen()\n            conn, addr = s.accept()\n            with conn:\n                print(f\"Received connection from {addr}\")\n                while True:\n                    data = conn.recv(1024)\n                    if not data:\n                        break\n                    print(data.decode(\"utf-8\"))\n                    # conn.sendall(data) # Echo server\n\n\ndef main():\n    server = Echo_Server(\"127.0.0.1:8000\")\n    server.run()\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"Coding/#terminal","title":"Terminal","text":""},{"location":"Coding/#input-validation-loop","title":"Input validation loop","text":"<p>Such a loop will continuously prompt for valid input, in this case an integer.</p> TryParsetry/catch <pre><code>while (true):\n{\nint option;\nint.TryParse(Console.ReadLine(), out option);\nif (option != null)\n{\n// ...\n}\nelse {break;}\n}\n</code></pre> <pre><code>while (true):\n{\ntry {\nint option = Int32.Parse(Console.ReadLine());\n}\ncatch (FormatException) {\n// Input was not an integer\n}\ncatch (OverflowException) {\n// Number was too big\n}\n}\n</code></pre> <p> </p> <pre><code>while True:\n    try:\n        option = int(input())\n    except ValueError:\n        # Integer was not able to be parsed\n</code></pre>"},{"location":"Coding/#guessing-game","title":"Guessing game","text":""},{"location":"Coding/#oxford-comma","title":"Oxford comma","text":"<pre><code>using System.CommandLine;\nusing System.CommandLine.Invocation;\nusing System.Linq;\n\nstatic int Main(string[] args)\n{\nvar cmd = new RootCommand\n{\nnew Argument&lt;string[]&gt;(\"names\")\n};\n\ncmd.Handler = CommandHandler.Create&lt;string[]&gt;(Handler);\n\nreturn cmd.Invoke(args);\n}\n\nstatic void Handler(string[] names)\n{\nConsole.WriteLine($\"{String.Join(\", \", names.Take(names.Length -1))}, and {names.Last&lt;string&gt;()}\");\n}\n</code></pre> <pre><code>import argparse\n\n\ndef get_args():\n    p = argparse.ArgumentParser(description=\"Listing args with Oxford comma\")\n    p.add_argument(\"words\", nargs=\"+\", help=\"Words to concatenate using Oxford comma\")\n    return p.parse_args()\n\n\ndef oxford_commafy(words):\n    l = len(words)\n    if l &gt; 2:\n        words[-1] = f\"and {words[-1]}\"\n        print(\", \".join(words))\n    elif l == 2:\n        print(f\"{words[0]} and {words[1]}\")\n    else:\n        print(words[0])\n\n\ndef main():\n    args = get_args().words\n    oxford_commafy(args)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"Coding/#color-output","title":"Color output","text":"<pre><code>Console.Color = ConsoleColor.Red;\nConsole.WriteLine(\"Red!\")\nConsole.ResetColor();\n</code></pre> <pre><code>print(f\"{colorama.Fore.RED} Red! {colorama.Style.RESET_ALL}\")\n</code></pre> <pre><code>Console.Color = ConsoleColor.Green;\nConsole.WriteLine(\"Green!\")\nConsole.ResetColor();\n</code></pre> <pre><code>print(f\"{colorama.Fore.GREEN} Green! {colorama.Style.RESET_ALL}\")\n</code></pre> <pre><code>Console.Color = ConsoleColor.Yellow;\nConsole.WriteLine(\"Yellow!\")\nConsole.ResetColor();\n</code></pre> <pre><code>print(f\"{colorama.Fore.YELLOW} Yellow! {colorama.Style.RESET_ALL}\")\n</code></pre> <pre><code>Console.Color = ConsoleColor.Blue;\nConsole.WriteLine(\"Blue!\")\nConsole.ResetColor();\n</code></pre> <pre><code>print(f\"{colorama.Fore.BLUE} Blue! {colorama.Style.RESET_ALL}\")\n</code></pre> <pre><code>Console.Color = ConsoleColor.Magenta;\nConsole.WriteLine(\"Magenta!\")\nConsole.ResetColor();\n</code></pre> <pre><code>print(f\"{colorama.Fore.MAGENTA} Magenta! {colorama.Style.RESET_ALL}\")\n</code></pre>"},{"location":"Coding/#calculator","title":"Calculator","text":"(argparse) <pre><code>import argparse\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"operand1\", type=float)\n    parser.add_argument(\"operand2\", type=float)\n    op = parser.add_mutually_exclusive_group()\n    op.add_argument(\"-a\", \"--add\", dest=\"add\", action=\"store_true\")\n    op.add_argument(\"-s\", \"--subtract\", action=\"store_true\")\n    op.add_argument(\"-d\", \"--divide\", action=\"store_true\")\n    op.add_argument(\"-m\", \"--multiply\", action=\"store_true\")\n    return parser.parse_args()\n\n\ndef main():\n    args = get_args()\n    if args.add:\n        print(\"Adding\")\n        print(args.operand1, \" + \", args.operand2, \" = \", args.operand1 + args.operand2)\n    elif args.subtract:\n        print(\"Subtracting\")\n        print(args.operand1, \" - \", args.operand2, \" = \", args.operand1 - args.operand2)\n    elif args.divide:\n        print(\"Dividing\")\n        print(args.operand1, \" / \", args.operand2, \" = \", args.operand1 / args.operand2)\n\n    elif args.multiply:\n        print(\"Multiplying\")\n        print(args.operand1, \" * \", args.operand2, \" = \", args.operand1 * args.operand2)\n    else:\n        print(\"Unknown operation!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"Coding/#input-validation","title":"Input validation","text":"<pre><code>string input;\nint inputParsed;\nwhile (true)\n{\ninput = System.Console.ReadLine();\ntry\n{\ninputParsed = int.Parse(input);\nbreak;\n}\ncatch {\nSystem.Console.WriteLine(\"Please input a number...\");\n}\n}\nSystem.Console.WriteLine($\"Number provided: {inputParsed}\");\n</code></pre>"},{"location":"Coding/#subcommands","title":"Subcommands","text":"<pre><code>./app command subcommand argument\n</code></pre> <pre><code>static int Main(string[] args)\n{\nvar rootCommand = new RootCommand(\"command\");\nvar command = new Command(\"subcommand\")\n{\nnew Argument&lt;string&gt;(\"argument\");\n};\ncommand.Handler = new CommandHandler.Create&lt;string&gt;(argumentHandler);\nrootCommand.Add(command);\nrootCommand.Invoke(args);\n}\n\nprivate static void argumentHandler(string argument)\n{\n/* ... */\n}\n</code></pre>"},{"location":"Coding/#to-do-app","title":"To-do app","text":"<p>Notably, the dstask Go application is a very sophisticated evolution of a terminal-based to-do app featuring subcommands, YAML-formatted tasks, and Git integration.</p>"},{"location":"Coding/#tdd","title":"TDD","text":"<p>Test fixture</p>"},{"location":"Coding/#oop","title":"OOP","text":""},{"location":"Coding/#dnd-character","title":"DnD character","text":"<p>Generating a Dungeons 'n Dragons character provides the opportunity to exercise a variety of OOP techniques: public and private fields and properties and methods using simple arithmetic.</p> <p>A Dungeons 'n Dragons character has six character attributes that can be randomly assigned. This process, called an ability roll, is calculated by rolling four six-sided dice (d6) and summing the highest three values, discarding the lowest. The raw ability score is then modified according to a table to produce a final ability score.</p> <p>In the implementations below, all ability scores are dynamically calculated using getter functions that sum the raw ability score (stored as a private field) and modifier. Both the ability roll and modifier lookup are implemented as public static functions.</p> <p> </p> ConstructorPropertiesMethods <pre><code>class Character:\n    def __init__(self, race: Race = Race.HUMAN):\n        self._strength_ability = self.ability_roll()\n        self._dexterity_ability = self.ability_roll()\n        self._constitution_ability = self.ability_roll()\n        self._intelligence_ability = self.ability_roll()\n        self._wisdom_ability = self.ability_roll()\n        self._charisma_ability = self.ability_roll()\n        self._race = race\n</code></pre> <pre><code>class Character:\n    @property\n    def Strength(self):\n        return self._strength_ability + self.get_modifier(self._strength_ability)\n\n    @property\n    def Dexterity(self):\n        return self._dexterity_ability + self.get_modifier(self._dexterity_ability)\n\n    @property\n    def Constitution(self):\n        return self._constitution_ability + self.get_modifier(\n            self._constitution_ability\n        )\n\n    @property\n    def Intelligence(self):\n        return self._intelligence_ability + self.get_modifier(\n            self._intelligence_ability\n        )\n\n    @property\n    def Wisdom(self):\n        return self._wisdom_ability + self.get_modifier(self._wisdom_ability)\n\n    @property\n    def Charisma(self):\n        return self._charisma_ability + self.get_modifier(self._charisma_ability)\n</code></pre> <pre><code>@staticmethod\ndef Roll(range: int = 6):\n    return random.randrange(range) + 1\n\n@staticmethod\ndef get_modifier(score: int):\n    return math.floor((score - 10) / 2)\n\n@classmethod\ndef ability_roll(cls):\n    rolls = [cls.Roll(), cls.Roll(), cls.Roll(), cls.Roll()]\n    rolls.remove(min(rolls))\n    return sum(rolls)\n\ndef report(self):\n    print(f\"Strength: {self.Strength}\")\n    print(f\"Dexterity: {self.Dexterity}\")\n    print(f\"Constitution: {self.Constitution}\")\n    print(f\"Intelligence: {self.Intelligence}\")\n    print(f\"Wisdom: {self.Wisdom}\")\n    print(f\"Charisma: {self.Charisma}\")\n</code></pre> ConstructorPropertiesMethods <pre><code>partial class Character\n{\nprivate int StrengthAbility;\nprivate int DexterityAbility;\nprivate int ConstitutionAbility;\nprivate int IntelligenceAbility;\nprivate int WisdomAbility;\nprivate int CharismaAbility;\nprivate Race Race { get; }\n\npublic Character(Race race)\n{\nthis.StrengthAbility = AbilityRoll();\nthis.DexterityAbility = AbilityRoll();\nthis.ConstitutionAbility = AbilityRoll();\nthis.IntelligenceAbility = AbilityRoll();\nthis.WisdomAbility = AbilityRoll();\nthis.CharismaAbility = AbilityRoll();\nthis.Race = race;\n}\n\npublic Character() : this(Race.HUMAN) { }\n}\n</code></pre> <pre><code>partial class Character\n{\npublic int Strength     { get =&gt; StrengthAbility + GetModifier(StrengthAbility) + GetRaceModifier(Abilities.STRENGTH) }\npublic int Dexterity    { get =&gt; DexterityAbility + GetModifier(DexterityAbility) + GetRaceModifier(Abilities.DEXTERITY) }\npublic int Constitution { get =&gt; ConstitutionAbility + GetModifier(ConstitutionAbility) + GetRaceModifier(Abilities.CONSTITUTION) }\npublic int Intelligence { get =&gt; IntelligenceAbility + GetModifier(IntelligenceAbility) + GetRaceModifier(Abilities.INTELLIGENCE) }\npublic int Wisdom       { get =&gt; WisdomAbility + GetModifier(WisdomAbility) + GetRaceModifier(Abilities.WISDOM) }\npublic int Charisma     { get =&gt; CharismaAbility + GetModifier(CharismaAbility) + GetRaceModifier(Abilities.CHARISMA) }\n}\n</code></pre> <pre><code>partial class Character\n{\npublic void Report()\n{\nConsole.Write($\"Strength: {Strength,2}\");\nConsole.Write($\"Dexterity: {Dexterity,2}\");\nConsole.Write($\"Constitution: {Constitution,2}\");\nConsole.Write($\"Intelligence: {Intelligence,2}\");\nConsole.Write($\"Wisdom: {Wisdom,2}\");\nConsole.Write($\"Charisma: {Charisma,2}\");\n}\n\nstatic int Roll(int ceiling)\n{\nRandom rng = new Random();\nreturn rng.Next(1, ceiling);\n}\n\nstatic int AbilityRoll()\n{\nList&lt;int&gt; rolls = new List&lt;int&gt; { Roll(6), Roll(6), Roll(6), Roll(6) };\nrolls.Remove(rolls.Min());\n\nreturn rolls.Sum();\n}\n\npublic static int GetModifier(int ability)\n{\nreturn (int)System.Math.Floor(((double)ability - 10) / 2);\n}\n}\n</code></pre>"},{"location":"Coding/#rpg-character-generator","title":"RPG character generator","text":"Player classSubclassesRace <pre><code>class Player():\n    def __init__(self, name : str, race: Race, hp : int, mp : int):\n        self._name = name\n        self._race = race\n        self._hp = hp\n        self._mp = mp\n\n    @property\n    def getName(self):\n        return self._name\n\n    @property\n    def getRace(self):\n        return self._race\n\n    @property\n    def getHp(self):\n        return self._hp\n\n    @property\n    def getMp(self):\n        return self._mp\n\n    def attack(self):\n        return \"Have at thee!\"\n</code></pre> <pre><code>class Warrior(Player):\n    def __init__(self, name : str, race: Race):\n        super().__init__(name, race, 200, 0)\n    def attack(self):\n        return \"I will destroy with my sword, foul demon!\"\n\nclass Priest(Player):\n    def __init__(self, name: str, race: Race):\n        super().__init__(name, race, 100, 200)\n    def attack(self):\n        return \"Taste the wrath of the Two True Gods!\"\n\nclass Mage(Player):\n    def __init__(self, name:str, race:Race):\n        super().__init__(name, race, 150, 150)\n    def attack(self):\n        return \"You are overmatched by my esoteric artifices!\"\n</code></pre> <pre><code>import enum\n\nclass Race(enum.Enum):\n    HUMAN = enum.auto(),\n    ELF = enum.auto(),\n    DWARF = enum.auto()\n</code></pre> Player classSubclassesRace <pre><code>#include &lt;string&gt;\n\nclass Player {\nprotected:\nstd::string _name{ \"Johnny Bravo\" };\nRace _race{Race::HUMAN };\nint _hp{ 100 };\nint _mp{ 100 };\n\npublic:\nPlayer(std::string n, Race r, int hp, int mp) : _name{n}, _race{r}, _hp(hp), _mp(mp) {}\nvirtual std::string attack()= 0;\nint getHp()                 { return _hp;   }\nint getMp()                 { return _mp;   }\n\nstd::string getRace()              {\nswitch (_race)\n{\ncase 0:\nreturn \"human\";\nbreak;\n\ncase 1:\nreturn \"elf\";\nbreak;\ncase 2:\nreturn \"dwarf\";\nbreak;\n\ndefault:\nreturn \"none\";\nbreak;\n}\n}\nstd::string getName()       { return _name; }\nvoid setHp(int n)           { _hp = n;   }\nvoid setMp(int n)           { _mp = n;   }\nvoid setName(std::string s) { _name = s; }\nvoid setRace(Race r)        { _race = r;}\n};\n</code></pre> <pre><code>class Warrior : public Player {\npublic:\nWarrior(std::string n, Race r) : Player(n, r, 200, 0) {}\nstd::string attack() {return \"I will destroy you with my sword, foul demon!\";}\n};\n\nclass Priest : public Player {\npublic:\nPriest(std::string n, Race r) : Player(n, r, 100, 200) {}\nstd::string attack() {return \"Taste the wrath of the Two True Gods!\";}\n};\n\nclass Mage : public Player {\npublic:\nMage(std::string n, Race r) : Player(n, r, 150, 150) {}\nstd::string attack() {return \"You are overmatched by my esoteric artifices!\";}\n};\n</code></pre> <pre><code>enum Race { HUMAN, ELF, DWARF\n};\n</code></pre>"},{"location":"Coding/#starships","title":"Starships","text":"<p>This project provides a scenario for implementing OOP and TDD principles in a variety of languages and implementations.</p> <p>Simple classes with intuitive properties and fields include Officer and Starship, which also has a field containing a variant of the StarshipClass enum. Fleet serves as a container for Starships. An Officer is paired with a Starship to form a StarshipDeployment.</p> <p>CaptainSelector, which is passed to StarshipDeployment by dependency injection, evaluates whether the Officer provided has what it takes to ply the inky black. This boils down to a check on the Officer's Grade property, which is simple to test in testing frameworks where a mocked Officer object can be set up with unsatisfactory Grade values.     - StarshipDeployment also takes a StarshipValidator object by dependency injection, which it uses to perform checks on a given Starship. These checks provide opportunities to mock Starship and Officer objects in unit testing.         - <code>IsCaptained()</code> checks if the Starship has a Captain assigned         - <code>ValidateRegistry()</code> makes sure the Starship's registry number begins with NCC or NX         - <code>Evaluate()</code> runs all the other methods in the class and returns True only if all checks pass. This provides the opportunity to test a mocked validator for invocation of the <code>Evaluate()</code> method.</p> <p> </p> OfficerStarship <p> </p> StarshipClassStarship <pre><code>from enum import Enum\n\n\nclass StarshipClass(Enum):\n    NX = 'NX'\n    GALAXY = 'Galaxy'\n    CONSTITUTION = 'Constitution'\n    SOVEREIGN = 'Sovereign'\n    DEFIANT = 'Defiant'\n    INTREPID = 'Intrepid'\n    MIRANDA = 'Miranda'\n</code></pre> <pre><code>class Starship:\n    def __init__(\n        self,\n        name=None,\n        starshipclass: StarshipClass = StarshipClass.NX,\n        registry=None,\n        crew=0,\n    ):\n        self.name = name\n        self.registry = registry\n        self._crew = crew\n        self.crew_on_leave = 0\n        self._starshipclass = starshipclass\n\n    @property\n    def crew(self):\n        return self._crew\n\n    @crew.setter\n    def crew(self, crew: int):\n        if crew &lt; 0:\n            raise Exception\n        else:\n            self._crew = crew\n\n    @property\n    def starshipclass(self):\n        return self._starshipclass\n\n    @starshipclass.setter\n    def starshipclass(self, starshipclass: StarshipClass):\n        if starshipclass not in StarshipClass:\n            raise Exception\n        else:\n            self._starshipclass = starshipclass\n</code></pre> StarshipClassOfficerCaptainSelectorStarshipValidatorStarshipDeployment <pre><code>public enum StarshipClass\n{\nNX,\nGALAXY,\nCONSTITUTION,\nSOVEREIGN,\nDEFIANT,\nINTREPID,\nMIRANDA\n}\n</code></pre> <pre><code>public interface IOfficer\n{\nstring FirstName { get; set; }\nstring LastName { get; set; }\nDateTime BirthDate { get; set; }\nchar Grade { get; set; }\nstring Name { get; }\n}\n\npublic class Officer : IOfficer\n{\npublic string FirstName { get; set; }\npublic string LastName { get; set; }\npublic DateTime BirthDate { get; set; }\npublic string Name { get { return $\"{FirstName} {LastName}\"; } }\npublic char Grade { get; set; }\n}\n</code></pre> <pre><code>public class CaptainSelector\n{\npublic IOfficer Officer { get; set; }\n\npublic CaptainSelector(IOfficer officer)\n{\nOfficer = officer;\n}\npublic bool Evaluate()\n{\nreturn Officer.Grade == 'A' ? true : false;\n}\n}\n</code></pre> <pre><code>public class StarshipValidator : IStarshipValidator\n{\npublic IStarship Starship { get; set; }\n\npublic bool IsCaptained()\n{\nreturn Starship.Captain != null ? true : false;\n}\n\npublic bool ValidateRegistry()\n{\nreturn Starship.Registry.StartsWith(\"NCC\") || Starship.Registry.StartsWith(\"NX\") ? true : false;\n}\n\npublic bool Evaluate()\n{\nreturn ValidateRegistry() &amp;&amp; IsCaptained();\n}\n}\n</code></pre> <pre><code>public class StarshipDeployment\n{\npublic IStarshipValidator StarshipValidator { get; set; }\n\npublic StarshipDeployment(IStarshipValidator validator)\n{\nStarshipValidator = validator ?? throw new ArgumentNullException(nameof(validator));\n}\n\npublic bool ValidateDestination(string destination)\n{\nreturn destination.Length &gt; 1 ? true : false;\n}\n\npublic StarshipMission Deploy(Starship starship, string destination)\n{\nbool destinationValidated = ValidateDestination(destination);\nbool starshipValidated = StarshipValidator.Evaluate();\n\nreturn destinationValidated &amp;&amp; starshipValidated\n? new StarshipMission { Starship = starship as Starship, Destination = destination }\n: throw new ArgumentException();\n}\n}\n</code></pre>"},{"location":"Coding/#glossary","title":"\ud83d\udcd8 Glossary","text":"C <p>\"A programming language is low level when its programs require attention to the irrelevant.\" -Alan Perlis</p> <p>Despite C's reputation as a low-level programming language, in fact it merely emulates the ancient PDP-11, which is the only machine for which its abstract machine can be described as \"close to the metal\".  In the age of parallel processes, C's serial nature...</p> <p>Sources:</p> <ul> <li>C is not a low-level programming language</li> </ul> Enumeration <p>In C# the term enumeration refers to the process of successively returning individual values.  In Python, the term iteration is used to refer to the same thing, and iterable refers to an object that can be iterated, or parsed out into sub-elements.</p> <ul> <li>In Python, any object that exposes the <code>__iter__()</code> and <code>__next__()</code> dunder methods are iterable.</li> <li>In C#, the <code>IEnumerable</code> interface implements enumeration.</li> </ul> <p>Both languages feature a keyword that allows a subclass to access its direct parent. Whereas in Python the terms superclass and subclass are used, in C# the terms base class and derived class are preferred.</p> Garbage collector A garbage collector is a feature of some programming language runtimes that periodically pauses execution to remove data that is no longer used. Such languages are considered unsuitable for use in database applications because of the unpredictable latency this garbage collection creates, despite the added memory safety. Loop unswitching One of the core optimizations that a C compiler performs; transforms a loop containing a conditional into a conditional with a loop in both parts, which changes flow control Register rename engine Component of modern high-end cores which is one of the largest consumers of die area and power Scalar Replacement Of Aggregates (SROA) One of the core optimizations that a C compiler performs; attempts to replace <code>struct</code>s and arrays with fixed lengths with individual variables, which allows the compiler to treat accesses as independent and elide operations entirely if it can prove the results are never visible, which also deletes padding sometimes. Segmented architecture Pointers might be segment IDs and an offset"},{"location":"Coding/6502/","title":"6502","text":"<p>The 6502 processor is an 8-bit CPU that was used in many computers and consoles, including the NES and SNES.</p>"},{"location":"Coding/6502/#specifications","title":"Specifications","text":"<ul> <li>Address bus: 16 bit</li> </ul>"},{"location":"Coding/6502/#emulation","title":"Emulation","text":"Component C++ Memory <code>struct</code>"},{"location":"Coding/6502/#memory","title":"Memory","text":"<p>The first 256B of memory is referred to as the  ($0000-$00FF).</p> Memory range Description 0x0000-0x00FF Zero Page 0x0100-0x01FF Stack"},{"location":"Coding/6502/#registers","title":"Registers","text":"# Register Size Description PC Program Counter 16 bit pointer to the next instruction SP Stack pointer 8 bit holds low 8 bits of the next free location on the stack A Accumulator 8 bit used for all arithmetic operations (except for incrementation and decrementation) X X register 8 bit available for holding counter or offset values for memory access. It also has the special function of copying or changing the value of SP. Y Y register 8 bits available for holding counter or offset values for memory access."},{"location":"Coding/6502/#opcodes","title":"Opcodes","text":"<p>All opcodes are 1 byte in size, and their operands are 0, 1, or 2 bytes</p> Opcode Code Description <code>CMP</code> (src) LDA Load from ZP to A <code>STA</code> $85 Store accumulator in memory (src)"},{"location":"Coding/6502/#lda","title":"LDA","text":"<pre><code>LDA #$33 ; Load 69 into A\n</code></pre>"},{"location":"Coding/6502/#sta","title":"STA","text":""},{"location":"Coding/6502/#exapunks","title":"Exapunks","text":"Instruction Description <code>LINK</code> Move <code>GRAB</code> <code>COPY</code>"},{"location":"Coding/C%23/","title":"C#","text":""},{"location":"Coding/C%23/#to-do","title":"To-do","text":"<ul> <li>Sort out Events section, in particular the example cited</li> <li>Develop C# implementation of CSV parser. This appears to be harder than it should be, apparently because the object returned by the <code>CsvReader.GetRecords&lt;T&gt;()</code> method is an <code>IEnumerable</code> which is one of the confusing points of the UWP course. YouTube tutorials do not seem helpful..</li> </ul>"},{"location":"Coding/C%23/#variables","title":"Variables","text":""},{"location":"Coding/C%23/#parsing","title":"Parsing","text":"<p>Data types can be used as static classes, exposing a <code>TryParse</code> method.</p> Int32DateTime <pre><code>parsedInt = Int32.TryParse(rawInt);\n</code></pre> <pre><code>parsedDate = DateTime.TryParse(rawDate);\n</code></pre>"},{"location":"Coding/C%23/#string","title":"String","text":"<p>Specify a verbatim literal string by prepending <code>@</code>, which disables escape characters and forces interpretation of backslashes literally: <pre><code>string filePath = @\"C:\\televisions\\sony\\bravia.txt\";\n</code></pre></p> <p>Specify a formatted string by prepending a <code>$</code> <pre><code>int n;\nstring s = $\"{n} is a number\";\n</code></pre> Standard numeric format strings are used to format common numeric types. They take the form of a character (i.e. <code>C</code> for currency, <code>N</code> for number) followed by a number. They can be passed as arguments to the <code>ToString</code> method of the literal or in the placeholder of a formatted string after <code>:</code>. <pre><code>Console.WriteLine($\"{123.456789:C }\");          // $123.46\nConsole.WriteLine(123.456789d.ToString(\"C\"));   // $123.46\n</code></pre> A precision specifier can define the number of fractional digits after the decimal separator. <pre><code>Console.WriteLine($\"{123.456789:C3 }\"); // $123.457\n</code></pre> Empty space can be added to either side of the value to create evenly spaced output by placing a number after a comma (positive for right-alignment, negative for left-alignment): <pre><code>Console.WriteLine($\"{123.456789, 15}\");\n</code></pre></p>"},{"location":"Coding/C%23/#casting","title":"Casting","text":"<p>Because real numbers are stored as <code>double</code>s by default, in order to assign to a float variable you must append <code>f</code> to the literal: <pre><code>float num = 3.14f;\n</code></pre> A similar logic pertains for integers to be declared as <code>doubles</code>: <pre><code>double num = 3d;\n</code></pre> <code>decimal</code> data type literals, which have 28-29 significant digits, can be declared with the <code>m</code> suffix <pre><code>decimal num = 123.4567890123456789m\n</code></pre> <code>char</code> literals can be encoded in Unicode: <pre><code>char umlaut = '\\u00F6';\n</code></pre> Variables can be explicitly cast to some other data types by placing the new data type in parentheses before the value: <pre><code>int pi = (int)System.Math.PI;\n</code></pre> This casting won't work with <code>string</code>, which can be cast by using the <code>Convert</code> type or parsed using the data type's <code>Parse</code> method. The differense is that using <code>Convert</code> will return a 0 if the value is null while <code>Parse</code> will throw an exception. <pre><code>w = \"5\";\nint wConverted = System.Convert.ToInt32(w);\nint wParsed = int.Parse(w);\n</code></pre></p>"},{"location":"Coding/C%23/#collection","title":"Collection","text":""},{"location":"Coding/C%23/#arrays","title":"Arrays","text":"<p>Arrays are declared differently from built-in arrays in C++.</p> C#C++ <pre><code>int[] primes = {1, 2, 3, 5, 7, 11, 13, 17, 19, 23};\n</code></pre> <pre><code>int primes[10] {1, 2, 3, 5, 7, 11, 13, 17, 19, 23}\n</code></pre> <p>An empty array must still have its size declared <pre><code>int[] primes = new int[10];\n</code></pre> An unnamed array: <pre><code>new[] {1, 2, 3};\n</code></pre> Arrays can be traversed with a <code>foreach</code> loop, but the elements can not be changed.: <pre><code>foreach (var i in container)\n{\n// ...\n}\n</code></pre></p> <p>Arrays can be copied with the <code>Clone()</code> and <code>Copy()</code> methods: see ArrayCloning.</p> <p>Arrays can be reversed in place with the <code>Reverse</code> method. <pre><code>int[] primes = {1, 2, 3, 5, 7, 11, 13, 17, 19, 23};\nArray.Reverse(primes);\n</code></pre></p>"},{"location":"Coding/C%23/#linq","title":"LINQ","text":"<p>Language Integrated Query (LINQ) refers to a C# library that facilitates querying of collections.  These are exposed as extension methods: methods that are available on already existing queryable types This means extension methods are exposedon existing collection types like Array and List because they are derived from <code>IEnumerable&lt;T&gt;</code>, and thus need no modification to serve as a LINQ data source.</p> <p>Linq methods are available in two semantically identical syntaxes: query syntax and method syntax (also lambda syntax).  Query syntax is meant to be more intuitive for developers familiar with SQL. Method syntax allows method chaining.</p> Query syntaxMethod syntaxPython <pre><code>int[] numbers = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };\nvar evens = from n in nums where n % 2 == 0 orderby n descending select n;\n</code></pre> <pre><code>int[] numbers = { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };\nvar evens = nums.Where(n =&gt; n % 2 == 0).OrderByDescending(n =&gt; n);\n</code></pre> <pre><code>numbers = [1,2,3,4,5,6,7,8,9,10]\nevens = [n for n in numbers if n % 2 == 0]\nlist(reversed(evens))\n</code></pre> <p>Notably, unlike loop structures in C#, LINQ methods can work on unordered collections like Dictionaries.</p>"},{"location":"Coding/C%23/#observablecollection","title":"ObservableCollection","text":"<p>The <code>ObservableCollection</code> class is used to define collections that provide notifications to data bindings when items are added or removed. As such, it is used in GUI programming...</p>"},{"location":"Coding/C%23/#datetime","title":"DateTime","text":"<p><code>DateTimeOffset</code> is preferred over <code>DateTime</code> because it includes an offset value that indicates the timezone.</p>"},{"location":"Coding/C%23/#parsing_1","title":"Parsing","text":"<p><code>DateTime</code> is a class that exposes several static methods of parsing raw values. All of them have overloads that accept CultureInfo objects (implementing <code>IFormatProvider</code>) which can affect parsing of ambiguous dates.</p> <ul> <li><code>Parse()</code> will attempt to parse a string and raise a FormatException if unable to do so.</li> <li><code>ParseExact()</code> requires an exact string template and requires a <code>CultureInfo</code> object as well.</li> </ul> Parse()Specifying cultureParseExact() <pre><code>string rawDate = \"07/04/1776\";\ntry {\nDateTime parsedDate = DateTime.Parse(rawDate);\n}\ncatch (FormatException)\n{\nConsole.WriteLine(\"Unparsable!\")\n}\nConsole.WriteLine(parsedDate.ToLongDateString()); // =&gt; \"July 4, 1776\"\n</code></pre> <pre><code>string rawDate = \"07/04/1776\";\ntry {\nDateTime parsedDate = DateTime.Parse(rawDate, CultureInfo.GetCultureInfo(\"en-GB\"));\n}\ncatch (FormatException)\n{\nConsole.WriteLine(\"Unparsable!\")\n}\nConsole.WriteLine(parsedDate.ToLongDateString()); // =&gt; \"April 7, 1776\"\n</code></pre> <pre><code>string rawDate = \"07/04/1776\";\ntry {\nDateTime parsedDate = DateTime.ParseExact(rawDate, \"M/d/yyyy\", CultureInfo.InvariantCulture);\n}\ncatch (FormatException)\n{\nConsole.WriteLine(\"Unparsable!\")\n}\nConsole.WriteLine(parsedDate.ToLongDateString()); // =&gt; \"July 4, 1776\"\n</code></pre> <p><code>TryParse()</code> returns no value, but takes an <code>out</code> parameter. It does not throw an exception if the date is unparsable, but rather outputs the default date January 1, 1 AD. The overload that accepts a Culture object also requires a DateTimeStyles object.</p> TryParse()Specifying culture <pre><code>string rawDate = \"07/04/1776\";\nDateTime parsedDate;\nDateTime.TryParse(\nrawDate, out parsedDate\n);\nConsole.WriteLine(parsedDate.ToLongDateString()); // =&gt; \"July 4, 1776\"\n</code></pre> <pre><code>string rawDate = \"07/04/1776\";\nDateTime parsedDate;\nDateTime.TryParse(\nrawDate, CultureInfo.GetCultureInfo(\"en-GB\"), DateTimeStyles.None, out parsedDate\n);\nConsole.WriteLine(parsedDate.ToLongDateString()); // =&gt; \"April 7, 1776\n</code></pre> <p><code>ParseExact()</code> <code>TryParseExact()</code></p>"},{"location":"Coding/C%23/#timezones","title":"Timezones","text":"<p><code>TimeZoneInfo</code> includes static methods that can access system timezones. <code>DateTime</code> does not include timezone information, so it must be specified at runtime.</p> <pre><code>TimeZoneInfo sidneyTimeZone = TimeZoneInfo.FindSystemTimeZoneById(\"E. Australia Standard Time\");\nvar sydneyTime = TimeZoneInfo.ConvertTime(DateTime.Now, sydneyTimeZone);\n</code></pre> <p>Enumerating all system timezones.</p> <pre><code>foreach (var timeZone in TimeZoneInfo.GetSystemTimeZones())\n{\nConsole.WriteLine(timeZone.GetUtcOffset());\n}\n</code></pre>"},{"location":"Coding/C%23/#methods","title":"Methods","text":""},{"location":"Coding/C%23/#lambda","title":"Lambda","text":"<p>A lambda expression can have two forms, both of which use the  lambda declaration operator <code>=&gt;</code></p> Expression lambdaStatement lambda <pre><code>(input-parameters) =&gt; expression\n</code></pre> <pre><code>(input-parameters) =&gt; { statements }\n</code></pre> <p>Anonymous event handlers can be reformulated as lambdas to reduce code complexity.</p> <pre><code>SubmitButton.Click += delegate(object sender, EventArgs e)\n{\nMessageBox.Show(\"Button Clicked\");\n}\n\n// Using a (statement) lambda:\nSubmitButton.Click += (s,e) =&gt; MessageBox.Show(\"Button Clicked\");\n</code></pre>"},{"location":"Coding/C%23/#ref","title":"<code>ref</code>","text":"<p><code>ref</code> allows variables that are normally passed by value to be passed by reference.</p> Pass by valuePass by referenceReturning a value <p>Integers are normally passed by value, so <code>number</code> will not change</p> <pre><code>static void Main() {\nint number = 0;\nplusOne(number);\n}\nstatic void plusOne(int n) {\nn++;\n}\n</code></pre> <p>Now <code>number</code> will increment by one because it is being passed by reference.</p> <pre><code>static void Main() {\nint number = 0;\nplusOne(ref number);\n}\nstatic void plusOne(ref int n) {\nn++;\n}\n</code></pre> <p>Alternatively, <code>number</code> can be reassigned a variable if the method is refactored to return the new value. </p> <pre><code>static void Main() {\nint number = 0;\nnumber = plusOne(number);\n}\nstatic int plusOne(ref int n) {\nn++;\nreturn n;\n}\n</code></pre>"},{"location":"Coding/C%23/#out","title":"<code>out</code>","text":"<p><code>out</code> allows a method to assign a value to a variable that has no value yet. It can be used to return multiple values.</p> <pre><code>static void Main()\n{\ndouble n = 5;\ndouble nSquared;\nsquare(n, out nSquared);\nConsole.WriteLine($\"{n} ^ 2 = {nSquared}\");\n}\nstatic void square(double x, out double y)\n{\ny = System.Math.Pow(x, 2);\n}\n</code></pre> <p><code>out</code> is prominently used in the <code>TryParse</code> method.</p>"},{"location":"Coding/C%23/#params","title":"<code>params</code>","text":"<p><code>params</code> allows you to process a variable number of similarly-typed arguments in the method signature. This collection of arguments is abstracted as an array. <pre><code>static void method(int[] args)\n{\nforeach (int el in args) {\nConsole.WriteLine(el);\n}\n}\n</code></pre> If the arguments to be accepted are themselves arrays, then you must define an array of arrays (ex.). This technique may not have worked in previous versions of C#. <pre><code>static void method(int[][] args)\n{\nforeach (var array in args){\nforeach (int el in array) {\nConsole.WriteLine(el);\n}\n}\n}\n</code></pre></p>"},{"location":"Coding/C%23/#delegates","title":"Delegates","text":"<p>Delegates are a functional programming feature in C# that facilitate loose coupling. They allow a function to be abstracted so that updated logic can be implemented without incurring technical debt.</p> <p>Delegates take the form of a method signature using the <code>delegate</code> keyword.  One or more methods implementing the delegate can be formulated which do not reference the delegate in any way, shape, or form, except for the fact that their method signature matches that specified by the delegate.</p> <p>Where the method is to be used, instead of calling the method directly, the delegate is instantiated like an object, but the name of the specific method that implements the delegate is passed as a parameter.  The instantiated delegate can then be called, which passes the parameters to the method.  This results in looser coupling because when changing implementation, only the parameter specifying the improved method needs to be adjusted, and the delegate ensures that the same pattern of parameters is enforced at compile-time.</p> <p>Delegates can be used for messaging in .NET and especially to tie  events  to event handlers, but they are no longer used as much as <code>Func&lt;T,TResult&gt;</code> and <code>Action&lt;T&gt;</code>.</p> Initial implementationImproved implementation <pre><code>public delegate void InformationNeeded(int n, string s);\n\nstatic void Main()\n{\nInformationNeeded form = new InformationNeeded(SimpleReport)\n\n// ...\n\nform(2, \"kiwi\");\nform(3, \"jackfruit\");\n}\n\nvoid SimpleReport(int m, string t)\n{\nConsole.WriteLine($\"int: {m}, string: {t}\");\n}\n</code></pre> <pre><code>public delegate void InformationNeeded(int n, string s);\n\nstatic void Main()\n{\nInformationNeeded form = new InformationNeeded(BetterReport)\n\n// ...\n\nform(2, \"kiwi\");\nform(3, \"jackfruit\");\n}\n\nvoid BetterReport(int m, string t)\n{\nConsole.WriteLine($\"There are {m} items of type {t}\");\n}\n</code></pre>"},{"location":"Coding/C%23/#events","title":"Events","text":"<p>Events signal the occurrence of an action or notification.  They are raised or fired (invoked) by the publisher and received by the event handler or subscriber.  They represent a syntactic sugar over the  delegate  structure,  which is used in the background as the pipeline to connect publisher and handler.</p> <p>The simplest way to define an event, using the builtin EventHandler type, is as follows: <pre><code>public event EventHandler Occurrence;\n</code></pre></p> <p>In actuality, EventHandler is itself a wrapper around a delegate, and any delegate can be wrapped by the event by the delegate's name as the event's data type: <pre><code>public delegate void InformationNeeded(int n, string s);\n\nclass Form\n{\npublic event InformationNeeded FormEvent;\n}\n</code></pre></p> <p>But because the event structure requires an object reference, the simplest implementation for raising an event is more involved. This is because the Main entry-point for C# programs is static,  and not an object instance.</p> <p>The event must be defined within a class that is then instantiated. The event is implemented in an event handler that is a method within the same class that defines the event. After first checking if the event is null (abbreviated syntax using the null-conditional member access operator is equivalent) the event object is called.</p> <p>Here, the event handler is called by the constructor itself. <pre><code>namespace SimpleEvent\n{\n\nclass Program\n{\nstatic void Main(string[] args)\n{\nTriggeringEvent eventTrigger = new TriggeringEvent();\n}\n\npublic class TriggeringEvent\n{\npublic event EventHandler Event;\n\npublic TriggeringEvent()\n{\nOnEvent(this, EventArgs.Empty);\n}\n\nprotected virtual void OnEvent(object s, EventArgs e)\n{\nvar newEvent = Event as EventHandler;\n\nif (newEvent != null)\n{\nnewEvent(this, EventArgs.Empty);\n}\n// Null-conditional operator available since C# 6:\n// newEvent?.Invoke(this, EventArgs.Empty);\n}\n}\n}\n}\n</code></pre></p> <p>If the method signature of the event handler is made public, then the event can be raised externally and called like any other method, and a slightly simpler example can be constructed. <pre><code>namespace SimpleEvent\n{\nclass Program\n{\nstatic void Main(string[] args)\n{\nTriggeringEvent eventTrigger = new TriggeringEvent();\neventTrigger.OnEvent(eventTrigger, EventArgs.Empty);\n}\n\npublic class TriggeringEvent\n{\npublic event EventHandler Event;\n\npublic virtual void OnEvent(object s, EventArgs e)\n{\nConsole.WriteLine(\"OnEvent\");\nvar newEvent = Event as EventHandler;\nnewEvent?.Invoke(this, EventArgs.Empty);\n}\n}\n}\n}\n</code></pre> Conventionally, however, the event handler is not made public, but defined using the  <code>protected virtual void</code> method signature.</p> <p>Event wiring refers to the process of adding subscribers to an event. In implementation, this involves adding the subscribers to the invocation list of the  delegate that is used to tie the event to event handler. <pre><code>Event += EventSubscriber;\n</code></pre></p> <p>In actuality, this syntax uses delegate inference, where the compiler automatically determines the correct delegate to use. The fuller syntax avoiding the use of this feature would be <pre><code>Event += new EventHandler(EventSubscriber);\n</code></pre></p> <p>The event is then fired by calling it, but this can only occur from within the type in which it is defined. So it has to be fired from within another of that type's methods.</p> <p>Anonymous methods and lambdas can also be used after the <code>+=</code> operator: <pre><code>Event += (s,e) =&gt; Console.WriteLine(\"Subscribing to event!\");\n</code></pre></p> <p>In  this example  , adapted from a Pluralsight course, the <code>OnMissionAccomplished</code> and <code>OnMissionStatusReport</code>  event handlers send two different types of events, respectively: <code>MissionStatusReport</code>  and <code>MissionAccomplished</code>. Even though both of these events are <code>EventHandler</code> types, they are actually events.</p>"},{"location":"Coding/C%23/#async","title":"Async","text":"<p>The <code>async</code> modifier is used to construct asynchronous code. By convention, asynchronous methods are named with \"Async\" to distinguish them. The <code>await</code> keyword marks the variable containing the result.</p> <p><pre><code>public int Addition()\n{\nvar a = SlowMethodOne();\nvar b = SlowMethodTwo();\nreturn a + b;\n}\n</code></pre> <pre><code>public async Task&lt;int&gt; AdditionAsync()\n{\nvar a = SlowMethodOneAsync();\nvar b = SlowMethodTwoAsync();\nreturn await a + await b;\n}\n</code></pre></p> <p>Return types used for async include: - <code>Task</code> - <code>Task&lt;T&gt;</code> - <code>Void</code> should generally be avoided with the exception of event handlers</p> <p>Async does not create new threads by default, so it is only suitable for UI and IO-bound methods, not CPU-bound methods.</p> <p>Here async is used to return an enumerable collection of <code>Customer</code> objects from the file IO system.</p> <pre><code>public class CustomerDataProvider\n{\nprivate static readonly string _customersFileName = \"customers.json\";\nprivate static readonly StorageFolder _localFolder = ApplicationData.Current.LocalFolder;\npublic async Task&lt;IEnumerable&lt;Customer&gt;&gt; LoadCustomersAsync()\n{\nvar storageFile = await _localFolder.TryGetItemAsync(_customersFileName) as StorageFile;\nList&lt;Customer&gt; customerList = null;\n// ...\n}\n}\n</code></pre> <p>Here threads are used to handle JSON files and data on application load in the data provider for a GUI application</p> LoadCustomersAsyncSaveCustomersAsync <pre><code>public async Task&lt;IEnumerable&lt;Customer&gt;&gt; LoadCustomersAsync()\n{\n\n}\n</code></pre> <pre><code>public async Task SaveCustomersAsync(IEnumerable&lt;Customer&gt; customers) { }\n</code></pre>"},{"location":"Coding/C%23/#exceptions","title":"Exceptions","text":"<p>Exceptions expose <code>Message</code> and <code>StackTrace</code> attributes that can be inspected for further information (ref. ExceptionHandling)</p> <p>Member access operators are syntactic sugars that allow operations to be performed without exception handling.</p> Operator Name Description <code>=&gt;</code>  Lambda declaration operator  <code>?.</code> Null-conditional member access operator Applies the operation to its operand only if it evaluates to non-null, otherwise it returns <code>null</code> <code>?[]</code> Null-conditional element access operator Applies the operation to its operand only if it evaluates to non-null, otherwise it returns <code>null</code> <code>??</code> Null-coalescing operator Returns value of left-hand operand if non-null, otherwise returns result of right-hand operand. <code>??=</code> Null-coalescing assignment operator Assigns the value of the right-hand operand to the left-hand operand, only if the left-hand operand evaluates to <code>null</code>."},{"location":"Coding/C%23/#classes","title":"Classes","text":""},{"location":"Coding/C%23/#access-modifiers","title":"Access modifiers","text":"<p>Classes can be declared with various access modifiers that affect the compiler's behavior. These are intended to prevent what would be runtime errors by turning them into compile-time errors, improving code quality. - static prevents instantiation - abstract indicates the class is to be completed in a derived class.  Every method marked as abstract has to be implemented in the derived class, and the class has to be marked with <code>abstract</code> as well. - sealed prevents inheritance - partial allows the same class to be defined across multiple files</p>"},{"location":"Coding/C%23/#constructor","title":"Constructor","text":"<p>If not defined, the compiler will provide a default constructor.</p> <p>A constructor can be overloaded by using the <code>this</code> keyword in the constructor's signature after a colon, as if invoking the second constructor: <pre><code>using System;\n\nclass Car\n{\npublic string brand { get; set; }\npublic Car() : this(\"Ford\") { }\npublic Car(string brand)\n{\nthis.brand = brand;\n}\n}\n\nclass Program\n{\nstatic void Main(string[] args)\n{\nCar ford = new Car();\nConsole.WriteLine(ford.brand); // =&gt; Ford\n}\n}\n</code></pre></p>"},{"location":"Coding/C%23/#properties","title":"Properties","text":"<p>A property protects the data of a private variable (\"field\") by implementing getter and setter accessor functions.  These allow data validation or other logic to be performed when the variable is changed. The private variable being protected is called the backing store.</p> <p>By convention, properties have identifiers in title case. The identifier for the backing field of a property is conventionally the same as the property, except lowercase or prepended with an underscore.</p> <p>In the <code>set</code> accessor, the keyword <code>value</code> is used for the argument passed in. <pre><code>private string name; // field\npublic string Name   // property\n{\nget { return name; }\nset { this.name = value; }\n}\n</code></pre> A common shorthand was introduced in C# 3 called automatically implemented properties, where the p <pre><code>public string Name { get; set; }\n</code></pre> The set accessor uses an implicit parameter <code>value</code>, whose value is the type of the property. <pre><code>class Person\n{\nprivate string _name; // the name field\npublic string Name    // the Name property\n{\nget =&gt; _name;\nset =&gt; _name = value;\n}\n}\n</code></pre> Data validation for setter accessor: <pre><code>public class Date\n{\nprivate int _month = 7;  // Backing store\n\npublic int Month\n{\nget =&gt; _month;\nset\n{\nif ((value &gt; 0) &amp;&amp; (value &lt; 13))\n{\n_month = value;\n}\n}\n}\n}\n</code></pre> A property can be made read-only by simply removing the setter.</p> <p>An access modifier can also be applied to only one or the other of the accessors to enforce encapsulation. This can make the property read-only externally while still allowing the class's own logic to change the property's value: <pre><code>private set\n{\nif ((value &gt; 0) &amp;&amp; (value &lt; 13))\n{\n_month = value;\n}\n}\n</code></pre> Similarly, fields can be modified with the <code>readonly</code> access modifier.  This will prevent the variable from being changed in external code as well as in any internal methods. Readonly fields can only be set by the constructor or variable initializers.</p>"},{"location":"Coding/C%23/#static-classes","title":"Static classes","text":"<p>Classes marked with <code>static</code> are not instantiated. An example is the <code>System.Console</code> class, which is never instantiated even though its methods are available for use. This structure is called a singleton and is useful as a container for assorted utilities.</p> <p>Methods marked with <code>static</code> are independent of the class instance itself, and as such do not have access to fields that are not <code>const</code>.</p>"},{"location":"Coding/C%23/#polymorphism","title":"Polymorphism","text":"<p>Modifiers like <code>abstract</code>, <code>virtual</code>, and <code>override</code> allow derived classes to implement logic that builds upon that of a base class.</p> <ul> <li><code>virtual</code> allows you to declare methods and properties in a base class which can be overriden in a derived class. <code>virtual</code> cannot be used with <code>static</code>, <code>abstract</code>, <code>private</code>, or <code>override</code>. </li> <li><code>abstract</code> is similar, except that the class itself must also be marked as an abstract class, preventing instantiation of the base class.  Instead of defining a base function, only the signature is declared. </li> <li>In both cases, <code>override</code> is used to mark the implementation in the derived class.</li> </ul> Base class (<code>abstract</code>)Derived classDerived class <p><pre><code>abstract class Shape\n{\npublic abstract double GetArea();\n}\n</code></pre> <pre><code>class Shape\n{\npublic virtual double GetArea()\n{\nreturn;\n}\n}\n</code></pre></p> <pre><code>class Rectangle : Shape\n{\npublic double Length { get; set; }\npublic double Width { get; set; }\n\npublic Rectangle()\n{\nLength = 2;\nWidth = 3;\n}\n\npublic override double GetArea()\n{\nreturn Length * Width;\n}\n}\n</code></pre> <pre><code>class Circle : Shape\n{\npublic double Radius { get; set; }\n\npublic Circle()\n{\nRadius = 3;\n}\n\npublic override double GetArea()\n{\nreturn System.Math.PI * System.Math.Pow(Radius, 2);\n}\n}\n</code></pre>"},{"location":"Coding/C%23/#interfaces","title":"Interfaces","text":"<p>Interfaces can be used to break up dependencies and implement the dependency inversion principle. This principle holds that components should be dependent on abstractions, and not on implementations. (src)</p> <p>Interfaces contain property and method definitions that must be implemented in derived classes, and as such are similar in concept to abstract classes. Like abstract classes, an interface may not be instantiated. Unlike abstract classes, the <code>override</code> keyword is not used on classes that implement interfaces, and access modifiers are not acceptable for interface members. Also unlike abstract classes, smplementation of interface members is mandatory. And although a derived class can only inherit from a single base class, there is no limit on the number of interfaces that a derived class can inherit from.</p> <p>Interface identifiers conventionally with the capital <code>I</code>.</p> InterfaceImplementation <pre><code>interface IAnimal\n{\nvoid AnimalSound();\n}\n</code></pre> <pre><code>class Pig : IAnimal\n{\npublic void AnimalSound()\n{\nConsole.WriteLine(\"Oink\");\n}\n}\n</code></pre> <p>Notably, a commonly encountered interface is IEnumerable because both Lists and Arrays implement it. So methods that iterate over either Lists or Arrays typically use IEnumerable to accept either data type.</p>"},{"location":"Coding/C%23/#attributes","title":"Attributes","text":"<p>Attributes appear to resemble Python decorators because like decorators appear on the line preceding a function or class definition, but they appear to be used for something else. Attributes in C# are used to adjust the function of code in a variety of ways.</p> <p><code>ObsoleteAttribute</code> will produce a compiler warning or error (preventing compilation entirely) when deprecated code is being used.</p> WarningError <pre><code>[Obsolete(\"Don't use this class anymore, instead use ...\")]\nclass Cow { }\n\nstatic void Main()\n{\nCow betsy = new Cow();\n}\n</code></pre> <pre><code>[Obsolete(\"Don't use this class anymore\", true)]\nclass Cow { }\n\nstatic void Main()\n{\nCow betsy = new Cow();\n}\n</code></pre> <p>A family of attributes exist to assist debugging.</p> DebuggerStepThroughDebuggerDisplay <p><code>DebuggerStepThrough</code> can decorate certain methods to be stepped through or skipped while debugging. This is useful for situations where only some properties of a class have to be debugged. This allows more controlled debugging than using the \"Step over properties and operators\" setting in Debugging Options. (src)</p> <pre><code>using System.Diagnostics;\n\nstruct Cow {\npublic string Name { [DebuggerStepThrough] get { return \"Bessy\"; } }\npublic int Weight { get { return 5; } }\n}\n\nstatic void Main()\n{\nCow betsy = new Cow();\n}\n</code></pre> <p><code>DebuggerDisplayAttribute</code> allows an object's state to be formatted to be more understandable in the debugger's watch window. (src) </p> <pre><code>using System.Diagnostics;\n\n[DebuggerDisplay(\"{Name} weighs {Weight} lbs\")]\nstruct Cow\n{\npublic string Name;\npublic int Weight;\n}\n\nclass Program\n{\nstatic void Main(string[] args)\n{\nConsole.WriteLine(\"Hello World!\");\n\n// This triggers instantiation of the attribute\ntypeof(Program).GetCustomAttributes(false);\n\nCow betsy = new Cow { Name = \"Betsy\", Weight = 1000 };\nConsole.WriteLine($\"{betsy.Name} weighs {betsy.Weight} lbs\");\n}\n}\n</code></pre> <p>The <code>CallerMemberNameAttribute</code> can be added to string parameters in functions that are meant to process the name of the function calling them. This avoids the verbosity of placing <code>nameof()</code> on every invocation. (src) <pre><code>using System.ComponentModel;\nusing System.Runtime.CompilerServices;\n\nnamespace WiredBrainCoffee.UWP.Models\n{\npublic class Customer : INotifyPropertyChanged\n{\nprivate string firstName;\n\npublic string FirstName\n{\nget =&gt; firstName;\nset\n{\nfirstName = value;\nOnPropertyChanged(nameof(FirstName));\n}\n}\npublic string LastName { get; set; }\npublic bool IsCoffeeDrinker { get; set; }\n\npublic event PropertyChangedEventHandler PropertyChanged;\n\nprivate void OnPropertyChanged([CallerMemberName]string propertyName = null)\n{\nPropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName));\n}\n}\n}\n</code></pre></p> <p>In XAML, the <code>ContentPropertyAttribute</code> attribute is used to define whether or not a control accepts a default <code>Content</code> property field</p> <pre><code>using Windows.UI.Xaml;\nusing Windows.UI.Xaml.Controls;\nusing Windows.UI.Xaml.Markup;\n\n[ContentProperty(Name = nameof(Customer))]\npublic sealed partial class CustomerDetailControl : UserControl\n{\npublic CustomerDetailControl()\n{\nthis.InitializeComponent();\n}\n}\n</code></pre>"},{"location":"Coding/C%23/#files","title":"Files","text":""},{"location":"Coding/C%23/#streams","title":"Streams","text":"<p>A Stream is an abstraction of a backing store, or sequence of bytes, which can be a file, an input/output device, a websocket, or an inter-process communication pipe.  The <code>Stream</code> class itself is an abstract base class that can't be instantiated. <code>FileStream</code> is the concrete class that uses files as its backing store.</p> <p>Streams can support seeking, although network streams do not support seeking. This can be checked by calling the stream's boolean <code>CanSeek</code> property.</p> <p><code>Stream</code> implements <code>IDisposable</code>, which means it can be disposed indirectly by being placed in a <code>using</code> block.</p> <p>A bit bucket is a stream with no backing store and is implemented as <code>Stream.Null</code>.</p>"},{"location":"Coding/C%23/#testing","title":"Testing","text":"<p>Tests are usually organized in a separate project that is linked to the project containing the system under test (SUT).</p> <p>Visual Studio has a built-in test-runner, but the <code>dotnet</code> CLI utility also allows the entire test suite to be executed from the command-line.</p> <pre><code>dotnet test\n</code></pre> <p>.NET supports several test frameworks.</p>"},{"location":"Coding/C%23/#xunit","title":"xUnit","text":"<p>In xUnit, tests are organized into public classes, and test cases are composed by individual methods on this class, decorated with the <code>Fact</code> attribute. Test assertions are made with static <code>Assert</code> method calls. (src)</p> <pre><code>public class TestCases\n{\n[Fact]\npublic void TestCase()\n{\nAssert.Equal(2 + 2, 4);\n}\n}\n</code></pre> <p>Assertions that an exception must be thrown are generic method calls typed to the specific exception.</p> <pre><code>public class StarshipDeploymentShould\n{\n[Fact]\npublic void ThrowOnNullValidator()\n{\nvar sut = new StarshipDeployment(null);\nAssert.Throws&lt;ArgumentNullException&gt;(sut);\n}\n}\n</code></pre> <p>Test fixtures can be formed on properties of the main test class. They must be initialized with the test class's constructor.</p> XunitClasses under test <pre><code>public class DeskBookerRequestProcessorTests\n{\npublic DeskBookerRequestProcessor processor { get; set; }\n\npublic DeskBookerRequestProcessorTests()\n{\nprocessor = new DeskBookerRequestProcessor();\n}\n\n[Fact]\npublic void ShouldReturnDeskBookerResultWithRequestValues()\n{\nvar request = new DeskBookerRequest\n{\nFirstName = \"Thomas\",\nLastName = \"Huber\",\nEmail = \"thomas@huber.com\",\nDate = new DateTime(2020, 1, 28)\n\n};\nvar result = processor.BookDesk(request);\n\nAssert.NotNull(result);\nAssert.Equal(request.FirstName, result.FirstName);\nAssert.Equal(request.LastName, result.LastName);\nAssert.Equal(request.Email, result.Email);\nAssert.Equal(request.Date, result.Date);\n\n}\n\n[Fact]\npublic void ShouldThrowExceptionIfRequestIsNull()\n{\nvar exception = Assert.Throws&lt;ArgumentNullException&gt;(() =&gt; processor.BookDesk(null));\nAssert.Equal(\"request\",exception.ParamName);\n}\n}\n</code></pre> <pre><code>namespace DeskBooker.Core.Processor\n{\n\npublic class DeskBookingResult\n{\npublic string FirstName { get; set; }\npublic string LastName { get; set; }\npublic DateTime Date { get; set; }\n}\n\npublic class DeskBookingRequest\n{\npublic string FirstName { get; set; }\npublic string LastName { get; set; }\npublic DateTime Date { get; set; }\n}\n\npublic class DeskBookingRequestProcessor\n{\npublic DeskBookingResult BookDesk(DeskBookingRequest request)\n{\nreturn new DeskBookingResult\n{\nFirstName = request.FirstName,\nLastName = request.LastName,\nDate = request.Date,\n};\n}\n}\n}\n</code></pre> <p>In this example, <code>PersonProcessor</code> is a public class whose constructor takes an <code>ISqlDataAccess</code> data provider by means of dependency injection. The <code>LoadData</code> method is setup, and the mocked object is instantiated with the <code>Create</code> method call. The mock will inject the mock data provider, which returns a <code>List&lt;PersonModel&gt;</code>.</p> <pre><code>using (var mock = AutoMock.GetLoose())\n{\nmock.Mock&lt;ISqliteDataAccess&gt;()\n.Setup(x =&gt; x.LoadData&lt;PersonModel&gt;(\"SELECT * FROM Person\"))\n.Returns(GetSamplePeople());\nvar sut = mock.Create&lt;PersonProcessor&gt;();\nvar expected = GetSamplePeople();\nvar actual = sut.LoadPeople();\nAssert.True(actual != null);\nAssert.Equal(actual.Count,expected.Count);\n}\n</code></pre> <p>The <code>Theory</code> attribute decorates a parameterized test and commonly appears in conjunction with <code>InlineData</code> attributes that contain the parameter values.</p> <pre><code>using System;\nusing Xunit;\nusing System.Linq;\n\nnamespace MathTests\n{\npublic class MathWorks\n{\n[Theory]\n[InlineData(2,2)]\n[InlineData(3,3,3)]\n[InlineData(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)]\npublic void Addition(params int[] ops)\n{\nint loopsum = 0;\nforeach (int i in ops)\n{   loopsum += i;\n}\nint linqsum = ops.Sum();\nAssert.Equal(loopsum,linqsum);\n}\n}\n}\n</code></pre> <p>The xUnit test-runner can be modified using a JSON file named xunit.runner.json. This file must be copied to the output directory by selecting \"Copy if newer\" in the file's properties.</p> <p>This example will display the method names only, rather than the fully-qualified dotted name with namespace and class. <pre><code>{\n\"methodDisplay\": \"method\"\n}\n</code></pre></p>"},{"location":"Coding/C%23/#moq","title":"Moq","text":"<p>Moq (\"mock-you\") is an open-source mocking library available as a NuGet package. Mock objects are generics that take the abstract base class or interface used by the mocked object (see provider pattern). Naturally, this means the concrete objects they are replacing must also be implementing those interfaces.</p> <p>There are two mock modes, strict and loose. By default, mock objects are loose, which means they will return default type values and not throw any exceptions to methods that have not been setup.</p> Loose (default)Strict <pre><code>var mock = new Mock&lt;IMockTarget&gt;();\n</code></pre> <pre><code>var mock = new Mock&lt;IMockTarget&gt;(MockBehavior.Strict);\n</code></pre> <p>Mock properties require setup.</p> <pre><code>mock.Setup(x =&gt; x.Property).Returns(\"Hello, world!\");\n</code></pre> <p>Methods of mock objects also require setup using an identical syntax. Concrete arguments can be provided, but preferable is using argument matching. In argument matching, <code>It.IsAny&lt;T&gt;</code> is used like a type declaration to fill the place of any concrete variable used as an argument.  (src)</p> Argument matchingConcrete <pre><code>mock.Setup(x =&gt; x.IsValid(It.IsAny&lt;string&gt;())).Returns(true);\n</code></pre> <pre><code>mock.Setup(x =&gt; x.IsValid(\"Hello, world!\")).Returns(true);\n</code></pre> <p>The mock object exposes an <code>Object</code> property that can be used to test assertions against properties of the mocked object.</p> <pre><code>Assert.Equal(mock.Object.Property, value)\n</code></pre> <p>A mock object's <code>Verify</code> is used to verify that a mocked method was called by the system under test. Verification is specific to the parameters of the mocked method call, and argument matching is available just as it is for setting up mocked methods.</p> <p>Here, the mocked validator, which is passed in to the SUT by dependency injection, must make a call to the validator's <code>Evaluate()</code> method. If the call is removed, the test will fail (\"Expected invocation on the mock at least once, but was never performed...\").</p> <p>An overload of the <code>Verify</code> method also allows a custom error message to be specified. Another overload can ensure that the mocked method was not called, by passing <code>Times.None</code> after the lambda. The Times struct exposes other members like <code>AtLeastOnce</code> and <code>Between</code> that can specify any imaginable number or range of invocations.</p> TestCustom error messageSUT <pre><code>public class StarshipDeploymentShould\n{\n[Theory]\n[InlineData(\"Betelgeuse\")]\npublic void EvaluateStarship(string destination)\n{\nvar mockValidator = new Mock&lt;IStarshipValidator&gt;();\nmockValidator.Setup(x =&gt; x.Evaluate()).Returns(true);\n\nvar mockStarship = new Mock&lt;IStarship&gt;();\n\nvar sut = new StarshipDeployment(mockValidator.Object as IStarshipValidator);\nsut.Deploy(mockStarship.Object as Starship, destination);\nmockValidator.Verify(x =&gt; x.Evaluate());\n}\n}\n</code></pre> <pre><code>public class StarshipDeploymentShould\n{\n[Theory]\n[InlineData(\"Betelgeuse\")]\npublic void EvaluateStarship(string destination)\n{\nvar mockValidator = new Mock&lt;IStarshipValidator&gt;();\nmockValidator.Setup(x =&gt; x.Evaluate()).Returns(true);\n\nvar mockStarship = new Mock&lt;IStarship&gt;();\n\nvar sut = new StarshipDeployment(mockValidator.Object as IStarshipValidator);\nsut.Deploy(mockStarship.Object as Starship, destination);\nmockValidator.Verify(x =&gt; x.Evaluate(), \"Starships should be validated\");\n}\n}\n</code></pre> <pre><code>public class StarshipDeployment\n{\npublic IStarshipValidator StarshipValidator { get; set; }\n\npublic StarshipDeployment(IStarshipValidator validator)\n{\nStarshipValidator = validator ?? throw new ArgumentNullException(nameof(validator));\n}\n\npublic bool ValidateDestination(string destination)\n{\nreturn destination.Length &gt; 1 ? true : false;\n}\n\npublic StarshipMission Deploy(Starship starship, string destination)\n{\nbool destinationValidated = ValidateDestination(destination);\nbool starshipValidated = StarshipValidator.Evaluate();\n\nreturn destinationValidated &amp;&amp; starshipValidated\n? new StarshipMission { Starship = starship as Starship, Destination = destination }\n: throw new ArgumentException();\n}\n}\n</code></pre> <p>A mocked method can also be setup to throw an exception with the <code>Throw&lt;Exception&gt;()</code> method, a generic method that takes an Exception type.</p>"},{"location":"Coding/C%23/#application-design","title":"Application design","text":"<p>Test-driven development and the requirement to be able to mock data providers has a strong influence on application architecture. Instead of tightly coupling models with a particular data provider (such as an hardcoding, an in-memory database, or parsing a file), the recommended pattern is dependency injection. A data provider that implements an interface is passed as an argument to the controller or viewmodel upon entry.</p> <p>For example, a <code>DataProvider</code> class is used to provide a list of integers on application load implements </p> <pre><code>public interface IDataProvider\n{\nIEnumerable&lt;int&gt; LoadAsync();\n}\n\npublic class DataProvider : IDataProvider\n{\nasync public List&lt;int&gt; LoadAsync()\n{\nreturn await List&lt;int&gt; {1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31};\n}\n}\n</code></pre> <p>A mocked data provider also implementing that interface can then be used in testing.</p>"},{"location":"Coding/C%23/#net","title":".NET","text":"<p>The .NET ecosystem has 3 runtimes, all of which implement the .NET Standard Library and rest on common build tools, languages, and runtime components</p> <ul> <li>.NET Framework released in 2002, making it the oldest runtime, and runs only on Windows. Two major components:<ul> <li>Common Language Runtime (CLR) runs managed code and performs garbage collection</li> <li>.NET Framework Class Library (also called the Base Class Library) is composed of many classes, interfaces, and value types</li> </ul> </li> <li>.NET Core is cross-platform, open-source, and optimized for performance. Its application host is <code>dotnet.exe</code><ul> <li>Core Common Language Runtime (CoreCLR) is more lightweight than that of .NET Framework, but implements Just-In Time compilation</li> <li>.NET Core Class Library is smaller than (and actually a subset of) that of .NET Framework</li> </ul> </li> <li>Mono for Xamarin is used for mobile platforms like IOS, Android, and OS X</li> </ul> <p>.NET Standard is a specification of which APIs are available across all these runtimes. It evolved from Portable Class Libraries (PCL) and will eventually replace them. .NET's package manager is NuGet.</p> <p>An assembly can be compiled to EXE or DLL.</p>"},{"location":"Coding/C%23/#dotnet","title":"dotnet","text":"<p>Install dotnet-format <pre><code>dotnet tool install -g dotnet-format\n</code></pre> Install the ASP.NET scaffolding engine <pre><code>dotnet tool install -g dotnet-aspnet-codegenerator\n</code></pre> Create a new xUnit project named tests <pre><code>dotnet new xunit -n tests\n</code></pre> Add a project file to a solution <pre><code>dotnet sln add ./Project/Project.csproj\n</code></pre> Add a project reference to a project <pre><code>dotnet add reference ./path/to/Project.csproj\n</code></pre> Install a NuGet package and add a <code>PackageReference</code> in the project file</p> MoqSystem.CommandLine <pre><code>dotnet add package Moq\n</code></pre> <pre><code>dotnet add package System.CommandLine\n</code></pre> <p>Run the dotnet try web server that supports .NET Interactive-style markdown:</p> <pre><code>    ```cs --source-file ./Program.cs --project ./project.csproj\n    ```\n</code></pre>"},{"location":"Coding/C%23/#project-files","title":"Project files","text":"<p>Project files are XML files that describe various metadata to the dotnet compiler. The root node is <code>Project</code> which has two subnodes that collect various information about the project:</p> <p>PropertyGroup can contain various elements that affect project settings:</p> <ul> <li><code>RootNamespace</code> specifies the namespace that contains the <code>Main()</code> method for console applications</li> <li><code>TargetFramework</code> specifies the targeted CLR framework: <code>net5.0</code>, <code>netcoreapp3.1</code>, etc</li> <li><code>LangVersion</code> C# version: <code>9.0</code>, etc </li> <li><code>Nullable</code> Enable nullable reference types </li> </ul> <p>ItemGroup contains references to NuGet packages (<code>PackageReference</code>) and other projects (<code>ProjectReference</code>).</p> LangVersionNullableItemGroup <pre><code>&lt;PropertyGroup&gt;\n&lt;LangVersion&gt;preview&lt;/LangVersion&gt;\n&lt;/PropertyGroup&gt;\n</code></pre> <pre><code>&lt;PropertyGroup&gt;\n&lt;Nullable&gt;enable&lt;/Nullable&gt;\n&lt;/PropertyGroup&gt;\n</code></pre> <pre><code>&lt;ItemGroup&gt;\n&lt;ProjectReference Include=\"/path/to/OtherProject.csproj\"/&gt;\n&lt;PackageReference Include=\"xunit\" Version=\"2.4.0\"/&gt;\n&lt;/ItemGroup&gt;\n</code></pre> <p>Adding a reference to another project is also easily accomplished from the command-line.</p> <pre><code>dotnet add project /path/to/OtherProject.csproj\n</code></pre>"},{"location":"Coding/C%23/#packages","title":"Packages","text":"<p>NuGet is the official package manager for .NET.</p> <p>NuGet packages required for any project were stored in a XML  packages.config  file. </p> <p>But projects that use PackageReference may store that information in /obj/project.assets.json.</p>"},{"location":"Coding/C%23/#systemcommandline","title":"System.CommandLine","text":"<p>Prior to System.CommandLine, it had been up to the developer to build a custom solution resolving command-line arguments as an array of strings. Although .NET includes several earlier attempts at solving this problem, none had emerged as a default solution.</p> <p>Similar to Python's argparse , the CommandLine library allows you to construct a <code>RootCommand</code> object that accepts definitions of argument and options.</p> <p>Here, an argument is required:</p> C#Python <pre><code>using System;\nusing System.CommandLine;\nusing System.CommandLine.Invocation;\n\nnamespace CommandLine\n{\nclass Program\n{\nstatic int Main(string[] args)\n{\nvar cmd = new RootCommand\n{\nnew Argument&lt;string&gt;(\"name\")\n};\n\ncmd.Handler = CommandHandler.Create&lt;string&gt;(HandleGreeting);\n\nreturn cmd.Invoke(args);\n}\n\nstatic void HandleGreeting(string name = \"world\")\n{\nConsole.WriteLine($\"Hello, {name}\");\n}\n}\n}\n</code></pre> <pre><code>import argparse\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=\"Say hello\")\n    parser.add_argument(\n        dest=\"name\",metavar=\"name\", default=\"World\", help=\"Name to greet\"\n    )\n    return parser.parse_args()\n\n\ndef main():\n    args = get_args()\n    print(f\"Hello, {args.name}!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Here, the greeting can be specified with an optional parameter</p> C#Python <pre><code>using System;\nusing System.CommandLine;\nusing System.CommandLine.Invocation;\n\nnamespace CommandLine\n{\nclass Program\n{\nstatic int Main(string[] args)\n{\nvar cmd = new RootCommand\n{\nnew Argument&lt;string&gt;(\"name\"),//, \"Your name\"),\nnew Option&lt;string?&gt;(new[] {\"--greeting\", \"-g\" },\"The greeting to use\"),\n};\n\ncmd.Handler = CommandHandler.Create&lt;string, string?&gt;(HandleGreeting);\n\nreturn cmd.Invoke(args);\n}\n\nstatic void HandleGreeting(string? greeting, string name)\n{\nConsole.WriteLine($\"{greeting}, {name}\");\n}\n}\n}\n</code></pre> <pre><code>import argparse\n\n\ndef get_args():\n    parser = argparse.ArgumentParser(description=\"Say hello\")\n    parser.add_argument(\n        dest=\"name\",metavar=\"name\", default=\"World\", help=\"Name to greet\"\n    )\n    parser.add_argument(\n        \"--greeting\",\"-g\", dest=\"greeting\", default=\"Hello\", help=\"Greeting to use\"\n    )\n    return parser.parse_args()\n\n\ndef main():\n    args = get_args()\n    print(f\"{args.greeting}, {args.name}!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"Coding/C%23/#documentation","title":"Documentation","text":"<p>C# supports documentation comments that can be exported to an XML file, which can then be imported into a static site generator (especially DocFX).</p> <p>Visual Studio can be set to export these comments upon build.</p>"},{"location":"Coding/C%23/#sdks","title":"SDKs","text":""},{"location":"Coding/C%23/#dynamodb","title":"DynamoDB","text":"<p>To develop a .NET application using DynamoDB, add the AWSSDK.DynamoDBv2 NuGet package. The AWS Explorer, part of the AWS Toolkit for Visual Studio extension, is also useful for setting up a new table. A user with programmatic access, including an Access Key and Secret Key, is necessary to use the toolkit. (src)</p> <p>Both .NET Core and .NET Framework are supported as target frameworks, but .NET Core uses exclusively asynchronous operations.</p> <p>A service client object is formed by instantiating <code>AmazonDynamoDBClient</code>.</p> <p>The exposed method <code>PutItemAsync</code> is used to save an item to a table as a <code>PutItemRequest</code> object. The item itself is provided as a Dictionary in the <code>Item</code> key, but the Dictionary's values are <code>AttributeValue</code> objects, formed with a magic key that determines the data type of the value.</p> StringIntegerBooleanList <pre><code>new AttributeValue{ S = \"Hello, world!\" }\n</code></pre> <pre><code>new AttributeValue{ N = \"3\" }\n</code></pre> <pre><code>new AttributeValue{ BOOL = true }\n</code></pre> <pre><code>new AttributeValue{ L = new List&lt;AttributeValue&gt;\n{\nnew AttributeValue{ S = \"Socrates\" },\nnew AttributeValue{ S = \"Plato\" },\nnew AttributeValue{ S = \"Aristotle\" },\n}}\n</code></pre> <pre><code>using Amazon.DynamoDBv2;\n\nnamespace DynamoDBDemo\n{\npublic class LowLevelSample\n{\npublic static async Task ExecuteAsync()\n{\nusing (IAmazonDynamoDB ddbClient = new AmazonDynamoDBClient()\n{\nawait ddbClient.PutItemAsync(new PutItemRequest\n{\nTableName = \"Users\",\nItem = new Dictionary&lt;string, AttributeValue&gt;\n{\n{ \"Id\", new AttributeValue { S = \"john@doe.com\" } },\n{ \"String\", new AttributeValue { /* ... */ } }\n}\n})\n})\n}\n}\n}\n</code></pre>"},{"location":"Coding/C%23/#concurrency","title":"Concurrency","text":""},{"location":"Coding/C%23/#asynchronous-programming","title":"Asynchronous programming","text":"<p>Consuming APIs:</p> <ul> <li>HttpClient </li> </ul>"},{"location":"Coding/C%23/#multithreading","title":"Multithreading","text":"<p>The Task Parallel Library offers a high-level way to set up multiple threads.</p> <p>A Task represents an asynchronous operation.</p> <p>Task.Run() queues the work passed as the action to run on a different thread in the thread pool. <code>Task.Run&lt;T&gt;()</code> represents an asynchronous operation that returns a specific value type.</p> <pre><code>Task.Run( () =&gt; {\n// ...\n});\n</code></pre> <p>Objects in other threads will be inaccessible without using an object like Dispatcher in WPF</p> <pre><code>Task.Run( () =&gt;\n{\nDispatcher.Invoke(() =&gt; {\n// ...\n});\n});\n</code></pre> <p>To avoid blocking, we can make it asynchronous</p> <pre><code>private async void Search_Click(object sender, RoutedEventArgs e)\n{\nawait Task.Run() =&gt;\n{\n// ...\n\nDispatcher.Invoke(() =&gt;\n{\n// ...\n}\n}\n}\n</code></pre>"},{"location":"Coding/C%23/#glossary","title":"\ud83d\udcd8 Glossary","text":"Assembly A collection of types and resources that are built to work together and form a logical unit of functionality and which form the building blocks of .NET applications. Module A portable executable file (DLL or EXE) consisting of one or more classes and interfaces.   Although multiple modules can theoretically compose a single assembly, in practice an assembly and module can be considered one and the same for most .NET applications. Provider pattern A favored development model in .NET, and a form of dependency injection where a class is passed as an argument to another class that uses it for some purpose.   The key is that the provider must derive from an abstract base class or an interface to support mocks in unit testing."},{"location":"Coding/C%2B%2B/","title":"C++","text":""},{"location":"Coding/C%2B%2B/#preprocessing","title":"Preprocessing","text":"<p>Preprocessing is the phase of executing preprocessing directives in a source file, which are then removed from the resulting translation unit, which combines the pure C or C++ code of a source file with all its included header files. The translation unit is then compiled into an object file, and it is the linker that then forms linkages between object files to produce an executable module.</p> <ul> <li><code>#define</code></li> <li><code>#include</code></li> </ul> <p>The <code>#define</code> directive specifies a macro which can define a text replacement to occur in code before it is compiled. Macros are considered a holdover from C, and other constructs like variable templates and function templates are considered better suited in C++. In practice, <code>#define</code> statements are most commonly used to handle header files.</p> <p>Here, any instance of \"<code>PI</code>\" in the source code will be replaced by the string of digits \"3.14159265\", but it will not be replaced if it forms part of an identifier or appears in a string literal or comment. <pre><code>#define PI 3.14159265\n</code></pre> If a substitution string isn't specified then any instance of the identifier will simply be removed. <pre><code>#define break\n</code></pre> Macros may not span multiple lines without escaped line breaks, but during preprocessing these are removed and the substitution is made inline. <pre><code>#define PI 3.14\\\n159265\n</code></pre></p> <p>Function-like macros are possible because the preprocessor can recognize a function call in the macro identifier and replace its arguments intelligently. Here any invocation of the <code>MAX()</code> function call will have its arguments incorporated into the substitution statement. <pre><code>#define MAX(A, B) A &gt;= B ? A : B\n</code></pre></p> <p>All the lines following <code>#ifndef</code> (<code>#if !defined</code>) will be kept in the file as long as the identifier \"MYHEADER_H\" has not already been defined. This common is called an <code>#include</code> guard. <pre><code>#ifndef MYHEADER_H\n#define MYHEADER_H\n// ...\n#endif\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#variables","title":"Variables","text":"<p>Since C++14, you can separate digits in a long integer with a single quote to make it more readable. <pre><code>int num {12'345}; // 12,345\n</code></pre> Hexadecimal literals are prefixed with \"0x\" and octals with \"0\": <pre><code>int hex {0xabcdef};\nint oct {0567};\n</code></pre> <code>constexpr</code> is used in some situations I can't figure out yet. <pre><code>static constexpr u32 MAX_MEM = 1024 * 64;\n</code></pre></p> <p><code>size_t</code> is a type alias defined in the Standard Library (in the <code>cstddef</code> header). It is an alias for an unsigned integer type.</p>"},{"location":"Coding/C%2B%2B/#initialization","title":"Initialization","text":"<p>A braced initializer refers to placing the initial value of a variable in braces.  This is a novel style of initialization introduced in C++11.  Its main advantage is that it will raise a compile-time error if the compiler has to perform a narrowing conversion of the value to match the declared type. <pre><code>int apples {15};\n</code></pre></p> <p>Older but equally valid ways of initializing variables: <pre><code>int oranges = 12;\nint kiwis(13); // \"functional notation\"\n</code></pre> Zero initialization refers to initializing a variable with empty braces. It works for any fundamental type, and numeric types initialize to zero. <pre><code>int grapes {}; // 0\n</code></pre></p> <p>Sequences, like this array class can be efficiently zero-initialized; the braces can contain any number of values up to the declared size of the array (remaining values will be zero-initialized). <pre><code>#include &lt;array&gt;\n\narray&lt;int, 5&gt; myIntArray{};\n</code></pre> Multi-dimensional arrays can be initialized with nested initializers: <pre><code>int myNums[2][3] {\n{1, 2, 3},\n{4, 5, 6}\n};\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#pointers","title":"Pointers","text":"<p>Smart pointers (also called managed pointers) are pointers that manage their own memory. They were introduced in C++11, and there is no longer a reason to use the earlier raw pointers. In older versions of C++, memory leaks were common because the programmer had to remember to release memory allocated dynamically from the heap/free store using the <code>delete</code> keyword. These older pointers are now called raw pointers</p> <p>The most commonly used smart pointer is <code>unique_ptr</code>: others include <code>shared_ptr</code> and <code>weak_ptr</code>.</p> <p>Only a single <code>unique_ptr&lt;T&gt;</code> can point to any memory address, unless ownership is transfered with <code>move()</code>. Since C++14, it is recommended to create unique pointers using <code>makeunique&lt;T&gt;()</code>. <pre><code>auto pdbl = make_unique&lt;dbouble&gt;();\n</code></pre></p> <p>When variables are declared with an asterisk <code>*</code> appended to the datatype or prepended to the identifier, the variable becomes a pointer to that type.  Pointer identifiers usually begin with \"p\", a convention known as Hungarian notation.  The size of pointers corresponds to the address space of available memory (4 bytes for 32-bit architectures, and 8 bytes for 64-bit). <pre><code>// The following statements are equivalent.\nlong* pnum {}; long *pnum {nullptr};\n</code></pre> <code>void *</code> is known as \"pointer to void type\", meaning variables defined as such are pointers to data of an unspecified type, making it similar to <code>var</code> in C#.</p> <p>The address-of operator <code>&amp;</code> obtains the address of a variable. The address-of operator typically also occurs with the indirection operator or dereference operator (also <code>*</code>) to access the data pointed to by a pointer. Using a dereferenced pointer is the same as using the variable to which it points. <pre><code>long num {12345L};\nlong* pnum {&amp;num};\nlong newnum {*pnum + 1};\n</code></pre> When a pointer points to an object with methods, like a <code>vector&lt;T&gt;</code>  container , the indirect member selection operator (<code>-&gt;</code>) can be used to access the methods. <pre><code>// The following statements are equivalent.\nauto* pdata {new std::vector&lt;int&gt;{}};\n\nstd::vector&lt;int&gt; data;\nauto* pdata = &amp;data;\n\n// The following statements are equivalent.\n(*pdata).push_back(66);\npdata-&gt;push_back(66);\n</code></pre></p> <p>Pointers to classes can be recast with the following syntax: <pre><code>Animal* ptr = &amp;kitty;\n((Cat*)ptr)-&gt;chaseMouse();\n\n// newer, safer syntax\n(reinterpret_cast&lt;Cat&gt;(ptr))-&gt;chaseMouse();\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#containers","title":"Containers","text":"<p>Containers are a type of data structure used to contain elements for various purposes. They are deeply tied to algorithms through iterators.</p> <p>Two array-like data structures defined in the Standard Library that are more typically used are <code>array&lt;T,N&gt;</code> and <code>vector&lt;T&gt;</code></p>"},{"location":"Coding/C%2B%2B/#arrays","title":"Arrays","text":"<p>An array is a variable that represents a contiguous sequence of memory locations, each storing an item of data of the same data type, each of which are called elements. Arrays must be declared with a constant integer expression that is fixed at compile time. Built-in arrays in C++ are inherited from C. </p> <pre><code>int primes[10] {1, 2, 3, 5, 7, 11, 13, 17, 19, 23}\n</code></pre>"},{"location":"Coding/C%2B%2B/#sequence-containers","title":"Sequence containers","text":"<p>The two most common sequence containers are <code>array&lt;T,N&gt;</code> and <code>vector&lt;T&gt;</code>. </p> <p>All sequence containers expose several of a family of related member functions:</p> Member function vector array list forward_list deque <code>front()</code> \u2705 \u2705 \u2705 \u2705 \u2705 <code>back()</code> \u2705 \u2705 \u2705 \u274c \u2705 <code>push_front()</code> \u274c \u274c \u2705 \u2705 \u2705 <code>pop_front()</code> \u274c \u274c \u2705 \u2705 \u2705 <code>push_back()</code> \u2705 \u274c \u2705 \u274c \u2705 <code>pop_back()</code> \u2705 \u274c \u2705 \u274c \u2705 <code>insert()</code> \u2705 \u274c \u2705 \u2705 \u2705 <code>erase()</code> \u2705 \u274c \u2705 \u2705 \u2705 <p><code>array&lt;T,N&gt;</code> (also \"array class\") is a fixed sequence defined with two template parameters to create an array of <code>N</code> elements of type <code>T</code>. Here it is zero initialized with an empty braced initializer. <pre><code>#include &lt;array&gt;\n\narray&lt;int, 5&gt; myIntArray{};\n</code></pre> Other methods: - <code>fill()</code>: Set every element of the array to the same value - <code>size()</code>: Return the number of elements as a type <code>size_t</code> - <code>at()</code>: Access an element at a given index but testing for a valid range. Safer than using the built-in index method.</p> <p>Vectors are sequential containers with typed elements like the array class, but are not limited to fixed sizes. The <code>push_back()</code> method is similar to a Python <code>List.append()</code>. Other methods like <code>front()</code>, <code>back()</code>, and <code>pop_back()</code> can be used to manipulate the vector.  <pre><code>#include &lt;vector&gt;\nvector&lt;int&gt; vals;\n</code></pre> The <code>insert()</code> method takes two arguments, one is an iterator, here provided by yet another vector method - <code>begin()</code>, and the content to be inserted. This code will insert the string at index 2. <pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main() {\nvector&lt;string&gt; family;\nfamily.push_back(\"Plato\");\nfamily.push_back(\"Aristotle\");\nfamily.push_back(\"Socrates\");\nfamily.push_back(\"Pythagoras\");\nfamily.push_back(\"Aristarchos\");\n\nfamily.insert(family.begin() + 2, \"Dgiapusccu\");\nfamily.pop_back();\nfor (string i : family) {\ncout &lt;&lt; i &lt;&lt; endl;\n}\n\nreturn 0;\n}\n</code></pre></p> <p>A <code>forward_list&lt;T&gt;</code> is an implementation of the singly-linked list and is rarely used.</p> <p>A <code>list&lt;T&gt;</code> is an implementation of the doubly-linked list and is rarely used.</p> <p>The double-ended queue (deque) exposes <code>push_Front()</code> and <code>push_back()</code> methods.</p>"},{"location":"Coding/C%2B%2B/#container-adapters","title":"Container adapters","text":"<p>A <code>stack&lt;T&gt;</code> implements last-in first-out (LIFO) semantics.</p> <p>Stacks support <code>push</code> and <code>pop</code> methods.</p> <p>A <code>queue&lt;T&gt;</code> implements first-in first-out (FIFO) semantics.</p>"},{"location":"Coding/C%2B%2B/#associate-containers","title":"Associate containers","text":""},{"location":"Coding/C%2B%2B/#standard-iterators","title":"Standard iterators","text":"<p>There are three types of iterator supported by containers in the Standard Library: - random access iterator support the widest variety of operations: <code>vector&lt;T&gt;</code>, <code>array&lt;T,N&gt;</code>, and <code>deque&lt;T&gt;</code> - forward iterators do not support decrement operations (\"going backwards\"), and this describes the operation of a <code>forward_list&lt;T&gt;</code> - bidirectional iterators support both increment and decrement operations, but cannot jump more than one value, describing the operation of a <code>list&lt;T&gt;</code></p> <p><code>stack&lt;T&gt;</code>, <code>queue&lt;T&gt;</code>, and <code>priority_queue&lt;T&gt;</code> do not have iterators whatsoever.</p> <p>Containers in the Standard Library expose a <code>begin()</code> member function, which is the most commonly used iterator. <pre><code>std::vector&lt;char&gt; letters{'a','b','c','d','e'}\nauto iter{letters.begin()};\n\n// Specifying type explicitly\nstd::vector::iterator iter{letters.begin()};\n</code></pre> At a deep level, iterators are pointers, so dereferencing them produces the element of the container being iterated. <pre><code>std::cout &lt;&lt; *iter &lt;&lt; std:: endl; // a\n</code></pre> The container can now be traversed by incrementing and (sometimes) decrementing the iterator. <pre><code>++iter;\nstd::cout &lt;&lt; *iter &lt;&lt; std:: endl; // b\n</code></pre></p> <p>A string can be reversed using the <code>rbegin()</code> and <code>rend()</code> iterators: <pre><code>string name{\"Lorem ipsum...\"};\nstring reverse(name.rbegin(), name.rend());\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#maps","title":"Maps","text":"<p>A syntactic sugar has been available since C++17: <pre><code>for ([x, y] : coords)\n{\nstd::cout &lt;&lt; x &lt;&lt; y &lt;&lt; endl;\n}\n</code></pre> It is equivalent to: <pre><code>for (std::pair&lt;int, int&gt; el : coords)\n{\nstd::cout &lt;&lt; el.first &lt;&lt; el.second &lt;&lt; endl;\n}\n</code></pre> The <code>pair</code> type has two public fields:</p> <ul> <li><code>first</code></li> <li><code>second</code>## Math</li> </ul> <pre><code>#include &lt;math.h&gt;\nusing namespace std;\n\nint main() {\nint num{2};\ncout &lt;&lt; pow(num,2) &lt;&lt; endl;\n}\n</code></pre>"},{"location":"Coding/C%2B%2B/#classes","title":"Classes","text":"<p>New data types in C++ are created as classes, which can be composites of member variables of other types and member functions, allowing complex and intuitive models to be created.</p> <p>The three primary principles of OOP are:</p> <ul> <li>Encapsulation: member variables and functions are packaged together<ul> <li>Data hiding preserves the integrity of an object</li> </ul> </li> <li>Inheritance allows one type to define another.</li> <li>Polymorphism (in C++ implemented by calling member functions using a pointer or reference) allow behavior of base classes to be exposed from objects of derived classes</li> </ul>"},{"location":"Coding/C%2B%2B/#member-variables","title":"Member variables","text":"<p>Classes can contain member variables that are <code>public</code> or <code>private</code> (\"access specifiers\"), but it is best practice to make variables private while implementing accessor functions (getters and setters): - Hiding data preserves the integrity of objects - Loose coupling facilitates future change in codebase - Extra code can be injected for logging or data validation - Debuggers can set breakpoints on these getters and setters  <pre><code>class Box\n{\nprivate:\ndouble length {1,0};\ndouble width {1,0};\ndouble height {1,0};\npublic:\ndouble volume()\n{\nreturn length * width * height;\n}\n};\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#initialization_1","title":"Initialization","text":"<p>A member initializer list can be used to initialize fields more efficiently than explicit assignment.  <pre><code>Box::Box(double lv, double wv, double hv) : length {lv}, width {wv}, height {hv} {}\n</code></pre> This technique must have an expression in braces, even if they are empty. <pre><code>// Compiler error\nBox::Box(double lv, double wv, double hv) : length {lv}, width {wv}, height {hv} </code></pre> Notably, this technique doesn't appear to work in derived class constructors. <pre><code>class Animal {\npublic:\nstd::string _name{};\nAnimal(std::string n) : _name {n} {}\n}\n\nclass Dog : public Animal\n{\npublic:\nDog(std::string n, std::string b) : Animal(n) {_breed = b;};\n}\n</code></pre></p> <p>A class constructor is called whenever a new instance of the class is defined. It always has the same name as the class itself and has no return data type because it returns no data. <pre><code>class Box\n{\nprivate:\n// ...\npublic:\nBox( double l, double w, double h)\n{\nlength = l;\nwidth = w;\nheight = h;\n}\n};\n</code></pre></p> <p>If a constructor isn't defined, the compiler will supply a default default constructor when an object is instantiated without initial values. To define a default constructor: <pre><code>Box() = default;\n</code></pre></p> <p>A destructor is a special member of a class executed to deal with cleanup upon use of the <code>delete</code> operator. A class can have only one destructor, and if one isn't defined then the compiler provides a default destructor that does nothing. The name of the destructor for a class is always the class name prefixed with a tilde, and similar to a constructor it cannot have a return type or parameters. <pre><code>~Box() = default;\nBox::~Box() = default; // when defined outside the class\n</code></pre></p> <p>Base class destructors should always be declared as <code>virtual</code>.</p>"},{"location":"Coding/C%2B%2B/#access","title":"Access","text":"<p>When variables of class types are instantiated with the <code>const</code> keyword, they are called const objects, and none of their member variables can be altered (member variables of const objects become immutable). The compiler will throw an error when attempting to invoke methods of const objects unless they are identified as const member functions by using the <code>const</code> keyword in the signature after the identifier (\"attribute\"?): <pre><code>class Box {\ndouble volume () const { /* ... */ }\ndouble getLength() const { return length; }\ndouble getWidth() const { return width; }\ndouble getHeight() const { return height; }\n}\n</code></pre></p> <p><code>public</code>, <code>private</code>, and <code>protected</code> are access specifiers that determine how a member variables and functions can be accessed from the outside. When inheriting from a base class, an access specifier can also be used to determine how accessible that base class's members are within the derived class. <pre><code>class Dog : public Animal {\n// ...\n}\n</code></pre> - When the base class specifier is <code>public</code>, inherited members are unchanged - When the base class specifier is <code>protected</code>, inherited public and protected members become protected - When the base class specifier is private, all inherited members become private.</p> <p>A friend is a function to which a class grants access to its private internals. They may be useful in rare situations where a single function needs access to the internals of different kinds of objects.</p>"},{"location":"Coding/C%2B%2B/#inheritance","title":"Inheritance","text":"<p>When creating subclasses, you must remember: - Private variables must be placed in the <code>protected</code> access specifier so that they are accessible to child classes. - The base class access specifier must allow access to the base class's private variables (<code>public</code> or <code>protected</code>) - Parent class must have a default constructor <pre><code>class Animal {\nprotected: // not `private:`!\nstd::string _name;\npublic:\nAnimal() = default;\n}\nclass Dog : public Animal { /* ... */ } // \n</code></pre></p>"},{"location":"Coding/C%2B%2B/#polymorphism","title":"Polymorphism","text":"<p>Polymorphism in C++ refers to the practice of invoking a base class's member function rather than the derived class. </p> <p>Because the compiler performs early binding by default, a pointer typed to a base class but initialized to a derived class will invoke the base class's member function. Late binding can be used to force the pointer to use the derived class's member function even when the type of the pointer is the base class. This is done by using the <code>virtual</code> keyword on the base class's member function. </p> <p>Classes with virtual functions are called abstract classes and may not be instantiated. Abstract classes that are made of only virtual functions are called interfaces. <pre><code>class Base {\npublic:\nvirtual void doStuff() { /* ... */ }\n}\n\nclass Derived : public Base\n{\npublic:\nvoid doStuff() { /* ... */ }\n}\n\nint main() {\nDerived derived{};\nBase* pointer = &amp;derived; // a pointer to an abstract class **may** be used\npointer-&gt;doStuff();\n}\n</code></pre> Derived classes must then override this virtual function with the <code>override</code> keyword.  <pre><code>class Derived : public Base {\noverride doStuff() // ...\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#enumerations","title":"Enumerations","text":"<p>Enumerations can be specified with <code>enum</code>. Without specifying a value, each element of the enum is given a successively greater integer value starting with 0, like the indexes of an array (an ordinal value). <pre><code>enum Choices {A, B, C, D }\n</code></pre> These elements can be specified with or without the scope resolution operator <code>::</code> <pre><code>cout &lt;&lt; A;          // 0\ncout &lt;&lt; Choices::A; // 0\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#templates","title":"Templates","text":"<p>Templates are used to have the compiler generate code automatically for a given data type. This is to avoid highly repetitive overloaded function definitions which only differ in parameter lists. </p> <p>The <code>template</code> and <code>typename</code> keywords define a template. The placeholder \"T\" represents the data type that will be replaced by a specific type by the compiler. <pre><code>template &lt;typename T&gt; T larger (T a, T b) {\nreturn a&gt;b ? a : b;\n}\n</code></pre> More than one data type can be used for the parameters, but in that case the return type must be explicitly specified: <pre><code>template &lt;typename T1, typename T2&gt; bool larger (T1 a, T2 b) {\nreturn a&gt;b;\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#control-flow","title":"Control flow","text":"<p>The choices in a <code>switch</code> statement are called cases. You can only switch on constant expressions that can be evaluated at compile-time, typically literals but excluding strings. Each case must be followed by a <code>break</code> statement to prevent fallthrough, except for the default case. <pre><code>switch (choice)\n{\ncase 1:\n// ...\nbreak;\ncase 2:\n// ...\nbreak;\ndefault:\n// ...\n}\n</code></pre></p> <p>Since C++11, the range-based for-loop is available, which works very similar to a Python for-in loop: <pre><code>for (string num : nums)\n{\ncout &lt;&lt; num &lt;&lt; endl;\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#functions","title":"Functions","text":"<p>Function prototypes, defining the function header (return data type, function name, and parameter list), describe a function sufficiently for the compiler to be able to compile calls to it and are required before using a function if the function declaration doesn't precede all the locations where it's called. <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\n// Without this prototype, there is a  compile-time error.\nvoid printSomething();\n\nint main() {\nprintSomething();\nreturn 0;\n}\n\nvoid printSomething()\n{\ncout &lt;&lt; \"something...\" &lt;&lt; endl;\n}\n</code></pre> Passing by reference allows variables to be changed in-place and works by using the reference to the argument. Passing by value is the default parameter passing scheme, which works by actually copying the argument. <pre><code>int func(int a) {\n// Pass by value\n}\nint func(int &amp;a) {\n// Pass by reference\n}\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#recursion","title":"Recursion","text":"<p>Recursion requires a base case and at least one recursive case. The call stack is a stack data structure that figures prominently in recursive computing.## Home</p> Project Description JamoftheMonthProject.cpp CLI application that calculates how much the user owes based on selected subscription tier and units purchased TicTacToe.cpp RPGCharGen.cpp Multiple classes using inheritance, virtual member functions, enums Task Description Reverse a string ...## Iterators <p>An iterator is a classical and widespread design pattern that allows a wide variety of container-like objects to be traversed by exposing a uniform interface.</p> <p>However, loops based on iterators should only be used if access to the iterator is needed for advanced processing in the loop body. A range-based for loop is the recommended way to iterate over all elements of a container.</p> <ul> <li>Standard iterators</li> <li><code>begin()</code></li> <li><code>end()</code></li> <li><code>rbegin()</code></li> </ul>"},{"location":"Coding/C%2B%2B/#memory","title":"Memory","text":"<p>Memory leaks can be detected using valgrind.</p>"},{"location":"Coding/C%2B%2B/#namespaces","title":"Namespaces","text":"<p>A namespace is a block that attaches an extra name to every entity name that is declared or defined within it. The qualified name of each entity is the namespace name followed by the scope resolution operator <code>::</code> followed by the basic entity name. Namespaces can be used to partition large codebases into logical groupings to avoid name clashes. If a namespace isn't defined, the global namespace, where entities have no namespace name attached, applies by default.</p> <p>You can define a namespace using the <code>namespace</code> keyword. <pre><code>namespace foo {\n// ...\n}\n</code></pre> Namespaces can be nested.. <pre><code>namespace outer {\nnamespace inner {\nvoid foo() {\n// ...\n}\n}\n}\nouter::inner::foo()\n</code></pre> Namespace aliases can be formed: <pre><code>namespace outin = outer::inner;\noutin::foo()\n</code></pre></p> <p>The <code>using</code> keyword allows you to reference any name from a namespace without qualifying it. <pre><code>using namespace std;\n</code></pre> It can also be used specify a type alias, where an alternative name is used to refer to an existing data type. <pre><code>using BigOnes = unsigned long long;\ntypedef unsigned long long BigOnes; // Older, less intuitive syntax\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#operators","title":"Operators","text":"<p>Each operator is associated with a particular named function. Operators can be overloaded by implementing that function.</p> <pre><code>bool Rectangle::operator==(const Rectangle&amp; other) const\n{\nreturn _length == other._length &amp;&amp; _width == other._width;\n}\n</code></pre>"},{"location":"Coding/C%2B%2B/#header-files","title":"Header files","text":"Topic Header file array <code>&lt;array&gt;</code> deque <code>&lt;deque&gt;</code> exception <code>&lt;exception&gt;</code> map <code>&lt;map&gt;</code> Mathematical functions <code>&lt;math.h&gt;</code> queue <code>&lt;queue&gt;</code> stack <code>&lt;stack&gt;</code> vector <code>&lt;vector&gt;</code> Smart pointers <code>&lt;memory&gt;</code>"},{"location":"Coding/C%2B%2B/#applications","title":"Applications","text":""},{"location":"Coding/C%2B%2B/#gtkmm","title":"gtkmm","text":"<p>gtkmm (historically \"GTK--\") is a C++ wrapper for an underlying GTK code base written in C. Compared to Qt, another GUI library, gtkmm uses more modern and native C++ features.</p> <p>In Ubuntu, installing the development environment is done with the <code>gnome-devel</code> metapackage: <pre><code>sudo apt install gnome-devel\n</code></pre></p>"},{"location":"Coding/C%2B%2B/#nes-emulator","title":"NES emulator","text":""},{"location":"Coding/C%2B%2B/#courses","title":"Courses","text":""},{"location":"Coding/C%2B%2B/#c-standard-template-library-in-practice","title":"C++ Standard Template Library in Practice","text":"/# Topic Video Projects 01.01 The Course Overview 01.02 Templates Introduction to the STL TemplateSTL.cpp 01.03 General Concepts ExceptionSTL.cpp 01.04 Utilities - Common Utilities StringSTL.cpp 01.05 Utilities - Regex RegexSTL.cpp 01.06 Project - Bitcoin Exchange Program BTCX.cpp 01.07 Project - Coding 01.08 Project - Custom Writer Function 01.09 Review 02.01 Understanding Containers 02.02 Vectors 02.03 Standard Array 02.04 Lists 02.05 Stacks and Queues 02.06 Maps and Multimaps - Overview 02.07 Maps - Coding 02.08 Multimaps - Coding 02.09 Sets and Multisets 02.10 Project 02.11 Review 03.01 Iterators 03.02 Input Iterators 03.03 Output Iterators 03.04 Forward Iterators 03.05 Bidirectional Iterators 03.06 Random Access Iterators 03.07 Auxiliary Iterator Functions 03.08 Iterator Adaptors 03.09 Writing Generic Functions for Iterators 03.10 User - Defined Iterators 03.11 Project 03.12 Review 04.01 Introduction to Algorithms 04.02 Sequence Algorithms - for_each 04.03 Sequence Algorithms - equals 04.04 Copying 04.05 Moving 04.06 Removing 04.07 Sorting and Gathering - std::sort 04.08 Sorting and Gathering - std::partial_sort algorithm 04.09 Sorting and Gathering - std::partition 04.10 Sorting and Gathering - std::partition_copy 04.11 Searching and Finding - std::find 04.12 Sorting and Gathering - std::find_first_of, std::adjacent_find 04.13 Sorting and Gathering - std::search 04.14 Sorting and Gathering - std::binary_search 04.15 Counting 05.01 Replacing and Transforming - std::replace 05.02 Replacing and Transforming - std::replace_copy 05.03 Replacing and Transforming - equals 05.04 Swapping 05.05 Rotating 05.06 Randomizing 05.07 Permutations 05.08 Sampling 05.09 Min 05.10 Max 05.11 Clamp 05.12 Fill and Generate 05.13 Numeric Algorithms - std::accumulate 05.14 Numeric Algorithms - std::partial_sum and std::adjacent_difference 05.15 Numeric Algorithms - std::gcd, and std::lcm 05.16 Numeric Algorithms - std::inner_product and std::iota 05.17 Review 06.01 Basic Architecture of the I/O Stream Library 06.02 Console I/O - Interact with a User 06.03 Console I/O - Read Input 06.04 File I/O 06.05 String Streams 06.06 Manipulators and Formatters 06.07 Stream States 06.08 Low Level I/O 06.09 Overloading Stream Operators 06.10 Project - Overview 06.11 Project - Classes and structures 06.12 Project - Implementation 06.13 Review 07.01 Unique Pointers 07.02 Shared Pointers 07.03 Allocators 07.04 Defining an Allocator 07.05 Uninitialized Memory 07.06 Review 08.01 Introduction to Threading 08.02 Creating Threads 08.03 Locks 08.04 Shared Locks 08.05 Atomic Values 08.06 Async 08.07 Condition Variables 08.08 Project 08.09 Review 09.01 Concepts 09.02 Modules 09.03 Coroutines 09.04 Course Review"},{"location":"Coding/C%2B%2B/#complete-c-developer-course","title":"Complete C++ Developer Course","text":"/# Topic Video Projects 1.1 Section Overview 1.2 Getting Started on Windows with Visual Studio Integrated Development Environment (IDE) 1.3 Getting Started on macOS or Linux with CodeBlocks IDE 1.4 Getting Started with macOS Catalina or Higher with Visual Studio Code 1.5 Finding Answers to Your Questions 2.1 Section Overview 2.2 Saying \"Hello\" to C++ 2.3 Variables and Data Types - Part 1 2.4 Variables and Data Types - Part Two 2.5 Variables and Data Types - Part Three 2.6 Comments 2.7 Arithmetic Operators 2.8 Relational Operators 2.9 Logical Operators 2.10 Symbolic Constants and Naming Conventions 2.11 User Input 2.12 Project - Average of Three 2.13 Project - MadLibs Clone 2.14 Section Wrap-Up 3.1 Section Overview 3.2 Introduction to Control Statements 3.3 Selection Control Statements 3.4 Repetition Control Statements 3.5 The Break and Continue Statements 3.6 Random Numbers 3.7 Project - Jam of the Month Club 3.8 Project - Odds and Evens 3.9 Project - Guess the Number 3.10 Section Wrap-Up 4.1 Section Overview 4.2 Built-in Arrays 4.3 The Array Class 4.4 The Vector Class 4.5 Multi-Dimensional Arrays 4.6 Project - Array Data 4.7 Project - Vector Data 4.8 Project - Parallel Arrays/Vectors 4.9 Section Wrap-Up 5.1 Section Overview 5.2 Function Prototypes and Definitions FunctionFun.cpp 5.3 Function Return Types and Parameters 5.4 Parameter Passing: Pass-by-Value and Pass-by-Reference PassingSchemes.cpp 5.5 Variable Scope and Lifetime ScopeFun 5.6 Function Overloading 5.7 The    &lt;cmath&gt; Library 5.8 Recursion 5.9 Project - Return the Product of Three Parameters 5.10 Project - Return the Sum of Built-in Array Elements 5.11 Project - Return the Sum of Array Object Elements 5.12 Project - Retrieve the Sum of Array Object Elements by Reference 5.13 Project - Tic-Tac-Toe (ADVANCED) 5.14 Section Wrap-Up 6.1 Section Overview 6.2 Basics of Object Oriented Programming (OOP) 6.3 Encapsulation: Data Members and Member Functions 6.4 Separate Compilation 6.5 Constructors and Destructors 6.6 A Rectangle Class Rectangle.cpp 6.7 A Book Class 6.8 Project - A Bank Account Class 6.9 Project - A Pizza Class 6.10 Project - A Circle Class 6.11 Section Wrap-Up 7.1 Section Overview 7.2 Exceptions and the Exception Hierarchy 7.3 Logic Errors 7.4 Runtime Errors and Throwing Exceptions 7.5 Rethrowing Exceptions 7.6 Custom Exceptions 7.7 Basic Testing and Debugging 7.8 Project - Throwing and Handling an Out_of_Range Exception 7.9 Project - Creating and Using Your Own Exception 7.10 Section Wrap-Up 8.1 Section Overview 8.2 Introduction to Pointers 8.3 Dynamic Memory - Part 1 8.4 Dynamic Memory (- Part 2 8.5 Const Correctness 8.6 Project - Dynamically Creating Rectangles 8.7 Project - Dynamically Creating Circles 8.8 Section Wrap-Up 9.1 Section Overview 9.2 Sequential File Output 9.3 Sequential File Input 9.4 More File Input/ Output (I/O) 9.5 Project - Reading Data from File and Printing Statistics 9.6 Project - Dynamically Creating Rectangles from File 9.7 Project - Shopping Item File 9.8 Section Wrap-Up 10.1 Section Overview 10.2 Inheritance - Part 1 10.3 Inheritance - Part 2) 10.4 Polymorphism and Late Binding 10.5 Enumerated Types This video explains enumerated types. EnumFun.cpp 10.6 Project - Derived Cat Class Cat.cpp 10.7 Project \u2013 Role Playing Game (RPG) Player Character Creation RPGCharGen 10.8 Section Wrap-Up 11.1 Section Overview 11.2 Templates - Standard Template Library (STL) TemplateFun.cpp 11.3 <code>queue&lt;T&gt;</code> <code>stack&lt;T&gt;</code> <code>deque&lt;T&gt;</code> Standard Template Library (STL) - Part 1) DequeFun.cpp, StackFun.cpp, QueueProject.cpp 11.4 <code>map&lt;T&gt;</code> Standard Template Library (STL) - Part 2 ContactsFun.cpp, AlgorithmFun.cpp 11.5 <code>unique_ptr&lt;T&gt;</code> Smart Pointers SmartPointerFun.cpp, Car.cpp 11.6 Friend functions Friend Functions and Friend Classes FriendFunctions.cpp 11.7 Operator Overloading OverloadingFun.cpp, Rectangle.h 11.8 <code>map&lt;T&gt;</code> Project - Dictionary of Terms DictionaryProject.cpp 11.9 Project - Aliens Aliens.cpp 11.10 Section Wrap-Up"},{"location":"Coding/C%2B%2B/#rpgchargen","title":"RPGCharGen","text":"cpph <pre><code>#include &lt;iostream&gt;\n#include \"RPGCharGen.h\"\nusing namespace std;\n\nint main() {\n\nWarrior w{\"Doofus McGroober\", Race::HUMAN};\ncout &lt;&lt; \"Player name: \" &lt;&lt; w.getName() &lt;&lt; endl;\ncout &lt;&lt; \"Player HP:   \" &lt;&lt; w.getHp() &lt;&lt; endl;\ncout &lt;&lt; \"Player MP:   \" &lt;&lt; w.getMp() &lt;&lt; endl;\ncout &lt;&lt; \"Player race: \" &lt;&lt; w.getRace() &lt;&lt; endl;\nw.attack();\n\nPriest m{\"Brother Tolkien\", Race::ELF};\ncout &lt;&lt; \"Player name: \" &lt;&lt; m.getName() &lt;&lt; endl;\ncout &lt;&lt; \"Player HP:   \" &lt;&lt; m.getHp() &lt;&lt; endl;\ncout &lt;&lt; \"Player MP:   \" &lt;&lt; m.getMp() &lt;&lt; endl;\ncout &lt;&lt; \"Player race: \" &lt;&lt; m.getRace() &lt;&lt; endl;\nm.attack();\n\nMage n{\"Smart Frodo\", Race::DWARF};\ncout &lt;&lt; \"Player name: \" &lt;&lt; n.getName() &lt;&lt; endl;\ncout &lt;&lt; \"Player HP:   \" &lt;&lt; n.getHp() &lt;&lt; endl;\ncout &lt;&lt; \"Player MP:   \" &lt;&lt; n.getMp() &lt;&lt; endl;\ncout &lt;&lt; \"Player race: \" &lt;&lt; n.getRace() &lt;&lt; endl;\nn.attack();\nreturn 0;\n}\n</code></pre> <pre><code>#if !defined(RPGCHARGEN_H)\n#define RPGCHARGEN_H\n#include &lt;string&gt;\n\nenum Race { HUMAN, ELF, DWARF };\n\nclass Player {\n\nprotected:\nstd::string _name{ \"Johnny Bravo\" };\nRace _race{Race::HUMAN };\nint _hp{ 100 };\nint _mp{ 100 };\n\npublic:\nPlayer(std::string n, Race r, int hp, int mp) : _name{n}, _race{r}, _hp(hp), _mp(mp) {}\nvirtual std::string attack()= 0;\nint getHp()                 { return _hp;   }\nint getMp()                 { return _mp;   }\n\nstd::string getRace()              {\nswitch (_race)\n{\ncase 0:\nreturn \"human\";\nbreak;\n\ncase 1:\nreturn \"elf\";\nbreak;\ncase 2:\nreturn \"dwarf\";\nbreak;\n\ndefault:\nreturn \"none\";\nbreak;\n}\n}\nstd::string getName()       { return _name; }\nvoid setHp(int n)           { _hp = n;   }\nvoid setMp(int n)           { _mp = n;   }\nvoid setName(std::string s) { _name = s; }\nvoid setRace(Race r)        { _race = r;}\n};\n\nclass Warrior : public Player {\npublic:\nWarrior(std::string n, Race r) : Player(n, r, 200, 0) {}\nstd::string attack() {return \"I will destroy you with my sword, foul demon!\";}\n};\n\nclass Priest : public Player {\npublic:\nPriest(std::string n, Race r) : Player(n, r, 100, 200) {}\nstd::string attack() {return \"Taste the wrath of the Two True Gods!\";}\n};\n\nclass Mage : public Player {\npublic:\nMage(std::string n, Race r) : Player(n, r, 150, 150) {}\nstd::string attack() {return \"You are overmatched by my esoteric artifices!\";}\n};\n\n#endif // RPGCHARGEN_H\n</code></pre>"},{"location":"Coding/C/","title":"C","text":""},{"location":"Coding/C/#linux","title":"Linux","text":""},{"location":"Coding/C/#compiling","title":"Compiling","text":""},{"location":"Coding/C/#pkg-config","title":"pkg-config","text":"<p>Compiling a GTK program written in C</p> <pre><code>gcc -Wall -g helloworld.c -o helloworld \\\n$(pkg-config --cflags gtk+-3.0)     \\ // (1)\n$(pkg-config --libs gtk+-3.0)         // (2)\n</code></pre> <ol> <li>pkg-config returns directory names, which gcc will use tto ensure all header files are available.</li> <li>Here, pkg-config appends options to eh command-line used by the linker including library directory path extensions and a list of libraries needed for linking to the executable.</li> </ol>"},{"location":"Coding/C/#syscalls","title":"Syscalls","text":"<p>The open(), close(), read(), and write() syscalls form the heart of low-level file I/O in Linux.</p> <p>Some system calls accept flag arguments, specified using symbolic constants. Some of these are single-bit values which are combined into a single value using the bitwise OR operator |.</p>"},{"location":"Coding/C/#close","title":"close","text":"<pre><code>close(fd);\n</code></pre> <pre><code>#include &lt;fcntl.h&gt;\n#include &lt;stdlib.h&gt;\n#define BSIZE 16384\n\nvoid main()\n{\nint fin, fout;\nchar buf[BSIZE];\nint count;\n\nif ((fin = open(\"foo\", O_RDONLY)) &lt; 0) {\nperror(\"foo\");\nexit(1);\n}\nif ((fout = open(\"bar\", O_WRONLY | O_CREAT, 0644)) &lt; 0) {\nperror(\"bar\");\nexit(2);\n}\nwhile ((count = read(fin, buf, BSIZE)) &gt; 0)\nwrite(fout, buf, count);\n\nclose(fin);\nclose(fout);\n}\n</code></pre>"},{"location":"Coding/C/#exec","title":"exec","text":"<p>There are seven variations of exec(), all of which are used to replace the current process with the contents of another thread.</p> <p>These variations are distinguished by how they pass arguments (list or vector), whether or not they create a new environment (e), and whether they require a full pathname or must search on the path environment variable (p). For example, execvpe specifies an executable on the path, creates a new environment, and passes arguments in a vector.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;stdlib.h&gt;\n\nmain()\n{\nchar line[100];\n\nwhile (printf(\"&gt; \"), gets(line) != NULL) {\nif (fork() == 0) {\nexeclp(line, line, (char *)0);\nprintf(\"%s: not found\\n\", line);\nexit(1);\n} else wait(0);\n}\n}\n</code></pre>"},{"location":"Coding/C/#exit","title":"exit","text":"exit() ends the program, returning the integer provided in parentheses as the exit status of the process."},{"location":"Coding/C/#fork","title":"fork","text":"<p>fork() is used to create a new process and is typically associated with exec() and wait().</p> <p>This simple example shows how the value returned by the fork() call differs between the parent and child processes. <pre><code>#include &lt;stdio.h&gt;\n\nvoid main() {\nif (fork()) // i.e. anything but 0\nprintf(\"I am the parent\\n\");\nelse printf(\"I am the child\\n\");\n}\n</code></pre></p> <pre><code>#include &lt;sys/types.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\npid_t pid;\n\npid = fork();\nif (pid &lt; 0) {\nfprintf(stderr, \"Fork Failed\");\nreturn 1;\n} else if (pid == 0) {\nexeclp(\"/bin/ls\",\"ls\",NULL);\n} else {\nwait(NULL);\nprintf(\"Child complete\");\n}\n\nreturn 0;\n}\n</code></pre>"},{"location":"Coding/C/#ftruncate","title":"ftruncate","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;sys/shm.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/mman.h&gt;\n\nint main() {\nconst int SIZE = 4096;              // size of shared memory object (bytes)\nconst char *name = \"OS\";            // name of shared memory object\nconst char *message_0 = \"Hello\";\nconst char *message_1 = \"World!\";\n\nint fd;     // shared memory file descriptor\nchar *ptr;  // pointer to shared memory object\n\n// create the shared memory object\nfd = shm_open(name, O_CREAT | O_RDWR, 0666); // configure size of the shared memory object\nftruncate(fd, SIZE);    // memory map the shared memory object\nptr = (char *) mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n\n// write to shared memory object\nsprintf(ptr, \"%s\", message_0);\nptr += strlen(message_0);\nsprintf(ptr, \"%s\", message_1);\nptr += strlen(message_1);\n\nreturn 0;\n}\n</code></pre>"},{"location":"Coding/C/#getpid","title":"getpid","text":"<pre><code>#include &lt;unistd.h&gt;\n\ngetpid();\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main()\n{\nint status;\nif (fork()) {\nprintf(\"parent waiting for child ... \\n\");\nwait(&amp;status);\nif (WIFEXITED(status))\nprintf(\"child ended normally, exit status = %d\\n\", WEXITSTATUS(status));\nif (WIFSIGNALED(status))\nprintf(\"child terminated by signal %d\\n\", WTERMSIG(status));\n} else {\nprintf(\"child running -- PID is %d\\n\", getpid());\nsleep(50);\nexit(3);\n}\n}\n</code></pre>"},{"location":"Coding/C/#getrandom","title":"getrandom","text":"Introduced in Linux 3.17 to allow userspace applications to request random numbers in the case of no access to random devices (i.e. containers). By default it will use the /dev/urandom pool, which normally does not block.  A flag can be provided to use the /dev/random pool instead."},{"location":"Coding/C/#lseek","title":"lseek","text":"<p>Repositions the file read/write offset, allowing random access to an open file descriptor. <pre><code>#include &lt;unistd.h&gt;\n\nlseek(\nfd, offset, // (1)\nwhence  // (2)\n);\n</code></pre></p> <ol> <li>Byte offset, positive or negative (usually negative when with respect to end-of file using SEEK_END flag).</li> <li>Accepts one of several flags that determine where the offset is relative to: SEEK_SET (beginning of file), SEEK_CUR (current position), or SEEK_END (end of file).</li> </ol> <pre><code>--8&lt;-- </code></pre>"},{"location":"Coding/C/#malloc","title":"malloc","text":""},{"location":"Coding/C/#memcpy","title":"memcpy","text":"<p>Used for copying stack-allocated data.</p> <pre><code>memcpy(\ndst,  //\nsize, //\nflags //\n);\n</code></pre>"},{"location":"Coding/C/#mmap","title":"mmap","text":"<p>Maps a file into memory, allowing it to be accessed as if were an array. <pre><code>mmap(\naddr,   // (1)\nlength, // (2)\nprot,   // (3)\nflags,  // (4)\nfd,     // (5)\noffset  // (6)\n);  // (7)\n</code></pre></p> <ol> <li>Commonly set to NULL, allowing the kernel to choose the address.</li> <li>Length of the mapping</li> <li>Typically a combination of PROT_READ and/or PROT_WRITE</li> <li>Determines whether the mapped region is shared with other processes: MAP_SHARED or MAP_PRIVATE</li> <li>File descriptor from open()</li> <li>Multiple of page size, and often set to 0 to map the entire file</li> <li>Return value is the address to which the file has been mapped (similar to malloc())</li> </ol> IPC producerIPC consumer <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;sys/shm.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/mman.h&gt;\n\nint main() {\nconst int SIZE = 4096;              // size of shared memory object (bytes)\nconst char *name = \"OS\";            // name of shared memory object\nconst char *message_0 = \"Hello\";\nconst char *message_1 = \"World!\";\n\nint fd;     // shared memory file descriptor\nchar *ptr;  // pointer to shared memory object\n\n// create the shared memory object\nfd = shm_open(name, O_CREAT | O_RDWR, 0666); // configure size of the shared memory object\nftruncate(fd, SIZE);    // memory map the shared memory object\nptr = (char *) mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n// write to shared memory object\nsprintf(ptr, \"%s\", message_0);\nptr += strlen(message_0);\nsprintf(ptr, \"%s\", message_1);\nptr += strlen(message_1);\n\nreturn 0;\n}\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;sys/shm.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;sys/mman.h&gt;\n\nint main() {\nconst int SIZE = 4096;\nconst char *name = \"OS\";\nint fd;\nchar *ptr;\n\nfd = shm_open(name, O_RDONLY, 0666);\nptr = (char *) mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\nprintf(\"%s\", (char *)ptr);\n\nshm_unlink(name);\n\nreturn 0;\n}\n</code></pre>"},{"location":"Coding/C/#msync","title":"msync","text":""},{"location":"Coding/C/#open","title":"open","text":"<p>A call to open() creates a new open file descriptor</p> <pre><code>fd = open(\"foo\", O_RDWR   | // (1) \nO_TRUNC  | // (2) \nO_APPEND   // (3)\n);\n</code></pre> <ol> <li>Access mode flag specifying reading and writing: O_RDWR, O_RDONLY, or O_WRONLY.</li> <li>Open-time flag required for writing. However, calling ftruncate() is recommended over use of this flag in open(), which is retained for backwards compatibility.</li> <li>Operating mode flag that makes all write operations write data at the end of the file, extending it, regardless of the current file position.</li> </ol> <pre><code>#include &lt;fcntl.h&gt;\n#include &lt;stdlib.h&gt;\n#define BSIZE 16384\n\nvoid main()\n{\nint fin, fout;\nchar buf[BSIZE];\nint count;\n\nif ((fin = open(\"foo\", O_RDONLY)) &lt; 0) {\nperror(\"foo\");\nexit(1);\n}\nif ((fout = open(\"bar\", O_WRONLY | O_CREAT, 0644)) &lt; 0) {\nperror(\"bar\");\nexit(2);\n}\nwhile ((count = read(fin, buf, BSIZE)) &gt; 0)\nwrite(fout, buf, count);\n\nclose(fin);\nclose(fout);\n}\n</code></pre>"},{"location":"Coding/C/#read","title":"read","text":"<p>Like write(), calls to read() require require a pointer to the buffer as well as the count of bytes which must not exceed the buffer's actual size. read() will return the number of bytes actually read and 0 on end-of-file. <pre><code>read(fd, buffer, count);\n</code></pre></p> <pre><code>#include &lt;fcntl.h&gt;\n#include &lt;stdlib.h&gt;\n#define BSIZE 16384\n\nvoid main()\n{\nint fin, fout;\nchar buf[BSIZE];\nint count;\n\nif ((fin = open(\"foo\", O_RDONLY)) &lt; 0) {\nperror(\"foo\");\nexit(1);\n}\nif ((fout = open(\"bar\", O_WRONLY | O_CREAT, 0644)) &lt; 0) {\nperror(\"bar\");\nexit(2);\n}\nwhile ((count = read(fin, buf, BSIZE)) &gt; 0)\nwrite(fout, buf, count);\n\nclose(fin);\nclose(fout);\n}\n</code></pre>"},{"location":"Coding/C/#shm_open","title":"shm_open","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;sys/shm.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;string.h&gt;\n#include &lt;sys/mman.h&gt;\n\nint main() {\nconst int SIZE = 4096;              // size of shared memory object (bytes)\nconst char *name = \"OS\";            // name of shared memory object\nconst char *message_0 = \"Hello\";\nconst char *message_1 = \"World!\";\n\nint fd;     // shared memory file descriptor\nchar *ptr;  // pointer to shared memory object\n\n// create the shared memory object\nfd = shm_open(name, O_CREAT | O_RDWR, 0666); // configure size of the shared memory object\nftruncate(fd, SIZE);    // memory map the shared memory object\nptr = (char *) mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n\n// write to shared memory object\nsprintf(ptr, \"%s\", message_0);\nptr += strlen(message_0);\nsprintf(ptr, \"%s\", message_1);\nptr += strlen(message_1);\n\nreturn 0;\n}\n</code></pre>"},{"location":"Coding/C/#shm_unlink","title":"shm_unlink","text":"Removes the shared-memory segment after the consumer has accessed it. <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;sys/shm.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;sys/mman.h&gt;\n\nint main() {\nconst int SIZE = 4096;\nconst char *name = \"OS\";\nint fd;\nchar *ptr;\n\nfd = shm_open(name, O_RDONLY, 0666);\nptr = (char *) mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n\nprintf(\"%s\", (char *)ptr);\n\nshm_unlink(name);\nreturn 0;\n}\n</code></pre>"},{"location":"Coding/C/#wait","title":"wait","text":"<p>wait() blocks until one of the process's children terminates and returns an integer.</p> <pre><code>int status;\nwait(&amp;status); // (1)\n</code></pre> <ol> <li>Passing 0 or NULL will discard the child's exit status.</li> </ol> <p>The exit status is separted into upper and lower bytes. If the process was killed by a signal the top bit of the lower byte is called the \"Core Dumped\" flag. There are several macros used to analyze the exit status.</p> <ul> <li>WIFEXITED true if child exited normally</li> <li>WEXITSTATUS</li> <li>WIFSIGNALED true if child terminated by signal</li> <li>WTERMSIG signal number</li> </ul> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main()\n{\nint status;\nif (fork()) {\nprintf(\"parent waiting for child ... \\n\");\nwait(&amp;status);\nif (WIFEXITED(status))\nprintf(\"child ended normally, exit status = %d\\n\", WEXITSTATUS(status));\nif (WIFSIGNALED(status))\nprintf(\"child terminated by signal %d\\n\", WTERMSIG(status));\n} else {\nprintf(\"child running -- PID is %d\\n\", getpid());\nsleep(50);\nexit(3);\n}\n}\n</code></pre> <pre><code>#include &lt;sys/types.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\nint main() {\npid_t pid;\n\npid = fork();\n\nif (pid &lt; 0) {\nfprintf(stderr, \"Fork Failed\");\nreturn 1;\n} else if (pid == 0) {\nexeclp(\"/bin/ls\",\"ls\",NULL);\n} else {\nwait(NULL);\nprintf(\"Child complete\");\n}\n\nreturn 0;\n}\n</code></pre>"},{"location":"Coding/C/#write","title":"write","text":"<p>Like read(), write() takes an integer file descriptor, a pointer to the buffer, as well as a count of bytes which must not exceed the buffer's size.</p> <pre><code>write(fd, buffer, count);\n</code></pre> <pre><code>#include &lt;fcntl.h&gt;\n#include &lt;stdlib.h&gt;\n#define BSIZE 16384\n\nvoid main()\n{\nint fin, fout;\nchar buf[BSIZE];\nint count;\n\nif ((fin = open(\"foo\", O_RDONLY)) &lt; 0) {\nperror(\"foo\");\nexit(1);\n}\nif ((fout = open(\"bar\", O_WRONLY | O_CREAT, 0644)) &lt; 0) {\nperror(\"bar\");\nexit(2);\n}\nwhile ((count = read(fin, buf, BSIZE)) &gt; 0)\nwrite(fout, buf, count);\n\nclose(fin);\nclose(fout);\n}\n</code></pre>"},{"location":"Coding/C/#pthreads","title":"Pthreads","text":"<p>Pthreads provides an API for multithreaded programming in C. In Pthreads, new threads are spawned explicitly using pthread_create passing the name of a function which the thread will run.</p> <p>Notably, this function must have precisely the following signature: <pre><code>void *func(void *arg)\n</code></pre></p> <p>Also, when compiling a program using Pthreads with gcc the -lpthread option must be set.</p>"},{"location":"Coding/C/#pthread_attr_init","title":"pthread_attr_init","text":"<pre><code>#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint sum;\nvoid *runner(void *param);\n\nint main(int argc, char *argv[])\n{\npthread_t tid;\npthread_attr_t attr;\n\npthread_attr_init(&amp;attr);\npthread_create(&amp;tid, &amp;attr, runner, argv[1]);\npthread_join(tid, NULL);\n\nprintf(\"sum = %d\\n\", sum);\n}\n\nvoid *runner(void *param)\n{\nint i, upper = atoi(param);\nsum = 0;\n\nfor (i = 1; i &lt;= upper; i++)\nsum += i;\n\npthread_exit(0);\n}\n</code></pre>"},{"location":"Coding/C/#pthread_create","title":"pthread_create","text":"<pre><code>#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint sum;\nvoid *runner(void *param);\n\nint main(int argc, char *argv[])\n{\npthread_t tid;\npthread_attr_t attr;\n\npthread_attr_init(&amp;attr);\npthread_create(&amp;tid, &amp;attr, runner, argv[1]);\npthread_join(tid, NULL);\n\nprintf(\"sum = %d\\n\", sum);\n}\n\nvoid *runner(void *param)\n{\nint i, upper = atoi(param);\nsum = 0;\n\nfor (i = 1; i &lt;= upper; i++)\nsum += i;\n\npthread_exit(0);\n}\n</code></pre>"},{"location":"Coding/C/#pthread_exit","title":"pthread_exit","text":"<pre><code>#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint sum;\nvoid *runner(void *param);\n\nint main(int argc, char *argv[])\n{\npthread_t tid;\npthread_attr_t attr;\n\npthread_attr_init(&amp;attr);\npthread_create(&amp;tid, &amp;attr, runner, argv[1]);\npthread_join(tid, NULL);\n\nprintf(\"sum = %d\\n\", sum);\n}\n\nvoid *runner(void *param)\n{\nint i, upper = atoi(param);\nsum = 0;\n\nfor (i = 1; i &lt;= upper; i++)\nsum += i;\n\npthread_exit(0);\n}\n</code></pre>"},{"location":"Coding/C/#pthread_join","title":"pthread_join","text":"<pre><code>#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint sum;\nvoid *runner(void *param);\n\nint main(int argc, char *argv[])\n{\npthread_t tid;\npthread_attr_t attr;\n\npthread_attr_init(&amp;attr);\npthread_create(&amp;tid, &amp;attr, runner, argv[1]);\npthread_join(tid, NULL);\nprintf(\"sum = %d\\n\", sum);\n}\n\nvoid *runner(void *param)\n{\nint i, upper = atoi(param);\nsum = 0;\n\nfor (i = 1; i &lt;= upper; i++)\nsum += i;\n\npthread_exit(0);\n}\n</code></pre>"},{"location":"Coding/C/#structs","title":"Structs","text":""},{"location":"Coding/C/#task_struct","title":"task_struct","text":"Represents the process control block"},{"location":"Coding/C/#tasks","title":"Tasks","text":""},{"location":"Coding/C/#gtk","title":"GTK","text":""},{"location":"Coding/C/#hello-world","title":"Hello, World!","text":"<pre><code>#include  &lt;gtk/gtk.h&gt;\n\nint main (int argc, char *argv[])\n{\nGtkWidget *window;\n\ngtk_init (&amp;argc, &amp;argv);\n\nwindow = gtk_window_new (GTK_WINDOW_TOPLEVEL);\ngtk_window_set_title (GTK_WINDOW (window), \"Hello, World!\");\ngtk_container_set_border_width (GTK_CONTAINER (window), 10);\ngtk_widget_set_size_request (window, 300, 300);\n\ng_signal_connect (G_OBJECT (window), \"destroy\", G_CALLBACK (gtk_main_quit), NULL); // (1)\n\nGtkWidget *label = gtk_label_new (\"Hello, World!\");\n\ngtk_container_add (GTK_CONTAINER (window), label);\ngtk_widget_show_all (window);\n\ngtk_main ();\nreturn 0;\n}\n</code></pre> <ol> <li>Without connecting the signals, the process will not terminate after clicking the close button, although the window will close.</li> </ol>"},{"location":"Coding/CS/","title":"MSCS","text":"Links <ul> <li>Program description</li> <li>Course descriptions</li> </ul>"},{"location":"Coding/CS/#core-requirements","title":"Core requirements","text":"<ul> <li>COP 6611 Operating Systems <ul> <li>Course description (2021-2022)</li> <li>Syllabus</li> <li>Book: Silberschatz, et al. Operating Systems Concepts. 10th ed.</li> </ul> </li> <li>EEL 6764 Principles of computer architecture <ul> <li>Course description (2021-2022)</li> <li>Syllabus</li> <li>Book: Hennessy, et al. Computer Architecture: A Quantitative Approach.</li> </ul> </li> <li>COT 6405 Theory of Algorithms<ul> <li>Course description (2021-2022)</li> <li>Syllabus</li> <li>Book: Cormen, et al. Introduction to Algorithms. 3rd ed.</li> </ul> </li> </ul>"},{"location":"Coding/CS/#operating-systems","title":"Operating Systems","text":"<p>System calls provide an interface to operating system services, but are to be distinguished from APIs (like libc in Linux) that expose functions intended for use by application programmers and abstract and hide the implementation detail of system calls. The runtime environment (RTE) includes all software needed to run applications written in a particular language, such as compilers, interpreters, libraries, and loaders. The RTE constitutes a system-call interface that links API functional calls to OS syscalls.</p> <p>At the level of CPU architecture, the ABI defines how binary code interfaces for a given OS on a given architecture.</p> <p>Three methods passing parameters to system calls:</p> <ul> <li>Parameters passed to registers individually</li> <li>Passing to a single register the address a block or table in memory containing parameters (if there are more parameters than registers)</li> <li>Push parameters onto a stack, which is popped by the OS</li> </ul> <p>Syscalls can be grouped into several functional categories:</p> <ul> <li>Process control: creating, controlling, and ending processes</li> <li>File management: creating, deleting, opening, reading, writing, repositioning files and getting and setting file attributes</li> <li>Device management: granting access to system resources, including physical and virtual devices</li> <li>Information maintenance: dumping memory for debugging, the single step CPU mode which executes a trap after every instruction, as well as trivial calls to retrieve date and time</li> <li>Communications: both message-passing and shared-memory models of IPC as well as network stack</li> <li>Protection: file and disk permissions</li> </ul> <p>System utilities facilitate user interfaces to system calls with CLI and GUI tools.</p> <p>Source files are compiled into relocatable object files that are combined into a single binary executable file by the linker, which is then loaded into memory by the loader. Associated with this process is relocation which assigns final memory addresses to the program parts, adjusting code and data accordingly. Most systems allow dynamically linked libraries which are linked and loaded when needed, reducing the size of the executable.</p> <p>Object and executable files have standard formats that determine the layout of the header, instructions, and variables which must be at certain locations in specified structures so that the OS can open the file:</p> <ul> <li>Linux: ELF</li> <li>Windows: Portable Executable (PE)</li> <li>macOS: Mach-O</li> </ul> <p>Operating systems can be categorized by design methodology:</p> <ul> <li>Monolithic kernels have the greatest performance because all the functionality of the kernel runs in a single address space loaded from a single binary file. However these kernels are tightly coupled systems and are harder to design and maintain.</li> <li>Layered operating systems have the advantage of simplicity, since once lower layers are debugged they can be relied on to support higher-level functions. However, performance is poor due to the overhead of traversing multiple layers.</li> <li>Microkernels remove all nonessential functions and move them into userspace. Extending the OS is easier, and security is good, but performance is worse than monolithic kernels.</li> <li>Modularity, as implemented in Linux device drivers which are implemented as LKMs, allows a kernel to dynamically load dependencies when needed.</li> </ul> <p>In practice, all OSes in use combine different structures as expedient, forming hybrids of these ideal types.</p> <p>Debugging is the activity of finding and fixing errors in a system. OSes typically write error information to logs and can also capture core dumps, a capture of the memory of a process.</p> <p>Performance of a system can be monitored using counters and tracing:</p> <ul> <li>Counters on Linux like ps, top, vmstat, netstat, and iostat can provide information on a granular, per-process level or across the system. They rely on the virtual filesystems mounted by the Linux kernel at /proc.</li> <li>Tracing tools like strace, gdb, perf, and tcpdump are used to investigate an individual event in the course of debugging. </li> </ul> <p>A promising new approach to debugging is using eBPF, which can also capture tracing information using an in-kernel virtual machine that executes eBPF instructions. BPF Compiler Collection (BCC) is a set of Python scripts that embed C code and provide a frontend to eBPF.</p>"},{"location":"Coding/CS/#processes","title":"Processes","text":"<p>A process is a program in execution and comprises the fundamental unit of work and main concern of a computer system.</p> <p>The memory layout of a process can be separated into several sections:</p> <ul> <li>Text: executable code</li> <li>Data: global variables</li> <li>Heap: memory dynamically allocated during runtime</li> <li>Stack: parameters, return addresses, and local variables used during function invocation</li> </ul> <p>Each time a function is called, an activation record containing function parameters, local variables, and the return address is pushed onto the stack.  When control is returned from the function, the activation record is popped from the stack. The stack (which begins at the top of the program's allocated memory range) and heap sections will grow toward each other but must never overlap. The memory used by these sections can be displayed with the size command.</p> <p>Each process is represented in the operating system by a process control block (PCB) (represented by task_struct in Linux). On systems that support threads, the PCB is expanded to include information for each thread.</p> <p>The CPU scheduler selects processes for execution, a process called dispatching, or moves them to and from various queues: the ready queue where a process awaits dispatch or the wait queue where a process awaits the completion of I/O. When the CPU core switches to another process, the state of one process is saved and that of another is restored, a process called context-switching.</p> <p>A parent process may create new processes called children (see fork), identified by an integer number known as a PID. In a normal operating system the processes form a process tree stemming from a single root, the initial process which has a PID of 1 (on modern Linux systems, systemd).</p> <p>Processes can terminate themselves (see exit) or be terminated due to a variety of circumstances. A parent process can wait for the termination of a child process with wait. A process that has terminated but whose parent has not yet called wait is a zombie process. All processes transition to this state briefly when they terminate. Some OSes like LInux allow orphan processes to continue existing after the parent process has terminated. In other systems, terminating all children when the parent is terminated is referred to as cascading termination.</p> <p>In IPC, processes exchange data using one of two methods: shared memory or message passing. Shared memory in Linux is implemented with memory-mapped files </p>"},{"location":"Coding/CS/#concurrency","title":"Concurrency","text":"<p>A thread, comprising a thread identifier, a program counter (PC), a register set, and a stack, is the basic unit of CPU utilization.  All threads from a single process share its code and data sections and other OS resources like open files and signals.</p> <p>Multithreaded programming allows more efficient use of multicore and multi-CPU systems, since each core is only capable of processing a single thread at a time. Such systems are pareallel systems because they can perform more than one task at a time. Concurrent systems are ones that support more than one task by allowing all tasks to make progress. Single-core systems could achieve concurrency through the use of CPU schedulers, but not parallelism.</p> <p>Contemporary OSes support kernel threads which are managed directly by the OS. User threads in contrast are supported above the kernel and managed without kernel support.</p> <p>Pthreads is the threads extension of the POSIX specification and can be provided as either a kernel-level or user-level library. In a Pthreads program, separate threads begin execution in a specified function.</p> <p>Implicit threading refers to the increasingly popular strategy of transfering the burden of creating and managing threading from application developers to compilers and runtime libraries. Several implicit threading approaches have evolved:</p> <ul> <li>Thread pools maintain a finite number of threads which await work, preventing resource exhaustion by having an unbounded number of possible threads.</li> <li>Fork-join model is often characterized as explicit thread creation, but by creating parallel tasks using the library instead of threads during the fork phase directly it can be implicit.</li> <li>OpenMP is a C++ library that provides an API of compiler directives that mark out parallel regions, or blocks of code that may run in parallel, creating as many threads as there are processing cores available.</li> <li>Grand Central Dispatch (GCD) is an Apple runtime library, API, and language extensions that allow developers to identify sections of code to run in parallel.</li> <li>Thread Building Blocks (TBB) is a C++ template library</li> </ul> <p>In Linux, a struct task_struct, which contains pointers to other data structures where data are stored, exists for each task in the system.</p>"},{"location":"Coding/Courses/","title":"Courses","text":""},{"location":"Coding/Courses/#the-complete-c-masterclass","title":"The Complete C# Masterclass","text":"/# Video Topic Projects 01.01 Welcome and a brief introduction to the Course 01.02 Guide Lecture - How to install Visual Studio 01.03 Guide lecture - Creating a project in Visual Studio 01.04 Your first C# program 02.01 What is a variable and what is its relationship with the data types IntegerDataTypes 02.02 The \"numbers\" data type - Integers 02.03 The \"numbers with a decimal point data types - float, double, decimal FloatingPointDataTypes 02.04 The \"Yes or No\" data types - booleans Boolean 02.05 The \"single symbol\" dat atypes - characters Characters 02.06 The \"information as text\" data types - strings Strings 02.07 Collections of information from a specific data type - arrays Arrays 02.08 Some cool, useful tricks with strings StringTricks 02.09 Transforming any data type into a string - allows you to use string methods 02.10 The 3 different ways to build strings 02.11 The 3 different ways to convert one data type to another 03.01 Write vs WriteLine, when to use which? WriteandWriteLine 03.04 Accepting single character inputs from the Console - Read method ReadingCharacter 03.05 Accepting string inputs from the Console - ReadLine method ReadLine 03.06 Accepting inputs as keys from the Console - <code>ReadKey</code> ReadKey 03.07 Changing the color of the text and the background of the text in the Console ConsoleColors 03.08 Changing cursor settings in the Console - Size, Visibility, Position CursorSettings 03.09 Controlling the size of the Console window - WindowSize, BufferSize and more ConsoleSize 04.01 Arithmetic Operators 04.02 Assignment Operators 04.03 Comparison Operators 04.04 Logical Operators <code>&amp;&amp;</code>, <code>||</code> 04.05 Ternary Operator 06.02 Practicing <code>while</code> loops MiniWhileGame 06.04 The <code>for</code> loops and their common uses ForLoops 06.05 Practicing <code>for</code> loops MenuWhile 06.06 <code>foreach</code> loop ForeachLoops 07.05 Methods with variable number of arguments <code>params</code> ListExamples 07.08 Methods with <code>ref</code> and <code>out</code> arguments <code>ref</code>, <code>out</code> RefAndOut 08.01 Introduction to one-dimensional arrays IntroductionToArrays 08.02 Outputting arrays <code>string.Join()</code> OutputtingArrays 08.03 Correctly cloning arrays <code>Array.Clone()</code> ArrayCloning 08.04 Reversing arrays <code>Array.Reverse()</code> 08.05 Bubble sorting algorithm BubbleSort 08.09 Lists <code>List&lt;T&gt;</code> 08.10 Practice working with <code>List&lt;T&gt;</code>s <code>List&lt;T&gt;</code> ListExamples 09.01 Introduction to multidimensional arrays 11.01 Introduction to exception handling <code>try</code> <code>catch</code> 11.02 Catching multiple exceptions 11.03 Inspecting caught exception <code>string.Substring()</code> MultipleExceptions 11.04 <code>finally</code> block <code>finally</code> TryCatchFinally 12.01 Introduction to object-oriented programming 12.02 Creating a basic class RPGCharGen 12.03 Fields and properties - the variables of a class RPGCharGen 12.04 Methods - the actions of a class RPGCharGen 12.05 Constructors - the builders of a class RPGCharGen 12.06 Namespaces and files - structuring your project RPGCharGen 13.02 Controlling the accessors of a property - read, write, and read-write properties RPGCharGen 13.03 Implementing validation in properties RPGCharGen 13.04 Validation and exceptions <code>throw</code> RPGCharGen 13.05 Properties and fields - when to use which RPGCharGen 14.01 <code>this</code> <code>this</code> RPGCharGen 14.03 Overloading constructors RPGCharGen 14.04 Chaining constructors RPGCharGen 15.01 <code>public</code> and <code>private</code> access modifiers <code>public</code>, <code>private</code> RPGCharGen 15.02 <code>internal</code> and <code>protected</code> access modifiers <code>internal</code>, <code>protected</code> RPGCharGen 16.01 Static fields and properties RPGCharGen 16.02 <code>const</code> and <code>readonly</code> 16.03 Static methods 16.04 Static classes 16.05 <code>enum</code> 17.01 Introduction to Inheritance"},{"location":"Coding/Courses/#learn-c-by-building-applications","title":"Learn C# By Building Applications","text":"/# Video Topic Projects 02.12 Static vs. non-static"},{"location":"Coding/Courses/#arraycloning","title":"ArrayCloning","text":"<pre><code>int[] primes = { 1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, };\n//int[] primesClone = (int[])primes.Clone();\nint[] primesClone = new int[primes.Length];\nArray.Copy(primes, primesClone, primes.Length);\nprimesClone[primesClone.Length -1 ] = 47;\n\nforeach (var i in primesClone)\n{\nConsole.WriteLine(i);\n}\n</code></pre>"},{"location":"Coding/Courses/#arrays","title":"Arrays","text":"<pre><code>int[] numbers = new int[10];\n\nfor (int i = 0; i &lt; numbers.Length; i++) {\nSystem.Console.WriteLine(numbers[i]);\n}\n\nstring[] fruits = { \"apple\", \"banana\", \"jackfruit\", \"kiwi\", \"mango\" };\n\nfor (int i = 0; i &lt; fruits.Length; i++)\n{\nSystem.Console.WriteLine(fruits[i]);\n}\n</code></pre>"},{"location":"Coding/Courses/#boolean","title":"Boolean","text":"<pre><code>int firstNumber = 4;\nint secondNumber = 6;\n\nbool isSmaller = firstNumber &lt; secondNumber;\n\nbool isTheCookieJarFull = false;\nbool isTheCookieJarEmpty = !isTheCookieJarFull;\n</code></pre>"},{"location":"Coding/Courses/#characters","title":"Characters","text":"<pre><code>System.Console.InputEncoding = System.Text.Encoding.UTF8;\nSystem.Console.OutputEncoding = System.Text.Encoding.UTF8;\n\nchar x = 'x';\nSystem.Console.WriteLine(x);\n\nchar plus = '\\u002b';\nSystem.Console.WriteLine(plus);\n\nchar umlaut = '\\u00F6';\nSystem.Console.WriteLine(umlaut);\n</code></pre>"},{"location":"Coding/Courses/#consolecolors","title":"ConsoleColors","text":"<pre><code>Console.ForegroundColor = ConsoleColor.Green;\nConsole.WriteLine(\"Once upon a midnight dreary\");\nConsole.ForegroundColor = ConsoleColor.Cyan;\nConsole.WriteLine(\"While I pondered weak and weary\");\nConsole.ResetColor();\nConsole.WriteLine(\"Over many a quaint and curious volume of forgotten lore,\");\n</code></pre>"},{"location":"Coding/Courses/#consolesize","title":"ConsoleSize","text":"<pre><code>Console.WindowHeight = 20;\nConsole.WindowWidth = 20;\nConsole.SetWindowSize(30, 30);\n\nConsole.BufferHeight= 40;\nConsole.BufferWidth = 40;\n\nConsole.WindowLeft = 10;\nConsole.WindowTop = 10;\nConsole.SetWindowPosition(10, 10);\n</code></pre>"},{"location":"Coding/Courses/#cursorsettings","title":"CursorSettings","text":"<pre><code>Console.Title = \"Terminal\";\nConsole.CursorVisible = true;\nConsole.CursorSize = 50;\nConsole.SetCursorPosition(20, 10);\n</code></pre>"},{"location":"Coding/Courses/#exceptionhandling","title":"ExceptionHandling","text":"<pre><code>Console.WriteLine(\"'q' to quit\");\nList&lt;int&gt; primes = new List&lt;int&gt;();\n\nwhile (true)\n{\nstring input = Console.ReadLine();\ntry\n{\nprimes.Add(Int32.Parse(input));\n}\ncatch (FormatException ex)\n{\nif (input.ToLower() == \"q\")\n{\nbreak;\n}\nelse\n{\nConsole.WriteLine(ex.Message);\n//string stacktrace = ex.StackTrace;\n//string filename = stacktrace.Substring(stacktrace.IndexOf(':') - 1);\n//Console.WriteLine(filename);\n}\n}\n\n}\nConsole.WriteLine(String.Join(\" \", primes));\n</code></pre>"},{"location":"Coding/Courses/#floatingpointdatatypes","title":"FloatingPointDataTypes","text":"<pre><code>float floatNum = 13.14321365431f;\n\nstring output = $\"Floating point numbers have a maximum precision of 8 digits: {floatNum}\";\nSystem.Console.WriteLine(output);\n\nfloat radius = 3.5f;\ndouble area = System.Math.PI * System.Math.Pow(radius, 2d);\nSystem.Console.WriteLine($\"A circle with a radius of {radius} has an are of {area}.\");\n\nfloat floatMax = float.MaxValue;\nfloat floatMin = float.MinValue;\nSystem.Console.WriteLine($\"float ranges from {floatMin} to {floatMax}\");\n\ndouble doubleMax = double.MaxValue;\ndouble doubleMin = double.MinValue;\nSystem.Console.WriteLine($\"double ranges from {doubleMin} to {doubleMax}\");\n\ndecimal decimalMax = decimal.MaxValue;\ndecimal decimalMin = decimal.MinValue;\nSystem.Console.WriteLine($\"decimal ranges from {decimalMin} to {decimalMax}\");\n</code></pre>"},{"location":"Coding/Courses/#foreachloops","title":"ForeachLoops","text":"<pre><code>int[] primes = { 1, 2, 3, 5, 7, 11, 13, 17, 19, 23 };\nforeach (var item in primes)\n{\nConsole.WriteLine(item);\n}\n</code></pre>"},{"location":"Coding/Courses/#forloops","title":"ForLoops","text":"<pre><code>int[] primes = { 1, 2, 3, 5, 7, 11, 13, 17, 19 };\n\nfor (int i = 0; i &lt;primes.Length; i++)\n{\nprimes[i] = 2 * primes[i];\nConsole.WriteLine(primes[i]);\n}\n</code></pre>"},{"location":"Coding/Courses/#integerdatatypes","title":"IntegerDataTypes","text":"<pre><code>int intMax = int.MaxValue;\nint intMin = int.MinValue;\n\nstring output = $\"int ranges from {intMin} to {intMax}\";\nConsole.WriteLine(output);\n\nuint uintMin = uint.MinValue;\nuint uintMax = uint.MaxValue;\n\noutput = $\"uint ranges from {uintMin} to {uintMax}\";\nConsole.WriteLine(output);\n\nbyte byteMin = byte.MinValue;\nbyte byteMax = byte.MaxValue;\n\noutput = $\"byte ranges from {byteMin} to {byteMax}\";\nConsole.WriteLine(output);\n\nlong longMin = long.MinValue;\nlong longMax = long.MaxValue;\n\noutput = $\"long ranges from {longMin} to {longMax}\";\nConsole.WriteLine(output);\n\nulong ulongMin = ulong.MinValue;\nulong ulongMax = ulong.MaxValue;\n\noutput = $\"ulong ranges from {ulongMin} to {ulongMax}\";\nConsole.WriteLine(output);\n</code></pre>"},{"location":"Coding/Courses/#listexamples","title":"ListExamples","text":"<pre><code>static void Main(string[] args)\n{\nint[] arr1 = { 0, 1, 2, 3, 4 };\nint[] arr2 = { 5, 6, 7, 8, 9 };\n\nList&lt;int&gt; list = new List&lt;int&gt;();\nlist = splat(arr1, arr2);\n\nforeach (var el in list)\n{\nConsole.WriteLine(el);\n}\n}\n\nstatic List&lt;int&gt; splat(params int[][] arg)\n{\nList&lt;int&gt; output = new List&lt;int&gt;();\nforeach (int[] arr in arg)\n{\noutput.AddRange(arr);\n}\nreturn output;\n}\n</code></pre>"},{"location":"Coding/Courses/#miniwhilegame","title":"MiniWhileGame","text":"<pre><code>static void Main(string[] args)\n{\nint mage = 30;\nint warrior = 40;\n\nwhile (mage &gt; 0 &amp;&amp; warrior &gt; 0)\n{\nwarrior -= mage_attack();\nmage -= warrior_attack();\n}\nConsole.WriteLine($\"Conflict ends with Mage having {mage} points and Warrior having {warrior}!\");\n}\n\nprivate static int warrior_attack()\n{\nvar r = new System.Random();\nint result = r.Next(1, 3);\nConsole.WriteLine($\"Warrior attacks Mage, dealing {result} damage!\");\nreturn result;\n}\n\nprivate static int mage_attack()\n{\nvar r = new System.Random();\nint result = r.Next(7, 9);\nConsole.WriteLine($\"Mage attacks Warrior, dealing {result} damage!\");\nreturn result;\n}\n</code></pre>"},{"location":"Coding/Courses/#menuwhile","title":"MenuWhile","text":"<pre><code>static void Main(string[] args)\n{\nstring[] fruits = { \"Apple\", \"Banana\", \"Date\", \"Grape\", \"Jackfruit\", \"Kiwi\", \"Lime\", \"Orange\", \"Peach\", \"Strawberry\" };\n\nstring[] menu = { \"Add New Item\", \"Edit Item\", \"Remove Item\", \"View All Items\", \"Exit\" };\nint choice;\ndo\n{\nchoice = Menu(menu);\n\nswitch (choice)\n{\ncase 1:\nfor (int i = 0; i &lt; fruits.Length; i++)\n{\nif (fruits[i] == null)\n{\nConsole.Write(\"Please add a new fruit: \");\nfruits[i] = Console.ReadLine();\nbreak;\n}\n}\nbreak;\ncase 2:\nint chosenFruit = 0;\ndo\n{\nConsole.Write($\"Edit fruit number (1 to {fruits.Length}): \");\ntry { chosenFruit = Convert.ToInt32(Console.ReadLine()); }\ncatch\n{\nInvalidInput();\n}\n} while (chosenFruit == 0);\nConsole.Write($\"Enter new value for the {fruits[chosenFruit - 1]}: \");\nfruits[chosenFruit - 1] = Console.ReadLine();\nbreak;\ncase 3:\n\n\nbreak;\ncase 4:\nConsole.WriteLine(\"Current fruits: \");\nfor (int i = 0; i &lt; fruits.Length; i++)\n{\nif (fruits[i] != null)\n{\nConsole.WriteLine(fruits[i]);\n}\n}\nbreak;\ncase 5:\nbreak;\ndefault:\nInvalidInput();\nbreak;\n}\n} while (true);\n}\n\nprivate static int Menu(string[] menu)\n{\nConsole.WriteLine('\\n');\nfor (var i = 0; i &lt; menu.Length; i++)\n{\nConsole.WriteLine(\"{0}. {1}\", i + 1, menu[i]);\n}\nConsole.Write(\"Your choice: \");\nstring input = Console.ReadLine();\ntry\n{\nint output = Int32.Parse(input);\nreturn output;\n}\ncatch (FormatException)\n{\nInvalidInput();\nreturn -1;\n}\ncatch (OverflowException)\n{\nInvalidInput();\nreturn -1;\n}\n}\n\nprivate static void InvalidInput()\n{\nConsole.ForegroundColor = ConsoleColor.Red;\nConsole.WriteLine(\"Invalid input!\");\nConsole.ResetColor();\n}\n</code></pre>"},{"location":"Coding/Courses/#outputtingarrays","title":"OutputtingArrays","text":"<pre><code>int[] primes = { 1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47 };\n\nConsole.WriteLine($\"{primes.Length} total primes\");\n\nList&lt;int&gt; lessThanTwenty = new List&lt;int&gt;();\nList&lt;int&gt; moreThanTwenty = new List&lt;int&gt;();\n\nforeach (int i in primes)\n{\nif (i &lt; 20) { lessThanTwenty.Add(i); }\nelse        { moreThanTwenty.Add(i); }\n}\n\nConsole.WriteLine($\"Primes &lt; 20:\\n  {string.Join(\", \", lessThanTwenty)}\");\nConsole.WriteLine($\"Primes &gt;= 20:\\n  {string.Join(\", \", moreThanTwenty)}\");\n</code></pre>"},{"location":"Coding/Courses/#readingcharacter","title":"ReadingCharacter","text":"<pre><code>Console.Write(\"How old are you? \");\nint age;\nint.TryParse(Console.ReadLine(), out age) ;\nConsole.WriteLine($\"You are {age} years old (allegedly).\");\n</code></pre>"},{"location":"Coding/Courses/#readkey","title":"ReadKey","text":"<pre><code>Console.WriteLine($\"\\n\\nKey pressed: {key.Key}\");\nConsole.WriteLine($\"Key as char: {key.KeyChar}\");\nConsole.WriteLine($\"Modifiers: {key.Modifiers}\");\n</code></pre>"},{"location":"Coding/Courses/#readline","title":"ReadLine","text":"<pre><code>Console.Write(\"Input the drive letter: \");\nstring driveLetter = Console.ReadLine();\nConsole.Write(\"Input the folder path: \");\nstring folderPath = Console.ReadLine();\nConsole.Write(\"Input the file name: \");\nstring fileName = Console.ReadLine();\nConsole.WriteLine($\"{driveLetter}:\\\\{folderPath}\\\\{fileName}.exe\");\n</code></pre>"},{"location":"Coding/Courses/#refandout","title":"RefAndOut","text":"<pre><code>static void Main(string[] args)\n{\nint number = 0;\nConsole.WriteLine(number);\nIncreaseByOne(ref number);\nConsole.WriteLine(number);\n\n}\n\nstatic void IncreaseByOne(ref int n)\n{\nn++;\n}\n</code></pre> <pre><code>static void Main()\n{\ndouble n = 5;\ndouble nSquared;\nsquare(n, out nSquared);\nConsole.WriteLine($\"{n} ^ 2 = {nSquared}\");\n}\nstatic void square(double x, out double y)\n{\ny = System.Math.Pow(x, 2);\n}\n</code></pre>"},{"location":"Coding/Courses/#rpgchargen","title":"RPGCharGen","text":""},{"location":"Coding/Courses/#strings","title":"Strings","text":"<pre><code>string username = \"admin\";\nSystem.Console.WriteLine(username[0]);\n\n// impossible, strings are immutable\nusername[0] = 'A';\n</code></pre>"},{"location":"Coding/Courses/#stringtricks","title":"StringTricks","text":"<pre><code>string fruitJuice = \"Strawberry juice\";\nstring separator = new string('-', fruitJuice.Length);\nSystem.Console.WriteLine(fruitJuice);\nSystem.Console.WriteLine(separator);\n\nSystem.Console.WriteLine(fruitJuice.Contains(\"j\"));\nSystem.Console.WriteLine(fruitJuice.IndexOf(\"r\"));\nSystem.Console.WriteLine(fruitJuice.LastIndexOf(\"r\"));\nSystem.Console.WriteLine(fruitJuice.ToUpper().Contains(\"J\"));\nSystem.Console.WriteLine(fruitJuice.ToUpper().IndexOf(\"RR\"));\nSystem.Console.WriteLine(fruitJuice.ToUpper().LastIndexOf(\"RR\"));\n</code></pre>"},{"location":"Coding/Courses/#trycatchfinally","title":"TryCatchFinally","text":"<pre><code>StreamWriter sw = null;\ntry\n{\n\nsw = File.CreateText(Directory.GetCurrentDirectory() + @\"/test.txt\");\n\nint number = int.Parse(Console.ReadLine());\nint dividend = 5 / number;\n\nsw.Write(number);\n}\ncatch (FormatException ex)\n{\nConsole.WriteLine(ex.Message);\n}\ncatch (DivideByZeroException ex)\n{\nConsole.WriteLine(ex.Message);\n}\nfinally\n{\nsw.Close();\n}\n</code></pre>"},{"location":"Coding/Courses/#writeandwriteline","title":"WriteAndWriteLine","text":"<pre><code>string heading = \"Protein Intake Week: 1\";\nstring underline = new string('=', heading.Length);\n\ndouble num1 = 80.885570;\ndouble num2 = 94.564645;\ndouble num3 = 78.678931;\ndouble num4 = 88.66654;\ndouble num5 = 88.6466;\ndouble num6 = 76.777;\ndouble num7 = 91.85759;\ndouble sum = num1 + num2 + num3 + num4 + num5 + num6 + num7;\ndouble[] array = { num1, num2, num3, num4, num5, num6, num7 };\n\nSystem.Console.WriteLine(\"|{0}|\", heading);\nSystem.Console.WriteLine(\"|{0}|\", underline);\nforeach (double i in array)\n{ System.Console.WriteLine($\"|{i, 22:N2}|\"); }\nSystem.Console.WriteLine(\"|{0}|\", underline);\nSystem.Console.WriteLine(\"|Total: {0, 15:N2}|\", sum);\n</code></pre>"},{"location":"Coding/Courses/#test-driven-development-in-c","title":"Test-Driven Development in C#","text":""},{"location":"Coding/Courses/#create-a-red-unit-test","title":"Create a Red Unit Test","text":""},{"location":"Coding/Courses/#mocking-with-moq-and-xunit","title":"Mocking with Moq and xUnit","text":""},{"location":"Coding/Debugging/","title":"Debugging","text":""},{"location":"Coding/Debugging/#debuggers","title":"Debuggers","text":""},{"location":"Coding/Debugging/#pdb","title":"pdb","text":"<pre><code>python -m pdb script.py\n</code></pre> <pre><code>import sys\n\n\ndef main():\n    name : str = sys.argv[1]\n    print(f\"Hello, {name}!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Use debugging to intercept the value of the variable before the final string is displayed.</p> <pre><code>import math\nimport sys\n\n\ndef main():\n    number = get_number()\n    factorial = get_factorial(number)\n    print(f\"{number}! = {factorial}\")\n\n\ndef get_factorial(number: int):\n    factorial = math.prod(list(range(number + 1)))\n    return factorial\n\n\ndef get_number():\n    number = 0\n\n    if len(sys.argv) == 2:\n        try:\n            number = int(sys.argv[1])\n            return number\n        except IndexError:\n            pass\n        except ValueError:\n            pass\n\n    while True:\n        try:\n            number = int(input(\"Enter a number: \"))\n            break\n        except ValueError:\n            print(\"Argument must be an integer\")\n\n    return number\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>When running pdb with no breakpoints, top-level statements begin to be executed. The debugger proceeds from top to bottom, following the interpreter, from import statements to function definitions, until it finally reaches the entrypoint. If the debugger is directed to step over the main function, the program will execute normally.</p> <p>The entirety of the source code can be printed to the interactive pdb shell by using <code>ll</code> or <code>longlist</code> .</p> <p>A similar command is l[ist]  which lists 11 lines around the current line.  Repeated execution progressively print more of the source.</p> <p>The c[ontinue]  command results in the execution being resumed without interruption until the next breakpoint.  If no breakpoints are defined, the program is executed as it would be normally.</p> <p>Invoking pdb without any breakpoints and proceeding with n[ext]  results in top-level code being executed.</p> <p>Stepping into function calls with s[tep]  is similar to adding a breakpoint at the function definition with b[reak] , at least for a single function call.</p> <p>In these examples, the factorial is being incorrectly calculated, such that it will always produce a 0. This can be inspected in the debugger by using the p  command, which evaluates the following arguments as an expression.</p> <p>Alternatively, any Python statement can be preceded with the !  command, with which you can change variable values. Notably, any whitespace after <code>!</code> will cause an IndentationError</p> <pre><code>p factorial\n!factorial = 120\n</code></pre> <p>The interact  command allows you to enter a Python REPL, which allows statements to be interactively entered.  However these do not have an effect on the program state once the shell is terminated.</p> <pre><code>(Pdb) p factorial\n0\n(Pdb) interact\n&gt;&gt;&gt; factorial = 120\n&gt;&gt;&gt; ^D\nnow exiting InteractiveConsole...\n(Pdb) p factorial\n0\n</code></pre>"},{"location":"Coding/Debugging/#gdb","title":"gdb","text":"<p>Invoke on executable \"program\", compiled with debugging symbols. <pre><code>gdb program\n</code></pre> Display the first 10 lines of source code from main.rs <pre><code>list main.rs:0\n</code></pre> Display the source code of the <code>stack_only</code> function <pre><code>list stack_only\n</code></pre></p> <p>Run code after placing a breakpoint on functions \"stack_only\" and \"stack_and_heap\" <pre><code>b stack_only\nb stack_and_heap\nr\n</code></pre> Display stack frames <pre><code>bt 2\n</code></pre> Inspect local variables and arguments <pre><code>info locals\ninfo args\n</code></pre> Step forward <pre><code>n\n</code></pre> Display data at given memory location as a digit <pre><code>x /d 0x55555559bba0\n</code></pre> Enter TUI mode Ctrl-XA.  This mode does not work well with print statements.</p> <p>GDB also contains a Python runtime, so you can run commands inline using the python command.</p>"},{"location":"Coding/Debugging/#glossary","title":"\ud83d\udcd8 Glossary","text":"step into <p>If the current line contains a function call, move execution context into it to continue stepwise execution of code statements within that function.</p> <p>If not, identical to step over</p> step over Execute the current line and pause on the next."},{"location":"Coding/DnD/","title":"\ud83d\udc32\ufe0f  Dungeons &amp; Dragons","text":""},{"location":"Coding/DnD/#ability-scores","title":"Ability scores","text":"<p>Six ability scores define the capabilities of every character and monster in the game. Each of these are obtained by rolling 4d6, then discarding the die with the lowest value.</p> <ul> <li>Strength</li> <li>Dexterity</li> <li>Constitution</li> <li>Intelligence</li> <li>Wisdom</li> <li>Charisma</li> </ul> <p>Alternatively, 27 points can be spent according to the following table to arbitrarily determine ability scores.</p> Ability score Cost 8 0 9 1 10 2 11 3 12 4 13 5 14 7 15 9 <p>Finally, the following set of scores can be used if either of the two methods above are unacceptable: 15, 14, 13, 12, 10, and 8.</p>"},{"location":"Coding/DnD/#ability-modifiers","title":"Ability modifiers","text":"<p>Ability modifiers apply to each score according to its value. These modifiers are equivalent to finding the floor of half of the score's difference with ten (i.e. (13-10) // 2 = 1, but (7-10) // 2 = -2)</p> Ability score Modifier Ability Score Modifier Ability Score Modifier 1 -5 12-13 +1 22-23 +6 2-3 -4 14-15 +2 24-25 +7 4-5 -3 16-17 +3 26-27 +8 6-7 -2 18-19 +4 28-29 +9 8-9 -1 20-21 +5 30 +10 10-11 0"},{"location":"Coding/DnD/#class","title":"Class","text":"<p>A class describes a character's vocation, talents, and combat style.</p> <ul> <li>Class features are capabilities unique to each class</li> <li>Proficiencies in armor, weapons, saving throws, and other items define a character's talents</li> </ul>"},{"location":"Coding/Dogfood/","title":"\ud83d\udc36 Dogfood data","text":"<p>A problem I've encountered is that when it comes to anything to do with software, learning is doing. But there isn't really much play data easily available. Some tutorials go to the trouble of providing files for download, and I'm sure anyone reading this already has a favorite API or JSON repo where they go to get stuff. But the situation is not ideal, and I've never encountered a body of data in any learning materials I've encountered that compelled me to come back to it time and again. So I made it</p> <p>raven</p> <p>These .csv files have proven useful to me as sample datasets to use while learning the Unix filters <code>grep</code>, <code>sed</code>, and <code>awk</code>. I hope whoever finds them finds them just as valuable.</p>"},{"location":"Coding/Dogfood/#greek-philosophers","title":"\ud83e\udde0 Greek philosophers","text":"<p>Very small dataset featuring all your favorite Ancients:</p> Name City Date of birth Socrates Athens 470 BC Plato Athens 428 BC Aristotle Stagira 384 BC Euclid Alexandria 325 BC Pythagoras Samos 570 BC"},{"location":"Coding/Dogfood/#ships-of-the-line","title":"\ud83d\udea2 Ships of the line","text":"<p>A somewhat larger, more complicated dataset featuring some of history's battliest battleships:</p> Name Country Displacement Length Beam Commissioned date Yamato Japan 65027 256 38.9 16 December 1941 USS Enterprise United States of America 19800 251.4 33.4 12 May 1938 Bismarck Germany 41700 251 36 24 August 1940 HMS Dreadnought United Kingdom 18120 160.6 25 2 December 1906 USS Iowa United States of America 46000 270.43 32.97 22 February 1943 HMS Vanguard United Kingdom 45200 248.2 32.9 12 May 1946"},{"location":"Coding/Dogfood/#starships","title":"\ud83d\ude80 Starships","text":"<p>Ships famous, to varying degrees, for plying the inky black. If these interest you, check out my Starships repo too.</p> StarshipsOfficers Name Class Registry Crew USS Enterprise Constitution NCC-1701 203 USS Constitution Constitution NCC-1700 204 USS Defiant Defiant NX-74205 50 USS Voyager Intrepid NCC-74656 141 USS Enterprise Galaxy NCC-1701-D 6000 USS Reliant Miranda NCC-1864 35 Name Date of birth Kirk, James 2233-03-22 Picard, Jean-Luc 2305-07-13"},{"location":"Coding/Dogfood/#mathematicians","title":"\ud83e\uddd4 Mathematicians","text":"<p>An expanded assortment of smartypants from a different era. The third and largest dataset, with two date fields and one full of semicolon-delimited subfields ripe for parsing:</p> Name Surname Date of birth Date of death Concepts Carl Gauss 30 April 1777 23 February 1855 Gaussian elimination; Gauss\u2013Jordan elimination; Gauss\u2013Seidel method; Gauss's cyclotomic formula; Gauss's lemma; Gaussian binomial coefficient; Gauss transformation; Gauss\u2013Bodenmiller theorem; Gauss\u2013Bolyai\u2013Lobachevsky space; Gauss\u2013Bonnet theorem; Generalized Gauss\u2013Bonnet theorem; Braid theory; Gauss\u2013Codazzi equations; Gauss\u2013Manin connection; Newton line; Gauss's area formula; Gauss's lemma; Gauss map; Gaussian curvature; Gauss circle problem; Gauss\u2013Kuzmin\u2013Wirsing constant; Gauss's constant; Gauss's digamma theorem; Gauss's generalization of Wilson's theorem; Gauss's lemma; Gauss map; Gaussian moat; Gauss class number problem; Gauss's multiplication formula George Berkeley 12 March 1685 14 January 1753 Gottfried Leibniz 1 July 1646 14 November 1716 Calculus; Monads; Best of all possible worlds; Pre-established harmony; Identity of indiscernibles; Matrix (mathematics); Leibniz integral rule; Principle of sufficient reason; Notation for differentiation; Product rule; Vis viva; Boolean algebra; Salva veritate; Stepped reckoner; Symbolic logic; Semiotics; Analysis situs; Law of Continuity; Transcendental law of homogeneity; Ars combinatoria; Calculus ratiocinator; Leibniz's notation; Characteristica universalis; Problem of why there is anything at all; Pluralistic idealism; Metaphysical dynamism; Relationism; Apperception; A priori/a posteriori distinction Immanuel Kant 22 April 1724 12 February 1804 Kantianism; Kantian ethics; Neo-Kantianism Isaac Newton 25 December 1642 20 March 1726 \"Gauss\u2013Newton algorithm; Newton\u2013Cotes formulas; Newton\u2013Okounkov body; Newton\u2013Pepys problem; Newton fractal; Newton's identities; Newton's inequalities; Newton's method; Newton's method in optimization; Newton's notation; Newton polygon; Newton polynomial; Newton series; Newton's theorem about ovals; Truncated Newton method; bucket argument; Newton's cannonball; Universal gravitational constant; Newton's cradle; Newton disc; Newton\u2013Cartan theory; Newton\u2013Euler equations; Newton's law of cooling; Newton's laws of motion; Newton's law of universal gravitation; Newton's metal; Newton's reflector; Newton's rings; Rotating spheres; Newton scale; Newton's sphere theorem John Locke 29 August 1632 28 October 1704 Labor theory of property; Social contract; State of nature Joseph Fourier 21 March 1768 16 May 1830 Fourier series; Fourier transform; Fourier's law of conduction; Fourier-Motzkin elimination Joseph-Louis Lagrange 25 January 1736 10 April 1813 Lagrangian analysis; Lagrangian coordinates; Lagrangian derivative; Lagrangian drifter; Lagrangian foliation; Lagrangian Grassmannian; Lagrangian intersection Floer homology; Lagrangian mechanics; Lagrangian (field theory); Lagrangian system; Lagrangian mixing; Lagrangian point; Lagrangian relaxation; Lagrangian submanifold; Lagrangian subspace; Nonlocal Lagrangian; Proca lagrangian; Special Lagrangian submanifold; Euler\u2013Lagrange equation; Green\u2013Lagrange strain; Lagrange bracket; Lagrange\u2013d'Alembert principle; Lagrange error bound; Lagrange form; Lagrange interpolation; Lagrange invariant; Lagrange inversion theorem; Lagrange multiplier; Lagrange number; Lagrange point colonization; Lagrange polynomial; Lagrange property; Lagrange reversion theorem; Lagrange resolvent; Lagrange spectrum; Lagrange stream function; Lagrange's approximation theorem; Lagrange's formula (disambiguation); Lagrange's identity (disambiguation); Lagrange's theorem (group theory); Lagrange's theorem (number theory); Lagrange's four-square theorem; Lagrange's trigonometric identities Pierre-Simon Laplace 23 March 1749 5 March 1827 Bayesian inference; Bayesian probability; Laplace's equation; Laplacian; Laplace transform; Inverse Laplace transform; Laplace distribution; Laplace's demon; Laplace expansion; Young\u2013Laplace equation; Laplace number; Laplace limit; Laplace invariant; Laplace principle; Laplace's principle of insufficient reason; Laplace's method; Laplace expansion; Laplace force; Laplace filter; Laplace functional; Laplacian matrix; Laplace motion; Laplace plane; Laplace pressure; Laplace resonance; Laplace's spherical harmonics; Laplace smoothing; Laplace expansion; Laplace expansion; Laplace-Bayes estimator; Laplace\u2013Stieltjes transform; Laplace\u2013Runge\u2013Lenz vector; Nebular hypothesis Ren\u00e9 Descartes 31 March 1596 11 February 1650 Cartesian circle; Cartesian coordinate system; Cartesian diagram; Cartesian diver; Cartesian morphism; Cartesian plane; Cartesian product; Cartesian product of graphs; Cartesian theater; Cartesian tree; Descartes' rule of signs; Descartes' theorem (4 tangent circles); Descartes' theorem (on total angular defect); Folium of Descartes"},{"location":"Coding/GUI/","title":"\ud83d\udda5\ufe0f GUI frameworks comparison","text":"<p>Although XAML widgets can declare their own headers, in Tkinter this is implemented as separate <code>LabelFrame</code> widgets, meant to contain controls.  Tkinter widgets must be slaved in a manner which ultimately leads to the root object initialized by <code>Tk()</code>, conceptually similar to the <code>Window</code> root node in XAML.</p> <p>To refer to UI elements, XAML prefers the term control whereas tkinter and other frameworks prefer widget. Elements that can contain other elements and are used to visually organize the application are known as layout panels.</p> WinUI control GTK tkinter Button Button Button Checkbox CheckButton Checkbutton TextBox Entry Entry ListView TreeView StackPanel Box DatePicker Calendar DateEntry"},{"location":"Coding/GUI/#widgets","title":"Widgets","text":""},{"location":"Coding/GUI/#label","title":"Label","text":"<p>In both GTK and Tkinter frameworks, a window size must be set or else it will collapse to the boundaries of the contained label.</p> PyGTKtkinter <p> </p> <pre><code>import gi\ngi.require_version(\"Gtk\",\"3.0\")\nfrom gi.repository import Gtk\nimport sys\n\n\nclass AppWindow(Gtk.ApplicationWindow):\n\n    def __init__(self, *args, name = \"world\", **kwargs):\n        super().__init__(*args, **kwargs)\n\nlabel = Gtk.Label.new(f\"Hello {name}\")\nself.add(label)\n        self.set_size_request(200, 200)\n\nclass Application(Gtk.Application):\n    def __init__(self, name, *args, **kwargs):\n        self.name = name\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, \n                                    name = self.name, \n                                    title = f\"Hello, {self.name}!\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application(sys.argv[-1])\n    app.run()\n</code></pre> <p></p> <pre><code>import tkinter\nfrom tkinter import ttk\nimport sys\n\n\nclass Window(tkinter.Tk):\n    def __init__(self, name=\"World\"):\n        super().__init__()\n        self.title(f\"Hello, {name}!\")\n        self.geometry(\"200x200\")\nself.resizable(False, False)\nttk.Label(self, text=f\"Hello, {name}!\").grid(column=0, row=0)\n\n\nif __name__ == '__main__':\n    try:\n        win = Window(name=sys.argv[1])\n    except IndexError:\n        win = Window()\n    win.mainloop()\n</code></pre>"},{"location":"Coding/GUI/#date-picker","title":"Date picker","text":"XAMLtkinter <pre><code>&lt;Window\nx:Class=\"EmployeeManager.WinUI.MainWindow\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:EmployeeManager.WinUI\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"&gt;\n\n&lt;DatePicker Header=\"Entry date\"/&gt;\n&lt;/Window&gt;\n</code></pre> <pre><code>import tkinter as tk\nfrom tkinter.ttk import LabelFrame\nfrom tkcalendar import DateEntry\n\n\nwindow = tk.Tk()\nframe=LabelFrame(window, text=\"Entry date: \")\nframe.pack()\n\nDateEntry(frame).pack()\ntk.mainloop()\n</code></pre>"},{"location":"Coding/GUI/#textbox","title":"Textbox","text":"PyGTK <pre><code>import os, sys\n\nimport gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\n\nclass AppWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_border_width(10)\n        prompt_str = \"What is the password for \" + os.getlogin() + \"?\"\n        question = Gtk.Label(label=prompt_str)\n        label = Gtk.Label(label=\"Password:\")\npasswd = Gtk.Entry()\npasswd.set_visibility(False)\n# passwd.set_invisible_char(\"*\")\n        hbox = Gtk.Box(orientation=Gtk.Orientation.HORIZONTAL, spacing=0)\n        hbox.pack_start(label, False, False, 5)\n        hbox.pack_start(passwd, False, False, 5)\n        vbox = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=0)\n        vbox.pack_start(question, False, False, 0)\n        vbox.pack_start(hbox, False, False, 0)\n        self.add(vbox)\n\n\nclass Application(Gtk.Application):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Password\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run(sys.argv)\n</code></pre>"},{"location":"Coding/GUI/#listview","title":"ListView","text":"PyGTK <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.gen_treeview()\n\n        scrolled_win = Gtk.ScrolledWindow.new(None,None)\n        scrolled_win.set_policy(Gtk.PolicyType.AUTOMATIC, Gtk.PolicyType.AUTOMATIC)\n        scrolled_win.add(self.treeview)\n\n        self.add(scrolled_win)\n        self.set_size_request(200,200)\n\n    def get_liststore(self):\n        store = Gtk.ListStore.new((str,))\n        store.append([\"Socrates\"])\n        store.append([\"Plato\"])\n        store.append([\"Aristotle\"])\n        return store\n\n    def gen_treeview(self):\n        self.treeview = Gtk.TreeView.new()\n        self.treeview.set_model(self.get_liststore())\n        self.treeview.append_column(Gtk.TreeViewColumn(\"Greeks\", Gtk.CellRendererText.new(), text=0))\n\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, title=\"Greeks\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Coding/GUI/#toggle-button","title":"Toggle Button","text":"<pre><code>#!/usr/bin/python3\n\nimport sys\nimport gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass AppWindow(Gtk.ApplicationWindow):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_border_width(10)\n        vbox = Gtk.Box.new(orientation=Gtk.Orientation.VERTICAL, spacing=0)\ntoggle1 = Gtk.ToggleButton.new_with_mnemonic(\"_Deactivate the other one!\")\ntoggle2 = Gtk.ToggleButton.new_with_mnemonic(\"_No! Deactivate that one!\")\ntoggle1.connect(\"toggled\", self.on_button_toggled, toggle2)\n        toggle2.connect(\"toggled\", self.on_button_toggled, toggle1)\n        vbox.pack_start(toggle1, True, True, 1)\n        vbox.pack_start(toggle2, True, True, 1)\n        self.add(vbox)\n\n    def on_button_toggled(self, toggle, other_toggle):\n        if (Gtk.ToggleButton.get_active(toggle)):\n            other_toggle.set_sensitive(False)\n        else:\n            other_toggle.set_sensitive(True)\n\nclass Application(Gtk.Application):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\",\n                         **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Toggle Buttons\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run(sys.argv)\n</code></pre>"},{"location":"Coding/GUI/#tasks","title":"Tasks","text":""},{"location":"Coding/GUI/#wired-brain-coffee","title":"Wired Brain Coffee","text":"tkinter <pre><code>import tkinter as tk\nfrom tkinter.ttk import Button\nfrom tkinter.ttk import Labelframe\nfrom tkinter.ttk import Label\nfrom tkinter.ttk import Entry\nfrom tkinter.ttk import Checkbutton\n# from tkinter.ttk import \nimport tkcalendar\n\nLabelFrame = Labelframe\n\nwindow = tk.Tk()\nwindow.title(\"Wired Brain Coffee\")\n\nmain = Labelframe(window)\nmain.pack()\n\nheadline = Label(main, text=\"Wired Brain Coffee\")\nheadline.grid(row=0, column=0, columnspan=2)\n\nsidebar = LabelFrame(main)\nsidebar.grid(row=1, column=0)\n\nrefresh = Button(sidebar, text=\"Refresh\")\nrefresh.pack()\n\nmainarea = LabelFrame(main)\nmainarea.grid(row=1, column=1)\n\nfirstname_frame = Labelframe(mainarea, text=\"First name\")\nfirstname_frame.pack()\nfirstname_textbox = Entry(firstname_frame).pack()\n# firstname_textbox.pack(expand='yes', fill='both')\n\ndateentry_frame = Labelframe(mainarea, text=\"Entry date\")\ndateentry_frame.pack()\ndateentry_picker = tkcalendar.DateEntry(dateentry_frame)\ndateentry_picker.pack()\n\njobrole_frame = Labelframe(mainarea, text=\"Job Role\")\njobrole_frame.pack()\njobrole_textbox = Entry(jobrole_frame).pack()\n# jobrole_textbox.pack(expand='yes', fill='both')\n\niscoffeedrinker = Checkbutton(mainarea, text=\"Is coffee drinker?\").pack()\n# iscoffeedrinker.pack()\n\nwindow.resizable=(True,True)\nwindow.mainloop()\n</code></pre>"},{"location":"Coding/GUI/#raven-lines","title":"Raven lines","text":"PyGTK <pre><code>import sys\nimport gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport itertools\n\nclass AppWindow(Gtk.ApplicationWindow):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_border_width(25)\n        button = Gtk.Button.new_with_mnemonic(\"_Raven\")\n        button.connect(\"clicked\", self.on_button_clicked)\n        button.set_relief(Gtk.ReliefStyle.NORMAL)\n        self.add(button)\n        self.set_size_request(200, 100)\n\n        with open(\"/home/jasper/notes/docs/Coding/Dogfood/raven.txt\") as f:\n            self.raven = itertools.cycle([l.strip() for l in f.readlines()])\n\n    def on_button_clicked(self, button):\nprint(next(self.raven))\nclass Application(Gtk.Application):\n\n    def __init__(self, argv , *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\",\n                        **kwargs)\n        self.name=argv[-1]\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, \n                                    title=f\"Hello {self.name}!\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application(sys.argv)\n    app.run(sys.argv)\n</code></pre>"},{"location":"Coding/GUI/#login-dialog-box","title":"Login dialog box","text":"PyGTK <pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(300,300)\n        grid = Gtk.Grid.new()\n        image = Gtk.Image.new_from_icon_name(\"dialog-password\", Gtk.IconSize.DIALOG)\n        grid.attach(image, 0, 0, 1, 1)\n        grid.attach(Gtk.Label(label=\"Enter your credentials.\"), 0, 1, 2, 1)\n        grid.attach(Gtk.Label(label=\"User name:\"), 0, 2, 1, 1)\n        grid.attach(Gtk.Entry(), 1, 2, 1, 1)\n        grid.attach(Gtk.Label(label=\"Password:\"), 0, 3, 1, 1)\n        grid.attach(Gtk.Entry(visibility=False), 1, 3, 1, 1)\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id=\"org.example.myapp\")\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, title=\"Hello, World!\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Coding/GUI/#timeshift-clone","title":"Timeshift clone","text":"TypeLocationScheduleUsers"},{"location":"Coding/Mermaid/","title":"Mermaid","text":"<p>From here <pre><code>%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'rotateCommitLabel': false}} }%%\ngitGraph\n  commit id: \"feat(api): ...\"\n  commit id: \"a\"\n  commit id: \"b\"\n  commit id: \"fix(client): .extra long label..\"\n  branch c2\n  commit id: \"feat(modules): ...\"\n  commit id: \"test(client): ...\"\n  checkout main\n  commit id: \"fix(api): ...\"\n  commit id: \"ci: ...\"\n  branch b1\n  commit\n  branch b2\n  commit</code></pre></p>"},{"location":"Coding/Others/","title":"\ud83e\uddaa Perl","text":"<p>Perl6 offers an interactive shell, but previous versions needed a specialized command to be run through the interpreter</p> <p>General syntax - Semicolons terminate lines - Whitespace is irrelevant, except inside strings - Enclosing function arguments in parentheses is optional</p> <p>Inline execution of code</p> <p>Compare similar syntax for sed (MP:17, YUG:614) <pre><code>perl6 -e 'code'\n</code></pre> Enable warning messages <pre><code>perl6 -w\n</code></pre> Request an implicit input-reading loop that stores records in <code>$_</code> <pre><code>perl6 -n\n</code></pre> Request an implicit input-reading loop that stores records in <code>$_</code> and automatically prints that variable after optional processing of its contents <pre><code>perl6 -p\n</code></pre></p> <p><code>-l</code> :automatically insert an output record separator at end of the output of <code>print</code></p> <code>-0digits</code> define the character that marks the end of an input record, using octal digits <p>Shebang <pre><code>#!/usr/bin/env perl`\n</code></pre></p> <p>Perl variables are of three types, associated with 3 corresponding sigils which begin the identifiers   - Scalars: <code>$</code>   - Arrays: <code>@</code>   - Hashes (associative arrays): <code>%</code></p> <p><code>my</code> declares and initializes a variable.  Variables can be typed by placing a type between <code>my</code> and the identifier. <pre><code>my $animal = \"camel\"\nmy Str $animal = \"camel\"\n</code></pre></p> <p>Predefined variables <pre><code>$.    # current line number\n$_    # conventionally used as a default pattern space for searches; is already initialized but not defined; does **not** function like in bash\n$[    # current array base subscript (0 by default)\n$/    # input line separator (newline by default)\n@ARGV # arguments passed from the command-line; index 0 is the first **additional** argument passed subsequent to the name of the script\n</code></pre></p> <p>Sources:</p> <ul> <li>Python to Perl6 - nutshell</li> </ul>"},{"location":"Coding/Others/#scalar","title":"Scalar","text":""},{"location":"Coding/Others/#operations","title":"Operations","text":"<code>$pbj = 'peanut butter'.' and '.'jelly'</code> string concatenation was performed with <code>.</code> operator in Perl5 (YUG:617) <code>$pbj = 'peanut butter'~' and '~'jelly'</code> string concatenation now performed with <code>~</code> operator in Perl6 <code>print '*' x 40</code> <code>x</code> operator repeats the string (YUG:617)"},{"location":"Coding/Others/#array","title":"Array","text":"<code>my @array = (element, element, element)</code> | <code>my @array = element, element, elmeent</code> initialize arrays by (optionally) enclosing elements in parentheses (not brackets) <code>@array[n]</code> retrieve element at (0-based) index {n} <code>$matrix[0]-&gt;[0]</code> arrow or infix operator can also be used to dereference array refrences <code>$#array</code> return number of the last subscript in the array (effectively length-1) <pre><code>@colors=('red','green','yellow','orange');\n($c[0], $c[1], $c[3], $c[5]) = @colors;\n</code></pre> arrays can be declared by initializing constituent elements (array slicing) (PBX:85)"},{"location":"Coding/Others/#operations_1","title":"Operations","text":"<code>@list=(2..10);</code> assign a range of numbers (arr-rng) (PBX:81) <code>@letters=( 'A' .. 'Z' );</code> assign a range of letters (PBX:82) <code>my @biglist = |@smalllist, |@littlelist</code> array unpacking is done using the <code>|</code> prefix operator, allowing for concatenation"},{"location":"Coding/Others/#hash","title":"Hash","text":"Hashes are key-value pairs <code>my %fruits = (apple =&gt; red, ...)</code> declare a hash <code>%fruits{'apple'}</code> values are obtained by referencing the key in curly braces (vice brackets) (p6)"},{"location":"Coding/Others/#functions","title":"Functions","text":"<code>defined</code> return 1 if the variable passed as argument has a value and null if it does not <code>die mesg</code> print {mesg} and exit; used to implement error-handling <p><code>join</code> (YUG...)</p> <code>print</code> print to STDOUT, but with no ending string specified <code>prompt</code> take input from STDIN <code>read filehandle, variable, n</code> read {n} bytes into {variable} from {filehandle} (deprecated in Perl6) (PBX:96) <code>say</code> print to STDOUT, but with a newline at the end (Perl6) <code>undef</code> undefine a defined variable, releasing the memory allocated for it"},{"location":"Coding/Others/#arrays","title":"Arrays","text":"<code>pop @array</code> remove and return last element of {array} <code>push @array, elements</code> append {elements} to {array} <code>shift @array</code> remove and return first element of {array} <code>splice @array, index, n[, elements]</code> remove {n} {elements} from {array}, starting at {index}; or, add {elements} to {array} at {index} <code>unshift @array, elements</code> prepend elements to an array (on the left side)"},{"location":"Coding/Others/#strings","title":"Strings","text":"<code>chomp</code> remove last character from a scalar or last character from each word in an array if and only if that character is the input line separator <code>chop</code> remove last character from a scalar or last character from each word in an array; intended for use in removing newlines <code>s/pattern/substitution/g ;</code> substitution command works similar to sed <code>tr/regex1/regex2/ ;</code> replace instances of {regex1} with {regex2}; like replacing lowercase letters with uppercase <p><code>split /delim/</code></p>"},{"location":"Coding/Others/#hashes","title":"Hashes","text":"<code>keys(%hash) ;</code> return an array of the keys of {hash} <code>values(%hash) ;</code> return an array of the values of {hash}"},{"location":"Coding/Others/#filehandles","title":"Filehandles","text":"<code>&lt;&gt;</code> null filehandle (YUG:618) <code>INFILE</code> filehandle used when opening a file for input (YUG:632) <code>OUTFILE</code> filehandle used when opening a file for writing <code>STDIN</code> deprecated in Perl6 (PBX:96)"},{"location":"Coding/Others/#special-literals","title":"Special literals","text":"<p>These have been deprecated in Perl6 (PBX:51)</p> <code>__LINE__</code> (Perl5) | <code>$?LINE</code> (Perl6) current line number <code>__FILE__</code> (Perl5) | <code>$?FILE</code> (Perl6) current filename <code>__END__</code> logical end of the script (\\004 in Unix and \\032 in Windows) <code>__DATA__</code> special filehandle <code>__PACKAGE__</code> (Perl5) | <code>$?PACKAGE</code> (Perl6) current package; default package is main"},{"location":"Coding/Others/#control-flow","title":"Control flow","text":""},{"location":"Coding/Others/#loops","title":"Loops","text":"<code>for @array { action }</code> | deprecated: <code>foreach $var (@arr) { statements}</code> <code>foreach</code> loops have been replaced by <code>for</code> in Perl6 <code>for @array { .print }</code> | deprecated: <code>for @array { print }</code> here the <code>print</code> function is working as a method on <code>$_</code>, the default variable <code>for @array1 Z @array2</code> zip up elements of two separate arrays (Source)[https://perl6advent.wordpress.com/2009/12/07/day-7-looping-for-fun-and-profit/]"},{"location":"Coding/Others/#documentation","title":"Documentation","text":"<p>Implemented using markup language called \"pod\", which uses directives distinguishable by the <code>=</code> character</p> <code>=begin pod</code> start documentation <code>=end pod</code> end documentation"},{"location":"Coding/Others/#glossary","title":"Glossary","text":"lvalue any value that can be \"assigned to\", and which represents a named region of storage (PBX:71) array slice when the elements of one array are assigned values from another (PBX:84)"},{"location":"Coding/Others/#object-oriented-programming","title":"Object-oriented programming","text":"<p>instance variables declared with <code>has</code> keyword: <code>has $.name;</code> class attributes are declard with <code>my</code> keyword, then a method is declared to allow it to be referenced </p>"},{"location":"Coding/Others/#math","title":"Math","text":"<p>Mathematical consonants have their own keywords in Perl6: <code>pi</code>, <code>e</code>, and <code>tau</code> (2*pi)</p>"},{"location":"Coding/Others/#other-topics","title":"Other topics","text":""},{"location":"Coding/Others/#rename-function-in-debian","title":"rename function in Debian","text":"<p>The Rename Command</p>"},{"location":"Coding/Others/#visual-basic","title":"Visual Basic","text":"<p>VB script doing manual backup <pre><code>On Error Resume Next \nSet objNetwork = WScript.CreateObject(\"WScript.Network\")\nobjNetwork.RemoveNetworkDrive \"P:\"\nobjNetwork.MapNetworkDrive \"P:\", \"\\\\islfs02.hlm.ad.moffitt.usf.edu\\research\\lab_proteomics\",, \"hlm\\proteomics_backup\",\"orbitrap\"\n\nDim WSHShell\nSet WSHShell = WScript.CreateObject(\"WScript.Shell\")\nq = \"\"\"\"\nsp = \" \"\n\nfrom = q &amp; \"c:\\xcalibur\\Data\\*.*\" &amp; q\ndest = sp &amp; q &amp; \"p:\\backup\\QE_FOCUS\\data\" &amp; q\ncmd = \"c:\\windows\\system32\\xcopy \" &amp; from &amp; dest &amp; \" /D /H /E /C /K /R /Y /I\"\nWSHShell.Run cmd, 1, true\n\nfrom = q &amp; \"c:\\xcalibur\\methods\\*.*\" &amp; q\ndest = sp &amp; q &amp; \"p:\\backup\\QE_FOCUS\\methods\" &amp; q\ncmd = \"c:\\windows\\system32\\xcopy \" &amp; from &amp; dest &amp; \" /D /H /E /C /K /R /Y /I\"\nWSHShell.Run cmd, 1, true\n\nSet WSHShell = Nothing\nWScript.Quit(0)\n</code></pre></p>"},{"location":"Coding/Python/","title":"\ud83d\udc0d Python","text":""},{"location":"Coding/Python/#decorators","title":"Decorators","text":"<p>Sources:</p> <ul> <li>Primer on Python Decorators </li> <li>YouTube tutorial</li> </ul> <p>A decorator is any function that accepts a function and returns a function.</p> <p>Decorators are one of the main ways that Python implements functional programming principles.</p> <p>Functions are first-class objects and can be passed as parameters. <pre><code>import logging\n\ndef hello_wrapper(name, func):\n  func(f'Hello {name}')\n\nhello_wrapper(\"world\", func=print) # Hello world\nhello_wrapper(\"logs\", func=logging.warning) # WARNING:root:Hello logs\n</code></pre> <pre><code>with open('hello.txt', 'w') as f:\n  hello_wrapper('everyone!', func=f.write)\n</code></pre> <pre><code>import random\n\ndef anagram(t):\n  l = [c for c in t]\n  random.shuffle(l)\n  print(\"\".join(l))\n\nhello_wrapper('Japushku', anagram) #  eHoulhluaskpJ\n</code></pre> The function has to be passed as a reference, actually calling it will cause the wrapper function to attempt to execute the value returned by the inner function. <pre><code>hello_wrapper(\"world\", func=print()) # Error\n</code></pre> <pre><code>def outer():\n  print('Hi from the outer function')\n  def inner():\n    print('Hello from the inner function')\n  inner()\n</code></pre></p> <p>We can use the <code>__name__</code> attribute to access a passed function's name. <pre><code>def hello(func):\n  print(f'Hello {func.__name__}')\n\nhello(outer) # Hello outer\n</code></pre> We can also return functions, which can then be invoked <pre><code>def hello(func):\n  print(f'Hello {func.__name__}')\n  return func\n\nhello(outer)()  \n'''\nHi from the outer function\nHello from the inner function\n'''\n\nnew_outer = hello(outer)\nnew_outer is outer # True\n</code></pre></p> <p><pre><code>def wrapper(func):\n  print(f'Before {func.__name__}')\n  func()\n  print(f'After {func.__name__}')\n\nwrapper(outer)\n'''\nBefore outer\nHi from the outer function\nHello from the inner function\nAfter outer\n'''\n</code></pre> The true decorator pattern appears here, where <code>wrapper</code> is called the decorator and <code>outer</code> has been decorated. <pre><code>def wrapper(func):\n  def _wrapper():\n    print(f'Before {func.__name__}')\n    func()\n    print(f'After {func.__name__}')\n  return _wrapper\n\nouter = wrapper(outer)\n</code></pre> But the usual syntax since Python 2.4 is to place the decorator on the line above the decorated function, preceded by <code>@</code>: <pre><code>@wrapper\ndef outer():\n  print('Hi from the outer function')\n  def inner():\n    print('Hello from the inner function')\n  inner()\n</code></pre> <code>_wrapper</code> here does not accept any positional arguments, so wrapping functions that take arguments will produce a <code>TypeError</code> <pre><code>@wrapper\ndef say_hello(name):\n  print(f'Hello {name}!') # error\n</code></pre> The solution is to incorporate <code>*args, **kwargs</code> into the definition of the inner function, as well as the invocation of the function passed in. <pre><code>def wrapper(func):\n  def _wrapper(*args, **kwargs):\n    print(f'Before {func.__name__}')\n    func(*args, **kwargs)\n    print(f'After {func.__name__}')\n  return _wrapper\n</code></pre> Returned values are not captured yet: <pre><code>def wrapper(func):\n  def _wrapper(*args, **kwargs):\n    print(f'Before {func.__name__}')\n    value = func(*args, **kwargs)\n    print(f'After {func.__name__}')\n    return value\n  return _wrapper\n</code></pre> Inspecting the decorated function's <code>__name__</code> attribute reveals that it is still named <code>_wrapper</code> <pre><code>say_hello.__name__ # '_wrapper'\n</code></pre> This is also true for other attributes, including docstring. <code>functools.wraps</code> is a decorator factory to reassign attributes to the wrapped function. This is considered superior to the <code>functools.update_wrapper</code> function which is also available. <pre><code>def wrapper(func):\n  @functools.wraps(func)\n  def _wrapper(*args, **kwargs):\n    print(f'Before {func.__name__}')\n    value = func(*args, **kwargs)\n    print(f'After {func.__name__}')\n    return value\n  return _wrapper\n</code></pre> This forms an ideal starting template for the creation of custom decorators.</p>"},{"location":"Coding/Python/#classes","title":"Classes","text":""},{"location":"Coding/Python/#properties","title":"Properties","text":"<p>In the Python documentation, attributes accessed with accessor functions are called managed attributes, which makes the term equivalent to properties in C#.</p> <p>Three methods can be defined using the <code>@property</code> decorator</p> ConstructorGetterSetterDeleter <pre><code>def __init__(self, price):\n    self._price = price\n</code></pre> <pre><code>@property\ndef price(self):\n  return self._price\n</code></pre> <pre><code>@price.setter\ndef price(self, new_price):\n    if new_price &gt; 0:\n        self._price = new_price\n    else:\n        raise ValueError\n</code></pre> <pre><code>@price.deleter\ndef price(self):\n    del self._price\n</code></pre>"},{"location":"Coding/Python/#class-methods","title":"Class methods","text":"<p>The <code>@classmethod</code> decorator prevents the interpreter from passing in the instantiated object using <code>self</code>, rather the class itself is passed in as the <code>cls</code> argument. This means that the methods decorated as such must take not <code>self</code> as the first argument but <code>cls</code></p> <pre><code>@classmethod\ndef classmethod(cls):\n  pass\n</code></pre> <p>The <code>@staticmethod</code> decorator prevents the interpreter from passing any additional arguments whatsoever. The resulting method has no access to the object itself nor the class and functions like a procedurally defined function.</p>"},{"location":"Coding/Python/#formatting","title":"Formatting","text":"<p><code>flake8</code>, <code>black</code>, and <code>yapf</code> (Google) are CLI tools used to automatically format Python code.</p>"},{"location":"Coding/Python/#web-frameworks","title":"Web frameworks","text":""},{"location":"Coding/Python/#django","title":"Django","text":"<p>A typical Django project contains multiple apps, which are Python packages containing their own models, views, templates, and urls.</p> <ul> <li>A model is the single definitive source of information about your data, and contains the essential fields and behaviors of the data you're storing. </li> <li> <p>Migrations are necessary when Model classes are updated. And for projects sufficiently advanced, migration scripts must be developed for any such changes.</p> </li> <li> <p>Async Server Gateway Interface (ASGI) is the spiritual successor to, and superset of, WSGI. It implements the new Python standard for asynchronous web servers and applications, which resembles that of websockets.  From WSGI to ASGI</p> </li> <li>WSGI is coupled tightly with the synchronous request-response model familiar from HTTP 1.1.</li> </ul> <p>URL patterns (stored in the <code>urlpatterns</code> list defined in the project-level urls.py file) can be parameterized. Here, the template <code>&lt;int:x&gt;</code> specifies an integer to be assigned to the view parameter <code>x</code>. <pre><code>from app.views import my_view\n\nurlpatterns = [\n  path('/example/&lt;int:x&gt;', my_view)\n]\n</code></pre> <code>modelform_factory</code> can be used to automatically produce a webform from a Model class. <pre><code># views.py\n\nMeetingForm = modelform_factory(Meeting, exclude=[])\n</code></pre> This can be placed into a template using the <code>{{ form }}</code> template tag. Note, a <code>{% csrf_token %}</code> template tag must also be present for a submit button to work. <pre><code>{% block content %}\n&lt;h1&gt;Plan a new meeting&lt;/h1&gt;\n&lt;form method=\"POST\"&gt;\n  &lt;table&gt;\n    {{form}}\n  &lt;/table&gt;\n  {% csrf_token %}\n  &lt;button type=\"submit\"&gt;Create&lt;/button&gt;\n&lt;/form&gt;\n{% endblock content %}\n</code></pre> When the <code>modelform_factory</code> class has been defined, it is instantiated within the view function. This object exposes several methods: - is_valid data validation is strongly recommended for any form input - save imports the validated form data into the database <pre><code>def new(request):\n  if request.method == 'POST':\n    form = MeetingForm(request.POST)\n    if form.is_valid():\n      form.save()\n      return redirect(\"home\")\n  else:\n    form = MeetingForm()\n\n  return render(request, \"meetings/new.html\", {\"form\": form})\n</code></pre></p>"},{"location":"Coding/Python/#template","title":"Template","text":"<p>Django templates are HTML files with additional markup to signify places where data can be dynamically inserted. The data used by the views file is called the template context.</p> <p>Templates must be placed within the /templates folder within the app, and it is considered best practice to place templates within a nested subdirectory within it, e.g. /templates/app.</p> <p>Django template tags are specified beween <code>{% .. %}</code> and allow for interpolation of data.</p> <pre><code>&lt;ul&gt;\n  {% for m in meetings %}\n\n  {% endfor %}\n&lt;/ul&gt;\n</code></pre> <p>URLs can be built by using the <code>url</code> template tag, specifying the name of a URL <pre><code>urlpatterns = [\n  path('', home, name='home')\n]\n</code></pre> <pre><code>&lt;a href=\"{% url 'home' %}\"&gt;Home&lt;/a&gt;\n</code></pre></p>"},{"location":"Coding/Python/#models","title":"Models","text":"<p> Models</p> <p>In Django, a Model class is mapped to a database table. Each object is a record in that table.</p> <p>Model objects expose several attributes and methods</p> <p>Get all objects <pre><code>meetings = Meeting.objects.all()\n</code></pre> Get count of objects in database <pre><code>count = Meeting.objects.count()\n</code></pre> Query for a specific object <pre><code>meeting = Meeting.objects.get(pk=id)\n</code></pre> <code>get_object_or_404</code> may be better for most cases <pre><code>meeting = get_object_or_404(Meeting, pk=id)\n</code></pre></p> <p>Adding a new app <pre><code>python manage.py startapp app\n</code></pre> Then add to settings.py in project directory <pre><code>INSTALLED_APPS = [\n  # ...\n  'app',\n]\n</code></pre></p> <p>There appears to be much flexibility in the arrangement of input controls in a form.</p> <p>So long as the Submit button is child to the <code>form</code> element, tasks are accepted in the To-Do app.</p> <p>Per Bulma documentation, the <code>field</code> class is intended as a container for <code>label.label</code>s, <code>.control</code>s, and optional <code>p.help</code> text. </p> <p>In contrast, <code>control</code> is a block container meant to enhance single form controls and can only contain <code>input</code>, <code>select</code>, <code>button</code>, or <code>icon</code> elements.  <pre><code>form.field(method=\"POST\", action=\"/\")\n    label.label Enter something to do\n    .control\n| {{form.title}}\n        | {% csrf_token %}\n    button.button.is-primary(type=\"submit\") Submit\n</code></pre></p>"},{"location":"Coding/Python/#fastapi","title":"FastAPI","text":"<p>Variables values can be taken from the route or from query parameters following a question mark.</p> RoutesQuery parameters <pre><code>from fastapi import FastAPI\n\nstarships = FastAPI()\n\n@starships.get(\"/starships/{registry}\")\ndef get_starship(name: str):\n    return {\"response\": f\"Hello, {name}\"}\n</code></pre> <pre><code>from fastapi import FastAPI\n\nstarships = FastAPI()\n\n@starships.get(\"/\")\ndef get_starship(name: str = \"world\"):\n    return {\"response\": f\"Hello, {name}\"}\n</code></pre> <p>FastAPI is notable for being able to use type hints to construct data models, which are much lighter than the object relational models used by other frameworks.</p> FastAPIDjango <pre><code>from pydantic import BaseModel\n\nclass Starship(BaseModel):\n    name : str\n    registry : str\n    crew : int\n</code></pre> <pre><code>from django.db import models\n\nclass Starship(models.Model):\n    name = models.CharField(max_length=50)\n    registry = models.CharField(max_length=15)\n    crew = models.IntegerField()\n</code></pre> <p>Dogfood data can be incorporated by using the keyword argument unpacking or \"double splat\" operator (<code>**</code>)</p> <pre><code>data = {\"name\": \"USS Enterprise\", \"registry\" : \"NCC-1701\", \"crew\" : 203}\nenterprise = Starship(**data)\n</code></pre> <p>POST method definitions then can use this newly defined class to validate posted data</p> <pre><code>db = []\n\n@app.post(\"/starships\")\nasync def create_starship(starship : Starship):\n    db.append(starship)\n</code></pre> <p>FastAPI supports Jinja templates to serve HTML templates <pre><code>import fastapi\nfrom fastapi.templating import Jinja2Templates\n\n# specifies the directory where templates are to be found\ntemplates = Jinja2Templates(\"templates\") \n\napi = fastapi.APIRouter()\n\n@api.get('/')\ndef index(request: starlette.requests.Request):\n    return templates.TemplateResponse(\"helloworld.html\", {\"request\" : request})\n</code></pre></p> <p>By default, FastAPI also exposes web applications at /docs where you can test out all the exposed API methods.</p> <p>FastAPI integrates with ASGI servers like Uvicorn and Hypercorn, which can run a specific web application by name from the command-line or from within the script:</p> ShellPython <pre><code>uvicorn main:starships --port 7000\n</code></pre> <pre><code>import uvicorn\n\nuvicorn.run(starships, port=7000)\n</code></pre>"},{"location":"Coding/Python/#virtual-environments","title":"Virtual environments","text":""},{"location":"Coding/Python/#pipenv","title":"pipenv","text":"<pre><code>pipenv --python 3.6\n</code></pre>"},{"location":"Coding/Python/#venv","title":"venv","text":"<p>Create a virtual environment named <code>project</code> <pre><code>python -m venv project\n</code></pre></p>"},{"location":"Coding/Python/#virtualenv","title":"virtualenv","text":"<p>Create a virtual environment named <code>project</code> using a different version of Python <pre><code>virtualenv -p /usr/bin/python2 project\n</code></pre></p>"},{"location":"Coding/Python/#testing","title":"Testing","text":"<p>Pytest is a popular testing framework preferred to unittest by many Python developers because it follows Pythonic conventions more closely. In contrast to unittest's custom methods, pytest relies on the builtin <code>assert</code> statement.</p> pytestunittestClass under test <p><pre><code>from phonebook import PhoneBook\nimport pytest\n\n@pytest.fixture\ndef phonebook():\n    phonebook = PhoneBook()\n    yield phonebook\n    phonebook.clear()\n\ndef test_lookup_by_name(phonebook):\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre> <pre><code>python -m pytest\n</code></pre></p> <p><pre><code>import unittest\n\nfrom phonebook import PhoneBook\n\n\nclass PhoneBookTest(unittest.TestCase):\n\n    def test_lookup_by_name(self):\n        self.phonebook.add(\"Bob\", \"12345\")\n        number = self.phonebook.lookup(\"Bob\")\n        self.assertEqual(\"12345\", number)\n\n    def test_missing_name(self):\n        with self.assertRaises(KeyError):\n            self.phonebook.lookup(\"missing\")\n\n    def test_empty_phonebook_is_consistent(self):\n        self.assertTrue(self.phonebook.is_consistent())\n\n    def setUp(self) -&gt; None:\n        self.phonebook = PhoneBook()\n\n    def tearDown(self) -&gt; None:\n        self.phonebook.clear()\n</code></pre> <pre><code>python -m unittest\n</code></pre></p> <pre><code>import os\n\nclass PhoneBook:\n    def __init__(self, cache_directory = os.getcwd()):\n        self.numbers = {}\n        self.filename = os.path.join(cache_directory, \"phonebook.txt\")\n        self.cache = open(self.filename, \"w\")\n\n    def add(self, name, number):\n        self.numbers[name] = number\n\n    def lookup(self, name):\n        return self.numbers[name]\n\n    def is_consistent(self):\n        return True\n\n    def names(self):\n        return set(self.numbers.keys())\n\n    def clear(self):\n        self.cache.close()\n        os.remove(self.filename )\n</code></pre>"},{"location":"Coding/Python/#doctest","title":"Doctest","text":"<p>A doctest is a docstring containing what looks like interactive Python sessions. Python Docs <pre><code>\"\"\"\nReturn the factorial of n, an exact integer &gt;= 0.\n\n&gt;&gt;&gt; [factorial(n) for n in range(6)]\n[1, 1, 2, 6, 24, 120]\n&gt;&gt;&gt; factorial(30)\n265252859812191058636308480000000\n&gt;&gt;&gt; factorial(-1)\nTraceback (most recent call last):\n    ...\nValueError: n must be &gt;= 0\n\nFactorials of floats are OK, but the float must be an exact integer:\n&gt;&gt;&gt; factorial(30.1)\nTraceback (most recent call last):\n    ...\nValueError: n must be exact integer\n&gt;&gt;&gt; factorial(30.0)\n265252859812191058636308480000000\n\nIt must also not be ridiculously large:\n&gt;&gt;&gt; factorial(1e100)\nTraceback (most recent call last):\n    ...\nOverflowError: n too large\n\"\"\"\n</code></pre> This can then be run  <pre><code>if __name__ == '__main__':\n  import doctest\n  doctest.testmod()\n</code></pre></p>"},{"location":"Coding/Python/#pytest","title":"pytest","text":"<p>PyTest relies on the built-in <code>assert</code> statement.</p>"},{"location":"Coding/Python/#fixtures","title":"Fixtures","text":"<p>The <code>@pytest.fixture</code> decorator facilitiates the creation of test fixtures. The fixture function's name is used as argument to the test case, and the value returned can be used by the logic within.  (src)</p> <p>Any clean-up logic can be invoked in this fixture as well by replacing <code>return</code> with <code>yield</code>. Pytest also provides its own <code>tmpdir</code> test fixture for temporary directories. (src)</p> BeforeAftertmpdir <pre><code>from phonebook import PhoneBook\nimport pytest\n\n\n\n\n\n\n\ndef test_lookup_by_name(phonebook):\n    phonebook=PhoneBook()\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    phonebook = PhoneBook()\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre> <pre><code>from phonebook import PhoneBook\nimport pytest\n\n@pytest.fixture\ndef phonebook():\n    phonebook = PhoneBook()\n    yield phonebook\n    phonebook.clear()\n\ndef test_lookup_by_name(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    # phonebook = PhoneBook()\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre> <pre><code>from phonebook import PhoneBook\nimport pytest\n\n@pytest.fixture\ndef phonebook(tmpdir):\n    phonebook = PhoneBook(tmpdir)\n    return phonebook\n\n\ndef test_lookup_by_name(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    # phonebook = PhoneBook()\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre>"},{"location":"Coding/Python/#unittest","title":"unittest","text":"<p>unittest is a testing framework built into Python's Standard Library that was based on JUnit.  unittest came out in 2001, when JUnit was being ported and adapted to many languages. Collectively, these frameworks were referred to as the xUnit family. unittest's method names do not follow Python conventions because it predates the PEP-8 naming standard.</p> <p>unittest allows you to create test classes that inherit from <code>TestCase</code>.</p>"},{"location":"Coding/Python/#assertions","title":"Assertions","text":"<p>Assertions are implemented in individual methods of the TestCase subclass through unittest methods like <code>assertEqual</code> and <code>assertRaises</code>, etc. Notably, TestCase subclasses must not have an <code>__init__()</code> constructor method defined.</p> <pre><code>def test_lookup_by_name(self):\n    phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"12345\")\n    number = phonebook.lookup(\"Bob\")\n    self.assertEqual(\"12345\", number)\n</code></pre> <p><code>assertRaises</code> must be placed in a context manager. Here, the test case will run the code within the <code>with</code> block and check to make sure it raises the specified exception: <code>KeyError</code>: (src)</p> <pre><code>def test_missing_name(self):\n    fleet = Fleet()\n    with self.assertRaises(KeyError):\n        fleet.lookup(\"bla\")\n</code></pre>"},{"location":"Coding/Python/#fixtures_1","title":"Fixtures","text":"<p><code>setUp</code> is run before every test method, allowing a test fixture to be created to avoid repetitive code. <code>tearDown</code> is called after every method, which allows these resources to be released, even if the test case raises an exception. However, if it is <code>setUp</code> that raises the exception, then neither the test case nor <code>tearDown</code> will run. (src, src)</p> BeforeAfter <pre><code>import unittest\n\nfrom phonebook import PhoneBook\n\n\nclass PhoneBookTest(unittest.TestCase):\n\n\n\n\n\n\n    def test_lookup_by_name(self):\n        phonebook = PhoneBook()\n        phonebook.add(\"Bob\", \"12345\")\n        number = phonebook.lookup(\"Bob\")\n        self.assertEqual(\"12345\", number)\n\n    def test_missing_name(self):\n        phonebook = PhoneBook()\n        with self.assertRaises(KeyError):\n            phonebook.lookup(\"missing\")\n\n    @unittest.skip(\"WIP\")\n    def test_empty_phonebook_is_consistent(self):\n        phonebook = PhoneBook()\n        self.assertTrue(phonebook.is_consistent())\n</code></pre> <pre><code>import unittest\n\nfrom phonebook import PhoneBook\n\n\nclass PhoneBookTest(unittest.TestCase):\n    def setUp(self) -&gt; None:\n        self.phonebook = PhoneBook()\n\n    def tearDown(self) -&gt; None:\n        self.phonebook.clear()\n\n    def test_lookup_by_name(self):\n        # phonebook = PhoneBook()\n        self.phonebook.add(\"Bob\", \"12345\")\n        number = self.phonebook.lookup(\"Bob\")\n        self.assertEqual(\"12345\", number)\n\n    def test_missing_name(self):\n        # phonebook = PhoneBook()\n        with self.assertRaises(KeyError):\n            self.phonebook.lookup(\"missing\")\n\n    @unittest.skip(\"WIP\")\n    def test_empty_phonebook_is_consistent(self):\n        # phonebook = PhoneBook()\n        self.assertTrue(self.phonebook.is_consistent())\n</code></pre> <p>The <code>@unittest.skip</code> decorator will tell the test runner to skip the decorated test case (src)</p> <pre><code>@unittest.skip(\"WIP\")\ndef test_empty_phonebook_is_consistent(self):\n    phonebook = PhoneBook()\n    self.assertTrue(phonebook.is_consistent())\n</code></pre> <p>The command line entry point is made with a call to <code>unittest.main()</code>, which executes the tests. (src)</p> <pre><code>import unittest\n\nfrom my_sum import sum\n\nclass TestSum(unittest.TestCase):\n  def test_list_int(self):\n\"\"\"\n    Test that it can sum a list of integers\n    \"\"\"\n    data = [1, 2, 3]\n    result = sum(data)\n    self.assertEqual(result, 6)\n\nif __name__ == '__main__':\n  unittest.main()\n</code></pre>"},{"location":"Coding/Python/#integration-tests","title":"Integration tests","text":"<p>By convention, tests are put in their own directory as sibling to the main module ( in order to be able to import it ). Integration and unit tests should be organized separately.</p> <pre><code>.\n\u251c\u2500\u2500 project\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 integration\n    \u2514\u2500\u2500 unit\n</code></pre> <p>Run all integration tests within specified directory. <pre><code>python -m unittest discover -s tests/integration\n</code></pre></p>"},{"location":"Coding/Python/#tasks","title":"Tasks","text":"<p>Deserialize</p> YAML JSON <pre><code>import yaml\n\n\nwith open('./starships.yaml') as f:\nstarships = yaml.safe_load(f)\n</code></pre> <pre><code>import json\n\n\nwith open('./starships.json') as f:\n    data=json.load(f)\n</code></pre> <p>Serialize</p> YAML JSON <pre><code>import yaml\n\n\nwith open('./starships.yaml','w') as f:\n    yaml.dump(starships, f)\n</code></pre> <pre><code>import json\n\n\nwith open('/starships.json',\"w\") as f:\n    json.dump(data,f)\n</code></pre>"},{"location":"Coding/Python/#modules","title":"Modules","text":"<p>When learning unfamiliar packages and importing them in a demonstration script, care must be taken that the  demonstration script does not have the same name as the package being studied.  If so, attempting to import the package while in an interpreter within that directory will cause the interpreter to try  importing the incomplete script and not the package.</p> <p>When running a Python interpreter within this directory, the files \"calc\" and \"main\" can be imported as modules by specifying their names with no file extension. <pre><code>. \n\u251c\u2500\u2500 calc.py \n\u2514\u2500\u2500 main.py\n</code></pre> <pre><code>import calc # No errors\nimport main # No errors\n</code></pre> Specifying the full filename including extension does produce an error <pre><code>import calc.py # Error\nimport main.py # Error\n</code></pre></p>"},{"location":"Coding/Python/#argparse","title":"argparse","text":"<p>The <code>ArgumentParser</code> object exposes an attribute that contains the value passed in from the command-line. This attribute takes its identifier from the <code>dest</code> keyword argument when invoking the <code>add_argument()</code> method.</p> PythonOutput <pre><code>import argparse\n\ndef get_args():\n  parser = argparse.ArgumentParser()\n  parser.add_argument(dest='bar')\n  return parser.parse_args()\n\ndef main():\n  args = get_args().bar\n</code></pre> <p>The optional value assigned to <code>description</code> will be displayed when running the script with the options <code>-h</code> or <code>--help</code></p> <pre><code>parser = argparse.ArgumentParser(description=helptext)\n</code></pre> <pre><code>usage: argparse_practice.py [-h] [-f bar]\n\noptional arguments:\n  -h, --help         show this help message and exit\n  -f bar, --foo bar\n</code></pre> <p>A help string can be provided as a keyword argument to <code>help</code>. <pre><code>parser.add_argument(\"foo\", help=\"bar\")\n</code></pre></p> <p>A data type can be specified as an argument to <code>type</code>: <pre><code>parser.add_argument(\"foo\", type=int)\n</code></pre> An alternative name for the <code>dest</code> value on the command-line (but which does not affect the identifier of the attribute on which the value is exposed) can be specified by <code>metavar</code>. <pre><code>parser.add_argument(\"foo\", metavar=\"bar\")\n</code></pre></p> <p>The examples above used positional parameters (i.e. an argument). A named parameter (an option or flag, i.e. <code>-h</code>, <code>--help</code>, etc) requires - at the beginning of the string and values from the command-line to be passed after <code>=</code> or Space. <code>add_argument</code> supports the <code>required</code> keyword argument for named parameters. Note that use of the option on the command-line at all requires an argument to it, even if the option is not required itself. <pre><code>parser.add_argument('-r','--radius',type=int,required=True,help='radius')\n</code></pre></p> <p>A flag option can be created by defining an <code>action</code> keyword parameter. (src) <pre><code>parser.add_argument('-o', '--on', help='A boolean flag', action='store_true')\n</code></pre></p> <p><code>add_mutually_exclusive_group()</code> can be used to add a group of mutually exclusive arguments. In this case, <code>add_argument()</code> is invoked on the new object returned by this method and not directly on the <code>ArgumentParser()</code> object. <pre><code>g=ArgumentParser.add_mutually_exclusive_group()\ng.add_argument(\"-v\",\"--verbose\", action=\"store_true\")\ng.add_argument(\"-q\",\"--quiet\",\"-s\",\"--silent\", action=\"store_true\",help='quiet/silent mode')\n</code></pre></p> <p>User input can be restricted by providing a value for <code>choices</code>, which will accept any iterable value including lists, ranges, and strings: <pre><code>parser.add_argument(\"foo\", choices=[\"bar\",\"baz\"])\nparser.add_argument(\"foo\", choices=range(1,10))\nparser.add_argument(\"foo\", choices='Hello, world!') # equivalent to ['H','e', ...]\n</code></pre></p> <p>Sources</p> <ul> <li> Python documentation</li> </ul>"},{"location":"Coding/Python/#asyncio","title":"asyncio","text":"<p>The <code>asyncio</code> module offers an implementation of coroutines which allow tasks to control context switching to implement concurrency.</p> <p>The <code>await</code> keyword is a checkpoint that indicates where it is safe for the process to go to another coroutine, allowing total control over context switching</p> <pre><code>import asyncio\nimport time\n\ncounter = 0\n\nasync def func1():\n    global counter\n\n    while True:\n        counter += 1\n        counter -= 1\n        await asyncio.sleep(0)\n\nasync def func2():\n    global counter\n\n    while True:\n        counter += 1\n        counter -= 1\n        await asyncio.sleep(0)\n\nasyncio.gather(func1(), func2())\nasyncio.get_event_loop().run_forever()\n</code></pre> <pre><code>async def get_users():\n    users = await client.do_query('select * from users')\n    return users\n\nasync def main():\n    task = asyncio.create_task(get_users())\n    # ...\n    await task\n\nasyncio.run(main())\n</code></pre> <p>Allows the joining of multiple threads. <pre><code>async def get_users():\n    users = await client.do_query('select * from users')\n    return users\n\nasync def main():\n    await asyncio.gather(\n        get_users(),\n        get_users(),\n    )\n\nasyncio.run(main())\n</code></pre> <pre><code>async def get_users():\n    users = await client.do_query('select * from users')\n    return users\n\nasyncio.run(get_users())\n</code></pre></p> <pre><code>async def main():\n    users = await get_users()\n    print(users)\n\nasyncio.run(main())\n</code></pre> <p>Sources:</p> <ul> <li>Demistifying Python's Async and Await keywords</li> </ul>"},{"location":"Coding/Python/#azurecosmos","title":"azure.cosmos","text":"<pre><code>import azure.cosmos\nfrom azure.cosmos.partition_key import PartitionKey\n\ndatabase = cosmos_client.create_database('RetailDemo')\ncontainer = database.create_container(id='WebsiteData', partition_key=PartitionKey(path='/CartID'))\nprint('Container WebsiteData created')\n</code></pre>"},{"location":"Coding/Python/#bullet","title":"bullet","text":"<p><code>bullet.Check()</code> implements a checkbox widget: <pre><code>cli = bullet.Check(prompt = \"Choose from the following items: \", choices=['pepperoni','sausage','green peppers'])\n</code></pre> <code>bullet.Bullet()</code> implements a radio button widget: <pre><code>cli = bullet.Bullet(prompt = \"Choose from the following items: \", choices=['red','white','blue'])\n</code></pre> The resulting object then exposes a <code>launch()</code> method. <pre><code>cli.launch()\n</code></pre></p>"},{"location":"Coding/Python/#click","title":"click","text":"<p><code>Click</code> modifies functions using decorators whch determine the command-line arguments elements that the decorated function can see.</p> <p>Hello World program. Click <pre><code>import click\n\n@click.command()\ndef hello():\n  click.echo('Hello World!')\n\nif __name__ = '__main__':\n  hello()\n</code></pre> Modified Hello World <pre><code>import click\n\n@click.command()\n@click.option('--count', default=1, help='number of greetings')\n@click.argument('name')\ndef hello(count, name):\n  for x in range(count):\n    click.echo('Hello %s!' % name)\n\nif __name__ == '__main__':\n  hello()\n</code></pre> Developing the pdfcropper tool; passing <code>--examref</code> changes the numbers. <pre><code>import click\n\n@click.command()\n@click.option('--examref',is_flag=True)\ndef hello(examref):\n  top, right, bottom, left = 0,0,0,0\n  if examref:\n    top, right, bottom, left = 1, 2, 3, 4\n  click.echo(f'Your numbers are: top ({top}), right {right}, bottom {bottom}, left {left}')\n\nif __name__ == '__main__':\n  hello()\n</code></pre> @click.group() decorators allow nested command groups to be created. There are two ways of adding commands to command groups: - Using the group as a decorator, whereby the name of the function decorated by <code>@click.group()</code> is then used to  decorate commands: <pre><code>@click.group()\ndef group1()\n  pass\n\n@group1.command()\ndef command1():\n  pass\n</code></pre> - Using the <code>add_command</code> method <pre><code>@click.group()\ndef group1()\n  pass\n\n@click.command()\ndef command1():\n  pass\n\ngroup1.add_command(command1)\n</code></pre> For example, to imitate the nested commands available in <code>netsh</code>: <pre><code>netsh interface ip\n</code></pre> <pre><code>@click.group()\ndef interface():\n  pass\n\n@interface.command('ip')\n@click.argument('args', nargs=-1) # All arguments passed in as tuple \"args\"\ndef interface_ip(args):\n  pass\n</code></pre> <p>Docstrings of groups and commands show up as progressive help messages when they are invoked from the command-line.</p> <p><pre><code>@click.group()\ndef cli():\n  pass\n\n@click.command()\ndef initdb():\n  click.echo('Initialized the database')\n\n@click.command()\ndef dropdb():\n  click.echo('Dropped the database')\n\ncli.add_command(initdb)\ncli.add_command(dropdb)\n\nif __name__ == '__main__':\n  cli()\n</code></pre> CommandCollection flattens the structure of grouped commands so that the commands in all the contained groups appear in a single tier. It also becomes the entry-point of the script.</p> <p>Example from GitHub: <pre><code># Three command groups cli1, cli2, and cli3 declared:\n\n@click.group()\ndef cli1():\n  pass\n\n@click.group()\ndef cli2():\n  pass\n\n@click.group()\ndef cli3():\n  pass\n\n# Three commands each belonging to a separate group\n\n@cli1.command()\ndef server():\n  pass\n\n@cli2.command()\ndef console():\n  pass\n\n@cli3.command()\ndef routes():\n  pass\n\n# CommandCollection flattens the grouped commands such that all the commands are available at once:\n\ncli = click.CommandCollection(sources=[cli1,cli2,cli3])\n\nif __name__ == '__main__':\n  cli()\n</code></pre></p>"},{"location":"Coding/Python/#collections","title":"collections","text":"<ul> <li>abc provides <code>Mapping</code> and <code>MutableMapping</code> ABCs to formalize the interfaces of dict and similar types</li> <li>ChainMap Lookups are performed on each mapping in order</li> <li>Counter Holds an integer count for each key; each new key adds to the count</li> <li>deque: Thread-safe double-ended queue that supports most <code>list</code> methods</li> <li>namedtuple <pre><code>Card = namedtuple('Card',['rank','suit'])`\nCity = namedtuple('City', 'Name Country Population Coordinates'.split(' ')]\n</code></pre></li> <li>OrderedDict: Maintains keys in insertion order</li> <li>UserDict: Designed to be subclassed</li> </ul>"},{"location":"Coding/Python/#colorama","title":"colorama","text":"<p>Colorama provides a set of enums that resolve to terminal codes when concatenated with strings. <pre><code>colorama.Fore.GREEN\n</code></pre> <pre><code>colorama.Style.RESET_ALL\n</code></pre></p>"},{"location":"Coding/Python/#csv","title":"csv","text":"<p><pre><code>with open('file.csv', newline=''):\n  data = [row for row in csv.reader(f)]\n</code></pre> csv.DictReader <pre><code>with open('greeks.csv') as f:\n  reader = csv.DictReader(f)\n  for row in reader:\n    print(row['name'],row['city'],row['dob'])\n</code></pre></p>"},{"location":"Coding/Python/#datetime","title":"datetime","text":"<p><pre><code>datetime.date(2016,7,24)\ndatetime.date.today()\n</code></pre> Difference between <code>datetime</code> objects is a <code>timedelta</code> Parse strings into datetime objects <pre><code>datetime.strptime(datestring,formatstring)\n</code></pre> <pre><code># Various metacharacters are defined for `strptime`\ndatetime.datetime.strptime('06/30/1992','%m/%d/%Y')\n</code></pre></p>"},{"location":"Coding/Python/#discordpy","title":"discord.py","text":"<p><pre><code>pip install discord.py\nclient = discord.Client()\n</code></pre> <code>Client</code> objects expose a decorator that is used for event handlers, functions named after various events: - <code>on_ready</code> - <code>on_member_join</code> - <code>on_error</code> - <code>on_message</code> <pre><code>@client.event\nasync def on_ready():\n  print(f'{client.user} has connected to Discord!')\n</code></pre> Another decorator is exposed for in-chat commands (<code>commands.Bot</code> has to be instantiated first.) <pre><code>@bot.command(name='roll_dice', help='Simulates rolling dice.')\nasync def roll(ctx, number_of_dice: int, number_of_sides: int):\n  dice = [\n    str(random.choice(range(1, number_of_sides + 1)))\n    for _ in range(number_of_dice)\n  ]\n  await ctx.send(', '.join(dice))\n</code></pre> <pre><code>client.run(token)\n</code></pre></p> <pre><code>bot = comands.Bot(command_prefix='!')\n</code></pre>"},{"location":"Coding/Python/#dotenv","title":"dotenv","text":"<p><pre><code>pip install -U python-dotenv\n</code></pre> Load a .env file placed in the current working directory. <pre><code>load_dotenv()\nvalue =  os.getenv('key')\n</code></pre></p>"},{"location":"Coding/Python/#functools","title":"functools","text":"<p>For higher-order functions (functions that act on or return other functions)\\ Apply <code>function</code> of two arguments cumulatively to the items of <code>iterable</code> in order to reduce it to a single value <pre><code>functools.reduce(function, iterable [, initializer])\n</code></pre> Calculate ((((1+2) +3) +4) +5) <pre><code>functools.reduce(lambda x, y: x+y, [1,2,3,4,5])\n</code></pre> <code>functools.reduce(lambda a,b: a*b, range(1,6))</code> =&gt; 120 : factorial</p>"},{"location":"Coding/Python/#glob","title":"glob","text":"<p>Produce a list of strings <pre><code>glob.glob('*.py')\n</code></pre></p>"},{"location":"Coding/Python/#heapq","title":"heapq","text":"<p>Support heaps, data objects where each node is either greater than or equal to its parent (max-heap) or less than or equal to its parent (min-heap) Create a heap from {iterable} <pre><code>heapq.heapify(iterable)\n</code></pre> Remove and return the smallest element of {heap} <pre><code>heapq.heappop(heap)\n</code></pre> Replace the smallest element of {heap} with {element} <pre><code>heapq.heapreplace(heap,element)\n</code></pre></p>"},{"location":"Coding/Python/#http","title":"http","text":"<p>Start an HTTP server for the current directory <pre><code>python http.server\n</code></pre></p>"},{"location":"Coding/Python/#itertools","title":"itertools","text":"<p><code>cycle()</code> works like <code>next()</code>, but it restarts from the beginning of the iterable that is passed as argument after the last element has been reached. <pre><code>with open('raven') as f:\n    raven = [ l for l in f ]\n\nitertools.cycle(raven)\n</code></pre></p>"},{"location":"Coding/Python/#json","title":"json","text":"Deserialize Serialize <pre><code>import json\n\n\nwith open('starships.json') as f:\n    data=json.load(f)\n</code></pre> <pre><code>import json\n\n\nwith open('starships.json',\"w\") as f:\n    json.dump(data,f)\n</code></pre>"},{"location":"Coding/Python/#logging","title":"logging","text":"<pre><code>import logging\n\ndef main():\n  logging.basicConfig(filename='/tmp/learn-logging.log', level=logging.ERROR, format='%(asctime)s %(levelname)s: %(message)s')\n  logging.info(\"Once upon a midnight dreary,\")\n  logging.warning('While I pondered weak and weary,')\n  logging.error('Over many a quaint and curious volume of forgotten lore,')\n\nif __name__ == '__main__':\n  main()\n</code></pre>"},{"location":"Coding/Python/#npyscreen","title":"npyscreen","text":"<p>Widget library and application framework built on top of <code>ncurses</code>. Documentation] <p>Three main types of object compose <code>npyscreen</code> applications: - Application objects manage forms and other classes - Form objects form the canvas upon which widgets are arrayed   - <code>Form</code> general-purpose   - <code>FormMutt</code> - Widget objects are individual controls   - <code>TitleText</code> text entry   - <code>TitleSelectOne</code> equivalent to radio buttons   - <code>TitleDateCombo</code> allows picking of date on a small calendar</p> <p><code>npyscreen.wrapper_basic</code> is the main entry point <pre><code>import npyscreen\n\ndef myFunction(*args):\n  pass\n\nif __name__ == '__main__':\n  npyscreen.wrapper_basic(myFunction)\n  print \"Blink and you missed it!\"\n</code></pre> <code>npyscreen.Form</code> is equivalent to the <code>Tk()</code> object, which is typically instantiated as <code>win</code> in GUI frameworks. <pre><code>F = npyscreen.Form(name='My Test Application')\n</code></pre> Several important methods are key: - <code>create()</code> The standard constructor calls this method, which does nothing by default and is meant to be overriden in subclasses. Widgets are defined here.</p> <p><code>npyscreen.FormMutt</code> imitates a UI layout popularized by applications like <code>mutt</code>, <code>irssi</code>, and <code>vim</code>, with a title bar at the top, a command line at the bottom, and a status line directly above the command line.</p> <p><code>ACTION_CONTROLLER</code> can be defined in the <code>FormMutt</code> subclass as the name of a subclass of <code>ActionControllerSimple</code>. Commands for the application can be defined as callbacks in the <code>create()</code> method. <pre><code>self.add_action(ident,call_back, True)\n</code></pre> Callbacks are called with the following arguments: <pre><code>call_back(command_line, control_widget_proxy, live=True)\n</code></pre> <pre><code>class ActionControllerSearch(npyscreen.ActionControllerSimple):\n    def create(self):\n        self.add_action('^/.*', self.set_search, True)\n\n    def set_search(self, command_line, widget_proxy, live):\n        self.parent.value.set_filter(command_line[1:])\n        self.parent.wMain.values = self.parent.value.get()\n        self.parent.wMain.display()\n\nclass FmSearchActive(npyscreen.FormMuttActiveTraditional):\n    ACTION_CONTROLLER = ActionControllerSearch\n</code></pre></p> <p><code>npyscreen.NPSAppManaged</code> is the preferred superclass to support object-oriented implementation. <pre><code>class MyApplication(npyscreen.NPSAppManaged):\n  pass\n</code></pre> Calling <code>run()</code> method of application object as main entry point. <code>run()</code> activates the default form, which should be given an id of <code>MAIN</code> <pre><code>if __name__ == '__main__':\n  TestApp = MyApplication().run()\n  print \"All objects, baby.\"\n</code></pre> Using a <code>try</code>/<code>except</code> block to allow for well-mannered exit in case of <code>KeyboardInterrupt</code> (Ctrl+C)GitHub <pre><code>try:\n  App().run()\nexcept KeyboardInterrupt:\n  sys.exit(0)\n</code></pre> There are three methods for registering a <code>Form</code> object with a <code>NPSAppManaged</code> instance; - <code>addForm()</code> creates a new form and returns a <code>weakref.proxy</code> to it - <code>addFormClass()</code> register a class of <code>Form</code> rather than an instance - <code>registerForm()</code></p> <p>It continually displays the Form named by its <code>NEXT_ACTIVE_FORM</code> attribute. Use the <code>afterEditing</code> method to allow exiting. <pre><code>class myEmployeeForm(npyscreen.Form):\n  def afterEditing(self):\n    self.parentApp.setNextForm(None)\n</code></pre></p>"},{"location":"Coding/Python/#numpy","title":"numpy","text":"<p><code>numpy.ndarray</code>   - 2-dimensional array   - items can be fetched using the syntax <code>a[i, j]</code>   - arrays can be sliced with syntax <code>a[m:n, k:l]</code>   - FP:35 <code>numpy.arange(n)</code> build a <code>numpy.ndarray</code> object with numbers 0 to n-1 (FP:52) <code>numpy.loadtxt(filename)</code> load numbers stored in a text file (FP:53)</p>"},{"location":"Coding/Python/#optparse","title":"optparse","text":"<p>Instantiate the parser object <pre><code>parser = optparse.OptionParser(usage=__doc__.strip())\n\n# add an option\nparser.add_option('--timeout')\n</code></pre></p>"},{"location":"Coding/Python/#os","title":"os","text":"<p>Execute shell command given by string.  The value returned is actually the exit code, not the output of the command to STDOUT. <pre><code>os.system('ls -la')\n</code></pre> Store output in a variable <pre><code>os.popen('ls -la').read()\n</code></pre> Navigate filesystem <pre><code>os.getcwd()\nos.chdir(path)\n</code></pre> Test for existence of a file <pre><code>os.path.isfile(file)\n</code></pre></p>"},{"location":"Coding/Python/#pandas","title":"pandas","text":"<p>summary: open-source Python library used for data science operation: runs over NumPy   - good for storing lists-of-lists (CSV) <code>print(df)</code>   - prints it out in an easy to read tabular format</p> <p><code>DataFrame</code> is the main object in <code>pandas</code> - <code>head()</code>, <code>tail()</code>   - prints out the first, last several rows (5 by default)   - optional numerical argument defines number of rows - <code>describe()</code>   - numerical analyses, including count, unique, mean, etc - <code>sort_values('field',ascending=False)</code></p>"},{"location":"Coding/Python/#pathlib","title":"pathlib","text":"<p>Create a new pathlib object; represents a file or directory <pre><code>pathlib.Path(path)\n</code></pre> Test for existence of a file <pre><code>pathlib.Path.is_file(file)\n</code></pre> Test for existence of a directory <pre><code>pathlib.Path.is_dir(dir)\n</code></pre> Find all <code>.py</code> files Returns a generator <pre><code>pathlib.Path.glob('*.py')\n</code></pre> Open a file. This makes a file object that is automatically closed, similar to <code>open</code> builtin: <pre><code>pathlib.Path.open()\n</code></pre> Display file extension <pre><code>pathlib.Path.suffix()\n</code></pre> Display file size <pre><code>pathlib.Path.stat().st_size\n</code></pre></p>"},{"location":"Coding/Python/#pyinstaller","title":"pyinstaller","text":"<p>Source: RealPython tutorial</p> <p>Installing PyInstaller, even in a virtual environment, will install the pyinstaller executable to $HOME/.local/bin. On Windows, it is installed to another directory within  <code>LOCALAPPDATA</code>. <pre><code>pip install pyinstaller\n</code></pre> PyInstaller creates primarily 3 items: - .spec file, named after the CLI script - build/ folder, which can be ignored - dist/ folder, containing the final artifact at dist/cli/cli or dist/cli/cli.exe</p> <p>Several options are available <code>hidden-import</code> <code>name</code> <code>onefile</code> <pre><code>pyinstaller script.py --onefile\n</code></pre> On Windows, if PyInstaller is run from a virtual environment without necessary modules installed, they may not be available for compilation into the artifact. This does not appear to be an issue with Linux.</p> <p>This problem appears to be specific to certain modules, like emoji.</p>"},{"location":"Coding/Python/#pythonnet","title":"pythonnet","text":"<ul> <li>Docs: ? ! Developers recommend Mono version 5.20.1 Issues 939 On Ubuntu, the <code>eoan</code> <code>universe</code> repository has to be added  <pre><code>deb https://archive.ubuntu.com/ubuntu/ eoan universe\ndeb https://archive.ubuntu.com/ubuntu/ eoan-updates universe\n</code></pre> But I can't figure out how to add the older version, because the recommended syntax produces the error \"Unable to correct problems, you have held broken packages\" <pre><code>sudo apt install mono-devel=5.18.0.240+dfsg-3\n</code></pre> Maybe try the tarballs on Mono's website... Or maybe there's another repo I don't know about.. <pre><code>apt install clang libglib2.0-dev python3-dev\n</code></pre> <pre><code>pip install pycparser pythonnet\npip install -U setuptools\n</code></pre></li> </ul>"},{"location":"Coding/Python/#random","title":"random","text":"<p>Random choice with replacement <pre><code>random.choice(iterable)\n</code></pre> Shuffle elements of an iterable in-place [FP:42] <pre><code>random.shuffle(iterable)\n</code></pre></p>"},{"location":"Coding/Python/#scrapy","title":"scrapy","text":"<p>Best used to obtain one \"stream\" of data at a time, without trying to obtain data from different pages <pre><code>scrapy runspider spider.py -o file.json\n</code></pre> Display HTML source of the scraped page <pre><code>print(response.txt)\n</code></pre> Get <code>{URL}</code> <pre><code>fetch('url')\n</code></pre> Select a CSS selector <pre><code># Returns a `SelectorList`\nresponse.css('p')\n# Retrieve full HTML elements\nresponse.css('p').extract()\n</code></pre> Retrieve only the text within the element <pre><code>response.css('p::text').extract()\nresponse.css('p::text').extract_first()\nresponse.css('p::text').extract()[0]\n</code></pre> Get the <code>href</code> attribute value for an anchor tag <pre><code>response.css('a').attrib['href']\n</code></pre> Launch Scrapy shell and scrape <code>$URL</code> <pre><code>scrapy shell $URL\n</code></pre> Make a default spider named {quotes} that will be restricted to {domain} <pre><code>scrapy genspider quotes domain\n</code></pre> <pre><code>scrapy runspider scrapy1.py\n</code></pre> Run a spider, saving scraped data to a JSON file <pre><code>scrapy runspider spider.py -o items.json\n</code></pre> Method which contains most of the logic of the spider, especially after the <code>yield</code> keyword. For multiple items, a structural basis for iteration must be found and for each iteration, data is yielded</p> <p>Extract URL from link using standard CSS selection techniques</p> <p>Add the domain name to a relative link <pre><code>response.urljoin()\n</code></pre> Recursively call the <code>parse</code> method again on the next page <pre><code>yield scrapy.Request(url=next_page_url, callback=self.parse)\n</code></pre> Scrape detail pages   - <code>parse_details</code> would be a spider method sibling to the main <code>parse</code> method   - if a detail page has more information than the main, then the <code>yield</code> keyword should be in <code>parse_details</code> <pre><code>yield scrapy.Request(url={url}, callback=self.parse_details)\n</code></pre></p>"},{"location":"Coding/Python/#setuptools","title":"setuptools","text":"<p>Setuptools is for uploading to PyPi. To create self-contained executable files, use pyinstaller.</p> <p><pre><code>PROJECT\n\u251c\u2500\u2500 PROJECT     # Additional code files will be placed in here\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 init.py\n\u2514\u2500\u2500 setup.py    # Containing a call to `setuptools.setup()`\n\n1 directory, 2 files\n</code></pre> setup.py <pre><code>from setuptools import setup\n\nsetup(\n  name='funniest',\n  version='0.1',\n  description='The funniest joke in the world',\n  url='http://github.com/storborg/funniest',\n  author='Flying Circus',\n  author_email='flyingcircus@example.com',\n  license='MIT',\n  packages=['funniest'],\n  zip_safe=False\n)\n</code></pre> If the package has dependencies, they can be added by appending a <code>install_requires</code> keyword argument passing an array of the module names <pre><code>setup(\n  install_requires=[ 'markdown', ],\n)\n</code></pre></p> <p>Reserve the name, upload package metadata, and create the pypi.python.org webpage <pre><code>python setup.py register\n</code></pre> Create a source distribution, producing a tarball inside the top-level directory <pre><code>python setup.py sdist\n</code></pre> Upload the source distribution <pre><code>python setup.py sdist upload\n</code></pre> Do all the above in a single step <pre><code>python setup.py register sdist upload\n</code></pre></p>"},{"location":"Coding/Python/#socket","title":"socket","text":"<p>The socket module is Python's standard interface for the transport layer. Sockets can be classified by <code>family</code></p> <ul> <li><code>AF_INET</code> Internet</li> <li><code>AF_UNIX</code> for UNIX sockets</li> </ul> <p>and <code>type</code>:   - <code>SOCK_STREAM</code> TCP   - <code>SOCK_DGRAM</code> UDP</p> <p>These enum values are required upon initialization of a socket object: Ortega: 25</p> <pre><code>client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n</code></pre> <p>Sources: </p> <ul> <li>Sockets tutorial</li> </ul> TCP serverTCP ClientUDP serverUDP client <pre><code>import socket\n\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST,PORT))\n</code></pre> <pre><code>import socket\n\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.connect((HOST,PORT))\n</code></pre> <pre><code>import socket\n\n\nwith socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n    s.bind((HOST,PORT))\n</code></pre> <pre><code>import socket\n\nmsg = \"Hello, world!\"\nwith socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n    s.sendto(msg.encode(), (HOST,PORT))\n</code></pre> <p>Define port on which to listen for connections. <pre><code>serversocket.bind(('localhost',80))\n</code></pre> Connect to a remote socket in one direction <pre><code>client_socket.connect(('www.packtpub.com',80))\n</code></pre> Convert a domain name into IPv4 address <pre><code>socket.gethostbyname('packtpub.com') # '83.166.169.231'\n</code></pre> Defaults to localhost with no arguments <pre><code>s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ns.bind((socket.gethostname(),1234))\n</code></pre> Get protocol name from port number <pre><code>socket.getservbyport(80) # 'http'\n</code></pre> Listen to a maximum of 10 connections <pre><code>serversocket.listen(10)\n</code></pre> Receive bytestream from server <pre><code>msg = s.recv(1024)\nprint(msg.decode('utf-8'))\n</code></pre></p>"},{"location":"Coding/Python/#sqlite3","title":"sqlite3","text":"<p>Create a <code>Connect</code> connection object and employee.db (binary) if it doesn't exist <pre><code>conn = sqlite.connect('employee.db')\n</code></pre> Create a <code>Connect.Cursor</code> object <pre><code>c = conn.cursor()\n</code></pre> Perform SQL commands with <code>Connect.Cursor.execute()</code>. Create <code>tablename</code> with fields <code>field</code> of type <code>type</code> (<code>null</code>, <code>integer</code>, <code>real</code>, <code>text</code>, <code>blob</code>); never use Python's native string operations (f-strings, etc) to form commands, because this method is vulnerable to SQL injection. YouTube <pre><code>c.execute('''CREATE TABLE {tablename} ({field} {type}, {field} {type} ...))\n</code></pre> Save changes <pre><code>conn.commit()\n</code></pre> Close connection <pre><code>conn.close()\n</code></pre></p>"},{"location":"Coding/Python/#subprocess","title":"subprocess","text":"<p>subprocess modules allows you to spawn new processes, interact with file descriptors, and obtain exit codes. The recommended approach is to use the <code>run()</code> function as default, which runs a CLI command with options as a list of strings and returns a <code>CompletedProcess</code> instance.\\ Execute shell command Unlike <code>os.system</code>, <code>subprocess.run()</code> takes a list of arguments.  <pre><code>subprocess.run(['ls','-l,'.'], 0)\n</code></pre> Set <code>capture_output</code> to <code>True</code> to save output, stored as property <code>stdout</code> of the returned object.  <pre><code>data = subprocess.run(['ls,'-l','.'], 0, capture_output=True)\n</code></pre> The data is stored as a bytestring, which can be decoded to a normal string. <pre><code>data.stdout.decode('utf-8')\n</code></pre> This return a <code>CompletedProcess</code> instance with the command's output stored under the <code>stdout</code> property <pre><code>subprocess.run(['ls','-l','/dev/null'], capture_output=True)\n</code></pre> This will raise a <code>CalledProcessError</code> exception because of the non-zero exit code <pre><code>subprocess.run('exit 1', shell=True, check=True)\n</code></pre></p>"},{"location":"Coding/Python/#sys","title":"sys","text":"<p>Return site-specific directory where Python files are installed  <pre><code>sys.prefix          # /usr/local/ by default\n</code></pre></p>"},{"location":"Coding/Python/#tabulate","title":"tabulate","text":""},{"location":"Coding/Python/#termcolor","title":"termcolor","text":"<p>Print <code>text</code> in a color code <pre><code>termcolor.cprint(text,color)\n</code></pre></p>"},{"location":"Coding/Python/#threading","title":"threading","text":"<p> Docs</p> <p><pre><code>counter = 0\nlock = threading.RLock()\n\ndef func1():\n  global counter\n\n  while True:\n    with lock:\n      counter += 1\n      counter -= 1\n\ndef func2():\n  global counter\n\n  while True:\n    with lock:\n      counter += 1\n      counter -= 1\n\nthreading.Thrad(target=func1).start()\nthreading.Thrad(target=func2).start()\n</code></pre> <pre><code>counter = 0\n\ndef func1():\n  global counter\n\n  while True:\n    counter += 1\n    counter -= 1\n\ndef func2():\n  global counter\n\n  while True:\n    counter += 1\n    counter -= 1\n\nthreading.Thrad(target=func1).start()\nthreading.Thrad(target=func2).start()\n</code></pre></p>"},{"location":"Coding/Python/#typing","title":"typing","text":"<p>As tuples, their attributes are immutable <pre><code>class Starship(NamedTuple):\n  name: str\n  registry: str\n  crew: int\n</code></pre></p>"},{"location":"Coding/Python/#urllib","title":"urllib","text":"<p>Download an RFC file from rfc-editor.org Ortega <pre><code>rfc_raw = urllib.request.urlopen(url).read()\nrfc = rfc_raw.decode()\n</code></pre></p>"},{"location":"Coding/Python/#weakref","title":"weakref","text":"<p>Weak references are references to objects which return exceptions when that object has been garbage collected Create a weak reference to {object}  <pre><code># A weak reference created using `ref` must be dereferenced \nr = weakref.ref(obj) \nr().method() \nr.method()          # will not work\n\n# A weak reference created using `proxy` does not need to be dereferenced:\nweakref.proxy(obj)\n</code></pre></p>"},{"location":"Coding/Python/#winrm","title":"winrm","text":"<p>Winrm allows you to connect Linux and Windows hosts over WinRM. adamtheautomator.com  Begin a WinRM session. If no errors are thrown, the session has been successfully established <pre><code>session = winrm.Session(ipaddress,auth=(username,password))\n</code></pre></p>"},{"location":"Coding/Python/#yaml","title":"yaml","text":"<pre><code>pip install pyyaml\n</code></pre>  Deserialize Serialize <pre><code>import yaml\n\n\nwith open('./starships.yaml') as f:\nstarships = yaml.safe_load(f)\n</code></pre> <p>There is a <code>load</code> method but it requires specifying one of four possible values for the Loader kwarg.</p> <pre><code>import yaml\n\n\nwith open('./starships.yaml','w') as f:\nyaml.dump(starships, f)\n</code></pre> Resources <ul> <li>Introduction to YAML</li> </ul>"},{"location":"Coding/Python/#xml","title":"xml","text":"books.xml <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;catalog&gt;\n&lt;book id=\"bk101\"&gt;\n&lt;author&gt;Gambardella, Matthew&lt;/author&gt;\n&lt;title&gt;XML Developer's Guide&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;44.95&lt;/price&gt;\n&lt;publish_date&gt;2000-10-01&lt;/publish_date&gt;\n&lt;description&gt;An in-depth look at creating applications with XML.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk102\"&gt;\n&lt;author&gt;Ralls, Kim&lt;/author&gt;\n&lt;title&gt;Midnight Rain&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-16&lt;/publish_date&gt;\n&lt;description&gt;A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk103\"&gt;\n&lt;author&gt;Corets, Eva&lt;/author&gt;\n&lt;title&gt;Maeve Ascendant&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2000-11-17&lt;/publish_date&gt;\n&lt;description&gt;After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk104\"&gt;\n&lt;author&gt;Corets, Eva&lt;/author&gt;\n&lt;title&gt;Oberon's Legacy&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2001-03-10&lt;/publish_date&gt;\n&lt;description&gt;In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk105\"&gt;\n&lt;author&gt;Corets, Eva&lt;/author&gt;\n&lt;title&gt;The Sundered Grail&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2001-09-10&lt;/publish_date&gt;\n&lt;description&gt;The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon's Legacy.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk106\"&gt;\n&lt;author&gt;Randall, Cynthia&lt;/author&gt;\n&lt;title&gt;Lover Birds&lt;/title&gt;\n&lt;genre&gt;Romance&lt;/genre&gt;\n&lt;price&gt;4.95&lt;/price&gt;\n&lt;publish_date&gt;2000-09-02&lt;/publish_date&gt;\n&lt;description&gt;When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk107\"&gt;\n&lt;author&gt;Thurman, Paula&lt;/author&gt;\n&lt;title&gt;Splish Splash&lt;/title&gt;\n&lt;genre&gt;Romance&lt;/genre&gt;\n&lt;price&gt;4.95&lt;/price&gt;\n&lt;publish_date&gt;2000-11-02&lt;/publish_date&gt;\n&lt;description&gt;A deep sea diver finds true love twenty thousand leagues beneath the sea.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk108\"&gt;\n&lt;author&gt;Knorr, Stefan&lt;/author&gt;\n&lt;title&gt;Creepy Crawlies&lt;/title&gt;\n&lt;genre&gt;Horror&lt;/genre&gt;\n&lt;price&gt;4.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-06&lt;/publish_date&gt;\n&lt;description&gt;An anthology of horror stories about roaches,\n        centipedes, scorpions  and other insects.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk109\"&gt;\n&lt;author&gt;Kress, Peter&lt;/author&gt;\n&lt;title&gt;Paradox Lost&lt;/title&gt;\n&lt;genre&gt;Science Fiction&lt;/genre&gt;\n&lt;price&gt;6.95&lt;/price&gt;\n&lt;publish_date&gt;2000-11-02&lt;/publish_date&gt;\n&lt;description&gt;After an inadvertant trip through a Heisenberg\n        Uncertainty Device, James Salway discovers the problems of being quantum.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk110\"&gt;\n&lt;author&gt;O'Brien, Tim&lt;/author&gt;\n&lt;title&gt;Microsoft .NET: The Programming Bible&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;36.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-09&lt;/publish_date&gt;\n&lt;description&gt;Microsoft's .NET initiative is explored in detail in this deep programmer's reference.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk111\"&gt;\n&lt;author&gt;O'Brien, Tim&lt;/author&gt;\n&lt;title&gt;MSXML3: A Comprehensive Guide&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;36.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-01&lt;/publish_date&gt;\n&lt;description&gt;The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk112\"&gt;\n&lt;author&gt;Galos, Mike&lt;/author&gt;\n&lt;title&gt;Visual Studio 7: A Comprehensive Guide&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;49.95&lt;/price&gt;\n&lt;publish_date&gt;2001-04-16&lt;/publish_date&gt;\n&lt;description&gt;Microsoft Visual Studio 7 is explored in depth,\n        looking at how Visual Basic, Visual C++, C#, and ASP+ are integrated into a comprehensive development environment.&lt;/description&gt;\n&lt;/book&gt;\n&lt;/catalog&gt;\n</code></pre> <p>The etree submodule contains the ElementTree object which can open a string filename to deserialize XML data using <code>parse()</code>, which returns an ElementTree object, representing an XML document. A Python string can also be parsed with <code>fromstring()</code>, which actually returns an Element object.</p> FileString <pre><code>tree = xml.etree.ElementTree.parse('books.xml')\n</code></pre> <pre><code>tree = xml.etree.ElementTree.fromstring(books)\n</code></pre> <p>The <code>getroot()</code> method returns an Element object of the XML document's root node. <pre><code>root = tree.getroot()\n</code></pre></p> <p>The parsed data can be displayed using the <code>tostring()</code> static method, providing an Element as argument. <pre><code>ElementTree.tostring(root)\n</code></pre></p> <p>Children of an element can be filtered using <code>findall()</code>. This returns a list of Elements. <pre><code>books = root.findall('book')\n</code></pre></p> <p>Any Element object exposes an <code>attrib</code> property which returns a dictionary of attributes. <pre><code>[b.attrib for b in books]\n</code></pre></p> <p>Attributes can be written to an Element using the <code>set()</code> method. <pre><code>root.set('foo','bar')\n</code></pre></p> <p>Attributes can also be manipulated on the attrib property with normal Python dictionary operations.</p> SettingDeleting <pre><code>root.attrib['foo'] = 'bar'\n</code></pre> <pre><code>del(root.attrib['hello'])\n</code></pre> <p>Commit changes to disk. The argument can be a string representing the filename or a file object (in which case the file must be opened as a binary). Encoding can be specified (default is UTF-8) and a XML declaration can also be automatically generated.</p> StringFile object <pre><code>tree.write('books.xml', encoding='UTF-16', xml_declaration=True)\n</code></pre> <pre><code>with open('books.xml', 'wb') as f:\n    tree.write(f)\n</code></pre> <p>Find elements by element name <pre><code>tree.findall('book')\n</code></pre></p>"},{"location":"Coding/Python/#glossary","title":"Glossary","text":""},{"location":"Coding/Python/#method-resolution-order","title":"Method resolution order","text":"<p>Method resolution order (MRO) is the order of base classes that are searched when using <code>super()</code>.  It is accessed with <code>__mro__</code>, which returns a tuple of base classes in order of precedence, ending in <code>object</code> which is the root class of all classes. (src)</p>"},{"location":"Coding/Python/#non-interactive-debugging","title":"Non-interactive debugging","text":"<p>Non-interactive debugging is the most basic form of debugging, dependent on <code>print</code> or <code>log</code> statements placed within the body of code.</p>"},{"location":"Coding/Python/#type-slot","title":"Type slot","text":"<p>A type slot is any of a number of fields within each magic method, including <code>__new__()</code>, <code>__init__()</code>, and <code>__prepare__()</code> (which returns a dictionary-like object that's used as the local namespace for all code from the class body)</p>"},{"location":"Coding/Testing/","title":"Testing","text":"<p>There has been a push toward adoption of unit-testing over the past decades, so much so that the amount of test code can exceed production code by up to 10 times.</p> <p>Testing can help to forestall software entropy, the phenomenon whereby a software project becomes progressively more complex and disorganized.</p> <p>There are two popular coverage metrics that quantitatively measure the quality of a test suite:</p> <ul> <li>Test coverage: the portion of total production code lines executed by any test</li> <li>Branch coverage: the portion of total number of branches traversed by any test</li> </ul>"},{"location":"Coding/Testing/#unit-testing","title":"Unit testing","text":"<p>A unit test quickly tests a small piece of code (or \"unit\") in isolation of others.</p> <p>There are two schools of unit testing which differ in their intepretation of how isolation should be achieved:</p> <ul> <li>London (also \"mockist\") approach emphasizes segregation of the system under test from its collaborators (dependencies) using [test doubles][test double], in particular [mocks][mock].</li> <li>Classical (also \"Detroit\") approach emphasizes segregation of unit tests themselves from each other, allowing them to be run independently. In classical testing, there is less emphasis on using test doubles, which are used strictly for shared dependencies</li> </ul>"},{"location":"Coding/Testing/#aaa","title":"AAA","text":"<p>Conventionally, tests have a three-part structure summarized in the acronym AAA (also 3A or Given-When-Then):</p> <ul> <li>Arrange: SUT and dependencies are brought to a desired state</li> <li>Act: methods on the SUT are called and output is captured</li> <li>Assert: outcome is verified</li> </ul> <p>Several recommendations when using this framework:</p> <ul> <li>Every unit test should have a single Action</li> <li>Avoid conditional logic in unit tests</li> <li>The Arrange section should be largest, but if it is too large then it should be extracted into a private method or a separate factory class.</li> <li>Unit tests should be loosely coupled. Placing reusable [test fixtures][test fixture] in the test class's constructor is an anti-pattern, unless every single test method uses the fixture.</li> <li>Test methods should have expressive, easily understood names.</li> </ul>"},{"location":"Coding/Testing/#tasks","title":"\ud83d\udee0\ufe0f Tasks","text":""},{"location":"Coding/Testing/#starship","title":"\ud83d\ude80 Starship","text":"C#Python <pre><code>public class StarshipShould\n{\n\n[Theory]\n[InlineData(\"USS Enterprise\",\"NCC-1701\",203)]\n[InlineData(\"USS Constitution\",\"NCC-1700\",204)]\n[InlineData(\"USS Voyager\",\"NCC-74656\",141)]\n[InlineData(\"USS Defiant\",\"NX-74205\",50)]\n[InlineData(\"USS Enterprise\",\"NCC-1701-D\",1000)]\npublic void BeValid(string name, string registry, int crew)\n{\nvar starship = new Starship{Name=name,Registry=registry,Crew=crew};\nAssert.Equal(starship.Name,name);\nAssert.Equal(starship.Registry,registry);\nAssert.Equal(starship.Crew,crew);\n}\n}\n</code></pre> <pre><code>import pytest\nfrom starships import Starship,StarshipClass,Fleet\n\n@pytest.fixture\ndef enterprise():\n    return Starship(\"USS Enterprise\",\"NCC-1701\",StarshipClass.CONSTITUTION)\n\ndef test_lookup_by_name(enterprise):\n    starfleet = Fleet()\n    starfleet.add(enterprise)\n    assert starfleet.lookup(enterprise.name) == enterprise\n</code></pre>"},{"location":"Coding/Testing/#starshipvalidator","title":"\ud83d\ude80\u2714\ufe0f StarshipValidator","text":"C# <pre><code>public class StarshipValidatorShould\n{\n[Theory]\n[InlineData(\"Jean-Luc Picard\", 2305, 7, 13)]\n[InlineData(\"James Kirk\", 2233, 3, 22)]\npublic void ValidateCaptainedStarships(string n, params int[] dob)\n{\nvar mockStarship = new Mock&lt;IStarship&gt;();\nCaptain captain = new Captain(n,new DateTime(dob[0], dob[1], dob[2]));\nmockStarship.Setup(x =&gt; x.Captain).Returns(captain);\n\nStarshipValidator starshipValidator = new StarshipValidator(mockStarship.Object);\nAssert.True(starshipValidator.IsCaptained());\n}\n\n[Theory]\n[InlineData(\"USS Enterprise\",\"NCC-1701\",203)]\n[InlineData(\"USS Constitution\",\"NCC-1700\",204)]\n[InlineData(\"USS Voyager\",\"NCC-74656\",141)]\n[InlineData(\"USS Defiant\",\"NX-74205\",50)]\n[InlineData(\"USS Enterprise\",\"NCC-1701-D\",1000)]\npublic void ValidateStarshipsWithValidRegistryNumbers(string name, string registry, int crew)\n{\nvar starship = new Starship{Name =name, Registry =registry,Crew= crew};\nStarshipValidator starshipValidator = new StarshipValidator(starship);\nAssert.True(starshipValidator.ValidateRegistry());\n}\n}\n</code></pre>"},{"location":"Coding/Testing/#starshipdeployment","title":"\ud83d\ude80\ud83c\udff9 StarshipDeployment","text":"C# Test (xUnit) <pre><code>public class StarshipDeploymentShould\n{\n[Fact]\npublic void ThrowOnNullValidator()\n{\nvar sut = new StarshipDeployment(null);\nAssert.Throws&lt;ArgumentNullException&gt;(sut);\n}        [Theory]\n[InlineData(\"Betelgeuse\")]\npublic void EvaluateStarship(string destination)\n{\nvar mockValidator = new Mock&lt;IStarshipValidator&gt;();\nmockValidator.Setup(x =&gt; x.Evaluate()).Returns(true);\n\nvar mockStarship = new Mock&lt;IStarship&gt;();\n\nvar sut = new StarshipDeployment(mockValidator.Object as IStarshipValidator);\nsut.Deploy(mockStarship.Object as Starship, destination);\nmockValidator.Verify(x =&gt; x.Evaluate());\n}\n}\n</code></pre>"},{"location":"Coding/Testing/#officer","title":"\ud83d\udc69\u200d\ud83d\ude80 Officer","text":""},{"location":"Coding/Testing/#captainselector","title":"\ud83d\udc69\u200d\ud83d\ude80\u2714\ufe0f CaptainSelector","text":"C# <pre><code>public class CaptainSelectorShould\n{\n[Theory]\n[InlineData('B')]\n[InlineData('C')]\n[InlineData('D')]\n[InlineData('F')]\npublic void OnlyAssignGoodCaptains(char grade)\n{\nvar mockOfficer = new Mock&lt;IOfficer&gt;();\nmockOfficer.Setup(x =&gt; x.Grade).Returns(grade);\n\nCaptainSelector captainSelector = new CaptainSelector(mockOfficer.Object);\nbool selectionResult = captainSelector.Evaluate();\nAssert.False(selectionResult);\n}\n}\n</code></pre>"},{"location":"Coding/Testing/#glossary","title":"\ud83d\udcd8 Glossary","text":"Mock <p>A mock is a test double that emulates outgoing interactions, or calls the system under test makes to change the state of a dependency.</p> <p>Mocks include [spies][spy].</p> Spike A spike is an experiment without tests to ensure that an idea will work. Once the spike succeeds, the spike code is thrown away and the logic is recreated following TDD, starting with tests. Stub <p>A stub is a test double that emulates incoming interactions, or calls the system under test makes to get data from a dependency.</p> <ul> <li>Fakes provide a working implementation of the dependency, however one which is unsuitable for production (e.g. in-memory databases)</li> <li>Dummies are passed around like real implementations but never accessed or used.  These are used to satisfy the parameters of a method.</li> </ul> Test double <p>Test double include a variety of objects that facilitate unit testing by replacing a production object, usually a data dependency. Test doubles can be classified  on what type of interaction the object emulates:</p> <ul> <li>Mocks emulate outgoing interactions</li> <li>Stubs emulate incoming interactions</li> </ul>"},{"location":"Coding/Windows/","title":"Windows programming","text":""},{"location":"Coding/Windows/#glossary","title":"\ud83d\udcd8 Glossary","text":"app model <p>App model is a term Microsoft began using after the release of UWP in 2012 to refer to the hosting model, or the rigidly defined parameters for how an application is installed, stores state, manages versions, and integrates with the operating system and other apps, that generally define an application lifecycle. Specifically, the term was used in the context of describing the security sandbox and other restrictions of the UWP app model for Microsoft Store applications.</p> <p>Previous to UWP, there had been no definition of an \"app model\" per se and developers of a Win32 application were free to determine these parameters individually.  This caused wide disparity in implementation among applications, resulting in registry bloat and poorly managed uninstallations.  The UWP App Model was specifically introduced to answer these concerns which had plagued generations of Windows. (src)</p> <p>The failure of UWP as an app model resulted in Project Reunion, an effort to reunify the bifurcated Windows development landscape.</p>"},{"location":"Coding/Windows/#ccx","title":"C++/CX","text":"<p>C++/CX is a legacy language projection that uses nonstandard C++ (see C++/WinRT).</p> <p>Compile a C++ to a DLL (src)</p> <p>Invoke  MSVC, creating:</p> <ul> <li>Library.dll</li> <li>Library.lib</li> <li>Library.exp</li> <li>Library.obj</li> </ul> Command-lineLibrary.cppLibrary.hLibrary.def <pre><code>cl /w4 /ld Library.cpp Library.def\n</code></pre> <pre><code>#include \"Library.h\"\n#include &lt;stdio.h&gt;\n\nvoid Cluck()\n{\nprintf(\"C-style cluck!\\n\");\n}\n</code></pre> <pre><code>#pragma once\n\nvoid Cluck();\n</code></pre> <p>A definitions file is broken into sections, all of which are optional. <pre><code>EXPORTS\n\nCluck\n</code></pre></p> <p>Now the libary can be used in an application</p> Command-lineApplication.cpp <pre><code>cl /W4 Application.cpp /link Library.lib\n</code></pre> <pre><code>#include \"Library.h\"\n\nint main()\n{\nCluck();\n}\n</code></pre>"},{"location":"Coding/Windows/#cwinrt","title":"C++/WinRT","text":""},{"location":"Coding/Windows/#cwin32","title":"C#/Win32","text":"<p>Resources:</p> <ul> <li> Windows APIs Everywhere in .NET</li> </ul>"},{"location":"Coding/Windows/#cwinrt_1","title":"C#/WinRT","text":"<p>.NET Core 3 and .NET Framework (\"NETFX\") applications can continue to use the Microsoft.Windows.SDK.Contracts NuGet package.</p> <p>C#/WinRT is the WinRT language projection for C#, created after .NET5 removed WinRT projection support for C# out of the .NET compiler.  This represents a decoupling of the Windows-specific APIs from .NET</p> <p>It is used to create C# runtime components hosted in non-.NET languages by first building interop assemblies from Windows Metadata files using  cswinrt.exe.</p> <p>Resources:</p> <ul> <li> How to call WinRT APIs from .NET5 applications</li> </ul>"},{"location":"Coding/Windows/#com","title":"COM","text":"<p>Component Object Model was developed in the late 1980s by Microsoft. The Component Object Model is a binary standard interface specification for objects. It originated in 1993 as a renaming of OLE (Object Linking and Embedding) 2.0, used by Microsoft Office at the time to link data between applications.</p> <p>COM objects support a collection of interfaces, most importantly <code>IUnknown</code> which all COM objects must implement. IUnknown includes <code>QueryInteface()</code> which returns pointers to the other interfaces also implemented by the COM object. It also includes <code>AddRef()</code> and <code>Release()</code>, which manage the object's lifetime.</p> <p>COM uses <code>HRESULT</code>s, 32-bit longs, to indicate success or failure. Bit 31 indicates success (0) or failure (1). With .NET interop, a failed <code>HRESULT</code> turns into a thrown COMException. Common <code>HRESULT</code>s include <code>S_OK</code>, <code>S_FALSE</code>, <code>E_FAIL</code>, and many other failure codes also beginning with <code>E_</code>.</p> <p>COM objects are created by calling <code>CoCreateInstance()</code>. This function, which is stored in ole32.dll, searches the Registry for the given class ID, then loads the apropriate COM Server DLL file. This DLL file then creates a class factory which then creates the COM instance, which is passed back to the client as an interface pointer. (src)</p> <p>COM classes must be registered in the Registry, at minimum by mapping the class ID (a GUID) to a DLL, in the HKEY_CLASSES_ROOT hive. This is done using the regsvr32.exe utility. (src)</p>"},{"location":"Coding/Windows/#core-application","title":"Core application","text":"Core application refers to the lifecycle of a UWP application, through which Windows offers app-specific services relating to power management, security, etc and abstracts the app itself. It offers a level of control over graphical applications comparable to that available for apps as services. (src)"},{"location":"Coding/Windows/#directx","title":"DirectX","text":"DirectX is a gaming API that was created by Eric Engstrom (d. 2020), Alex St. John, and Craig Eisler in 1994 to support game development on Windows 95."},{"location":"Coding/Windows/#interop-assembly","title":"Interop assembly","text":"<p>Interop assemblies allow .NET applications to call native code.  They can be distributed along with applications that reference them.</p> <p>Language projections like C#/WinRT produce interop assemblies composed in C# which can then be compiled into a projection assembly.</p>"},{"location":"Coding/Windows/#language-projection","title":"Language projection","text":"<p>A language projection (or simply \"projection\") is a native adapter that enables programming APIs in a way that is idiomatic to a given language.</p> Framework C# C++ WinRT C#/WinRT C++/WinRT Win32 C#/Win32 ? <p>Resources:</p> <ul> <li> C#/WinRT (MSDocs)</li> <li> Windows APIs Everywhere in .NET</li> </ul>"},{"location":"Coding/Windows/#tfm","title":"TFM","text":"<p>Target Framework Monikers (TFM) are used in NuGet packages and project files to refer to the flavor of .NET targeted by an application.</p> <p>Only for .NET5, Microsoft introduced new monikers that indicate the targeted OS after a hyphen, e.g. <code>net5.0-windows</code>, etc. These monikers will pull in the projection assemblies that are needed to access those APIs and replace earlier use of the Microsoft.Windows.SDK.Contracts package reference.</p> <p>Example TMFs include:</p> <ul> <li><code>net5.0-windows10.0.19041.0</code> Windows 10 version 2004</li> <li><code>net5.0-windows10.0.18362.0</code> Windows 10 version 1903</li> <li><code>net5.0-windows10.0.17763.0</code> Windows 10 version 1809</li> </ul> <p>References:</p> <ul> <li> Windows APIs Everywhere in .NET</li> </ul>"},{"location":"Coding/Windows/#uwp","title":"UWP","text":"<p>Universal Windows Platform (UWP) refers to both a UI framework incorporating the Fluent Design System as well as an app model. When the UWP XAML framework was released in 2012, UWP was touted as a means to develop for many different device platforms, including mobile and tablet.  Until recently, the UWP XAML framework was only available for applications using the UWP app model for apps destined for the Microsoft Store.</p> <p>However, UWP development has floundered over the past half decade as Microsoft has been unable to produce sufficient interest in its mobile and tablet devices or the Microsoft Store.  Microsoft itself has ceased development of UWP apps for Office or for Xbox, for which it has turned rather to Electron.</p>"},{"location":"Coding/Windows/#win32","title":"Win32","text":""},{"location":"Coding/Windows/#winmd","title":"WinMD","text":"<p>Windows metadata files (*.winmd) are machine-readable files that define Windows Runtime APIs. All public types in a .winmd file must be WinRT types. They use the same physical file format as CLR assemblies.</p> <p>Resources:</p> <ul> <li> Windows Metadata (WinMD) files</li> </ul>"},{"location":"Coding/Windows/#winrt","title":"WinRT","text":"<p>The Windows Runtime is a framework introduced with Windows 8 to provide access to system resources.  WinRT is separate from, although it is used by, .NET. Under the surface, WinRT is implemented as COM components.</p> <p>UWP XAML controls were included in WinRT until recently when they were moved to the WinUI NuGet package.</p> <p>Resources:</p> <ul> <li> Windows APIs Everywhere in .NET</li> </ul>"},{"location":"Coding/Windows/#winui","title":"WinUI","text":"<p>Windows UI Library (WinUI) 3 is a native UI framework that represents a rebranding of the UWP UI framework, which had previously only been available for applications using the UWP app model, and a move to make it available for both app models.</p> <p>Still in development, it promises to deliver a unified framework and all the styles and controls previously distributed in WinUI 2, which in turn is a NuGet packaging containing the UWP XAML controls and styles.</p> <p>Unfortunately, because the UWP framework had been available only for the UWP app model, it did not experience wide adoption among developers who prefered the flexibility of the older Win32 \"app model\" (or rather, the lack of one). </p>"},{"location":"Coding/Wired%20Brain%20Coffee/","title":"\u2615 Wired Brain Coffee","text":""},{"location":"Coding/Wired%20Brain%20Coffee/#basic-layout","title":"Basic layout","text":"MainPage.xaml <pre><code>&lt;Window\nx:Class=\"WiredBrainCoffee.UWP.MainWindow\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"&gt;\n\n&lt;Grid&gt;\n&lt;Grid.RowDefinitions&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt;\n&lt;RowDefinition/&gt;\n&lt;/Grid.RowDefinitions&gt;\n&lt;Grid.ColumnDefinitions&gt;\n&lt;ColumnDefinition Width=\"350\"/&gt;\n&lt;ColumnDefinition Width=\"*\"/&gt;\n&lt;/Grid.ColumnDefinitions&gt;\n\n&lt;Border Grid.ColumnSpan=\"2\" Background=\"#f05a28\"&gt;\n&lt;StackPanel Orientation=\"Horizontal\" HorizontalAlignment=\"Center\"&gt;\n&lt;Image Height=\"90\" Margin=\"5\" Source=\"/Images/logo.png\"/&gt;\n&lt;TextBlock Text=\"Employee Manager\" FontSize=\"40\" VerticalAlignment=\"Center\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/Border&gt;\n\n&lt;!-- Sidebar --&gt;\n&lt;Grid Grid.Row=\"1\"&gt;\n&lt;Grid.RowDefinitions&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt;\n&lt;RowDefinition /&gt;\n&lt;/Grid.RowDefinitions&gt;\n\n&lt;Button Content=\"Refresh\" Margin=\"10\"/&gt;\n&lt;ListView Grid.Row=\"1\"/&gt;\n&lt;/Grid&gt;\n\n&lt;!--MainArea--&gt;\n&lt;Grid Grid.Row=\"1\" Grid.Column=\"1\"&gt;\n&lt;Grid.RowDefinitions&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt; &lt;RowDefinition Height=\"*\"/&gt; &lt;/Grid.RowDefinitions&gt;\n\n&lt;TextBox Header=\"Firstname\" Margin=\"10\"/&gt;\n&lt;DatePicker Grid.Row=\"1\" Header=\"Entry date\" Margin=\"10\"/&gt;\n&lt;ComboBox Grid.Row=\"2\" Header=\"Job role\" Margin=\"10\" HorizontalAlignment=\"Stretch\"/&gt;\n&lt;CheckBox Grid.Row=\"3\" Content=\"Is coffee drinker?\" Margin=\"10\"/&gt;\n&lt;Button Grid.Row=\"4\" Content=\"Save\" Margin=\"10 10 10 30\"\nVerticalAlignment=\"Bottom\" HorizontalAlignment=\"Left\"/&gt;\n&lt;/Grid&gt;\n&lt;/Grid&gt;\n&lt;/Window&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#custom-control","title":"Custom control","text":"Controls/HeaderControl.xaml <pre><code>&lt;UserControl\nx:Class=\"WiredBrainCoffee.UWP.Controls.HeaderControl\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP.Controls\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nd:DesignHeight=\"300\"\nd:DesignWidth=\"400\"&gt;\n\n&lt;Border Background=\"#F05A28\"&gt;\n&lt;Grid&gt;\n&lt;Grid.ColumnDefinitions&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition Width=\"Auto\"/&gt;\n&lt;/Grid.ColumnDefinitions&gt;\n\n&lt;StackPanel Orientation=\"Horizontal\" HorizontalAlignment=\"Center\"&gt;\n&lt;Image Source=\"/Images/WiredBrainLogo.png\" Height=\"90\"/&gt;\n&lt;TextBlock Text=\"Wired Brain Coffee\" FontSize=\"40\" VerticalAlignment=\"Center\"/&gt;\n\n&lt;/StackPanel&gt;\n&lt;Button HorizontalAlignment=\"Right\" Grid.Column=\"1\" Margin=\"10\"&gt;\n&lt;SymbolIcon Symbol=\"AlignRight\"/&gt;\n&lt;/Button&gt;\n\n&lt;/Grid&gt;\n&lt;/Border&gt;\n&lt;/UserControl&gt;\n</code></pre> MainPage.xaml <pre><code>&lt;Page\nx:Class=\"WiredBrainCoffee.UWP.MainPage\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\" xmlns:controls=\"using:WiredBrainCoffee.UWP.Controls\"\nmc:Ignorable=\"d\"\nBackground=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\"&gt;\n\n&lt;Grid&gt;\n&lt;Grid.RowDefinitions&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt;\n&lt;RowDefinition/&gt;\n&lt;/Grid.RowDefinitions&gt;\n&lt;Grid.ColumnDefinitions&gt;\n&lt;ColumnDefinition Width=\"350\"/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;/Grid.ColumnDefinitions&gt;\n\n&lt;!-- Header --&gt;\n&lt;controls:HeaderControl Grid.ColumnSpan=\"2\"/&gt;\n\n&lt;!-- Sidebar --&gt;\n&lt;Grid Grid.Row=\"1\"&gt;\n&lt;Grid.RowDefinitions&gt;\n&lt;RowDefinition Height=\"Auto\"/&gt;\n&lt;RowDefinition/&gt;\n&lt;/Grid.RowDefinitions&gt;\n&lt;StackPanel Orientation=\"Horizontal\"&gt;\n&lt;Button Margin=\"10\"&gt;\n&lt;SymbolIcon Symbol=\"AddFriend\"/&gt;\n&lt;/Button&gt;\n&lt;Button Margin=\"10\"&gt;\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/Button&gt;\n&lt;/StackPanel&gt;\n&lt;ListView Grid.Row=\"1\"&gt;\n&lt;ListViewItem&gt;Aristotle&lt;/ListViewItem&gt;\n&lt;ListViewItem&gt;Euclid&lt;/ListViewItem&gt;\n&lt;ListViewItem&gt;Plato&lt;/ListViewItem&gt;\n&lt;ListViewItem&gt;Socrates&lt;/ListViewItem&gt;\n&lt;/ListView&gt;\n&lt;/Grid&gt;\n&lt;StackPanel Grid.Row=\"1\" Grid.Column=\"1\"&gt;\n&lt;TextBox Header=\"First name\" Margin=\"10\"/&gt;\n&lt;TextBox Header=\"Last name\" Margin=\"10\"/&gt;\n&lt;CheckBox Content=\"Drinks coffee\" Margin=\"10\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/Grid&gt;\n&lt;/Page&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#sidebar","title":"Sidebar","text":"<p>Setting an <code>x:Name</code> attribute on an element allows it to be manipulated in C#. (src)</p> MainPage.xaml.cs <pre><code>private void btn_MoveSideBar_Click(object sender, RoutedEventArgs e)\n{\nint column = Grid.GetColumn(customerListGrid);\nint newcolumn;\nif (column == 0)\n{\nnewcolumn = 2;\nbtn_MoveSideBar_Symbol.Symbol = Symbol.AlignLeft;\n}\nelse\n{\nnewcolumn = 0;\nbtn_MoveSideBar_Symbol.Symbol = Symbol.AlignRight;\n}\nGrid.SetColumn(customerListGrid, newcolumn);\n}\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#data-provider","title":"Data provider","text":"<p>A data provider class accomodates the need for mock data while also loosely coupling the data with the source. (src)</p> DataProviders/CustomerDataProvider.cs <pre><code>using Newtonsoft.Json;\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nusing System.IO;\nusing Windows.Storage;\nusing Windows.Storage.Streams;\nusing WiredBrainCoffee.UWP.Models;\n\nnamespace WiredBrainCoffee.UWP.DataProviders\n{\nclass CustomerDataProvider\n{\nprivate static readonly string _customersFileName = \"customers.json\";\nprivate static readonly StorageFolder _localFolder = ApplicationData.Current.LocalFolder;\n\npublic async Task&lt;IEnumerable&lt;Customer&gt;&gt; LoadCustomersAsync()\n{\nvar storageFile = await _localFolder.TryGetItemAsync(_customersFileName) as StorageFile;\nList&lt;Customer&gt; customerList = null;\n\nif (storageFile == null)\n{\ncustomerList = new List&lt;Customer&gt;\n{\nnew Customer{FirstName=\"Clark\",LastName=\"Kent\",IsCoffeeDrinker=true},\nnew Customer{FirstName=\"Bruce\",LastName=\"Wayne\",IsCoffeeDrinker=false},\nnew Customer{FirstName=\"Diana\",LastName=\"Prince\",IsCoffeeDrinker=true}\n};\n}\n\nelse\n{\nusing (var stream = await storageFile.OpenAsync(FileAccessMode.Read))\n{\nusing (var dataReader = new DataReader(stream))\n{\nawait dataReader.LoadAsync((uint)stream.Size);\nvar json = dataReader.ReadString((uint)stream.Size);\ncustomerList = JsonConvert.DeserializeObject&lt;List&lt;Customer&gt;&gt;(json);\n}\n}\n}\n\nreturn customerList;\n}\n\n\npublic async Task SaveCustomersAsync(IEnumerable&lt;Customer&gt; customers)\n{\nvar storageFile = await _localFolder.CreateFileAsync(_customersFileName, CreationCollisionOption.ReplaceExisting);\n\nusing (var stream = await storageFile.OpenAsync(FileAccessMode.ReadWrite))\n{\nusing (var dataWriter = new DataWriter(stream))\n{\nvar json = JsonConvert.SerializeObject(customers, Formatting.Indented);\ndataWriter.WriteString(json);\nawait dataWriter.StoreAsync();\n}\n}\n}\n}\n}\n</code></pre> Models/Customer.cs <pre><code>namespace WiredBrainCoffee.UWP.Models\n{\npublic class Customer\n{\npublic string FirstName { get; set; }\npublic string LastName { get; set; }\npublic bool IsCoffeeDrinker { get; set; }\n}\n}\n</code></pre> <p>Event hooks are used to populate the <code>ListView</code> with data from the data provider.</p> MainPage.xaml.cs <pre><code>public MainPage()\n{\nthis.InitializeComponent();\nthis.Loaded += MainPage_LoadedAsync;\n\nApp.Current.Suspending += App_SuspendingAsync;\n\n_customerDataProvider = new CustomerDataProvider();\n}\n\nprivate async void App_SuspendingAsync(object sender, Windows.ApplicationModel.SuspendingEventArgs e)\n{\nvar deferral = e.SuspendingOperation.GetDeferral();\nawait _customerDataProvider.SaveCustomersAsync(customerListView.Items.OfType&lt;Customer&gt;());\ndeferral.Complete();\n}\n\nprivate async void MainPage_LoadedAsync(object sender, RoutedEventArgs e)\n{\ncustomerListView.Items.Clear();\n\nvar customers = await _customerDataProvider.LoadCustomersAsync();\nforeach (var customer in customers)\n{\ncustomerListView.Items.Add(customer);\n}\n}\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#data-binding-using-events","title":"Data binding using events","text":"<p>Synchronize the customer detail textboxes to the selected item in the ListView. A rough form of data binding is possible with event handling. (src)</p> <p>First implement an event handler when the <code>ListView.SelectionChanged</code> event is fired.</p> MainPage.xaml <pre><code>&lt;ListView Grid.Row=\"1\" x:Name=\"customerListView\" DisplayMemberPath=\"FirstName\"\nSelectionChanged=\"customerListView_SelectionChanged\"/&gt;\n</code></pre> MainPage.xaml.cs <pre><code>private void customerListView_SelectionChanged(object sender, SelectionChangedEventArgs e)\n{\nvar customer = customerListView.SelectedItem as Customer;\ntxtFirstName.Text = customer?.FirstName ?? \"\";\ntxtLastName.Text = customer?.LastName ?? \"\";\nchkDrinksCoffee.IsChecked = customer?.IsCoffeeDrinker;\n}\n</code></pre> <p>Implement event handlers on the controls in the main area (<code>TextBox.TextChanged</code> and <code>CheckBox.Checked</code> and <code>CheckBox.Unchedked</code> events) when changes are made.</p>  MainPage.xaml  <pre><code>&lt;StackPanel Grid.Row=\"1\" Grid.Column=\"1\"&gt;\n&lt;TextBox x:Name=\"txtFirstName\"\nHeader=\"First name\" Margin=\"10\"\nTextChanged=\"UpdateCustomer\"/&gt;\n&lt;TextBox x:Name=\"txtLastName\"\nHeader=\"Last name\" Margin=\"10\"\nTextChanged=\"UpdateCustomer\"/&gt;\n&lt;CheckBox x:Name=\"chkDrinksCoffee\"\nContent=\"Caffeine fiend\" Margin=\"10\"\nChecked=\"UpdateCustomer\"\nUnchecked=\"UpdateCustomer\"/&gt;\n&lt;/StackPanel&gt;\n</code></pre> MainPage.xaml.cs <pre><code>private void UpdateCustomer(object sender, RoutedEventArgs e)\n{\nvar customer = customerListView.SelectedItem as Customer;\n\nif (customer != null)\n{\ncustomer.FirstName = txtFirstName.Text;\ncustomer.LastName = txtLastName.Text;\ncustomer.IsCoffeeDrinker = chkDrinksCoffee.IsChecked.GetValueOrDefault();\n}\n}\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#update-listview","title":"Update ListView","text":"<p><code>ListView</code> still won't update as a result of changes. In order to implement this, you have to raise the <code>PropertyChanged</code> event. We implement the <code>INotifyPropertyChanged</code> interface and make it the base class of Customer. Also, we implement a helper method to fire the event handler whenever a property is changed. This helper is invoked every time a property is set. The <code>CallerMemberName</code> attribute passes the name of the calling property as a string, and allows us to avoid placing <code>typeof(FirstName)</code>, etc with every invocation. (src)</p> Models/Customer.cs <pre><code>using System.ComponentModel;\nusing System.Runtime.CompilerServices;\n\nnamespace WiredBrainCoffee.UWP.Models\n{\npublic class Observable : INotifyPropertyChanged\n{\npublic event PropertyChangedEventHandler PropertyChanged;\n\nprotected virtual void OnPropertyChanged([CallerMemberName] string propertyName = null)\n{\nPropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName));\n}\n}\n\npublic class Customer : Observable\n{\nprivate string firstName;\nprivate string lastName;\nprivate bool isCoffeeDrinker;\n\npublic string FirstName\n{\nget =&gt; firstName;\nset\n{\nfirstName = value;\nOnPropertyChanged();\n}\n}\npublic string LastName\n{\nget =&gt; lastName;\nset\n{\nlastName = value;\nOnPropertyChanged();\n}\n}\npublic bool IsCoffeeDrinker\n{\nget =&gt; isCoffeeDrinker; set\n{\nisCoffeeDrinker = value;\nOnPropertyChanged();\n}\n}\n\n}\n}\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#addremove-customers","title":"Add/remove customers","text":"<p>Implement event handlers for the Add and Delete buttons. (src)</p> MainPage.xaml.cs <pre><code>private void DeleteCustomer_Click(object sender, RoutedEventArgs e)\n{\nvar customer = customerListView.SelectedItem;\nif (customer != null)\n{\ncustomerListView.Items.Remove(customer);\n}\n}\nprivate void AddCustomer_Click(object sender, RoutedEventArgs e)\n{\nvar customer = new Customer { FirstName = \"New\" };\ncustomerListView.Items.Add(customer);\ncustomerListView.SelectedItem = customer;\n}\n</code></pre> MainPage.xaml <pre><code>&lt;Button x:Name=\"AddCustomer\" Margin=\"10\" Click=\"AddCustomer_Click\" &gt;\n&lt;SymbolIcon Symbol=\"AddFriend\"/&gt;\n&lt;/Button&gt;\n&lt;Button x:Name=\"DeleteCustomer\" Margin=\"10\" Click=\"DeleteCustomer_Click\"&gt;\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/Button&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#custom-control_1","title":"Custom control","text":"<p>We abstract controls in the main area of the app into a new CustomerDetailControl. As before, we cut the UI elements into a new XAML file and reference the new control in MainPage. However, now, customerListView is inaccessible.</p> <p>The lynchpin is forming a property on customerDetailControl that is populated with the customer object by the <code>SelectionChanged</code> event handler</p> MainPage.xaml.cs <pre><code>private void customerListView_SelectionChanged(object sender, SelectionChangedEventArgs e)\n{\nvar customer = customerListView.SelectedItem as Customer;\ncustomerDetailControl.Customer = customer;\n}\n</code></pre> Controls/CustomerDetailControl.xaml <pre><code>&lt;UserControl\nx:Class=\"WiredBrainCoffee.UWP.Controls.CustomerDetailControl\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP.Controls\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nd:DesignHeight=\"300\"\nd:DesignWidth=\"400\"&gt;\n\n&lt;StackPanel&gt;\n&lt;TextBox x:Name=\"txtFirstName\"\nHeader=\"First name\" Margin=\"10\"\nTextChanged=\"UpdateCustomer\"/&gt;\n&lt;TextBox x:Name=\"txtLastName\"\nHeader=\"Last name\" Margin=\"10\"\nTextChanged=\"UpdateCustomer\"/&gt;\n&lt;CheckBox x:Name=\"chkDrinksCoffee\"\nContent=\"Caffeine fiend\" Margin=\"10\"\nChecked=\"UpdateCustomer\"\nUnchecked=\"UpdateCustomer\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/UserControl&gt;\n</code></pre> Controls/CustomerDetailControl.xaml.cs <pre><code>using Windows.UI.Xaml;\nusing Windows.UI.Xaml.Controls;\nusing WiredBrainCoffee.UWP.Models;\n\nnamespace WiredBrainCoffee.UWP.Controls\n{\npublic sealed partial class CustomerDetailControl : UserControl\n{\npublic CustomerDetailControl()\n{\nthis.InitializeComponent();\n}\n\nprivate Customer _customer;\n\npublic Customer Customer\n{\nget { return _customer; }\nset\n{\n_customer = value;\n\ntxtFirstName.Text = _customer?.FirstName ?? \"\";\ntxtLastName.Text = _customer?.LastName ?? \"\";\nchkDrinksCoffee.IsChecked = _customer?.IsCoffeeDrinker;\n}\n}\n\n\n\nprivate void UpdateCustomer(object sender, RoutedEventArgs e)\n{\nif (Customer != null)\n{\nCustomer.FirstName = txtFirstName.Text;\nCustomer.LastName = txtLastName.Text;\nCustomer.IsCoffeeDrinker = chkDrinksCoffee.IsChecked.GetValueOrDefault();\n\n}\n\n}\n}\n}\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#assign-mock-content","title":"Assign mock content","text":"<p>We combine two different namespace mappings (one for the Customer model and another for the CustomerDetailControl) to prepopulate the CustomerDetailControl with a customer defined in XAML. Because CustomerDetailControl exposes a public Customer property, this data can be assigned to the <code>Customer</code> property using property-element syntax. (src)</p> MainPage.xaml <pre><code>&lt;controls:CustomerDetailControl x:Name=\"customerDetailControl\" Grid.Row=\"1\" Grid.Column=\"1\"&gt;\n&lt;controls:CustomerDetailControl.Customer&gt;\n&lt;model:Customer FirstName=\"Clark\" LastName=\"Kent\" IsCoffeeDrinker=\"True\"/&gt;\n&lt;/controls:CustomerDetailControl.Customer&gt;\n&lt;/controls:CustomerDetailControl&gt;\n</code></pre> <p>In order to be able to assign the customer as direct content without specifying the property explicitly, the custom control class has to be decorated with the <code>ContentProperty</code> attribute.  This is because by default any direct child is assigned to the <code>Content</code> property, which does not exist for this custom control. Using the <code>ContentProperty</code> allows us to specify a property to which to assign direct children.</p> Controls/CustomerDetailControl.xaml.cs <pre><code>[ContentProperty(Name = nameof(Customer))]\npublic sealed partial class CustomerDetailControl : UserControl { /* ... */ }\n</code></pre> MainPage.xaml <pre><code>&lt;controls:CustomerDetailControl x:Name=\"customerDetailControl\" Grid.Row=\"1\" Grid.Column=\"1\"&gt;\n&lt;model:Customer FirstName=\"Clark\" LastName=\"Kent\" IsCoffeeDrinker=\"True\"/&gt;\n&lt;/controls:CustomerDetailControl&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#xaml-type-conversion","title":"XAML Type conversion","text":"<p>Passing the customer as an attribute requires custom logic to parse the string. The target model is then decorated with the <code>CreateFromString</code> attribute. This is only for custom classes: primitive types and enumerations can be parsed by the XAML processor automatically.</p> Models/CustomerConverter.cs <pre><code>namespace WiredBrainCoffee.UWP.Models\n{\npublic static class CustomerConverter\n{\npublic static Customer ParseStringAsCustomer(string s)\n{\nstring[] values = s.Split(';');\nreturn new Customer { FirstName = values[0], LastName = values[1], IsCoffeeDrinker = bool.Parse(values[2]) };\n}\n}\n}\n</code></pre> Models/Customer.cs <pre><code>[CreateFromString(MethodName =\"WiredBrainCoffee.UWP.Models.CustomerConverter.ParseCustomerFromString\")]\npublic class Customer : Observable\n{\n/* ... */\n}\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#staticresource","title":"StaticResource","text":"<p>You can use the StaticResource Markup Extension to define the equivalent of XAML variables to store elements for attribution using attribute syntax.</p> <p>Every UI element has a property named <code>Resources</code> to which you can assign elements. Unlike the <code>Items</code> property of a ListView, however, this property is a Dictionary type, which means you must specify a key for these values (i.e. specify <code>x:Key</code>). Because the XAML processor looks for resources as it crawls up the element tree, these resources can be organized at any level of the application, even in the App.xaml where it will become available to other files: (src)</p> MainPage.xaml <pre><code>&lt;Page.Resources&gt;\n&lt;model:Customer x:Key=\"Shazam\" FirstName=\"William\" LastName=\"William Batson\" IsCoffeeDrinker=\"false\"/&gt;\n&lt;/Page.Resources&gt;\n\n&lt;!-- ... --&gt;\n&lt;controls:CustomerDetailControl Customer=\"{StaticResource Shazam}\"/&gt;\n</code></pre> <p>However, mocking data in XAML is an anti-pattern; Resource dictionaries are typically used for colors and predefined strings.</p> <p>Resource dictionaries are consolidated into their own files: (src)</p> Resources/Brushes.xaml <pre><code>&lt;ResourceDictionary\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\" xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"&gt;\n&lt;SolidColorBrush x:Key=\"customerListBackgroundBrush\" Color=\"#EEEEEE\"/&gt;\n&lt;/ResourceDictionary&gt;\n</code></pre> Resources/Strings.xaml <pre><code>&lt;ResourceDictionary\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\" xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"&gt;\n&lt;x:String x:Key=\"applicationTitle\"&gt;Wired Brain Coffee&lt;/x:String&gt;\n&lt;/ResourceDictionary&gt;\n</code></pre> <p>These can then be referenced from App.xaml and are available for assignment in any appropriate attribute</p> App.xaml <pre><code>&lt;Application\nx:Class=\"WiredBrainCoffee.UWP.App\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP\"&gt;\n&lt;Application.Resources&gt;\n&lt;ResourceDictionary&gt;\n&lt;ResourceDictionary.MergedDictionaries&gt;\n&lt;ResourceDictionary Source=\"Resources/Brushes.xaml\"/&gt;\n&lt;ResourceDictionary Source=\"Resources/Strings.xaml\"/&gt;\n&lt;/ResourceDictionary.MergedDictionaries&gt;\n&lt;/ResourceDictionary&gt;\n&lt;/Application.Resources&gt;\n&lt;/Application&gt;\n</code></pre> Controls/HeaderControl.xaml <pre><code>&lt;UserControl\nx:Class=\"WiredBrainCoffee.UWP.Controls.HeaderControl\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP.Controls\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nd:DesignHeight=\"300\"\nd:DesignWidth=\"400\"&gt;\n\n&lt;Border Background=\"#F05A28\"&gt;\n&lt;Grid&gt;\n&lt;Grid.ColumnDefinitions&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition Width=\"Auto\"/&gt;\n&lt;/Grid.ColumnDefinitions&gt;\n\n&lt;StackPanel Orientation=\"Horizontal\" HorizontalAlignment=\"Center\"&gt;\n&lt;Image Source=\"/Images/WiredBrainLogo.png\" Height=\"90\"/&gt;\n&lt;TextBlock Text=\"{StaticResource applicationTitle}\" FontSize=\"40\" VerticalAlignment=\"Center\"/&gt;\n\n&lt;/StackPanel&gt;\n&lt;Button x:Name=\"ButtonMove\" HorizontalAlignment=\"Right\" Grid.Column=\"1\" Margin=\"10\" Click=\"ButtonMove_Click\"&gt;\n&lt;SymbolIcon x:Name=\"ButtonMove_Symbol\" Symbol=\"AlignRight\"/&gt;\n&lt;/Button&gt;\n\n&lt;/Grid&gt;\n&lt;/Border&gt;\n&lt;/UserControl&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#themeresource","title":"ThemeResource","text":"<p>The ThemeResource Markup Extension makes UWP-specific theme resource dictionaries available. These same resources are available using StaticResource, but with ThemeResource they will be updated if the user changes his Windows theme from light to dark. (src)</p> Resources/Brushes.xaml <pre><code>&lt;ResourceDictionary\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\" xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"&gt;\n&lt;ResourceDictionary.ThemeDictionaries&gt;\n&lt;ResourceDictionary x:Key=\"Dark\"&gt;\n&lt;SolidColorBrush x:Key=\"customerListBackgroundBrush\" Color=\"#222222\"/&gt;\n&lt;/ResourceDictionary&gt;\n&lt;ResourceDictionary x:Key=\"Light\"&gt;\n&lt;SolidColorBrush x:Key=\"customListBackgroundBrush\" Color=\"#EEEEEE\"/&gt;\n&lt;/ResourceDictionary&gt;\n\n&lt;/ResourceDictionary.ThemeDictionaries&gt;\n&lt;/ResourceDictionary&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#theme-selection","title":"Theme selection","text":"<p>A specific theme can be specified at any element by specifying a <code>RequestedTheme</code> attribute. However, this property cannot be changed at runtime.</p> App.xaml <pre><code>&lt;Application\nx:Class=\"WiredBrainCoffee.UWP.App\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP\"\nRequestedTheme=\"Dark\"&gt;\n&lt;Application.Resources&gt;\n&lt;ResourceDictionary&gt;\n&lt;ResourceDictionary.MergedDictionaries&gt;\n&lt;ResourceDictionary Source=\"Resources/Brushes.xaml\"/&gt;\n&lt;ResourceDictionary Source=\"Resources/Strings.xaml\"/&gt;\n&lt;/ResourceDictionary.MergedDictionaries&gt;\n&lt;/ResourceDictionary&gt;\n&lt;/Application.Resources&gt;\n&lt;/Application&gt;\n</code></pre> <p>A button to manually change theme involves simply assigning an <code>ElementTheme</code> enum value to the MainPage's <code>RequestedTheme</code> property. However, because on startup this has an <code>ApplicationTheme</code> enum value that is not evailable in <code>ElementTheme</code>, the MainPage's constructor must be changed to set the correct theme enum. Without this change, the first click after the application's startup will not change the theme at all, only set the correct <code>ElementTheme</code>.  (src)</p> MainPage.xaml <pre><code>&lt;!-- Header --&gt;\n&lt;controls:HeaderControl Grid.ColumnSpan=\"3\"/&gt;\n\n&lt;Button Grid.ColumnSpan=\"3\" Click=\"ChangeTheme\" Margin=\"10\" VerticalAlignment=\"Top\" HorizontalAlignment=\"Right\"&gt;\n&lt;SymbolIcon Symbol=\"Placeholder\"/&gt;\n&lt;/Button&gt;\n</code></pre> MainPage.xaml.cs <pre><code>public MainPage()\n{\nthis.InitializeComponent();\nthis.Loaded += MainPage_LoadedAsync;\n\nApp.Current.Suspending += App_SuspendingAsync;\n\n_customerDataProvider = new CustomerDataProvider();\nRequestedTheme = App.Current.RequestedTheme == ApplicationTheme.Dark\n? ElementTheme.Dark\n: ElementTheme.Light;\n}\n\nprivate void ChangeTheme(object sender, RoutedEventArgs e)\n{\nthis.RequestedTheme = RequestedTheme == ElementTheme.Dark ? ElementTheme.Light : ElementTheme.Dark;\n}\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#color-theme","title":"Color theme","text":"<p>The Fluent XAML Theme Editor on the Microsoft Store can generate ThemeResource dictionaries </p>"},{"location":"Coding/Wired%20Brain%20Coffee/#data-binding","title":"Data binding","text":"<p>Use the Binding markup extension to establish a binding on the CustomerDetailControl to the Customer property of customerListView</p> <p>Here, the Customer property is the target property, and the SelectedItem property of customerListView is the source property. So this data binding makes the information in the customerDetailControl (target) dependent on which item is selected (source).</p> MainPage.xaml.cs <pre><code>&lt;controls:CustomerDetailControl x:Name=\"customerDetailControl\" Grid.Row=\"1\" Grid.Column=\"1\"\nCustomer=\"{Binding ElementName=customerListView,Path=SelectedItem,Mode=OneWay}\"&gt;\n</code></pre> <p>However, the target of a data binding needs to be a Dependency Property. The purpose of dependency properties is to provide a way to compute the value of a property based on the value of other inputs. The Visual Studio snippet for a dependency property is <code>propdp</code>.</p> <p>A dependency property includes a static readonly field of type <code>DependencyProperty</code> and a normal property that works as a frontend for that field by wrapping <code>GetValue</code> and <code>SetValue</code>.</p> <p>We implement the logic to update the controls with the selected customer as a callback function passed as the second argument of the <code>PropertyMetadata</code> object in the dependency property definition. This callback must be a static void function, and as such it has no access to the instantiated objects we have already named with <code>x:Name</code>. However, these objects are retrievable from the <code>DependencyObject</code> and <code>DependencyPropertyChangedEventArgs</code> parameters that are passed to the callback. (src)</p> Controls/CustomerDetailControl.xaml.cs <pre><code>public Customer Customer\n{\nget { return (Customer)GetValue(CustomerProperty); }\nset { SetValue(CustomerProperty, value); }\n}\n\n// Using a DependencyProperty as the backing store for Customer.  This enables animation, styling, binding, etc...\npublic static readonly DependencyProperty CustomerProperty =\nDependencyProperty.Register(\"Customer\", typeof(Customer), typeof(CustomerDetailControl), new PropertyMetadata(null, CustomerChangedCallback));\n\nprivate static void CustomerChangedCallback(DependencyObject d, DependencyPropertyChangedEventArgs e)\n{\nif (d is CustomerDetailControl customerDetailControl)\n{\nvar customer = e.NewValue as Customer;\n\ncustomerDetailControl.txtFirstName.Text = customer?.FirstName ?? \"\";\ncustomerDetailControl.txtLastName.Text = customer?.LastName ?? \"\";\ncustomerDetailControl.chkDrinksCoffee.IsChecked = customer?.IsCoffeeDrinker;\n}\n}\n</code></pre> <p>This bound the customerDetailControl to the item selected in customerListView. </p> <p>Now we implement the data bindings on each control of customerDetailControl. We give the root UserControl an <code>x:Name</code> so that we can refer to it in the binding markup extensions of the children as the value of <code>ElementName</code>.  We can also remove the <code>x:Name</code>s of the individual controls, as well any trace of the event handlers! (src)</p> Controls/CustomerDetailControl.xaml <pre><code>&lt;UserControl\nx:Class=\"WiredBrainCoffee.UWP.Controls.CustomerDetailControl\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP.Controls\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nd:DesignHeight=\"300\"\nd:DesignWidth=\"400\"\nx:Name=\"root\"&gt;\n\n&lt;StackPanel&gt;\n&lt;TextBox Header=\"First name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Customer.FirstName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\n/&gt;\n&lt;TextBox Header=\"Last name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Customer.LastName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\n\n/&gt;\n&lt;CheckBox Content=\"Caffeine fiend\" Margin=\"10\"\nIsChecked=\"{Binding ElementName=root,Path=Customer.FirstName,Mode=TwoWay}\"\n/&gt;\n&lt;/StackPanel&gt;\n&lt;/UserControl&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#viewmodel","title":"ViewModel","text":"<p>In the work above, we used the binding markup extension to bind one element to another, using that other element as a data source</p> <pre><code>&lt;TextBlock Text=\"{Binding ElementName=root,...}\"&gt;\n</code></pre> <p>We can use the MVVM pattern to assign the object to be bound to customerDetailControl as a data context. Every UI element has a <code>DataContext</code> property that can be set, and if it is set to an object then it can be placed there as a default data source that the XAML processor will find as it walks up the element tree. (src)</p> <p>This will allow us to simplify the markup, removing the <code>x:Name</code> from the root and the <code>ElementName</code> from the data bindings of the children. </p> <p>First we create the ViewModel, which incorporates some of the logic from the former <code>App_SuspendingAsync</code> and <code>MainPage_LoadedAsync</code> event handler methods. The ViewModel can dispose of the references to customerDetailControl and customerListView and replace them with its own Customers property.</p> ViewModel/MainViewModel.cs <pre><code>using System.Collections.ObjectModel;\nusing System.Threading.Tasks;\nusing WiredBrainCoffee.UWP.DataProviders;\nusing WiredBrainCoffee.UWP.Models;\n\nnamespace WiredBrainCoffee.UWP.ViewModel\n{\npublic class MainViewModel\n{\npublic ObservableCollection&lt;Customer&gt; Customers { get; }\npublic MainViewModel()\n{\n_customerDataProvider = new CustomerDataProvider();\nCustomers = new ObservableCollection&lt;Customer&gt;();\n}\n\nprivate CustomerDataProvider _customerDataProvider;\n\n\npublic async Task LoadAsync()\n{\nCustomers.Clear();\n\nvar customers = await _customerDataProvider.LoadCustomersAsync();\nforeach (var customer in customers)\n{\nCustomers.Add(customer);\n}\n}\n\npublic async Task SaveAsync()\n{\nawait _customerDataProvider.SaveCustomersAsync(Customers);\n}\n}\n}\n</code></pre> <p>To further decouple the ViewModel from the data provider, in order to facilitate testing, we extract an interface from CustomerDataProvider.</p> DataProviders/ICustomerDataProvider.cs <pre><code>using System.Collections.Generic;\nusing System.Threading.Tasks;\nusing WiredBrainCoffee.UWP.Models;\n\nnamespace WiredBrainCoffee.UWP.DataProviders\n{\npublic interface ICustomerDataProvider\n{\nTask&lt;IEnumerable&lt;Customer&gt;&gt; LoadCustomersAsync();\nTask SaveCustomersAsync(IEnumerable&lt;Customer&gt; customers);\n}\n}\n</code></pre> <p>Now we implement an <code>ICustomerDataProvider</code> parameter to the ViewModel constructor, and remember to pass in a new data provider as an argument implementing that interface. The private field _customerDataProvider can be removed.</p> ViewModel/MainViewModel.cs <pre><code>private ICustomerDataProvider _customerDataProvider;\npublic MainViewModel(ICustomerDataProvider customerDataProvider)\n{\n_customerDataProvider = customerDataProvider;\nCustomers = new ObservableCollection&lt;Customer&gt;();\n}\n</code></pre> MainPage.xaml.cs <pre><code>this.ViewModel = new MainViewModel(new CustomerDataProvider());\nDataContext = ViewModel;\n</code></pre> <p>Finally, since we have a data context on MainPage, we can set it as a source for the ListView</p> MainPage.xaml <pre><code>&lt;ListView ItemsSource=\"{Binding Customers,Mode=OneWay}\"\nGrid.Row=\"1\" x:Name=\"customerListView\" DisplayMemberPath=\"FirstName\"&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#binding-the-selected-customer","title":"Binding the selected customer","text":"<p>At this moment, customerDetailControl is still tied to customerListView's SelectedItem property directly, and not through the ViewModel. To change this, we implement a SelectedCustomer property on the ViewModel that will be bound to both. We reuse the Observable base class that implement the <code>INotifyPropertyChanged</code> interface. This allows us to use the <code>OnPropertyChanged()</code> method in the setter of the new SelectedItem property. We replace the element binding of customerListView with a binding to the SelectedCustomer property in the data context.</p> ViewModel/MainViewModel.cs <pre><code>public class MainViewModel : Observable\n{\nprivate Customer selectedCustomer;\n\npublic Customer SelectedCustomer\n{\nget { return selectedCustomer; }\nset { selectedCustomer = value;\nOnPropertyChanged();\n}\n}\n\n// ...\n}\n</code></pre> MainPage.xaml <pre><code>&lt;ListView ItemsSource=\"{Binding Customers,Mode=OneWay}\"\nGrid.Row=\"1\" x:Name=\"customerListView\" DisplayMemberPath=\"FirstName\"\nSelectedItem=\"{Binding SelectedCustomer,Mode=TwoWay}\"&gt;\n&lt;/ListView&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#datatemplate","title":"DataTemplate","text":"<p>At this moment, customerListView is being populated by a single property of each Customer - their first name. If we want to compose more complex information, we can assign DataTemplate to the ListView's ItemTemplate property. This will create the enclosed controls for each element in the ListView. Remember to remove the <code>DisplayMemberPath</code> attribute!</p> <pre><code>&lt;ListView ItemsSource=\"{Binding Customers,Mode=OneWay}\"\nGrid.Row=\"1\" x:Name=\"customerListView\" SelectedItem=\"{Binding SelectedCustomer,Mode=TwoWay}\"&gt;\n&lt;ListView.ItemTemplate&gt;\n&lt;DataTemplate&gt;\n&lt;StackPanel Orientation=\"Horizontal\"&gt;\n&lt;TextBlock Text=\"{Binding FirstName}\"/&gt;\n&lt;TextBlock Text=\"{Binding LastName}\" Margin=\"5 0 0 0\" FontWeight=\"Bold\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/DataTemplate&gt;\n&lt;/ListView.ItemTemplate&gt;\n&lt;/ListView&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#xbind","title":"x:Bind","text":"<p>There are two data binding types available in XAML (src)</p> <ul> <li>Binding markup extension resolves the binding path at runtime.</li> <li>x:Bind resolves the binding path at compile-time, generating C# code and offering better performance and compile-time errors. You can also step into the compiled code, providing a better debugging experience. x:Bind should generally be preferred, however it is available only in UWP.</li> </ul> <p>Binding markup extension can have several different data sources, depending on defined attributes.</p> <ul> <li><code>ElementName</code></li> <li><code>Source</code></li> <li><code>RelativeSource</code></li> </ul> <p>If none of these are defined, then the binding markup extension resolves to the DataContext property.</p> <p>x:Bind, in contrast, binds only to the parent Page or UserControl element. So any property of MainPage will be accessible, and any property of that object will also be accessible using dot notation.</p> <p>Most bindings are easily translated between the two types if the ViewModel has already been implemented as a property of MainPage:</p> Binding markup extensionx:Bind <p><pre><code>public MainPage()\n{\nthis.InitializeComponent;\nthis.ViewModel = new MainViewModel();\nDataContext = ViewModel;\n}\n</code></pre> <pre><code>&lt;ListView\nItemsSource=\"{Binding Customers,Mode=OneWay}\"&gt;\n&lt;!-- ...--&gt;\n&lt;/ListView&gt;\n</code></pre></p> <p><pre><code>public MainPage()\n{\nthis.InitializeComponent;\nthis.ViewModel = new MainViewModel();\n// DataContext = ViewModel;\n}\n</code></pre> <pre><code>&lt;ListView\nItemsSource=\"{x:Bind ViewModel.Customers,Mode=OneWay}\"&gt;\n&lt;!-- ...--&gt;\n&lt;/ListView&gt;\n</code></pre></p> <p>Notably, the default binding mode of the Binding markup extension is <code>OneWay</code> <code>x:Bind</code> is <code>OneTime</code>, although this can be changed by setting <code>x:DefaultBindMode</code> on the root element.</p> Set explicitlyChanging default binding mode <pre><code>&lt;Page&gt;\n\n&lt;Listview ItemsSource=\"{x:Bind ViewModelCustomers,Mode=OneWay}\"/&gt;\n&lt;/Page&gt;\n</code></pre> <pre><code>&lt;Page\nx:DefaultBindMode=\"OneWay\"&gt;\n&lt;Listview ItemsSource=\"{x:Bind ViewModelCustomers}\"/&gt;\n&lt;/Page&gt;\n</code></pre> <p>customDetailControl, which previously used the binding markup extension but set the root element as an explicitly named source property, is notably simplified after replacing with <code>x:Bind</code>. We can now directly access the user control's property.</p> BeforeAfter <pre><code>&lt;UserControl\nx:Class=\"WiredBrainCoffee.UWP.Controls.CustomerDetailControl\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP.Controls\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nd:DesignHeight=\"300\"\nd:DesignWidth=\"400\"\nx:Name=\"root\"&gt;\n\n&lt;StackPanel&gt;\n&lt;TextBox Header=\"First name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Customer.FirstName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\n/&gt;\n&lt;TextBox Header=\"Last name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Customer.LastName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\n\n/&gt;\n&lt;CheckBox Content=\"Caffeine fiend\" Margin=\"10\"\nIsChecked=\"{Binding ElementName=root,Path=Customer.FirstName,Mode=TwoWay}\"\n/&gt;\n&lt;/StackPanel&gt;\n&lt;/UserControl&gt;\n</code></pre> <pre><code>&lt;UserControl\nx:Class=\"WiredBrainCoffee.UWP.Controls.CustomerDetailControl\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP.Controls\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nd:DesignHeight=\"300\"\nd:DesignWidth=\"400\"\n&gt;\n\n&lt;StackPanel&gt;\n&lt;TextBox Header=\"First name\" Margin=\"10\"\nText=\"{x:Bind Customer.FirstName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\n/&gt;\n&lt;TextBox Header=\"Last name\" Margin=\"10\"\nText=\"{x:Bind Customer.LastName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\n\n/&gt;\n&lt;CheckBox Content=\"Caffeine fiend\" Margin=\"10\"\nIsChecked=\"{x:Bind Customer.IsCoffeeDrinker,Mode=TwoWay}\"\n/&gt;\n&lt;/StackPanel&gt;\n&lt;/UserControl&gt;\n</code></pre> <p>x:Bind can also be implemented in the ListView's ItemTemplate, so long as the x:DataType attribute is set on DataTemplate. We must also remember to set the Mode binding property, since x:Bind's default is OneTime! (src)</p> <pre><code>&lt;ListView Grid.Row=\"1\" ItemsSource=\"{x:Bind ViewModel.Customers}\" SelectedItem=\"{x:Bind ViewModel.SelectedCustomer,Mode=TwoWay}\"&gt;\n&lt;ListView.ItemTemplate&gt;\n&lt;DataTemplate x:DataType=\"model:Customer\"&gt;\n&lt;StackPanel Orientation=\"Horizontal\"&gt;\n&lt;TextBlock Text=\"{x:Bind FirstName}\"/&gt;\n&lt;TextBlock Text=\"{x:Bind LastName}\" Margin=\"5 0 0 0\" FontWeight=\"Bold\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/DataTemplate&gt;\n&lt;/ListView.ItemTemplate&gt;\n&lt;/ListView&gt;\n</code></pre> <p>x:Bind can also hide or reveal controls depending on boolean value. A new boolean property is formed on the ViewModel, and we wire the <code>OnPropertyChanged</code> event handler to it. We also bind this value to the Visibility attribute of customerDetailControl. This will hide the customerDetailControl on application startup before the user selects a customer. (src)</p> <p><pre><code>public Customer SelectedCustomer\n{\nget { return selectedCustomer; }\nset\n{\nif (selectedCustomer != value)\n{\n\nselectedCustomer = value;\nOnPropertyChanged();\nOnPropertyChanged(nameof(IsCustomerSelected));\n}\n}\n}\n\npublic bool IsCustomerSelected =&gt; SelectedCustomer != null;\n</code></pre> <pre><code>&lt;controls:CustomerDetailControl x:Name=\"customerDetailControl\" Grid.Row=\"1\" Grid.Column=\"1\"\nCustomer=\"{x:Bind ViewModel.SelectedCustomer,Mode=TwoWay}\"\nVisibility=\"{x:Bind ViewModel.IsCustomerSelected}\"/&gt;\n</code></pre></p> <p>We can also implement a third TextBlock in the ListView's ItemTemplate to show a string depending on the value of the CheckBox.</p> <pre><code>&lt;ListView Grid.Row=\"1\" ItemsSource=\"{x:Bind ViewModel.Customers}\"\nSelectedItem=\"{x:Bind ViewModel.SelectedCustomer,Mode=TwoWay}\"&gt;\n&lt;ListView.ItemTemplate&gt;\n&lt;DataTemplate x:DataType=\"model:Customer\"&gt;\n&lt;StackPanel Orientation=\"Horizontal\"&gt;\n&lt;TextBlock Text=\"Dev\" Opacity=\"0.5\" Visibility=\"{x:Bind IsCoffeeDrinker}\" Margin=\"0 0 5 0\"/&gt;\n&lt;TextBlock Text=\"{x:Bind FirstName}\" /&gt;\n&lt;TextBlock Text=\"{x:Bind LastName}\" Margin=\"5 0 0 0\" FontWeight=\"Bold\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/DataTemplate&gt;\n&lt;/ListView.ItemTemplate&gt;\n&lt;/ListView&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#toggling-visibility","title":"Toggling visibility","text":"<p>In order to fully implement the logic of the MVVM pattern, we should move functionality that deals with the logic of the app as a whole to the ViewModel. That would include the Add and Delete buttons. (src)</p> BeforeAfter <pre><code>&lt;CommandBar&gt;\n\n&lt;AppBarButton x:Name=\"AddCustomer\" Click=\"AddCustomer_Click\" Label=\"Add\"&gt;\n&lt;SymbolIcon Symbol=\"Add\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"DeleteCustomer\" Click=\"DeleteCustomer_Click\" Label=\"Delete\"&gt;\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"btn_MoveSideBar\" Click=\"btn_MoveSideBar_Click\" Label=\"Move sidebar\"&gt;\n&lt;SymbolIcon x:Name=\"btn_MoveSideBar_Symbol\" Symbol=\"AlignRight\"/&gt;\n&lt;/AppBarButton&gt;\n\n&lt;/CommandBar&gt;\n</code></pre> <pre><code>&lt;CommandBar&gt;\n\n&lt;AppBarButton x:Name=\"AddCustomer\" Click=\"{x:Bind ViewModel.AddCustomer_Click}\" Label=\"Add\"&gt;\n&lt;SymbolIcon Symbol=\"Add\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"DeleteCustomer\" Click=\"{x:Bind ViewModel.DeleteCustomer_Click}\" Label=\"Delete\"&gt;\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"btn_MoveSideBar\" Click=\"btn_MoveSideBar_Click\" Label=\"Move sidebar\"&gt;\n&lt;SymbolIcon x:Name=\"btn_MoveSideBar_Symbol\" Symbol=\"AlignRight\"/&gt;\n&lt;/AppBarButton&gt;\n\n&lt;/CommandBar&gt;\n</code></pre>"},{"location":"Coding/Wired%20Brain%20Coffee/#styling","title":"Styling","text":"<p>You can define a style that has to be used more than once by declaring a Style element on a UserControl's Resources property. (src)</p> <pre><code>&lt;UserControl&gt;\n&lt;UserControl.Resources&gt;\n&lt;Style x:Key=\"myTextBoxStyle\" TargetType=\"TextBox\"&gt;\n&lt;Style.Setters&gt;\n&lt;Setter Property=\"Margin\" Value=\"10\"/&gt;\n&lt;Setter Property=\"CornerRadius\" Value=\"10\"/&gt;\n&lt;/Style.Setters&gt;\n&lt;/Style&gt;\n&lt;/UserControl.Resources&gt;\n&lt;/UserControl&gt;\n</code></pre> <p>This Style can then be used as a StaticResource, setting the value of the Style attribute.</p>"},{"location":"Coding/WinUI/","title":"WinUI","text":""},{"location":"Coding/WinUI/#syntax","title":"Syntax","text":"<p>Every XAML element maps to a C# class, and every XAML attribute maps to a class property or an  event . </p> <p>There are several syntaxes available for use that correspond to various methods of declaring objects:</p> <ul> <li>Object-element syntax has the type's name within angle brackets, similar to HTML. When the object contains other objects, it is called a container. If the object does not contain other objects, it can be declared with a self-closing tag:</li> <li>Attribute syntax has the property value set by declaring an attribute.</li> <li>In property-element syntax, signified by a period in the element name, where the portion of the element following the dot representing the identifier of the property.</li> <li>Content-property syntax is similar to the property element syntax in that a property's value is set by a child.  However, in this case the XAML processor interpolates the correct property element, typically Content.  Some controls can accept more than one child element. In the background, this is actually using the content-property syntax to assign to the <code>Children</code> property.</li> </ul> Object-elementAttributeProperty-elementContent-propertyMultiple children <pre><code>&lt;Canvas&gt;\n&lt;Rectangle /&gt;\n&lt;/Canvas&gt;\n</code></pre> <pre><code>&lt;Rectangle Name=\"rectangle1\" Width=\"100\" Height=\"100\" Fill=\"Blue\" /&gt;\n</code></pre> <pre><code>&lt;Rectangle Name=\"rectangle1\" Width=\"100\" Height=\"100\"&gt; &lt;Rectangle.Fill&gt; &lt;SolidColorBrush Color=\"Blue\"/&gt; &lt;/Rectangle.Fill&gt;\n&lt;/Rectangle&gt;\n</code></pre> <pre><code>&lt;Button&gt;\nAdd customer\n&lt;/Button&gt;\n</code></pre> <pre><code>&lt;StackPanel&gt;\n&lt;TextBlock&gt;Hello&lt;/TextBlock&gt;\n&lt;TextBlock&gt;World&lt;/TextBlock&gt;\n&lt;/StackPanel&gt;\n</code></pre>"},{"location":"Coding/WinUI/#namespaces","title":"Namespaces","text":"<p>A XAML file usually declares a default XAML namespace in its root element. This default namespace defines elements that can be declared without qualifying them by a prefix (e.g. <code>x:</code>).</p> <p>XAML namespaces apply only to the specific element on which they are declared and its children, which explains why they are typically placed on the root element. (src)</p> <p>Most XAML files have two <code>xmlns</code> declarations</p> <ul> <li>xmlns maps a default XAML namespace</li> <li>xmlns:x maps a separate XAML namespace for XAML-defined language elements to the <code>x:</code> prefix:</li> <li>xmlns:mc indicates and supports a markup compatibility mode for reading XAML. <pre><code>xmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\n</code></pre></li> </ul>"},{"location":"Coding/WinUI/#directives","title":"Directives","text":"<ul> <li>x:Name uniquely identifies object elements for access to the object from code-behind </li> <li>x:Key sets a unique key for each resource in a ResourceDictionary </li> <li>x:Class specifies the CLR namespace and class name for the class that provides code-behind  for a XAML page. The <code>x:Class</code> directive configures XAML markup compilation to join partial classes  between markup and code-behind. In this example it can be seen how it refers to the <code>MainPage</code>  class within the <code>Project</code> namespace. (src)</li> <li>x:Bind is a form of data-binding</li> </ul> <p>Language elements are commonly used features necessary for Windows Runtime apps. For example, to join any code-behind to a XAML file through a partial class, you must name that class as the <code>x:Class</code> attribute in the root element of the XAML file.</p> XAMLCode-behind <pre><code>&lt;Page x:Class=\"Project.MainPage\"/&gt;\n</code></pre> <pre><code>namespace Project\n{\npublic sealed partial class MainPage : Page\n{\npublic MainPage()\n{\nthis.InitializeComponent();\n}\n}\n}\n</code></pre>"},{"location":"Coding/WinUI/#attached-property","title":"Attached property","text":"<p>Attached properties can be modified or queried in C# code as well, as long as the XAML element has an x:Name defined, which gives that particular element an identifier. For the column property of <code>Grid</code>, the static methods <code>GetColumn</code> and <code>SetColumn</code> are available.</p> <p>Here a button press changes the column value of an enclosing Grid and toggles between two different <code>Symbol</code> values. (src)</p> <pre><code>private void ButtonMove_Click(object sender, RoutedEventArgs e)\n{\nint column = Grid.GetColumn(customerListGrid);\nint newcolumn = column == 0 ? 2 : 0;\nGrid.SetColumn(customerListGrid, newcolumn);\nmoveSymbolIcon.Symbol = newcolumn == 0 ? Symbol.Forward : Symbol.Back;\n}\n</code></pre>"},{"location":"Coding/WinUI/#event-handling","title":"Event handling","text":"<p>Event hooks can be used to subscribe to events. For example, the <code>MainPage</code> class exposes a <code>Loaded</code> event that can be used to fill a prototype app with dogfood data, rather than putting hardcoding it in the XAML markup. Notably, these event handlers must return only <code>void</code> types.</p> <pre><code>public sealed partial class MainPage : Page\n{\npublic MainPage()\n{\nthis.InitializeComponent();\nthis.Loaded += MainPage_Loaded;\n}\n\nprivate void MainPage_Loaded(object sender, RoutedEventArgs e)\n{\nthrow new NotImplementedException();\n}\n}\n</code></pre> <p>Some XAML controls have attributes that map to events:</p> Element Property <code>Button</code> <code>Click</code> <code>CheckBox</code> <code>Checked</code>, <code>Unchecked</code> <code>ListView</code> <code>SelectionChanged</code> <code>TextBox</code> <code>TextChanged</code> <p>Defining an event handler in XAML is equivalent to doing so in C#.</p> XAMLC# <pre><code>&lt;Button Content=\"Add customer\" Click=\"Button_ClickHandler\"&gt;\n</code></pre> <pre><code>var btn = new Button { Content = \"Add customer\"\nthis.Click = // No clue if this is right...\n};\n</code></pre> SelectionChangedTextChanged MarkupCode-behind <pre><code>&lt;ListView x:Name=\"customerListView\" SelectionChanged=\"CustomerListView_SelectionChanged\"/&gt;\n</code></pre> <pre><code>private void CustomerListView_SelectionChanged(object sender, SelectionChangedEventArgs e)\n{\nvar customer = customerListView.SelectedItem as Customer;\ntxtFirstName.Text = customer?.FirstName ?? \"\"; txtLastName.Text = customer?.LastName ?? \"\";\nchkIsDeveloper.IsChecked = customer?.IsDeveloper;\n}\n</code></pre> MarkupCode-behind <pre><code>&lt;StackPanel&gt;\n&lt;TextBox x:Name=\"txtFirstName\" Header=\"Firstname\" TextChanged=\"TextBox_TextChanged\"\nMargin=\"10\" /&gt;\n&lt;TextBox x:Name=\"txtLastName\" Header=\"Lastname\" TextChanged=\"TextBox_TextChanged\"\nMargin=\"10\" /&gt;\n&lt;CheckBox x:Name=\"chkIsDeveloper\"\nContent=\"IsDeveloper\" Margin=\"10\" Checked=\"CheckBox_IsCheckedChanged\" Unchecked=\"CheckBox_IsCheckedChanged\"/&gt;\n&lt;/StackPanel&gt;\n</code></pre> <pre><code>private void TextBox_TextChanged(object sender, TextChangedEventArgs e)\n{\nUpdateCustomer();\n}\n\nprivate void CheckBox_IsCheckedChanged(object sender, RoutedEventArgs e)\n{\nUpdateCustomer();\n}\n\nprivate void UpdateCustomer()\n{\nvar customer = customerListView.SelectedItem as Customer;\nif (customer != null)\n{\ncustomer.FirstName = txtFirstName.Text;\ncustomer.LastName = txtLastName.Text;\ncustomer.IsDeveloper = chkIsDeveloper.IsChecked.{{c4::GetValueOrDefault}}();\n}\n}\n</code></pre> <p>Handlers for Loaded and Unloaded are automatically attached to any Page that uses the <code>NavigationHelper</code> class.</p> <ul> <li>Loaded</li> <li>Unloaded</li> </ul>"},{"location":"Coding/WinUI/#custom-controls","title":"Custom controls","text":"<p>You can take a group of controls and create a custom control using what is called a namespace mapping, where a C# class is made available in the XAML markup.</p> <p>More specifically, a custom control defined in XAML along with its accompanying code-behind file must use <code>UserControl</code> as its base class. In this sense, a custom control is really a special case of a namespace mapping, which can also be used to populate an application with mock data during development.</p> MarkupCode-behind <pre><code>&lt;UserControl\nx:Class=\"Project.Controls.CustomControl\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:WiredBrainCoffee.UWP.Controls\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"&gt;\n\n&lt;TextBlock Text=\"Hello, world!\"/&gt;\n&lt;/UserControl&gt;\n</code></pre> <pre><code>namespace Project.Controls\n{\npublic sealed partial class CustomControl : UserControl\n{\npublic CustomControl()\n{\nthis.InitializeComponent();\n}\n}\n}\n</code></pre>"},{"location":"Coding/WinUI/#mock-data","title":"Mock data","text":"<p>The most basic method of adding mock data is by hardcoding data in the XAML markup.</p> <p>Somewhat more sophisticated is the option of hardcoding data in the code-behind. The <code>x:Bind</code> directive can be used to bind an <code>IEnumerable</code> data source to either the <code>Items</code> or <code>ItemsSource</code> attributes. An ObservableCollection is preferred in WinUI programming because it raises events when properties are changed, but Lists and Arrays also work.  If the collection is made of objects, the <code>DisplayMemberPath</code> allows the specification of a particular property on those objects to be displayed. Notably, classes specifically need to be used, and not structs, for the members of these collections. <p>With namespace mapping, classes within the C# namespace can be used in XAML markup. (src)</p> <p>Most robust of all is creating a Data Provider class which will fall back to mock data when the data source is not available.  This will allow any number of other data sources to be plugged in, such as databases or REST services. (src)</p> Hardcoding in XAMLHardcoding in C#Namespace mappingData provider <pre><code>&lt;ListView&gt;\n&lt;ListViewItem&gt;Aristotle&lt;/ListViewItem&gt;\n&lt;ListViewItem&gt;Euclid&lt;/ListViewItem&gt;\n&lt;ListViewItem&gt;Plato&lt;/ListViewItem&gt;\n&lt;ListViewItem&gt;Socrates&lt;/ListViewItem&gt;\n&lt;/ListView&gt;\n</code></pre> MarkupCode-behind <pre><code>&lt;Page&gt;\n\n\n&lt;ListView\nItemsSource=\"{x:Bind Starships}\" SelectedItem=\"{x:Bind Starships[0]}\"\nDisplayMemberPath=\"Display\"/&gt;\n&lt;/Page&gt;\n</code></pre> <pre><code>namespace Starships.Models\n{\nclass Starship\n{\npublic string Name;\npublic string Registry;\npublic int Crew;\npublic string Display\n{\nget { return Name + Registry; }\n}            }\n}\n</code></pre> MarkupCode-behind <pre><code>&lt;Page xmlns:model=\"using:Project.Models\"&gt;\n\n&lt;ListView DisplayMemberPath=\"Display\"&gt;\n&lt;model:Starship Name=\"USS Enterprise\" Registry=\"NCC-1701\" Crew=\"140\"/&gt;\n&lt;/ListView&gt;\n&lt;/Page&gt;\n</code></pre> <pre><code>namespace Starships.Models\n{\nclass Starship\n{\npublic string Name;\npublic string Registry;\npublic int Crew;\npublic string Display\n{\nget { return Name + Registry; }\n}\n}\n}\n</code></pre>"},{"location":"Coding/WinUI/#themes","title":"Themes","text":"<p>Windows 10 themes ( \"Light\" ,  \"Dark\" , and \"HighContrast\" can be specified as a property of the  Application element:</p> LightDarkTheme colors <p> <pre><code>&lt;Application\nx:Class=\"Scratchpad.App\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:Scratchpad\"\nRequestedTheme=\"Light\"&gt;\n&lt;Application.Resources&gt;\n&lt;ResourceDictionary&gt;\n&lt;ResourceDictionary.MergedDictionaries&gt;\n&lt;XamlControlsResources xmlns=\"using:Microsoft.UI.Xaml.Controls\" /&gt;\n&lt;!-- Other merged dictionaries here --&gt;\n&lt;/ResourceDictionary.MergedDictionaries&gt;\n&lt;!-- Other app resources here --&gt;\n&lt;/ResourceDictionary&gt;\n&lt;/Application.Resources&gt;\n&lt;/Application&gt;\n</code></pre></p> <p> <pre><code>&lt;Application\nx:Class=\"Scratchpad.App\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:Scratchpad\"\nRequestedTheme=\"Dark\"&gt;\n&lt;Application.Resources&gt;\n&lt;ResourceDictionary&gt;\n&lt;ResourceDictionary.MergedDictionaries&gt;\n&lt;XamlControlsResources xmlns=\"using:Microsoft.UI.Xaml.Controls\" /&gt;\n&lt;!-- Other merged dictionaries here --&gt;\n&lt;/ResourceDictionary.MergedDictionaries&gt;\n&lt;!-- Other app resources here --&gt;\n&lt;/ResourceDictionary&gt;\n&lt;/Application.Resources&gt;\n&lt;/Application&gt;\n</code></pre></p> <p> </p>"},{"location":"Coding/WinUI/#layout","title":"Layout","text":"<p>The layout panels in XAML serve a similar function to the geometry manager methods in tkinter.  There are various layout panels available.</p> <ul> <li>Grid</li> <li>RelativePanel</li> <li>StackPanel</li> <li>VariableSizeWrapGrid</li> </ul>"},{"location":"Coding/WinUI/#data-binding","title":"Data binding","text":"<p>There are two data binding types available in XAML (src)</p> <ul> <li>Binding markup extension resolves the binding path at runtime. It can accept data sources from the binding properties <code>ElementName</code>, <code>Source</code>, and <code>RelativeSource</code>. If none of these are defined, then the binding markup extension resolves to the DataContext property.</li> <li>x:Bind resolves the binding path at compile-time, generating C# code and offering better performance and compile-time errors. You can also step into the compiled code, providing a better debugging experience. <code>x:Bind</code> should generally be preferred, however it is available only in UWP.</li> </ul> <p><code>x:Bind</code>, in contrast, binds only to the parent <code>Page</code> or <code>UserControl</code> element. So any property of MainPage will be accessible, and any property of that object will also be accessible using dot notation.</p> <p>Most bindings are easily translated between the two types:</p> Binding markup extensionx:Bind <p><pre><code>public MainPage()\n{\nthis.InitializeComponent;\nthis.ViewModel = new MainViewModel();\nDataContext = ViewModel;\n}\n</code></pre> <pre><code>&lt;ListView\nItemsSource=\"{Binding Customers,Mode=OneWay}\"&gt;\n&lt;!-- ...--&gt;\n&lt;/ListView&gt;\n</code></pre></p> <p><pre><code>public MainPage()\n{\nthis.InitializeComponent;\nthis.ViewModel = new MainViewModel();\n// DataContext = ViewModel;\n}\n</code></pre> <pre><code>&lt;ListView\nItemsSource=\"{x:Bind ViewModel.Customers,Mode=OneWay}\"&gt;\n&lt;!-- ...--&gt;\n&lt;/ListView&gt;\n</code></pre></p> <p>Notably, the default binding mode of the binding markup extension is OneWay<code>**, whereas that of</code>x:Bind<code>is **</code>OneTime, although this can be changed by setting <code>x:DefaultBindMode</code> on the root element.</p> Changing default bind modeSet explicitly <pre><code>&lt;Page\nx:DefaultBindMode=\"OneWay\"&gt;\n&lt;Listview ItemsSource=\"{x:Bind ViewModelCustomers}\"/&gt;\n&lt;/Page&gt;\n</code></pre> <pre><code>&lt;Page&gt;\n&lt;Listview ItemsSource=\"{x:Bind ViewModelCustomers,Mode=OneWay}\"/&gt;\n&lt;/Page&gt;\n</code></pre>"},{"location":"Coding/WinUI/#type-conversion","title":"Type conversion","text":"<p>By default, XAML attribute values are strings. In order for the XAML processor to interpret them as objects, they must be converted.</p> <p>Type converters can convert string representations of attribute values to property elements. For example, a type converter is what is used with the XAML declaration <code>HorizontalAlignment=\"Left\"</code>,  which is mapped to a specific enumeration within the Windows.UI.XAML namespace. ref</p> <p>In UWP, the XAML processor integrates the conversion logic to convert the Margin declaration to a <code>Thickness</code> object.  But in  WPF , TypeConverters are used.</p> MarkupCode-behind <pre><code>&lt;Button Margin=\"10,20,10,30\" Content=\"Click me\"/&gt;\n</code></pre> <pre><code>var btn = new Button\n{\nMargin = new Thickness(10, 20, 10, 30);\n};\n</code></pre>"},{"location":"Coding/WinUI/#markup-extensions","title":"Markup Extensions","text":"<p>Markup extensions are placed between curly braces <code>{</code> and <code>}</code> and create a reference to a   ResourceDictionary .  They can be used to unify styling across an  application.</p> <p>The most common markup extensions are:</p> <ul> <li><code>StaticResource</code> refers to resources defined in  resource dictionaries </li> <li><code>ThemeResource</code> for Windows native themeing colors</li> <li><code>Binding</code> for data binding expressions, which require the bound property to be a dependency property</li> </ul> <p>Here, the background of the grid is bound to a color from the Windows-native theming and the TextBlock's Foreground property is bound to a color defined in a resource dictionary defined on the same page.</p> <p>Multiple properties can be set at the same time by setting a <code>Style</code> property element. <pre><code>&lt;Page&gt;\n&lt;Page.Resources&gt;\n&lt;Style TargetType=\"Button\" x:Key=\"MyButtonStyle\"&gt;\n&lt;Setter Property=\"Background\" Value=\"Blue\"/&gt;\n&lt;Setter Property=\"FontFamily\" Value=\"Arial Black\"/&gt;\n&lt;Setter Property=\"FontSize\" Value=\"36\"/&gt;\n&lt;/Style&gt;\n&lt;/Page.Resources&gt;\n\n&lt;Button Content=\"Hello world\" Style=\"{StaticResource MyButtonStyle}\"/&gt;\n&lt;/Page&gt;\n</code></pre></p> <pre><code>&lt;Page&gt;\n&lt;Page.Resources&gt;\n&lt;SolidColorBrush x:Key=\"MyBrush\" Color=\"Brown\" /&gt;\n&lt;/Page.Resources&gt;\n\n&lt;Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\"&gt;\n&lt;TextBlock Text=\"Hello World\" Foreground=\"{StaticResource MyBrush}\" /&gt;\n&lt;/Grid&gt;\n&lt;/Page&gt;\n</code></pre> <p>src</p>"},{"location":"Coding/WinUI/#dependency-properties","title":"Dependency properties","text":"<p>Only dependency properties can be targets for data binding in UWP and WPF. The propdp snippet in Visual Studio can be used to create one.</p> <p>The DependencyObject class, which is a base class of all UI elements in UWP and WPF, exposes the <code>GetValue</code> and <code>SetValue</code> methods, which are used to ...</p>"},{"location":"Coding/WinUI/#multi-instance","title":"Multi-instance","text":"<p>A multi-instance application is one that can run in several instances, which is necessary to allow users to open new windows.</p> <p>A collection of templates is available as a Visual Studio extension. These templates modify the appxmanifest file by setting the SupportsMultipleInstances attribute to true:</p> <pre><code>&lt;Package\n...\nxmlns:desktop4=\"http://schemas.microsoft.com/appx/manifest/desktop/windows10/4\"\nxmlns:iot2=\"http://schemas.microsoft.com/appx/manifest/iot/windows10/2\"  IgnorableNamespaces=\"uap mp desktop4 iot2\"&gt;\n...\n  &lt;Applications&gt;\n&lt;Application Id=\"App\"\n...\ndesktop4:SupportsMultipleInstances=\"true\"\niot2:SupportsMultipleInstances=\"true\"&gt;\n...\n    &lt;/Application&gt;\n&lt;/Applications&gt;\n...\n&lt;/Package&gt;\n</code></pre> <p>Resources:</p> <ul> <li> Create a multi-instance UWP app</li> </ul>"},{"location":"Coding/WinUI/#patterns","title":"Patterns","text":""},{"location":"Coding/WinUI/#action-on-focus","title":"Action on focus","text":"<p>UI elements expose the GotFocus event hook for when a user clicks or tabs into a control.</p> <p>Example handler selecting all text in a TextBox: (src)</p> MarkupCode-behind <pre><code>&lt;Page&gt;\n&lt;TextBox GotFocus=\"TextBox_GotFocus\"/&gt;\n&lt;/Page&gt;\n</code></pre> <pre><code>void TextBox_GotFocus(object sender, RoutedEventArgs e)\n{\nTextBox textBox = sender as TextBox;\ntextBox.SelectAll();\n}\n</code></pre>"},{"location":"Coding/WinUI/#listdetails","title":"List/Details","text":"<p>The list/details pattern has a master pane (usually a ListView) and a details pane for content.</p>"},{"location":"Coding/WinUI/#mvvm","title":"MVVM","text":"<p>In the Model, View, ViewModel (MVVM) pattern, which implicitly relies on OOP principles, the Model represents the data model for the objects being manipulated,  and the ViewModel is the model for the View, that is, the state of the application as represented in a class.</p> <p>In WinUI, the project that contains the Views (that is, the XAML files) must first add references to the projects where the Models and ViewModel are contained.  These will allow the code-behind file of the MainWindow to reference those classes.</p> <p>The class representing the ViewModel is instantiated and assigned to an attribute. That class's methods can then be called by using the <code>x:Bind</code> attribute syntax on, for instance, a <code>ListView</code> element.</p> MarkupCode-behind <pre><code>&lt;Window&gt;\n&lt;ListView ItemsSource=\"{x:Bind ViewModel.Employees, Mode=OneWay}\"\nSelectedItem=\"{x:Bind ViewModel.SelectedEmployee, Mode=OneWay}\"\nDisplayMemberPath=\"FirstName\"/&gt;\n&lt;/Window&gt;\n</code></pre> <pre><code>using EmployeeManager.DataAccess;\nusing EmployeeManager.ViewModel;\nusing Microsoft.UI.Xaml;\n\nnamespace EmployeeManager.WinUI\n{\npublic sealed partial class MainWindow : Window\n{\npublic MainWindow()\n{\nViewModel = new MainViewModel(new EmployeeDataProvider());\nthis.InitializeComponent();\n}\n\npublic MainViewModel ViewModel { get; }\n}\n}\n</code></pre>"},{"location":"Coding/WinUI/#navigation","title":"Navigation","text":"<p>App layout typically begins with the choice of navigation model, which defines how users navigate between pages in the app. There are two common navigation models: left nav and top nav</p> <p></p>"},{"location":"Coding/WinUI/#examples","title":"Examples","text":""},{"location":"Coding/WinUI/#list-and-details","title":"List and details","text":"<pre><code>&lt;Page\nx:Class=\"Superheroes.MainPage\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:Superheroes\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"\nBackground=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\"&gt;\n\n&lt;StackPanel&gt;\n&lt;CommandBar&gt;\n&lt;AppBarButton x:Name=\"AddHero\" Click=\"AddHero_Click\" Label=\"Add hero\"&gt;\n&lt;SymbolIcon Symbol=\"Add\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"DelHero\" Click=\"DelHero_Click\" Label=\"Remove hero\"&gt;\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;/CommandBar&gt;\n\n&lt;TextBox Header=\"First name\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.FirstName,Mode=TwoWay}\"/&gt;\n&lt;TextBox Header=\"Last name\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.LastName,Mode=TwoWay}\"/&gt;\n&lt;TextBox Header=\"Alias\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.Superhero,Mode=TwoWay}\"/&gt;\n\n&lt;ListView x:Name=\"heroesListView\" ItemsSource=\"{Binding Heroes,Mode=TwoWay}\" SelectedItem=\"{Binding SelectedHero,Mode=TwoWay}\"&gt;\n\n&lt;ListView.ItemTemplate&gt;\n&lt;DataTemplate&gt;\n&lt;StackPanel Orientation=\"Horizontal\"&gt;\n&lt;TextBlock Text=\"{Binding Superhero}\" FontWeight=\"Bold\"/&gt;\n&lt;TextBlock Text=\"{Binding FirstName}\" Margin=\"5 0 0 0\"/&gt;\n&lt;TextBlock Text=\"{Binding LastName}\" Margin=\"5 0 0 0\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/DataTemplate&gt;\n&lt;/ListView.ItemTemplate&gt;\n&lt;/ListView&gt;\n\n&lt;/StackPanel&gt;\n&lt;/Page&gt;\n</code></pre> <p>In order to link two controls, some form of data binding is necessary. Here, TextBox elements are individually bound to the string properties of the selected ListView element with the Binding markup extension using the <code>ElementName</code> binding property. The selected item and the path to the string property are combined using dot notation and assigned to the <code>Path</code> binding property. </p>"},{"location":"Coding/WinUI/#custom-control","title":"Custom control","text":"<p>The textboxes can also be consolidated into a custom control using UserControl.  In this case, the custom control must expose a target property that will be bound to the ListView's SelectedItem property. </p> Individual TextBoxes bound to ListViewUserControl <pre><code>&lt;TextBox Header=\"First name\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.FirstName,Mode=TwoWay}\"/&gt;\n&lt;TextBox Header=\"Last name\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.LastName,Mode=TwoWay}\"/&gt;\n&lt;TextBox Header=\"Alias\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.Superhero,Mode=TwoWay}\"/&gt;\n\n&lt;!-- &lt;local:MyTextBoxes Hero=\"{Binding ElementName=heroesListView,Path=SelectedItem,Mode=TwoWay}\"/&gt; --&gt;\n</code></pre> <pre><code>&lt;!--&lt;TextBox Header=\"First name\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.FirstName,Mode=TwoWay}\"/&gt;\n&lt;TextBox Header=\"Last name\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.LastName,Mode=TwoWay}\"/&gt;\n&lt;TextBox Header=\"Alias\" Text=\"{Binding ElementName=heroesListView,Path=SelectedItem.Superhero,Mode=TwoWay}\"/&gt;--&gt;\n\n&lt;local:MyTextBoxes Hero=\"{Binding ElementName=heroesListView,Path=SelectedItem,Mode=TwoWay}\"/&gt;\n</code></pre> <p>In order to accept the data binding, the target property must be implemented as a dependency property. This dependency property works through a static callback function which sets the individual textbox values to the bound target property.</p> <p>Naively, the callback function can be made to change the individual TextBox elements, provided they have <code>x:Name</code> defined. But a better technique is using the Binding markup extension to bind the individual TextBoxes to the root node using the <code>ElementName</code> binding property. This requires the root node to have <code>x:Name</code> defined.</p> <p>Both MyTextBoxes's binding to heroesListView and the individual TextBox bindings to the Hero property of root need to be TwoWay in order for changes made in the TextBox to take effect. Notably, the ListView does not reflect any changes made yet.</p> CallbackBinding <pre><code>&lt;TextBox x:Name=\"FirstNameTextbox\"\nHeader=\"First name\" Margin=\"10\"\n/&gt;\n&lt;TextBox x:Name=\"LastNameTextbox\"\nHeader=\"Last name\" Margin=\"10\"\n/&gt;\n&lt;TextBox x:Name=\"SuperheroTextbox\"\nHeader=\"Alias\" Margin=\"10\"\n/&gt;\n</code></pre> <pre><code>private static void HeroChangedCallback(DependencyObject d, DependencyPropertyChangedEventArgs e)\n{\nif (d is MyTextBoxes myTextBoxes)\n{\nvar hero = e.NewValue as Hero;\n\nmyTextBoxes.FirstNameTextbox.Text = hero.FirstName;\nmyTextBoxes.LastNameTextbox.Text = hero.LastName;\nmyTextBoxes.SuperheroTextbox.Text = hero.Superhero;\n}\n}\n</code></pre> <pre><code>&lt;TextBox x:Name=\"FirstNameTextbox\"\nHeader=\"First name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Hero.FirstName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"/&gt;\n&lt;TextBox x:Name=\"LastNameTextbox\"\nHeader=\"Last name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Hero.LastName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"/&gt;\n&lt;TextBox x:Name=\"SuperheroTextbox\"\nHeader=\"Alias\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Hero.Superhero,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"/&gt;\n</code></pre> <pre><code>private static void HeroChangedCallback(DependencyObject d, DependencyPropertyChangedEventArgs e)\n{\n//if (d is MyTextBoxes myTextBoxes)\n//{\n//    var hero = e.NewValue as Hero;\n\n//    myTextBoxes.FirstNameTextbox.Text = hero.FirstName;\n//    myTextBoxes.LastNameTextbox.Text = hero.LastName;\n//    myTextBoxes.SuperheroTextbox.Text = hero.Superhero;\n//}\n}\n</code></pre>"},{"location":"Coding/WinUI/#listview","title":"ListView","text":"<p>In order for the ListView to update, the underlying model must raise the PropertyChanged event. I really don't understand this very well, so here is the Observable class that implements the INotifyPropertyChanged interface. The model must inherit from this base class and the Set accessor of any property should fire <code>OnPropertyChanged()</code>.</p> <pre><code>public class Observable : INotifyPropertyChanged\n{\npublic event PropertyChangedEventHandler PropertyChanged;\nprotected void OnPropertyChanged([CallerMemberName] string propertyName = null)\n{\nPropertyChanged?.Invoke(this, new PropertyChangedEventArgs(propertyName));\n}\n}\n</code></pre>"},{"location":"Coding/WinUI/#viewmodel","title":"ViewModel","text":""},{"location":"Coding/WinUI/#xbind","title":"x:Bind","text":"<p>Binding markup extensions are trivially changed to compiled data bindings by replacing <code>Binding</code> with <code>x:Bind</code>.</p> <p>!!!     Note that ListView will enter an infinite loop if the SelectedHero property does not incorporate additional logic.</p> <pre><code>```csharp\npublic Hero SelectedHero\n{\n    get { return _selectedHero; }\n    set\n    {\n        if (_selectedHero != value)\n        {\n            _selectedHero = value;\n            OnPropertyChanged();\n            OnPropertyChanged(nameof(IsHeroSelected));\n        }\n    }\n}\n```\n</code></pre> Binding markup extensionCompiled data binding <p><pre><code>&lt;ListView x:Name=\"heroesListView\" ItemsSource=\"{Binding Heroes,Mode=OneWay}\" SelectedItem=\"{Binding SelectedHero,Mode=TwoWay}\"\nMargin=\"0\"&gt;\n</code></pre> <pre><code>&lt;TextBox x:Name=\"FirstNameTextbox\"\nHeader=\"First name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Hero.FirstName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\nGotFocus=\"Textbox_GotFocus\"\n/&gt;\n&lt;TextBox x:Name=\"LastNameTextbox\"\nHeader=\"Last name\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Hero.LastName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\nGotFocus=\"Textbox_GotFocus\"\n/&gt;\n&lt;TextBox x:Name=\"SuperheroTextbox\"\nHeader=\"Alias\" Margin=\"10\"\nText=\"{Binding ElementName=root,Path=Hero.Superhero,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\nGotFocus=\"Textbox_GotFocus\"\n/&gt;\n</code></pre></p> <p><pre><code>&lt;ListView x:Name=\"heroesListView\" ItemsSource=\"{x:Bind ViewModel.Heroes,Mode=OneWay}\" SelectedItem=\"{x:Bind ViewModel.SelectedHero,Mode=TwoWay}\"\nMargin=\"0\"&gt;\n</code></pre> <pre><code>&lt;TextBox x:Name=\"FirstNameTextbox\"\nHeader=\"First name\" Margin=\"10\"\nText=\"{x:Bind Hero.FirstName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\nGotFocus=\"Textbox_GotFocus\"\n/&gt;\n&lt;TextBox x:Name=\"LastNameTextbox\"\nHeader=\"Last name\" Margin=\"10\"\nText=\"{x:Bind Hero.LastName,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\nGotFocus=\"Textbox_GotFocus\"\n/&gt;\n&lt;TextBox x:Name=\"SuperheroTextbox\"\nHeader=\"Alias\" Margin=\"10\"\nText=\"{x:Bind Hero.Superhero,Mode=TwoWay,UpdateSourceTrigger=PropertyChanged}\"\nGotFocus=\"Textbox_GotFocus\"\n/&gt;\n</code></pre></p> <p>x:Bind can also be implemented in the ListView's ItemTemplate, so long as the x:DataType attribute is set on DataTemplate. We must also remember to set the Mode binding property, since x:Bind's default is OneTime!</p> Binding markup extensionCompiled data binding <pre><code>&lt;ListView.ItemTemplate&gt;\n&lt;DataTemplate&gt;\n&lt;StackPanel Orientation=\"Horizontal\"&gt;\n&lt;TextBlock Text=\"{Binding Superhero}\" FontWeight=\"Bold\"/&gt;\n&lt;TextBlock Text=\"{Binding FirstName}\" Margin=\"5 0 0 0\"/&gt;\n&lt;TextBlock Text=\"{Binding LastName}\" Margin=\"5 0 0 0\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/DataTemplate&gt;\n&lt;/ListView.ItemTemplate&gt;\n</code></pre> <pre><code>&lt;ListView.ItemTemplate&gt;\n&lt;DataTemplate x:DataType=\"local:Hero\"&gt;\n&lt;StackPanel Orientation=\"Horizontal\"&gt;\n&lt;TextBlock Text=\"{x:Bind Superhero}\" FontWeight=\"Bold\"/&gt;\n&lt;TextBlock Text=\"{x:Bind FirstName}\" Margin=\"5 0 0 0\"/&gt;\n&lt;TextBlock Text=\"{x:Bind LastName}\" Margin=\"5 0 0 0\"/&gt;\n&lt;/StackPanel&gt;\n&lt;/DataTemplate&gt;\n&lt;/ListView.ItemTemplate&gt;\n</code></pre> <p>x:Bind can also hide or reveal controls depending on boolean value. A new boolean field is formed on the ViewModel.</p> <pre><code>public class ViewModel\n{\npublic bool IsHeroSelected =&gt; SelectedHero != null;\n}\n</code></pre> BeforeAfter <pre><code>&lt;CommandBar&gt;\n&lt;AppBarButton x:Name=\"AddHero\" Click=\"AddHero_Click\" Label=\"Add hero\"&gt;\n&lt;SymbolIcon Symbol=\"Add\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"DelHero\" Click=\"DelHero_Click\" Label=\"Remove hero\" &gt;\n\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;/CommandBar&gt;\n</code></pre> <pre><code>&lt;CommandBar&gt;\n&lt;AppBarButton x:Name=\"AddHero\" Click=\"AddHero_Click\" Label=\"Add hero\"&gt;\n&lt;SymbolIcon Symbol=\"Add\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"DelHero\" Click=\"DelHero_Click\" Label=\"Remove hero\" IsEnabled=\"{x:Bind ViewModel.IsHeroSelected,Mode=OneWay}\"&gt;\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;/CommandBar&gt;\n</code></pre>"},{"location":"Coding/WinUI/#history","title":"History","text":"<p>Windows has a long history of introducing UI frameworks to facilitate the creation of GUI applications:</p> <ul> <li>MFC (1992) was based on Native C++</li> <li>WinForms (2002) was based on .NET Framework</li> <li>WPF (2006) was also based on .NET Framework</li> <li>UWP XAML (2012) was based on C++ and .NET</li> <li>WinUI 2 is a NuGet package containing controls and styles for UWP Apps, intended to decouple UWP applications from the latest version of Windows</li> <li>WinUI 3 (2020) is meant to provide a UX framework for both Win32 and UWP applications</li> </ul> <p>XAML is a declarative markup language used to create UIs for .NET Core apps. The logic of the app is separated in code-behind files that are joined to the markup through partial class definitions. In Visual Studio this is emphasized by the fact that the code-behind file is literally presented as a child node of the XAML document.</p> <p>The root element (of which there must be only one in order to be a valid XAML file) contains attributes  that define the XAML  namespaces  for the program that will be parsing the XAML file, or a  namescope .</p>"},{"location":"Coding/WinUI/API/","title":"API","text":""},{"location":"Coding/WinUI/API/#combobox","title":"ComboBox","text":"<p>Important attributes:</p> <ul> <li><code>Items</code> or <code>ItemsSource</code> specify the collection (preferably <code>IObservableCollection</code> to support event handling on value changes) to be used to populate the control.</li> <li><code>SelectedItem</code> defines the element that appears selected by the control by default.  If not defined, no element will be selected.</li> <li><code>DisplayMemberPath</code> defines the name of the property to be used to display each individual choice.</li> </ul> <pre><code>&lt;ComboBox ItemsSource=\"{x:Bind Items}\" SelectedItem=\"{x:Bind Items[0]}\"\nDisplayMemberPath=\"Display\" /&gt;\n</code></pre>"},{"location":"Coding/WinUI/API/#commandbar","title":"CommandBar","text":"<p>CommandBar is a lightweight control that can organize a bar of buttons.</p> <p></p> <pre><code>&lt;CommandBar&gt;\n&lt;AppBarButton x:Name=\"AddCustomer\" Click=\"AddCustomer_Click\" Label=\"Add\"&gt;\n&lt;SymbolIcon Symbol=\"AddFriend\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"DeleteCustomer\" Click=\"DeleteCustomer_Click\" Label=\"Delete\"&gt;\n&lt;SymbolIcon Symbol=\"Delete\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;AppBarButton x:Name=\"btn_MoveSideBar\" Click=\"btn_MoveSideBar_Click\" Label=\"Move sidebar\"&gt;\n&lt;SymbolIcon x:Name=\"btn_MoveSideBar_Symbol\" Symbol=\"AlignRight\"/&gt;\n&lt;/AppBarButton&gt;\n&lt;/CommandBar&gt;\n</code></pre>"},{"location":"Coding/WinUI/API/#datagrid","title":"DataGrid","text":""},{"location":"Coding/WinUI/API/#dialog-boxes","title":"Dialog boxes","text":"<p>In XAML, the MessageDialog object can be used to create a modal dialog box (i.e. one that does not allow interaction with the main window until the dialog box has been cleared).</p> <p>The MessageDialog object can take a string argument containing the text of the dialog box. It is actually displayed by calling the object's ShowAsync() method. Because this is an asynchronous call, it must be <code>await</code>ed, which requires the <code>System</code> namespace. (src)</p> <pre><code>using Microsoft.UI.Xaml;\nusing Microsoft.UI.Xaml.Controls;\nusing Windows.UI.Popups;\nusing System;\n\nnamespace WiredBrainCoffee.UWP\n{\npublic sealed partial class MainPage : Page\n{\npublic MainPage()\n{\nthis.InitializeComponent();\n}\n\nprivate async void AddCustomer(object sender, RoutedEventArgs e)\n{\nvar messageDialog = new MessageDialog(\"Customer added!\");\nawait messageDialog.ShowAsync();\n}\n}\n}\n</code></pre>"},{"location":"Coding/WinUI/API/#grid","title":"Grid","text":"<p>The <code>Grid</code> layout panel is analogous to the grid geometry manager in tkinter. However, in XAML you are forced to explicitly declare RowDefinition<code>** and **</code>ColumnDefinition elements.  Whereas in tkinter, the widget being placed declares its own grid position. If the grid is sparse, the empty rows and columns appear to be ignored.</p> <p>Grid star-sizing works similar to <code>flex-grow</code> and <code>flex-shrink</code> CSS style statements used with Flexbox.</p> RowsColumns <p> <p><pre><code>&lt;Grid&gt;\n&lt;Grid.RowDefinitions&gt;\n&lt;RowDefinition/&gt;\n&lt;RowDefinition/&gt;\n&lt;RowDefinition/&gt;\n&lt;RowDefinition/&gt;\n&lt;RowDefinition/&gt;\n&lt;RowDefinition/&gt;\n&lt;RowDefinition/&gt;\n&lt;RowDefinition/&gt;\n&lt;/Grid.RowDefinitions&gt;\n\n&lt;Rectangle Fill=\"LightGray\"/&gt;\n&lt;Rectangle Fill=\"LightSteelBlue\" Grid.Row=\"1\"/&gt;\n&lt;Rectangle Fill=\"LightBlue\" Grid.Row=\"2\"/&gt;\n&lt;Rectangle Fill=\"LightCyan\" Grid.Row=\"3\"/&gt;\n&lt;Rectangle Fill=\"LightSeaGreen\" Grid.Row=\"4\"/&gt;\n&lt;Rectangle Fill=\"LightGreen\" Grid.Row=\"5\"/&gt;\n&lt;Rectangle Fill=\"LightGoldenrodYellow\" Grid.Row=\"6\" /&gt;\n&lt;Rectangle Fill=\"LightSalmon\" Grid.Row=\"7\"/&gt;\n&lt;Rectangle Fill=\"LightCoral\" Grid.Row=\"8\"/&gt;\n&lt;/Grid&gt;\n</code></pre> </p> <p> <p><pre><code>&lt;Grid&gt;\n&lt;Grid.ColumnDefinitions&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;ColumnDefinition/&gt;\n&lt;/Grid.ColumnDefinitions&gt;\n\n&lt;Rectangle Fill=\"LightGray\"/&gt;\n&lt;Rectangle Fill=\"LightSteelBlue\" Grid.Column=\"1\"/&gt;\n&lt;Rectangle Fill=\"LightBlue\" Grid.Column=\"2\"/&gt;\n&lt;Rectangle Fill=\"LightCyan\" Grid.Column=\"3\"/&gt;\n&lt;Rectangle Fill=\"LightSeaGreen\" Grid.Column=\"4\"/&gt;\n&lt;Rectangle Fill=\"LightGreen\" Grid.Column=\"5\"/&gt;\n&lt;Rectangle Fill=\"LightGoldenrodYellow\" Grid.Column=\"6\" /&gt;\n&lt;Rectangle Fill=\"LightSalmon\" Grid.Column=\"7\"/&gt;\n&lt;Rectangle Fill=\"LightCoral\" Grid.Column=\"8\"/&gt;\n&lt;/Grid&gt;\n</code></pre> </p>"},{"location":"Coding/WinUI/API/#listdetailsview","title":"ListDetailsView","text":"<p>ListDetailsView is a custom control available from the Windows Community Toolkit (Nuget package <code>Microsoft.Toolkit.UWP</code>) that implements the Master/Details pattern.</p> IllustrationBasic structureXAML <p></p> <ul> <li><code>xmlns:toolkit=\"using:Microsoft.Toolkit.Uwp.UI.Controls</code>: namespace<ul> <li>toolkit:ListDetailsView<ul> <li><code>toolkit:ListDetailsView.</code>ItemTemplate property-element for how items are rendered in sidebar</li> <li><code>toolkit:ListDetailsView.</code>DetailsTemplate property-element for how items are rendered in the main pane</li> <li><code>toolkit:ListDetailsView.</code>NoSelectionContentTemplate property-element for how the main pane is rendered with no item selected</li> <li><code>toolkit:ListDetailsView.</code>AppCommandBar</li> </ul> </li> </ul> </li> </ul> <pre><code>&lt;Page\n&lt;!-- ... --&gt;\nxmlns:toolkit=\"using:Microsoft.Toolkit.Uwp.UI.Controls\"&gt;\n    &lt;toolkit:ListDetailsView&gt;\n&lt;toolkit:ListDetailsView.ItemTemplate&gt;\n&lt;/toolkit:ListDetailsView.ItemTemplate&gt;\n\n&lt;toolkit:ListDetailsView.DetailsTemplate&gt;\n&lt;/toolkit:ListDetailsView.DetailsTemplate&gt;\n\n&lt;toolkit:ListDetailsView.NoSelectionContentTemplate&gt;\n&lt;/toolkit:ListDetailsView.NoSelectionContentTemplate&gt;\n\n&lt;toolkit:ListDetailsView.AppCommandBar&gt;\n&lt;/toolkit:ListDetailsView.AppCommandBar&gt;\n&lt;/toolkit:ListDetailsView&gt;\n&lt;/Page&gt;\n</code></pre>"},{"location":"Coding/WinUI/API/#listview","title":"ListView","text":"<pre><code>&lt;ListView\nItemsSource=\"{x:Bind Items}\" SelectedItem=\"{x:Bind Items[0]}\"\nDisplayMemberPath=\"Display\"/&gt;\n</code></pre> <p>Important attributes:</p> <ul> <li><code>Items</code> or <code>ItemsSource</code> specify the collection (preferably <code>IObservableCollection</code> to support event handling on value changes) to be used to populate the control.</li> <li><code>SelectedItem</code> defines the element that appears selected by the control by default.  If not defined, no element will be selected.</li> <li><code>DisplayMemberPath</code> defines the name of the property to be used to display each individual choice.</li> </ul> MainWindow.xamlMainWindow.xaml.cs <pre><code>&lt;Window\nx:Class=\"Scratchpad1.MainWindow\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:Scratchpad1\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"&gt;\n\n&lt;StackPanel Orientation=\"Horizontal\" HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\"&gt;\n&lt;ComboBox ItemsSource=\"{x:Bind Items}\" SelectedItem=\"{x:Bind Items[0]}\"\nDisplayMemberPath=\"Name\" /&gt;\n&lt;/StackPanel&gt;\n&lt;/Window&gt;\n</code></pre> <pre><code>using System.Collections.Generic;\nusing Microsoft.UI.Xaml;\n\nnamespace Scratchpad1\n{\n\npublic class Starship\n{\npublic string Name { get; set; }\npublic string Registry { get; set; }\npublic int Crew { get; set; }\n\npublic Starship(string name, string registry, int crew)\n{\nName = name;\nRegistry = registry;\nCrew = crew;\n}\n}\n\n\npublic sealed partial class MainWindow : Window\n{\n//List&lt;string&gt; Items = new List&lt;string&gt;();\nStarship[] Items = new Starship[3];\n\n\npublic MainWindow()\n{\nthis.InitializeComponent();\nItems[0]=new Starship(\"USS Enterprise\",\"NCC-1701\",204);\nItems[1]=new Starship(\"USS Constitution\",\"NCC-1700\",203);\nItems[2]=new Starship(\"USS Defiant\",\"NCC-1764\",202);\n}\n}\n}\n</code></pre>"},{"location":"Coding/WinUI/API/#navigationview","title":"NavigationView","text":"<p>NavigationView provides top-level navigation by implementing a collapsible navigation bar (\"hamburger menu\") that is reactive to window size. It organizes two areas - Pane and Content - into two layout options that differ in the placement of the Pane.  The Header content is placed above the Content in both layouts.</p> LeftTop <p></p> <p></p> <p>It has various display modes that can be specified by setting PaneDisplayMode. By default, PaneDisplayMode is set to Auto, which enables adaptive (i.e. reactive) behavior, switching between Left, LeftCompact, and LeftMinimal display modes depending on window size.</p> LeftLeftCompactLeftMinimalTop <p></p> <p></p> <p></p> <p></p> <p>The Pane is the central feature of NavigationView, and it can contain many items organized into several sections.</p> <ul> <li>MenuItems  is the main section containing NavigationView items at the beginning of the control. </li> <li>FooterMenuItems  is similar but they are added to the end of the control.</li> <li>PaneTitle  can accept text, which will appear next to the menu button.</li> <li>PaneHeader  is similar but can accept non-text content.</li> <li>PaneFooter  can also accept any content.</li> </ul> <p>NavigationView items can be of various types:</p> <ol> <li>NavigationViewItemHeader can visually organize other navigation items</li> <li>NavigationViewItem  exposes Content and Icon properties.</li> <li>NavigationViewItemSeparator</li> <li>AutoSuggestBox</li> <li>Settings button visible by default but can be hidden by setting IsSettingsVisible</li> </ol> LeftTopMenuItems <p></p> <p></p> <pre><code>&lt;Page&gt;\n&lt;NavigationView&gt;\n&lt;NavigationView.MenuItems/&gt;\n&lt;/NavigationView&gt;\n&lt;/Page&gt;\n</code></pre> <p>Navigation using NavigationView is not automatically implemented but relies on event handling.  NavigationView raises an ItemInvoked event when selected, and if the selection has changed then SelectionChanged is also raised.</p> <p>NavigationView also feature a Back button, which can be disabled or removed by setting IsBackButtonVisible or IsBackEnabled to false. If enabled, this button raises the BackRequested event.</p> <p>Typical implementations pair NavigationView with a Frame nested within ScrollViewer to support navigating to different views while supporting the back button (see below).</p> XAMLCode-behind <pre><code>&lt;Page&gt;\n&lt;Grid&gt;\n&lt;NavigationView&gt;\n&lt;ScrollViewer&gt;\n&lt;Frame x:Name=\"ContentFrame\"/&gt;\n&lt;/ScrollViewer&gt;\n&lt;/NavigationView&gt;\n&lt;/Grid&gt;\n&lt;/Page&gt;\n</code></pre> <pre><code>private void Navigation_ItemInvoked(NavigationView sender, NavigationViewItemInvokedArgs args)\n{\nContentFrame.Navigate(typeof(Page1));\n}\n</code></pre>"},{"location":"Coding/WinUI/API/#page","title":"Page","text":"<p>The Page element in UWP is equivalent to <code>Window</code> in WPF.</p> <p>Page elements can only accept a single Content sub-element, necessitating the use of a layout panel like Grid, StackPanel, etc.</p>"},{"location":"Coding/WinUI/API/#relativepanel","title":"RelativePanel","text":"<p>RelativePanel allows children to declare attributes (e.g. <code>RelativePanel.RightOf</code> ) to specify position relative to the <code>x:Name</code> of other children. This is useful in building responsive layouts.</p> <p>Supports several attached properties that allow elements to be aligned with siblings or with the panel itself.</p> <ul> <li>Panel alignment relations like <code>AlignLeftWithPanel</code>, <code>AlignTopWithPanel</code>, <code>AlignRightWithPanel</code>, <code>AlignBottomWithPanel</code>,  align controls to the border of the RelativePanel containing them.</li> <li>Sibling alignment relationships like <code>AlignLeftWith</code>, <code>AlignTopWith</code>, <code>AlignVerticalCenterWith</code> etc. specify the name of a sibling control to provide alignment.</li> <li>Sibling positional relations like <code>LeftOf</code>, <code>Above</code>, <code>RightOf</code>, and <code>Below</code> also specify a sibling control.</li> </ul>"},{"location":"Coding/WinUI/API/#resourcedictionary","title":"ResourceDictionary","text":"<p>Resource dictionaries</p> <p>Here, Buttons will now be able to be styled using a  markup extension  <pre><code>&lt;Button Style=\"{StaticResource SubmitButton}\" Content=\"Submit\"/&gt;\n</code></pre></p> App.xaml/ResourceDictionaries/ButtonDictionary.xaml <pre><code>&lt;Application&gt;\n&lt;Application.Resources&gt;\n&lt;ResourceDictionary Source=\"ResourceDictionaries/ButtonDictionary.xaml\"/&gt;\n&lt;/Application.Resources&gt;\n&lt;/Application&gt;\n</code></pre> <pre><code>&lt;ResourceDictionary&gt;\n&lt;Style TargetType=\"Button\" x:Key=\"SubmitButton\"&gt;\n&lt;Setter Property=\"Background\" Value=\"Green\"/&gt;\n&lt;Setter Property=\"Padding\" Value=\"5\"/&gt;\n&lt;/Style&gt;\n&lt;/ResourceDictionary&gt;\n</code></pre> <p>Managing a consistent style will typically necessitate using multiple resource dictionaries. But some elements can only contain a single ResourceDictionary element.</p> <p>The solution is to place a ResourceDictionary.MergedDictionaries property element within the outermost <code>ResourceDictionary</code>. Multiple <code>ResourceDictionary</code> objects can be placed as children of it.</p> <pre><code>&lt;Page&gt;\n&lt;Page.Resources&gt;\n&lt;ResourceDictionary&gt;\n&lt;ResourceDictionary.MergedDictionaries&gt;\n&lt;ResourceDictionary Source=\"Dictionary1.xaml\" /&gt;\n&lt;ResourceDictionary Source=\"Dictionary2.xaml\" /&gt;\n&lt;/ResourceDictionary.MergedDictionaries&gt;\n&lt;/ResourceDictionary&gt;\n&lt;/Page.Resources&gt;\n&lt;/Page&gt;\n</code></pre> <p>Sources</p> <ul> <li> ResourceDictionary</li> <li> YouTube</li> </ul>"},{"location":"Coding/WinUI/API/#splitview","title":"SplitView","text":"<p>SplitView can be used to implement hamburger-style navigation. SplitView has two attributes into which controls can be placed, <code>Pane</code> and <code>Content</code>. Pane is not displayed by default. However, by setting the SplitView instance's <code>IsPaneOpen</code> attribute to True it can be displayed.</p> <p>The <code>DisplayMode</code> attribute controls how the Pane interacts with Content with opened:</p> <ul> <li>Overlay: Pane covers up Content</li> <li>Inline: Pane pushes Content to the right.</li> <li>CompactInline: Where Pane will fit Pane elements closely, if <code>CompactPaneLength</code> is not specified</li> <li>CompactOverley: Pane's dimensions can be specified using <code>CompactPaneLength</code> and <code>OpenPaneLength</code></li> </ul>"},{"location":"Coding/WinUI/API/#stackpanel","title":"StackPanel","text":"<p>The StackPanel layout panel in XAML is similar in function to the pack() geometry manager in tkinter, although its default behavior appears to horizontally center elements and stack them vertically.</p> <p>Notably, StackPanel does not support scroll bars. (src)</p>"},{"location":"Coding/WinUI/API/#tabview","title":"TabView","text":""},{"location":"Coding/WinUI/API/#textbox","title":"Textbox","text":"XAMLtkinter <pre><code>&lt;Window\nx:Class=\"EmployeeManager.WinUI.MainWindow\"\nxmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\nxmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\nxmlns:local=\"using:EmployeeManager.WinUI\"\nxmlns:d=\"http://schemas.microsoft.com/expression/blend/2008\"\nxmlns:mc=\"http://schemas.openxmlformats.org/markup-compatibility/2006\"\nmc:Ignorable=\"d\"&gt;\n\n&lt;TextBox Header=\"First name\"/&gt;\n&lt;/Window&gt;\n</code></pre> <pre><code>import tkinter as tk\nfrom tkinter.ttk import Entry\nfrom tkinter.ttk import LabelFrame\n\nwin = tk.Tk()\nframe=LabelFrame(win, text=\"First name\")\nframe.pack()\nEntry(frame).pack()\ntk.mainloop()\n</code></pre>"},{"location":"Coding/WinUI/API/#variablesizedwrapgrid","title":"VariableSizedWrapGrid","text":"<p>VariableSizedWrapGrid can be used to define a field of tiles similar to an HTML flex container (<code>display: flex;</code> with <code>flex-wrap: wrap;</code>). The <code>Orientation</code> property is similar to a flex container's <code>flex-direction</code>, in that the direction of alignment can be specified.</p> <p> <pre><code>&lt;Page&gt;\n&lt;VariableSizedWrapGrid Orientation=\"Horizontal\" ItemWidth=\"100\" ItemHeight=\"100\"&gt;\n&lt;Rectangle Fill=\"LightGray\"/&gt;\n&lt;Rectangle Fill=\"LightSteelBlue\" /&gt;\n&lt;Rectangle Fill=\"LightBlue\" /&gt;\n&lt;Rectangle Fill=\"LightCyan\" /&gt;\n&lt;Rectangle Fill=\"LightSeaGreen\" /&gt;\n&lt;Rectangle Fill=\"LightGreen\" /&gt;\n&lt;Rectangle Fill=\"LightGoldenrodYellow\"  /&gt;\n&lt;Rectangle Fill=\"LightSalmon\" /&gt;\n&lt;Rectangle Fill=\"LightCoral\" /&gt;\n&lt;Rectangle Fill=\"Gray\"/&gt;\n&lt;Rectangle Fill=\"SteelBlue\" /&gt;\n&lt;Rectangle Fill=\"CadetBlue\" /&gt;\n&lt;Rectangle Fill=\"Cyan\" /&gt;\n&lt;Rectangle Fill=\"SeaGreen\" /&gt;\n&lt;Rectangle Fill=\"Green\" /&gt;\n&lt;Rectangle Fill=\"Goldenrod\"  /&gt;\n&lt;Rectangle Fill=\"Salmon\" /&gt;\n&lt;Rectangle Fill=\"Coral\" /&gt;\n&lt;/VariableSizedWrapGrid&gt;\n&lt;/Page&gt;\n</code></pre> </p> <p>Notably, the horizontal or vertical alignment of XAML controls is defined on each control, whereas in HTML alignment is specified at the level of the enclosing container.</p> XAMLHTML and CSS <pre><code>&lt;TextBlock Content=\"Hello, world!\" HorizontalAlignment=\"Left\" VerticalAlignment=\"Top\"/&gt;\n</code></pre> <p><pre><code>.container\np Hello, world!\n</code></pre> <pre><code>.container {\ntext-align: right top;\n}\n</code></pre></p>"},{"location":"DevOps/","title":"Automation using Azure DevOps and Ansible","text":"<p>Azure Pipelines are used to automate the building of source code, including executing associated tasks like unit tests and packaging. Every execution of a pipeline, or a run, produces an artifact.</p> <p>Pipelines makes use of several concepts.</p> <ul> <li>A pipeline is started by a trigger </li> <li>A pipeline is made up of one or more stages, each of which can have one or more jobs</li> <li>Each job runs on an agent and can be made of one or more steps or tasks which are run sequentially.</li> <li>A task refers to a predefined action</li> </ul> <p>The simplest possible pipeline is a YAML file with a single line defining a trigger.  Creating a new repo with a single YAML file with only the trigger keyword defined will allow a Pipeline to then be created. But attempting to run it will produce an error reading \"The pipeline must contain at least one stage with no dependencies.\"</p> pipeline.yml<pre><code>trigger: none\n</code></pre> <p>Simple pipelines can omit the stages and jobs container and directly specify the steps keyword. In this case the pipeline is said to have a single implicit stage, as well as a single implicit job.</p> <p>This single-stage, single-job pipeline will place a short message in the user directory of the service account of a self-hosted agent.</p> <pre><code>trigger: none\npool: Hyper-V # (1)!\nsteps:\n- checkout: self  - bash: | # (2)!\necho \"Hello, World!\" &gt; ~/hello\n</code></pre> <ol> <li>Without the pool property, ADO will allocate a VM from the cloud.</li> <li>The pipe symbol here represents the block style indicator, one of many formats supported by YAML for multiline strings.</li> </ol> <p>Here the stages and jobs lists are made explicit. </p> <pre><code>trigger: none\npool: Hyper-V\nstages:\n- stage: helloWorldStage # (1)\njobs:\n- job: helloWorldJob\nsteps:\n- checkout: self  - bash: |\necho \"Hello, World!\" &gt; ~/hello\n</code></pre> <ol> <li>Values for stages.stage and jobs.job must be an alphanumeric string with no spaces. Both also expose an optional displayName property that appears in the web interface.</li> </ol> <p>This example can be developed further to provide the ability to choose between agent pools using templates, which define reusable content such as parameters.</p> <p>Parameters must contain a name and data type, for example this string. Parameters are references using the ${{ ... }} syntax. </p> <pre><code>trigger: none\nparameters:\n- name: name\ntype: string\ndefault: World\njobs:\n- job: helloWorldJob\nsteps:\n- checkout: self  - bash: echo \"Hello, ${{ parameters.name  }}!\" &gt; ~/hello\n</code></pre> <p>Enums, rendered as dropdowns, are defined using a list of values placed under the values key.</p> <pre><code>trigger: none\nparameters:\n- name: pool\ndefault: Home\nvalues:\n- Home\n- Work\n- name: name\ntype: string\ndefault: World\njobs:\n- job: helloWorld\npool: ${{ parameters.pool }} # (1)!\nsteps:\n- checkout: self  - bash: |\necho \"Hello, ${{ parameters.name }}!\" &gt; ~/hello\n</code></pre> <ol> <li>It is also possible to specify the agent pool at stages.stage: <pre><code>stages:\n- stage: helloWorldStage\npool: ${{ parameters.pool }}\njobs:\n# ...\n</code></pre></li> </ol> <p>/etc/motd contains a message that is displayed to users who login for the first time in that day.  If the ADO agent is also an Ansible control host, with properly defined sudo permissions, it can be used to set the motd on a managed host.</p> <p>Ensure that the control node has privilege escalation enabled.</p> <pre><code>trigger: none\nparameters:\n- name: pool\ndefault: Home\nvalues:\n- Home\n- Work\n- name: name\ntype: string\ndefault: World\njobs:\n- job: helloWorldJob\npool: ${{ parameters.pool }}\nsteps:\n- checkout: self\n- bash: |\nansible all -m copy -a 'dest=/etc/motd content=\"Hello, ${{ parameters.name }}!\"'\n</code></pre> <p>Instead of running an Ansible ad-hoc command, we can create a role, which groups content in a way that allows Ansible content to be shared.</p> <p>Here, the pipeline executes the motd-role role which is specified in the requirements file and defined in a separate repo. The pipeline parameter is passed to the playbook via the --extra-vars option.</p> <pre><code>trigger: none\nparameters:\n- name: pool\ndefault: Home\nvalues:\n- Home\n- Work\njobs:\n- job: HelloWorldJob\npool: ${{ parameters.pool }}\nsteps:\n- checkout: self\n- bash: |\nansible-galaxy role install -r ansible/requirements.yml -p ansible/roles -f \nansible-playbook ansible/playbook.yml \\\n--extra-vars \"greet_name=${{parameters.name}}\"\n# (1)!\n</code></pre> <ol> <li>ansible/playbook.yml<pre><code>- name: Running motd role\nhosts: all\nroles:\n- role: 'motd-role'\n</code></pre> ansible/requirements.yml<pre><code>roles:\n- src: git+https://jasperzanjani@dev.azure.com/jasperzanjani/NewDevOpsProject/_git/motd-role\n</code></pre></li> </ol> <p>The extends keyword can be used to remove complexity from a pipeline. Parameters defined in the parent must be passed to the child explicitly, and they must be defined again within the child to make them available to any template experssions. This makes it possible to abstract the frontend of parameter definitions from the backend of build logic.</p> pipeline.yml<pre><code>trigger: none\nparameters:\n- name: pool\ndefault: Home\nvalues:\n- Home\n- Work\n- name: name\ntype: string\ndefault: World\nextends:\ntemplate: jobs.yml\nparameters:\npool: ${{ parameters.pool }}\nname: ${{ parameters.name }}\n</code></pre> jobs.yml<pre><code>parameters:\n- name: pool\n- name: name\njobs:\n- job: helloWorldJob\npool: ${{ parameters.pool }}\nsteps:\n- checkout: self\n- bash: |\nansible-galaxy role install -r ansible/requirements.yml -p ansible/roles -f \nansible-playbook ansible/playbook.yml \\\n--extra-vars \"greet_name=${{parameters.name}}\"\n</code></pre> <p>Secure files are one of two types of files that can be made available via the Library. Secure files provide a way to store files that can be shared across pipelines, especially security-related items like signatures and keys.</p> <p>In order to consume a secure file in a pipeline, the DownloadSecureFile task task is used. Here it is used to make a private SSH key available on the agent.</p> <pre><code>- task: DownloadSecureFile@1\nname: sshkey\ninputs:\nsecureFile: ansible@hyperv-ubuntu2004\n</code></pre> <p>The secure file can then be used in the following line to make the key available to Ansible. Note that the template syntax $( ... ) differs from the template syntax used for pipelines parameters.</p> <pre><code>- bash: |\neval $(ssh-agent); ssh-add &lt;(cat \"$(sshkey.secureFilePath)\")\nansible-galaxy role install -r ansible/requirements.yml -p ansible/roles -f \nansible-playbook ansible/playbook.yml \\\n--extra-vars \"greet_name=${{parameters.name}}\"\npkill ssh-agent \n# (1)!\n</code></pre> <ol> <li>Repeated runs of the pipeline will continue to start new instances of ssh-agent, so an additional line killing the process at the end of the pipline is good form.</li> </ol> <p>An Ansible vault password file can be placed in Pipelines as a secure file.  This file is downloaded to the agent using the DownloadSecureFile task and can be used in downstream tasks, such as the argument to the --vault-password-file option, using the secureFilePath output variable.</p> pipeline.yaml<pre><code>trigger: none\nparameters:\n- name: pool\ndisplayName: Agent pool\ndefault: Home\nvalues:\n- Home\n- Work\njobs:\n- task: DownloadSecureFile@1\nname: sshkey\ninputs:\nsecureFile: ansible@hyperv-ubuntu2004\n- task: DownloadSecureFile@1\nname: vaultpw\ninputs:\nsecureFile: vault-pw\n- job: HelloWorldJob\npool: ${{ parameters.pool }}\nsteps:\n- checkout: self\n- bash: |\neval $(ssh-agent); ssh-add &lt;(cat \"$(sshkey.secureFilePath)\")\nansible-galaxy role install -r ansible/requirements.yml -p ansible/roles\nansible-playbook ansible/playbook.yml \\\n--extra-vars \"greet_name=${{parameters.name}}\" \\\n--vault-password-file=$(vaultpw.secureFilePath)  \npkill ssh-agent \n# (1)!\n</code></pre> <ol> <li>The magic variable role_path points to the path of the currently running role. roles/motd-role/tasks/main.yml<pre><code>---\n# tasks file for motd\n- include_vars:\nfile: \"{{ role_path }}/defaults/main.yml\" # (1)\n- copy:\ndest: /etc/motd\ncontent: Hello, {{ greet_name }}!\nnotify: Confirm motd\n</code></pre> Here, the encrypted value for the greet_name variable is encrypted inline in an otherwise unencrypted vars file. roles/motd-role/defaults/main.yml<pre><code>---\n# defaults file for motd\ngreet_name: !vault |\n$ANSIBLE_VAULT;1.1;AES256\n32306266363035376539336165613665393533653331363063303630353737633965646634356233\n3761346166386235336362623435653264336435623261610a313864346535343534616530313461\n61656438633862333038376239343132616537623664633536306264653636333835633735353531\n6331623962383261340a666330666438613764636162353831356432623461386437313963663333\n3137\n</code></pre></li> </ol>"},{"location":"DevOps/#triggers","title":"Triggers","text":"<p>A push trigger specifies which branches cause a continuous integration build to run. trigger: none disables CI triggers.</p> <p>Scheduled triggers can be defined with the  schedules key.</p> <pre><code>trigger: none\nschedules:\n- cron: \"0 3 * * *\"\ndisplayName: Daily 3 AM scan\nbranches:\ninclude:\n- main\nalways: true # (1)\n</code></pre> <ol> <li>always ensures that the pipeline runs even when there are no code changes.</li> </ol>"},{"location":"DevOps/ADO/","title":"Azure Devops","text":""},{"location":"DevOps/ADO/#agent","title":"Agent","text":"<p>An agent represents compute infrastructure with installed agent software. Agents can be Microsoft-hosted (i.e. Azure VMs created specifically for the job and discarded after use) or self-hosted. Agents are organized into pools; an agent instance can only belong to a single pool, unless more than one agent is installed.</p> <p>The agent software package contains several shell scripts that provide various ways of running and managing the agent.</p> <ul> <li>config.sh must be run to configure the agent after installation by providing the server URL and PAT token.</li> <li>run.sh allows manual, interactive execution of the agent software</li> <li>svc.sh allows management of the agent software as a SystemD service. The service itself is named according to the pattern vsts.agent.[ORGANIZATION].[AGENTPOOL].[AGENTNAME].service.</li> </ul> Self-hosted agent setup <p>Because the agent software itself is based on .NET Core 3.1, some operating systems (such as Ubuntu 22.04) are not compatible. Some like CentOS 9 have an unsupported version of OpenSSL installed, which results in the configuration script producing a libssl error. CentOS 9 provides OpenSSL 1.1.1k libraries in a separate package:</p> <pre><code>dnf install compat-openssl11\n</code></pre> <p>Also note it appears that the git utility needs to be installed on Red Hat derivatives like CentOS, although it doesn't appear to be explicitly installed by the installdependencies.sh script. This may be because git is assumed to exist on Ubuntu.</p> <p>The agent software package must be downloaded from ADO, and a personal access token must be created with the Agent Pools (read, manage) scope.</p> <pre><code>wget \"https://vstsagentpackage.azureedge.net/agent/3.218.0/vsts-agent-linux-x64-3.218.0.tar.gz\"\nmkdir agent; cd agent\ntar xfz \"vsts-agent-linux-x64-3.218.0.tar.gz\"\n./config.sh\nsudo ./svc.sh install\nsudo ./svc.sh run\n</code></pre>"},{"location":"DevOps/ADO/#azure-cli","title":"Azure CLI","text":"<p>There is an Azure DevOps extension for the Azure CLI.</p> <pre><code># Installation and configuring defaults\naz extension add --name azure-devops\naz devops configure --defaults organization=$ORG\naz devops configure --defaults project=$PROJECT\n\n# Display users\naz devops user list --organization $ORG\n\n# Display a single user\naz devops user show --organization $ORG --user $USER\n\n# Upgrade Azure CLI\naz upgrade # (1)!\n</code></pre> <ol> <li><pre><code># The extension used to need to be updated separately from the core Azure CLI\naz extension list-versions --name azure-devops\naz extension update --name azure-devops </code></pre></li> </ol> <p>ADO offers the opportunity to create wikis for repos (\"codewiki\") or projects (\"projectwiki\"). These can also be done through the CLI.</p> ADO wikis<pre><code>az devops wiki list\n</code></pre> <p>A separate command group for Azure Pipelines is installed with the azure-devops extension, with limited functionality.</p> <pre><code>az pipelines runs list --query '[*].result' # (1)\naz pipelines run --id 1 --parameters \"name=Dgiapusccu pool=Work\" # (2)\naz pipelines delete --id 1\n</code></pre> <ol> <li>Like other JSON output from the Azure CLI, JMESPATH queries can be passed to the --query option to filter results.</li> <li>The --parameters options appears to be relatively new and buggy. The help indicates that multiple space-delimited key-value pairs should be able to be passed, however this appears not to be the case.</li> </ol>"},{"location":"DevOps/ADO/#force-push","title":"Force push","text":"<p>Git force-push is specifically disabled for the main branch by default. This setting can only be changed by setting branch permissions that take effect for the main branch across the entire organization.</p>"},{"location":"DevOps/Ansible/","title":"Ansible","text":"Projects for learning <p>There are [several areas][https://opensource.com/article/19/8/ops-tasks-ansible] where Ansible can be used in personal projects for learning purposes. </p> <ol> <li>Use the <code>users</code> module to manage users, assign groups, and define custom aliases in the <code>profile</code> property.</li> <li>Put a time limit on the availability of the <code>sudo</code> command</li> <li>Use Ansible Tower to produce a GUI interface to restart certain services.</li> <li>Use Ansible Tower to look for files larger than a particular size in a directory.</li> <li>Debug a system performance problem. </li> </ol> <p>Ansible is an automation tool used for configuration management using human-readable YAML templates.  Ansible is distinguished for being agentless, meaning no special software is required on the nodes it manages.</p> <p>Ansible can be used in one of two ways:</p> <ul> <li>Running ad hoc commands, executed in realtime by an administrator working at the terminal using the ansible command</li> <li>Running playbooks, YAML documents that represent a sequence of scripted actions which apply changes uniformly over a set of hosts, using the ansible-playbook  command. </li> </ul> <p>A playbook is a YAML document that represents a sequence of scripted actions called tasks which apply changes uniformly over a set of hosts. Any ad hoc command can be rewritten as a playbook, but some modules can only be used effectively as playbooks.</p> playbooks/motd.yml<pre><code>- hosts: all\ntasks:\n- copy:\ndest: /etc/motd\ncontent: \"Hello, World!\"\n</code></pre> <p>Ansible host management relies on an inventory file containing a list of IP addresses or hostnames organized in groups. Inventories can be INI or YAML format. Inventories are conventionally organized as a file named hosts at the root of a project directory, although a system hosts file can be defined at /etc/ansible/hosts.</p>"},{"location":"DevOps/Ansible/#variables","title":"Variables","text":"<p>Variables can be defined under vars (as properties), and they are referenced using Jinja2-style double braces: <code>{{ }}</code>.  YAML syntax requires a value starting with double braces to be quoted.</p> playbooks/motd.yml<pre><code>- hosts: all\nvars:\nname: World\ntasks:\n- command: echo \"Hello, {{ name }}!\"\n</code></pre> <p>Variables can also be defined in variables files, YAML-format dictionaries conventionally placed in the vars directory, and referenced using the vars_files property. The path for vars files appears to be interpreted relative to the location of the playbook.</p> <p>playbooks/motd.yml<pre><code>- hosts: all\nvars_files:\n- vars/name.yml\ntasks:\n- copy:\ndest: /etc/motd\ncontent: Hello, {{ greet_name }}!\n</code></pre> playbooks/vars/name.yml<pre><code>greet_name: World\n</code></pre></p> <p>Variables can also be defined at runtime using the --extra-vars/-e option. Variables can be passed as space-delimited or JSON format.</p> <pre><code>ansible-playbook release.yml -e \"version=1.23.45 other_variable=foo\"\n</code></pre> <p>Variables cane be encrypted inline in an otherwise cleartext vars file.</p>"},{"location":"DevOps/Ansible/#jinja2","title":"Jinja2","text":"<p>Various effects are possible using Jinja2 templates:</p> <p>Jinja2 control structures support control flow features like loops and conditionals inside <code>{% ... %}</code> blocks. <pre><code>- name: Find any YUM/DNF variables\nfind:\npaths: \"/etc/{% 'dnf' if ansible_distribution_major_version == '8' else 'yum' %}/vars\"\nregister: _repository_vars_files\n</code></pre></p> <p>Filters follow a pipe in the template.</p> Capitalize a value<pre><code>line: \" {{ hypervisor | upper }}\n</code></pre> <p>Ansible provides additional filters. Here both the basename, b64decode, and combine Ansible filters are used as well as trim which is native to Jinja2. <pre><code>- set_fact:\nrepository_vars: \"{{ (repository_vars | default({})) | combine({ (_file.source | basename): _file.content | b64decode | trim }) }}\"\nloop: \"{{ _repository_vars_slurped_files.results }}\"\nloop_control:\nloop_var: _file\n</code></pre></p>"},{"location":"DevOps/Ansible/#roles","title":"Roles","text":"<p>Ansible roles group content in a way that allows it to be shared. They typically correspond to the service offered (web servers or databases, etc).</p> <p>Roles have a highly standardized directory structure.</p> <ul> <li>defaults: default values for variables with low perecedence that can be overriden by inventory variables</li> <li>files: static files referenced by role tasks</li> <li>handlers: handler definitions</li> <li>meta: metadata about the role, such as author, license, platforms, dependencies, etc</li> <li>tasks: task definitions</li> <li>vars: role variables with high precedence that cannot be overriden by inventory variables</li> </ul> <p>A skeleton directory can be created with ansible-galaxy. </p> <pre><code>ansible-galaxy init $ROLENAME\n</code></pre> <p>Roles can be called in a playbook under the roles property. The value of the role is interpreted as a path, appended to the project directory or various other potential locations. Because roles are meant to be reused by many playbooks, a central location is recommended:</p> <ul> <li>~/.ansible/roles</li> <li>/etc/ansible/roles</li> <li>/usr/share/ansible/roles</li> </ul> playbooks/motd.yml<pre><code>- hosts: all\nroles:\n- role: roles/motd\nvars:\ngreet_name: Dgiapusccu # (1)\n</code></pre> <ol> <li>Without providing an overriding variable value: <pre><code>- hosts: all\nroles: - roles/motd\n</code></pre></li> </ol> motd role<pre><code># motd/tasks/main.yml\n- copy:\ncontent: Hello, {{ greet_name }}!\ndest: /etc/motd\n\n# motd/defaults/main.yml\ngreet_name: World # (1)\n</code></pre> <ol> <li>Role variables defined in vars have a high precedence and cannot be overriden. Only values defined in defaults can be overriden.</li> </ol> <p>It appears that variables with values defined in the main.yml file located vars or defaults are automatically picked up. But if variables are defined in additional files they must be explicitly imported.</p> motd/tasks/main.yml<pre><code>- include_vars:\nfile: \"{{ role_path }}/defaults/secure.yml\"\n- copy:\ncontent: Hello, {{ greet_name }}!\ndest: /etc/motd\n</code></pre> <p>Normally, tasks in a role execute before the other tasks of a playbook. pre_tasks and post_tasks can be defined as well. </p> <p>Roles can have dependencies on other dependencies, as defined in the meta directory.</p> <pre><code>dependencies:\n- { role: apache, port: 80 }\n- { role: mariadb, dbname: addresses, admin_user: bob }\n</code></pre>"},{"location":"DevOps/Ansible/#collections","title":"Collections","text":"<p>Ansible collections comprise a standardized format for Ansible content distribution, allowing it to be delivered asynchronously and on-demand separately from Ansible Automation Platform releases. Ansible content can include playbooks, modules, roles, documentation, tests, plugins. Ansible collections are delivered using Ansible Galaxy and each collection needs a galaxy.yml file that describes the collection.</p> <p>Collections can be installed from a YAML-format requirements file: <pre><code>ansible-galaxy collection install -r ansible/requirements.yml\n</code></pre></p> ansible/requirements.yml<pre><code>roles:\n- src: git@ssh.dev.azure.com:v3/PODS-LLC/SWE/devops_inventory_role\nversion: master # (2)\nscm: git\nname: inventory # (1)\n</code></pre> <ol> <li>This apparently determines how the directory is renamed.</li> <li>Branch name</li> </ol>"},{"location":"DevOps/Ansible/#handlers","title":"Handlers","text":"<p>Handlers are tasks that are executed when notified by a task. They are only run once, and only if the notifying task has made a change to the system. </p> <p>Here, Enable Apache will be called if Install Apache makes a change.  If apache2 is already installed, the handler is not called. </p> <pre><code>- hosts: webservers\nbecome: yes\ntasks:\n- name: Install Apache\napt: name=apache2 update_cache=yes state=latest\nnotify: enable apaches\n\nhandlers:\n- name: Enable Apache\nservice: name=apache2 enabled=yes state=started\n</code></pre> <pre><code>- hosts: all\nvars:\npackage_name: apache2\ntasks:\n- name: this installs a package\napt: \"name={{ package_name }} update_cache=yes state=latest\"\nnotify: enable apache\nhandlers:\n- name: enable apache\nservice: \"name={{ package_name }} enabled=yes state=started\" </code></pre> <p>Conditional logic is [implemented][https://www.linuxjournal.com/content/ansible-part-iii-playbooks] on each task by defining a value for the when statement:</p> <pre><code>- hosts: all\nvars:\nstartme: true\ntasks:\n- command: echo Hello, World!\nwhen: startme\n</code></pre>"},{"location":"DevOps/Ansible/#vault","title":"Vault","text":"<p>Ansible Vault is a place to safely keep passwords. There are two types of vaulted content:</p> <ul> <li>Vaulted files, where the full file, which can contain Ansible variables or other content, is encrypted</li> <li>Single encrypted variables, where only specific variables within a normal \"variable file\" are encrypted.</li> </ul> Run a playbook providing a vault password file<pre><code>ansible-playbook --vault-password-file $pwfile playbooks/motd.yml\n</code></pre>"},{"location":"DevOps/Ansible/#tasks","title":"Tasks","text":""},{"location":"DevOps/Ansible/#setup","title":"Setup","text":"<p>The Ansible control node needs to be configured to elevate privileges. This is done by modifying ansible.cfg in the relevant project directory or the system config at /etc/ansible/ansible.cfg</p> ansible.cfg<pre><code>[privilege_escalation]\nbecome=yes\n</code></pre> <p>An Ansible service account is created on each managed node. <pre><code>useradd ansible -s /usr/bin/bash -mG wheel # sudo\npasswd ansible\nsu - ansible\nssh-keygen -A\n</code></pre></p> <p>Now the service account is given the ability to sudo any command without a password.</p> /etc/sudoers.d/ansible<pre><code>ansible ALL=(ALL) NOPASSWD: ALL\n# (1)!\n</code></pre> <ol> <li>Without this line, plays will fail with the message \"Missing sudo password\"  <pre><code>PLAY [Running motd role] *******************************************************\n\nTASK [Gathering Facts] *********************************************************\nfatal: [hyperv-centos9]: FAILED! =&gt; {\"msg\": \"Missing sudo password\"}\n\nPLAY RECAP *********************************************************************\nhyperv-centos9             : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   \n</code></pre></li> </ol> <p>The system inventory is an INI-format config located at etc/ansible/hosts and defines the clients which are to be controlled by the server.</p> <p>The group name all is implicitly defined, and the following command will display all defined hosts.</p> Display all available hosts<pre><code>ansible all --list-hosts\n</code></pre>"},{"location":"DevOps/Ansible/#apache","title":"Apache","text":"<pre><code>- hosts: all\ntasks:\n- package:\nname: httpd\nstate: latest\n- service:\nname: httpd\nenabled: true\nstate: started\n- ansible.posix.firewalld:\nimmediate: true\npermanent: true\nservice: http\nstate: enabled\n</code></pre> <p>Using vars<pre><code>- name: Install Apache\nhosts: all\nvars:\napache_package: httpd\ntasks:\n- name: Install {{ apache_package }} package\npackage:\nname: \"{{ apache_package }}\"\nstate: latest\n- name: Enable and start {{ apache_package }} service\nservice:\nname: \"{{ apache_package }}\"\nenabled: true\nstate: started\n- name: Open firewall\nansible.posix.firewalld:\nimmediate: true\npermanent: true\nservice: http\nstate: enabled\n</code></pre></p>"},{"location":"DevOps/Ansible/#files","title":"Files","text":"Create file<pre><code>- copy:\ndest: /etc/motd\ncontent: \"Hello, World!\\n\" # (1)\n</code></pre> <ol> <li>Alma Linux 9 additionally requires the libselinux-python package to handle SELinux contexts. It is incorrectly identified as \"libselinux-python\" in the Ansible error message.</li> </ol> Delete file<pre><code>- file:\npath: /etc/motd\nstate: absent\n</code></pre> Create directory<pre><code>- file:\npath: /home/ansible/.vim/autoload\nstate: directory\nmode: 0755\n</code></pre>"},{"location":"DevOps/Ansible/#user-creation","title":"User creation","text":"<pre><code>- hosts: all\nvars:\n- username: newuser\n- password: password\ntasks:\n- user:\nname: \"{{ username }}\"\npassword: \"{{ password }}\"\n</code></pre> <p>More secure is using a separate vaulted variables file to keep the credential secure.</p> <p>playbooks/user.yml<pre><code>- hosts: all\nvars_files:\n- vars/user.yml\ntasks:\n- user:\nname: \"{{ username }}\"\npassword: \"{{ password }}\"\n</code></pre> playbooks/vars/user.yml<pre><code>username: newuser\npassword: password\n</code></pre> Run playbook providing a password file<pre><code>ansible-playbook --vault-password-file vault-pw playbooks/user.yml\n</code></pre></p>"},{"location":"DevOps/Ansible/#commands","title":"Commands","text":""},{"location":"DevOps/Ansible/#ansible_1","title":"ansible","text":"<p>Used to run ad-hoc commands from the command-line.</p> Ad-hoc commands<pre><code>ansible all -m shell -a env\nansible all -a env # (1)\n</code></pre> <ol> <li>The command module is default and does not have to be made explicit</li> </ol> Display all available hosts<pre><code>ansible localhost --list-hosts\n</code></pre>"},{"location":"DevOps/Ansible/#ansible-config","title":"ansible-config","text":"Display non-default settings<pre><code>ansible-config dump --only-changed\n</code></pre>"},{"location":"DevOps/Ansible/#ansible-doc","title":"ansible-doc","text":"<pre><code># List currently installed modules\nansible-doc -l\n\n# Get module-specific information\nansible-doc $MODULE\n\n# Get example code\nansible-doc -s $MODULE\n</code></pre>"},{"location":"DevOps/Ansible/#ansible-galaxy","title":"ansible-galaxy","text":"<pre><code># Log in\nansible-galaxy login\n\n# Search for roles\nansible-galaxy search $ROLE\n\n# Install a public role (to ~/.ansible/roles by default)\nansible-galaxy install $USER.$ROLE\n\n# Initiate the skeleton structure of a role\nansible-galaxy init $ROLENAME\n\n# Upload a role\nansible-galaxy import $USERNAME $REPONAME\nansible-galaxy import --no-wait $USERNAME $REPONAME # send job to background\n</code></pre> <p>A requirements file can also be used. <pre><code>ansible-galaxy role install -r requirements.yml\n</code></pre> requirements.yml<pre><code>roles:\n- src: git+https://jasperzanjani@dev.azure.com/jasperzanjani/NewDevOpsProject/_git/motd-role # (1)\nversion: master\n</code></pre></p> <ol> <li>By default, ansible-galaxy will expect a tarball, unless <code>git+</code> is prepended to the URL.</li> </ol> <p>As long as a public key is registered with Azure DevOps (and an outbound SSH connection isn't blocked by the firewall), the requirements file can use an SSH connection. <pre><code>roles:\n- src: git@ssh.dev.azure.com:v3/jasperzanjani/NewDevOpsProject/motd-role\nversion: master\n</code></pre></p> <p>Variables in </p>"},{"location":"DevOps/Ansible/#ansible-playbook","title":"ansible-playbook","text":"Verify YAML syntax<pre><code>ansible-playbook --syntax-check $FILE\n</code></pre>"},{"location":"DevOps/Ansible/#ansible-vault","title":"ansible-vault","text":"<pre><code># Create an encrypted file, providing password interactively\nansible-vault create $file\n\n# Use a cleartext password file\nansible-vault view --vault-password-file=vault-pw $file\n\n# Encrypt/decrypt a file in-place, overwriting original file\nansible-vault encrypt $file\nansible-vault decrypt $file\n\nansible-vault edit secret.yml\n</code></pre>"},{"location":"DevOps/Ansible/#modules","title":"Modules","text":"archive<pre><code>- name: Compress directory /path/to/foo/ into /path/to/foo.tgz\narchive:\npath: /path/to/foo\ndest: /path/to/foo.tgz\n- name: Create a bz2 archive of multiple files, rooted at /path\narchive:\npath:\n- /path/to/foo\n- /path/wong/foo\ndest: /path/file.tar.bz2\nformat: bz2\n</code></pre> cli_config<pre><code># Platform-agnostic way of [pushing text-based configurations](https://opensource.com/article/19/9/must-know-ansible-modules) to network devices over the **network_cli_connection** plugin.\n- name: Set hostname for a switch and exit with a commit message\ncli_config:\nconfig: set system host-name foo\ncommit_comment: this is a test\n- name: Back up a config to a different destination file\ncli_config:\nconfig: \"{{ lookup('template', 'basic/config.j2') }}\"\nbackup: yes\nbackup_options:\nfilename: backup.cfg\ndir_path: /home/user\n</code></pre> command<pre><code>- name: Return motd to registered var\ncommand: cat /etc/motd\nregister: mymotd\n- name: Change the working directory to somedir/ and run the command as db_owner if /path/to/database does not exist.\ncommand: /usr/bin/make_database.sh db_user db_name\nbecome: yes\nbecome_user: db_owner\nargs:\nchdir: somedir/\ncreates: /path/to/database\n</code></pre> copy<pre><code>- name: Copy a new \"ntp.conf file into place, backing up the original if it differs from the copied version\ncopy:\nsrc: /mine/ntp.conf\ndest: /etc/ntp.conf\nowner: root\ngroup: root\nmode: '0644'\nbackup: yes\n- name: Copy file with owner and permission, using symbolic representation\ncopy:\nsrc: /srv/myfiles/foo.conf\ndest: /etc/foo.conf\nowner: foo\ngroup: foo\nmode: u=rw,g=r,o=r\n</code></pre> debug<pre><code>- name: Display all variables/facts known for a host\ndebug:\nvar: hostvars[inventory_hostname]\nverbosity: 4\n# Display content of copy module only when verbosity of 2 is specified\n- name: Write some content in a file /tmp/foo.txt\ncopy:\ndest: /tmp/foo.txt\ncontent: |\nGood Morning!\nAwesome sunshine today.\nregister: display_file_content\n- name: Debug display_file_content\ndebug:\nvar: display_file_content\nverbosity: 2\n</code></pre> <p>file<pre><code>- name: Change file ownership, group and permissions\nfile:\npath: /etc/foo.conf\nowner: foo\ngroup: foo\nmode: '0644'\n- name: Create a directory if it does not exist\nfile:\npath: /etc/foo\nstate: directory\nmode: '0755'\n</code></pre> file<pre><code># Create a symlink\nansible $CLIENT -b -m file -a \"src=/etc/ntp.conf dest=/home/user/ntp.conf owner=user group=user state=link\"\n\n# Create a folder using an ad hoc command\nansible $CLIENT -b -m file -a \"path=/etc/newfolder state=directory mode=0755\"\n</code></pre></p> git<pre><code>- git:\nname: Create git archive from repo\nrepo: https://github.com/ansible/ansible-examples.git\ndest: /src/ansible-examples\narchive: /tmp/ansible-examples.zip\n- git:\nrepo: https://github.com/ansible/ansible-examples.git\ndest: /src/ansible-examples\nseparate_git_dir: /src/ansible-examples.git\n</code></pre> lineinfile<pre><code>- name: Ensure SELinux is set to enforcing mode\nlineinfile:\npath: /etc/selinux/config\nregexp: '^SELINUX='\nline: SELINUX=enforcing\n- name: Add a line to a file if the file does not exist, without passing regexp\nlineinfile:\npath: /etc/resolv.conf\nline: 192.168.1.99 foo.lab.net foo\ncreate: yes\n</code></pre> package<pre><code>- name: Install Apache and MariaDB\ndnf:\nname:\n- httpd\n- mariadb-server\nstate: latest\n- name: Install PostgreSQL and NGINX\nyum:\nname:\n- nginx\n- postgresql\n- postgresql-server\nstate: present\n</code></pre> replace<pre><code>- name: Comment out a line in a config\nansible.builtin.replace:\npath: /etc/motd\nregexp: '^Hello, (.*)'\nreplace: '# Hello, \\1'\n</code></pre> service<pre><code>- name: Start service foo, based on running process /usr/bin/foo\nservice:\nname: foo\npattern: /usr/bin/foo\nstate: started\n- name: Restart network service for interface eth0\nservice:\nname: network\nstate: restarted\nargs: eth0\n</code></pre> setup<pre><code># Display all available information about a system\nansible $CLIENT -b -m setup\n\n# Filter results to ansible_os_family, which indicates if the OS is Debian or Red Hat\nansible $CLIENT -b -m setup -a \"filter=*family*\"\n</code></pre> snap<pre><code>- name: Install VS Code\nsnap:\nname: code\nstate: present\nclassic: yes   </code></pre> template<pre><code># This example creates a HTML document on each client that is customized using Ansible variables. \n---\n- hosts: webservers\nbecome: yes\n\ntasks:\n- name: install apache2\napt: name=apache2 state=latest update_cache=yes\nwhen: ansible_os_family == \"Debian\"\n\n- name: install httpd\nyum: name=httpd state=latest\nwhen: ansible_os_family == \"RedHat\"\n\n- name: start apache2\nservice: name=apache2 state=started enable=yes\nwhen: ansible_os_family == \"Debian\"\n\n- name: start httpd\nservice: name=httpd state=started enable=yes\nwhen: ansible_os_family == \"RedHat\n\n- name: install index\ntemplate:\nsrc: index.html.j2\ndest: /var/www/html/index.html\n# (1)!\n</code></pre> <ol> <li>Jinja2 template file<pre><code>&lt;html&gt;\n  &lt;h1&gt;This computer is running {{ ansible_os_family }},\n  and its hostname is:&lt;/h1&gt;\n  &lt;h3&gt;{{ ansible_hostname }}&lt;/h3&gt;\n  {# this is a comment, which won't be copied to the index.html file #}\n&lt;/html&gt;\n</code></pre></li> </ol>"},{"location":"DevOps/Ansible/#glossary","title":"Glossary","text":"<ul> <li>Ad Hoc: type of command run in realtime by an administrator working at the terminal</li> <li>Ansible Galaxy: online portal where a gallery of roles made by the Ansible community can be found</li> <li>Ansible Tower: web-based RESTful API endpoint that provides the officially supported GUI frontend to Ansible configuration management, available in two versions: standard ($13,000/yr) and premium ($17,500/yr)</li> <li>Ansible Vault: place to keep encrypted passwords</li> <li>AWX: Open-source project upon which Ansible Tower was built</li> <li>Fact: System property gathered by Ansible when it executes a playbook on a node</li> <li>Inventory: INI-format file containing a list of servers or nodes that you are managing and configuring</li> <li>Module: standalone scripts that enable a particular task across many OSes, services, applications, etc.  Predefined modules are available in the module library, and new ones can be defined via Python or JSON.</li> <li>Play: script or instruction that defines the task to be carried out in a server</li> <li>Playbook:   </li> <li>Role: organize components of playbooks, allowing them to be reused</li> <li>Task: A single scripted action in a playbook, equivalent to an ad hoc command</li> <li>Vault: feature of Ansible that allows you to keep sensitive data such as passwords or keys protected at rest, rather than as plaintext in playbooks or roles.</li> </ul>"},{"location":"GTK/","title":"Overview","text":"Resources <ul> <li>PyGObject API reference</li> <li>PyGObject docs</li> </ul> <p>Documentation for Rust GTK bindings</p> <ul> <li>GTK3</li> <li>GTK4</li> </ul> <p>GTK is an open-source cross-platform widget toolkit developed by The GNOME Project for creating GUI applications. Major desktop environments including GNOME and Xfce are based on GTK.</p> <p>GTK was originally designed for use in GIMP as a replacement for the previous Motif toolkit which was unsatisfactory. Since GTK 2.8 (2005), GTK uses the Cairo library to render vector graphics.</p> <p>Building GTK application UIs can be done procedurally by defining UI elements in code or declaratively in XML interfaces.</p>"},{"location":"GTK/#interfaces","title":"Interfaces","text":"<p>XML interfaces can be defined in XML files or less commonly as string literals which are then loaded in the constructor for Gtk.Builder. Interfaces are also known as \"Glade files\" after the popular Glade UI design application.</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt; # (1)\n  &lt;requires lib=\"gtk+\" version=\"3.40\"/&gt; &lt;!-- (2) --&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;signal name=\"destroy\" handler=\"on_main_window_destroy\"/&gt; &lt;!-- (3) --&gt;\n&lt;child&gt; &lt;!-- (4) --&gt;\n&lt;object class=\"GtkBox\"&gt;\n&lt;property name=\"orientation\"&gt;vertical&lt;/property&gt; &lt;!-- (5) --&gt;\n&lt;object class=\"GtkLabel\" id=\"label\"&gt;\n&lt;property name=\"label\"&gt;Hello, World!&lt;/property&gt;\n&lt;/object&gt;\n&lt;/object&gt;\n&lt;/child&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre> <ol> <li>The root node in these files is the interface element itself.</li> <li>The first direct child of an interface is the requires element, with a version number that specifies the required version of GTK. If this interface used Gtk.ApplicationWindow instead of Gtk.Window, this number would have to be 3.40 because that is the version this class was introduced.</li> <li>Signals and callbacks can be specified in the markup on the signal element, which is the direct child to the object emitting the signal and also self-closing. Callback method names are specified in the handler attribute</li> <li>Container widgets like Gtk.Box wrap every child in a child element. Note that the interface element does not need a but is immediate parent to the outermost container of the UI.</li> <li>Each property of an object is a property element with the name of the property provided in a name attribute and the value provided as the element's value.</li> </ol> <p>The UI is then loaded into the application using Gtk.Builder. Individual UI elements can be bound if they have an id attribute assigned.</p>  Rust Python <pre><code>fn main() {\nlet app = gtk::Application::builder()\n.application_id(\"org.example.gtk-app\")\n.build();\n\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application):{\nlet builder = gtk::Builder::from_string(include_str!(\"window.ui\"));\nlet window: ApplicationWindow = builder.object(\"window\")\n.expect(\"Error loading ApplicationWindow!\");\nwindow.set_application(Some(app));\nwindow.show_all();\nwindow.present();\n}\n</code></pre> <pre><code>class Application(Gtk.Application):\n    def __init__(self, *args, **kwargs):\n        super().__init__(application_id = \"org.example.gtk-app\")\n\n    def do_activate(self):\nbuilder = Gtk.Builder.new_from_file(\"window.ui\")\nself.window = builder.get_object(\"window\")\nself.window.show_all()\n        self.window.present()\n\n    def run(self):\n        super().run()\n        Gtk.main() # (1)\n</code></pre> <ol> <li>For some reason, one of the differences between a PyGTK script that specifies its UI procedurally in code4 and one that takes it from an interface file is that <code>Gtk.main()</code> must be explicitly called somewhere. The Application object's run() method can be overridden to call it, or it can be placed in the script's entrypoint.</li> </ol>"},{"location":"GTK/#builder-pattern","title":"Builder pattern","text":"<p>A typical ways of building UIs procedurally in gtk-rs is the Builder design pattern.  This pattern supports procedural construction of the object using a chain of method calls, ending in <code>build()</code>. Note, this is not to be confused with the Gtk.Builder API that is actually used for declarative UI specification in interfaces.</p> gtk-rs<pre><code>use gtk4 as gtk;\nuse gtk::prelude::*;\nuse gtk::{Application, ApplicationWindow};\n\nfn main() {\nlet app = Application::builder()\n.application_id(\"org.example.HelloWorld\")\n.build();\napp.connect_activate(|app| {\nlet window = ApplicationWindow::builder()\n.application(app)\n.default_width(320)\n.default_height(200)\n.title(\"Hello, World!\")\n.build();\nwindow.show();\n});\n\napp.run();\n}\n</code></pre> <p>Other objects, like Box, do not expose this API.</p>"},{"location":"GTK/#connect_activate","title":"connect_activate","text":"<p>This simple (nonfunctional) example produces an error that demands a handler be implemented for the <code>activate</code> signal. <pre><code>use gtk::prelude::*;\nuse gtk::Application;\n\nfn main() {\nlet app = Application::builder()\n.application_id(\"org.gtk-rs.example\")\n.build();\n\napp.run();\n}\n</code></pre></p> <p>Here the <code>activate</code> signal is bound to the <code>build_ui()</code> function. Alternatively, a closure can be used for simple windows. ApplicationWindow's <code>present()</code> and <code>show()</code> methods appear to be interchangeable.</p> FunctionClosure <pre><code>fn main() {\n// ...\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet window = ApplicationWindow::builder()\n.application(app)\n.title(\"My GTK App\")\n.build();\nwindow.present();\n}\n</code></pre> <pre><code>fn main() {\n// ...\napp.connect_activate(|app| {\nlet window = ApplicationWindow::builder()\n.application(app)\n.title(\"Hello, World!\")\n.build();\nwindow.show();\n});\napp.run();\n}\n</code></pre> <p>Widgets are added as children of containers like ApplicationWindow or Box. This can be done using one of two ways:</p> <ul> <li>child() builder helper method, passing an immutable reference to the widget.</li> <li>set_child() method after instantiation, but this time passing a <code>Some()</code> result containing the immutable reference to the widget.</li> </ul> child()set_child() <pre><code>let window = ApplicationWindow::builder()\n.application(app)\n.title(\"Hello, World!\")\n.child(&amp;button)\n.build();\n</code></pre> <pre><code>let window = ApplicationWindow::builder()\n.application(app)\n.title(\"Hello, World!\")\n.build();\n\nwindow.set_child(Some(&amp;button));\n</code></pre>"},{"location":"GTK/API/","title":"API","text":""},{"location":"GTK/API/#gio","title":"Gio","text":""},{"location":"GTK/API/#action","title":"Action","text":"<p>Gio.Action is a way to expose any single task an application or widget does by a name. Classes like Gio.MenuItem and Gtk.ModelButton support properties to set an action name. These actions can be collected into a Gio.ActionGroup.</p> <ul> <li>Gio.ActionMap are interfaces implemented by Gtk.ApplicationWindow</li> </ul>"},{"location":"GTK/API/#gtk","title":"Gtk","text":""},{"location":"GTK/API/#actiongroup_1","title":"ActionGroup","text":""},{"location":"GTK/API/#adjustment","title":"Adjustment","text":"<p>Gtk.Adjustment is not a widget per se but is used in many widgets, including spin buttons, view ports, and children of Gtk.Range.</p> <ul> <li>page increment and page size refer to actions taken when the user presses PgUp or PgDn <pre><code>Gtk.Adjustment.new(initial_value, lower_range, upper_range, step_increment, page_increment, page_size)\n</code></pre></li> </ul>"},{"location":"GTK/API/#alignment","title":"Alignment","text":"Gtk.Alignment controls the alignment and size of its child widget."},{"location":"GTK/API/#application","title":"Application","text":"<p>Subclasses of Gtk.Application encapsulate application behavior, including application startup and CLI processing. In practice it is simply a wrapper for the ApplicationWindow class which is instantiated in the <code>do_activate()</code> hook. Notably, the Application subclass provides the value for the <code>application_id</code> kwarg passed to the Gtk.Application constructor. This value is validated, and any simple string is not silently accepted.</p> <p>Application must expose several important methods:</p> <ul> <li><code>do_activate()</code> <pre><code>def do_activate(self):\nself.window = ApplicationWindow(application=self, title=\"Hello, World!\")\nself.window.show_all()\nself.window.present()\n</code></pre></li> <li><code>do_startup()</code></li> </ul>"},{"location":"GTK/API/#applicationwindow","title":"ApplicationWindow","text":"<p>The Gtk.ApplicationWindow class is the main visible window for the application, and the only window for \"single-instance\" applications (which is the default). The ApplicationWindow class was introduced in GTK 3.4.</p> <p>When an action has the prefix <code>win.</code> it specifies that the ApplicationWindow subclass will process the signal.</p>"},{"location":"GTK/API/#assistant","title":"Assistant","text":"Gtk.Assistant widgets are used to build wizards."},{"location":"GTK/API/#box","title":"Box","text":""},{"location":"GTK/API/#builder","title":"Builder","text":"<p>Gtk.Builder allows the use of interfaces to define widget layouts. Individual UI elements can be bound if they have an id attribute assigned.</p>  Rust Python <pre><code>fn main() {\nlet app = gtk::Application::builder()\n.application_id(\"org.example.gtk-app\")\n.build();\n\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application):{\nlet builder = gtk::Builder::from_string(include_str!(\"window.ui\"));\nlet window: ApplicationWindow = builder.object(\"window\")\n.expect(\"Error loading ApplicationWindow!\");\nwindow.set_application(Some(app));\nwindow.show_all();\nwindow.present();\n}\n</code></pre> <pre><code>class Application(Gtk.Application):\n    def __init__(self, *args, **kwargs):\n        super().__init__(application_id = \"org.example.gtk-app\")\n\n    def do_activate(self):\nbuilder = Gtk.Builder.new_from_file(\"window.ui\")\nself.window = builder.get_object(\"window\")\nself.window.show_all()\n        self.window.present()\n\n    def run(self):\n        super().run()\n        Gtk.main()\n</code></pre>"},{"location":"GTK/API/#checkbutton","title":"CheckButton","text":"Gtk.CheckButtons are checkboxes."},{"location":"GTK/API/#clone","title":"clone","text":"<p>glib::clone! is used to facilitate passing strong or weak references into closures.</p> StrongWeak <pre><code>use glib;\nuse glib_macros::clone;\nuse std::rc::Rc;\n\nlet v = Rc::new(1);\nlet closure = clone!(@strong v =&gt; move |x| {\nprintln!(\"v: {}, x: {}\", v, x);\n});\n\nclosure(2);\n</code></pre> <pre><code>use glib;\nuse glib_macros::clone;\nuse std::rc::Rc;\n\nlet u = Rc::new(2);\nlet closure = clone!(@weak u =&gt; move |x| {\nprintln!(\"u: {}, x: {}\", u, x);\n});\n\nclosure(3);\n</code></pre>"},{"location":"GTK/API/#container","title":"Container","text":"Both Gtk.ApplicationWindow and Gtk.Window classes indirectly derive from the abstract class Gtk.Container. The main purpose of a container subclass is to allow a parent widget to contain one or more child widgets, and there are two types:"},{"location":"GTK/API/#dialog","title":"Dialog","text":"<p>Gtk.Dialog  provides a convenient way to prompt the user for a small amount of input. It is a widget that can be instantiated and customized in its own right as well as a parent to various subclasses.  <pre><code>dialog = Gtk.Dialog(title=\"Hello, World!\", parent=parent)\n</code></pre></p> <p>Dialogs are split into two parts:</p> <ul> <li>Content area containing interactive widgets</li> <li>Action area containing buttons</li> </ul> <p>These areas are both combined in a vertical Box that is assigned to the <code>vbox</code> field. The action area is packed to the end of this vbox, so the <code>pack_start()</code> method is used to add widgets to the content area.</p> <p>Dialog boxes can be modal, meaning they prevent interaction with the main window while open, or nonmodal.</p> ModalNonmodal <pre><code>dialog = Gtk.Dialog(title=\"Hello, World!\", parent=parent, modal=True)\n</code></pre> <pre><code>dialog = Gtk.Dialog(title=\"Hello, World!\", parent=parent, modal=False)\n</code></pre> <p>Gtk.MessageDialog is a subtype of Dialog meant to simplify the process of creating simple dialogs.</p> <p>Buttons are added procedurally using <code>add_button()</code>, passing a display string (with support for mnemonics using <code>_</code>) and a ResponseType enum (they once could be added on instantiation by passing a tuple to the <code>buttons</code> keyword argument).</p> <pre><code>dialog.add_button(\"_OK\", Gtk.ResponseType.OK)\n</code></pre> <p>Methods:</p> <ul> <li>add_button() </li> </ul>"},{"location":"GTK/API/#entry","title":"Entry","text":"<p>Unlike other widgets, Gtk.Entry can be instantiated without using a specific constructor. <pre><code>entry = Gtk.Entry()\n</code></pre></p> <p>Default text can be provided by passing a string to the text keyword argument or with the <code>set_text()</code> setter method:</p> kwargsetter <pre><code>entry = Gtk.Entry(text=\"Hello, World!\")\n</code></pre> <pre><code>entry.set_text(\"Hello, World!\")\n</code></pre> <p>A password field can be made by concealing text by passing False to  visibility or with the <code>set_visibility()</code> setter:</p> kwargsetter <pre><code>password = Gtk.Entry(visibility=False)\n</code></pre> <pre><code>password.set_visibility(False)\n</code></pre> <ul> <li><code>get_text()</code>  retrieve contents (string)</li> <li><code>set_visibility(bool)</code>  conceal text</li> </ul>"},{"location":"GTK/API/#eventbox","title":"EventBox","text":"<p>Gtk.EventBox is a container widget that allows event handling for widgets like Gtk.Label that do not have an associated GDK window. The event box can be positioned above or below the windows of its child with <code>set_above_child()</code> (False by default.) An EventBox must also have a Gtk.EventMask enum set to specify the type of events the widget may receive. This enum is passed as a value to <code>set_events()</code>.</p> <p>In the following example, an event handler is connected to the EventBox to handle <code>button_press_event</code>.  This event handler changes the text of the Label after a double-click.</p> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk, Gdk\n\n\nclass AppWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_border_width(10)\n        self.set_size_request(200, 50)\neventbox = Gtk.EventBox.new()\nlabel = Gtk.Label.new(\"Double-Click Me!\")\neventbox.set_above_child(False)\neventbox.connect(\"button_press_event\", self.on_button_pressed, label)\neventbox.add(label)\nself.add(eventbox)\neventbox.set_events(Gdk.EventMask.BUTTON_PRESS_MASK)\neventbox.realize()\ndef on_button_pressed(self, eventbox, event, label):\n        if event.type == Gdk.EventType._2BUTTON_PRESS:\n            text = label.get_text()\n            if text[0] == 'D':\n                label.set_text(\"I Was Double-Clicked!\")\n            else:\n                label.set_text(\"Double-Click Me Again!\")\n        return False\n\nclass Application(Gtk.Application):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Hello World!\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/API/#filechooserdialog","title":"FileChooserDialog","text":"<p>Gtk.FileChooserDialog is one of the important subtypes of Gtk.Dialog. Like other dialogs, it is provided a title and parent window on instantiation. Additionally a FileChooserAction enum must be specified.</p> <p>FileChooserActions include:</p> <ul> <li>Gtk.FileChooserAction.SAVE</li> <li>Gtk.FileChooserAction.OPEN</li> <li>Gtk.FileChooserAction.SELECT_FOLDER</li> <li>Gtk.FileChooserAction.CREATE_FOLDER</li> </ul> <pre><code>dialog = Gtk.FileChooserDialog(\n    title=\"Save file as ...\",\n    parent=parent,\n    action=FileChooserAction.SAVE\n)\n</code></pre> <p>Selected files are then retrieved using <pre><code>dialog.get_filenames()\n</code></pre></p> <p>| Setter                                                                                                                            | Property          | Description                                                                           | | --------------------------------------------------------------------------------------------------------------------------------- | ----------------- | | <code>set_current_folder</code> |                   | Specify directory in filesystem where FileChooser will start                          | | <code>set_current_name</code>         |                   | For FileChooserAction.SAVE, suggest a filename                                        | | <code>set_select_multiple</code>   | <code>select_multiple</code> | For FileChooserAction.OPEN or SELECT_FOLDER, allow multiple file or folder selections |</p>"},{"location":"GTK/API/#grid","title":"Grid","text":"<p>Gtk.Grid allows children to be packed in a two-dimensional grid. Grids are instantiated with <code>new()</code> and widgets are laid out by calling <code>attach()</code> (see Login for an example).</p> <ul> <li><code>attach()</code> lay out a widget providing column and row numbers followed by column and row spans <pre><code>grid.attach(label, 0, 0, 1, 1)\n</code></pre></li> </ul>"},{"location":"GTK/API/#headerbar","title":"HeaderBar","text":"<p>Gtk.HeaderBar allows the titlebar to be customized. Like other widgets, it can be configured on instantiation by providing values to keyword arguments or by using setters.</p> <p>Adding to a window</p> <p>HeaderBars are added with <code>set_titlebar()</code>. This is unlike other widgets which are assigned to an ApplicationWindow or Window using <code>pack_start()</code>, <code>pack_end()</code>, or <code>add()</code>, </p> kwargsetter <pre><code>class ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\nheaderbar = Gtk.HeaderBar(title=f\"Hello, World!\", \nsubtitle=\"HeaderBar example\", \nshow_close_button=True)\nself.set_titlebar(headerbar)\n</code></pre> <pre><code>class ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\nheaderbar = Gtk.HeaderBar()\nheaderbar.set_title(f\"Hello, World!\")\nheaderbar.set_subtitle(\"HeaderBar example\")\nheaderbar.set_show_close_button(True)\nself.set_titlebar(headerbar)\n</code></pre>"},{"location":"GTK/API/#label","title":"Label","text":"<p>Note that Gtk.Label sets its text with \"label\" and not \"text\" as you may expect from the corresponding setter.</p> kwargsetter <pre><code>label = Gtk.Label(label=\"Hello, World!\")\n</code></pre> <pre><code>label.set_text(\"Hello, World!\")\n</code></pre>"},{"location":"GTK/API/#listbox","title":"ListBox","text":"Gtk.ListBox is a vertical container of Gtk.ListBoxRow children used as an alternative to TreeView when the children need to be interactive, as in a list of settings. ListBox"},{"location":"GTK/API/#liststore","title":"ListStore","text":"<p>Gtk.ListStore is one of the two major classes that serves as combination schema and database backing Gtk.TreeView, the other being Gtk.TreeStore.</p> <p>It is instantiated with a sequence of data types, similar to a database schema.  These can be standard Python types or GObjects (which are mapped to the Python types anyway):</p> Python typesGObject types <pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\nliststore = Gtk.ListStore((str, int, str))\n</code></pre> <pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk, GObject\nliststore = Gtk.ListStore((GObject.TYPE_STRING, GOBject).TYPE_INT, GObject.TYPE_STRING))\n</code></pre> <p>This object then exposes an <code>append</code> method which is used to add records: <pre><code>liststore.append([\"Socrates\", 350, \"Athens\"])\n</code></pre></p> <p>The store is then associated with the treeview with <code>set_model</code> <pre><code>treeview.set_model(liststore)\n</code></pre></p>"},{"location":"GTK/API/#menubar","title":"MenuBar","text":"<p>Gtk.MenuBar is populated with Gtk.MenuItems, corresponding to the expandable menu items (i.e. \"File\", \"Edit\", and \"Help\"). Gtk.Menu is actually used for the submenu, which like MenuBar is also populared with MenuItems.  A Menu is attached to the MenuItem of a MenuBar by using the <code>set_submenu()</code> method on the Menu object. This setter does not have a corresponding kwarg, so all menus have to be constructed procedurally.</p> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass AppWindow(Gtk.ApplicationWindow):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(250, -1)\n        menubar = Gtk.MenuBar.new()\n        self.add(menubar)\n\n        file = Gtk.MenuItem.new_with_label(\"File\")\n        menubar.append(file)\n        filemenu = Gtk.Menu.new()\n        file.set_submenu(filemenu)\n        new = Gtk.MenuItem.new_with_label(\"New\")\n        open = Gtk.MenuItem.new_with_label(\"Open\")\n        filemenu.append(new)\n        filemenu.append(open)\n\n        edit = Gtk.MenuItem.new_with_label(\"Edit\")\n        menubar.append(edit)\n        editmenu = Gtk.Menu.new()\n        edit.set_submenu(editmenu)\n        cut = Gtk.MenuItem.new_with_label(\"Cut\")\n        copy = Gtk.MenuItem.new_with_label(\"Copy\")\n        paste = Gtk.MenuItem.new_with_label(\"Paste\")\n        editmenu.append(cut)\n        editmenu.append(copy) \n        editmenu.append(paste)\n\n        help = Gtk.MenuItem.new_with_label(\"Help\")\n        menubar.append(help)\n        helpmenu = Gtk.Menu.new()\n        help.set_submenu(helpmenu)\n        contents = Gtk.MenuItem.new_with_label(\"Help\")\n        about = Gtk.MenuItem.new_with_label(\"About\")\n        helpmenu.append(contents)\n        helpmenu.append(about)\n\nclass Application(Gtk.Application):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Menu Bars\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/API/#notebook","title":"Notebook","text":"<p>Gtk.Notebook is a layout container that organizes content into tabbed pages. It is instantiated with the <code>new()</code> method and pages are appended with the <code>append_page()</code> method, passing content and label widgets as arguments.</p> <p>The tab bar can be placed using <code>set_tab_pos()</code>, passing a Gtk.PositionType enum</p> TopRightBottomLeft <pre><code>notebook = Gtk.Notebook.new()\n# notebook.set_tab_pos(Gtk.PositionType.TOP)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nnotebook.set_tab_pos(Gtk.PositionType.RIGHT)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nnotebook.set_tab_pos(Gtk.PositionType.BOTTOM)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nnotebook.set_tab_pos(Gtk.PositionType.LEFT)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nlabel = Gtk.Label.new(\"Tab title\")\nchild = Gtk.Label.new(\"Tab content\")\nnotebook.append_page(child, label)\n</code></pre> <p>The label widget is commonly Gtk.Label but can also be a Gtk.Box.</p> <p>The tab bar can be made scrollable using <code>set_scrollable()</code>, passing a bool.</p>"},{"location":"GTK/API/#scale","title":"Scale","text":"<p>Gtk.Scale widgets are sliders, and they can be instantiated in one of two ways:</p> <ul> <li><code>new()</code> passing an Adjustment object</li> <li><code>new_with_range(min, max, step)</code> passing values for minimum, maximum, and step</li> </ul> <p>Scale values are stored as doubles, so integers have to be simulated by reducing the number of digits to 0 using <code>set_digits()</code>. By default, the number of digits is set to that of the step value.</p>"},{"location":"GTK/API/#scrolledwindow","title":"ScrolledWindow","text":"<p>Gtk.ScrolledWindow is a decorator container that accepts a single child widget. Widgets that implement the Gtk.Scrollable interface have native scrolling suppport, like Gtk.TreeView, Gtk.TextView, and Gtk.Layout. Other widgets have to use Gtk.Viewport as an adaptor, and must be added to a Viewport which is then added to the ScrolledWindow.</p> <p>It is instantiated with the <code>new()</code> method, optionally passing two Adjustment objects that affect horizontal and vertical scrolling behavior when stepping or paging. <pre><code>scrolled_win = Gtk.ScrolledWindow.new(None,None)\n</code></pre></p>"},{"location":"GTK/API/#statusbar","title":"Statusbar","text":"Gtk.Statusbar (note the lowercase b ) stores a stack of messages, the topmost of which is displayed. Before adding messages, a context identifier, a unique unsigned integer associated with a context description string, must be retrieved from the newly created Statusbar by passing a string value to <code>get_context_id()</code>.  This allows messages to be categorized and pushed to separate stacks. <pre><code>statusbar.push(context_id, message)\n</code></pre>"},{"location":"GTK/API/#switch","title":"Switch","text":"<p>Gtk.Switch allows a user to toggle a boolean value. Switch exposes getters and setters for both state (which is represented by the trough color) and active (switch position) properties. State is the backend to activ, and they are kept in sync.</p> <pre><code>import gi\n\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_border_width(10)\n\n        box_outer = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=6)\n        listbox = Gtk.ListBox(selection_mode=Gtk.SelectionMode.NONE)\n        row = Gtk.ListBoxRow()\n        hbox = Gtk.Box(orientation=Gtk.Orientation.HORIZONTAL, spacing=50)\n        label1 = Gtk.Label(label=\"Automatic Date &amp; Time\", xalign=0)\n\n        hbox.add(label1)\n        self.switch = Gtk.Switch(valign=Gtk.Align.CENTER, state=False)\n        hbox.add(self.switch)\n        row.add(hbox)\n        listbox.add(row)\n        box_outer.add(listbox)\n        self.add(box_outer)\n        button = Gtk.Button(label=\"Click\")\n        button.connect(\"clicked\", self.on_button_clicked)\n        box_outer.add(button)\n\n    def on_button_clicked(self, button):\n        print(f\"Value of get_active(): {self.switch.get_active()}\")\n        print(f\"Value of get_state(): {self.switch.get_state()}\")\n\n\nclass Application(Gtk.Application):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window=ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/API/#treeview","title":"TreeView","text":"<p>In order to create a tree or list in GTK, the Gtk.TreeView widget is paired with a Gtk.TreeModel interface, the most typical implementation of which is Gtk.ListStore or Gtk.TreeStore. TreeView is a complicated widget that must be constructed procedurally:</p> <ol> <li>Gtk.TreeView is instantiated. A ListStore is specified as data model and passed in as the value of the model kwarg. The ListStore specifies the schema of the data as a collection of types. <pre><code>treeview = Gtk.TreeView(model=Gtk.ListStore.new((str)))\n</code></pre> Alternatively, the ListStore can be specified after instantiation. <pre><code>treeview = Gtk.TreeView.new()\ntreeview.set_model(Gtk.ListStore.new([str]))\n</code></pre></li> <li>A Gtk.TreeViewColumn is created for every column in the model. These require a Gtk.CellRenderer to be defined. The TreeViewColumn is added to the treeview by calling the <code>append_column()</code> method on the treeview. The text kwarg appears to refer to the column of the data store to use for the column's values. <pre><code>treeview.append_column(Gtk.TreeViewColumn(\"Greeks\", Gtk.CellRendererText.new(), text=0))\n</code></pre></li> <li>Items are added to the ListStore procedurally using the <code>append()</code> method. Note that the method takes only a single argument, so collections like lists or tuples must be used. <pre><code>liststore.append((\"Socrates\",))\nliststore.append((\"Plato\",))\nliststore.append((\"Aristotle\",))\n</code></pre></li> </ol> <p>Changing the number of columns affects the types used to define the ListStore, the appended records, as well as the number of columns added to the TreeView itself.</p> 1 column2 columns <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.gen_treeview()\n\n        scrolled_win = Gtk.ScrolledWindow.new(None,None)\n        scrolled_win.set_policy(Gtk.PolicyType.AUTOMATIC, Gtk.PolicyType.AUTOMATIC)\n        scrolled_win.add(self.treeview)\n\n        self.add(scrolled_win)\n        self.set_size_request(200,200)\n\n    def get_liststore(self):\n        store = Gtk.ListStore.new((str,))\n        store.append((\"Socrates\",))\n        store.append((\"Plato\",))\n        store.append((\"Aristotle\",))\n        return store\n\n    def gen_treeview(self):\n        self.treeview = Gtk.TreeView.new()\n        self.treeview.set_model(self.get_liststore())\n        self.treeview.append_column(Gtk.TreeViewColumn(\"Greeks\", Gtk.CellRendererText.new(), text=0))\n\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, title=\"Greeks\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.gen_treeview()\n\n        scrolled_win = Gtk.ScrolledWindow.new(None,None)\n        scrolled_win.set_policy(Gtk.PolicyType.AUTOMATIC, Gtk.PolicyType.AUTOMATIC)\n        scrolled_win.add(self.treeview)\n\n        self.add(scrolled_win)\n        self.set_size_request(200,200)\n\n    def get_liststore(self):\nstore = Gtk.ListStore.new((str, str))\nstore.append([\"Socrates\", \"Athens\"])\nstore.append([\"Plato\", \"Athens\"])\nstore.append([\"Aristotle\", \"Athens\"])\nreturn store\n\n    def gen_treeview(self):\n        self.treeview = Gtk.TreeView.new()\n        self.treeview.set_model(self.get_liststore())\n        self.treeview.append_column(Gtk.TreeViewColumn(\"Greeks\", Gtk.CellRendererText.new(), text=0))\nself.treeview.append_column(Gtk.TreeViewColumn(\"Place of birth\", Gtk.CellRendererText.new(), text=1))\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, title=\"Greeks\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <p>The model backing a TreeView (usually a ListStore), can be retrieved with the <code>get_model()</code> method. <pre><code>treeview.get_model().append(('foo','bar'))\n</code></pre></p> <p>TreeView emits several signals:</p> <ul> <li><code>row_activated</code> when a row is double-clicked, with the following implicit argument<ul> <li><code>widget</code> refering to the emitting TreeView widget itself</li> <li><code>path</code> is a TreePath. </li> <li><code>column</code> is of type TreeViewcolumn <pre><code>treeview.connect(\"row_activated\", self.on_row_activated, widget, path, column)\n</code></pre> <pre><code>def on_row_activated(self, widget, path, column):\n    row = path.get_indices()[0]\n    print(f\"row={path.get_indices()[0]},col={column.props.title}\")\n    print(widget.get_model()[row][:])\n</code></pre></li> </ul> </li> </ul>"},{"location":"GTK/API/#treepath","title":"TreePath","text":"<p>Gtk.TreePath is a type used to implement the rows of a TreeView. Although it prints to an integer with the print statement, it cannot be treated as one.</p> <p>A path object can be passed as the index to a TreeModel like ListStore, as can an integer. The row number of a TreePath from a normal list-style TreeView can be retrieved with the <code>get_indices()</code> method.</p> <pre><code>row = path.get_indices()[0]\n\n# Using TreePath object as index to model\nmodel[path][:]\n\n# Using row integer as index to model\nmodel[row][:]\n</code></pre> <p>Another method on TreePath, <code>get_depth()</code> always returns 1 for list-style TreeViews, but may be more useful for tree-style TreeViews.</p>"},{"location":"GTK/API/#treeselection","title":"TreeSelection","text":"Gtk.TreeSelection objects represent selection information for each tree view."},{"location":"GTK/API/#treeviewcolumn_1","title":"TreeViewColumn","text":"Gtk.TreeViewColumn represents a visible column in a Treeview. Its props property exposes many associated values, including title. <pre><code>print(column.props.title)\n</code></pre> A column is made sortable by calling <code>set_sort_column_id()</code>, passing the column of the model to sort by. <pre><code>column.set_sort_column_id(0)\n</code></pre>"},{"location":"GTK/API/#window","title":"Window","text":"Gtk.Window"},{"location":"GTK/Glade/","title":"Glade","text":"<p>The application will not close correctly without explicitly binding the destroy signal. This is because signal handlers specified in the markup must be mapped to actual methods in the code.  This is done with the <code>connect_signals()</code> method, which can be used in two different ways depending on the object passed:</p> <ul> <li>Class that implements the named methods exactly</li> <li>Dictionary that maps handler values from markup to function names</li> </ul> Handler objectDictionary <pre><code>class Handlers():\n    def on_window_destroy(self):\n        Gtk.main_quit()\n\nbuilder.connect_signals(Handlers())\n</code></pre> <pre><code>handlers = {\n    \"on_window_destroy\": Gtk.main_quit\n}\n\nbuilder.connect_signals(handlers)\n</code></pre> <pre><code>import gi\ngi.require_version(\"Gtk\",\"3.0\")\nfrom gi.repository import Gtk\nimport sys\n\n\nclass Application(Gtk.Application):\n    def __init__(self, *args, name = \"World\", **kwargs):\n        self.name = name\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n\n    def do_activate(self):\n        builder = Gtk.Builder.new_from_file('hwp.glade')\n        self.window = builder.get_object('window')\n        self.window.connect(\"destroy\",Gtk.main_quit)\n        self.window.set_title(f'Hello, {self.name}!')\n        label = builder.get_object('label')\n        label.set_text(f'Hello, {self.name}!')\n        self.window.show_all()\n        self.window.present()\n\n    def run(self):\n        super().run()\n        Gtk.main()\n\nif __name__ == '__main__':\n    app = Application(name=sys.argv[-1])\n    app.run()\n</code></pre>"},{"location":"GTK/Glade/#hello-world-interactive","title":"Hello, World! (interactive)","text":"<p>All of the examples in this task extend the following application markup and differ exclusively in the implementation of the <code>on_button_clicked()</code> signal handler.</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!-- Generated with glade 3.38.2 --&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.4\"/&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;property name=\"width-request\"&gt;200&lt;/property&gt;\n&lt;property name=\"height-request\"&gt;200&lt;/property&gt;\n&lt;property name=\"can-focus\"&gt;False&lt;/property&gt;\n&lt;signal name=\"destroy\" handler=\"on_window_destroy\" swapped=\"no\"/&gt;\n&lt;child&gt;\n&lt;object class=\"GtkBox\"&gt;\n&lt;property name=\"can-focus\"&gt;False&lt;/property&gt;\n&lt;property name=\"orientation\"&gt;vertical&lt;/property&gt;\n&lt;child&gt;\n&lt;object class=\"GtkEntry\" id=\"entry\"&gt;\n&lt;property name=\"can-focus\"&gt;True&lt;/property&gt;\n&lt;property name=\"show-emoji-icon\"&gt;True&lt;/property&gt;\n&lt;/object&gt;\n&lt;packing&gt;\n&lt;property name=\"expand\"&gt;False&lt;/property&gt;\n&lt;property name=\"fill\"&gt;True&lt;/property&gt;\n&lt;property name=\"position\"&gt;0&lt;/property&gt;\n&lt;/packing&gt;\n&lt;/child&gt;\n&lt;child&gt;\n&lt;object class=\"GtkButton\" id=\"button\"&gt;\n&lt;property name=\"label\"&gt;Greet&lt;/property&gt;\n&lt;property name=\"can-focus\"&gt;True&lt;/property&gt;\n&lt;property name=\"receives-default\"&gt;False&lt;/property&gt;\n&lt;signal name=\"clicked\" handler=\"on_button_clicked\" swapped=\"no\"/&gt;\n&lt;/object&gt;\n&lt;packing&gt;\n&lt;property name=\"expand\"&gt;False&lt;/property&gt;\n&lt;property name=\"fill\"&gt;True&lt;/property&gt;\n&lt;property name=\"position\"&gt;1&lt;/property&gt;\n&lt;/packing&gt;\n&lt;/child&gt;\n&lt;child&gt;\n&lt;object class=\"GtkLabel\" id=\"label\"&gt;\n&lt;property name=\"can-focus\"&gt;False&lt;/property&gt;\n&lt;/object&gt;\n&lt;packing&gt;\n&lt;property name=\"expand\"&gt;True&lt;/property&gt;\n&lt;property name=\"fill\"&gt;True&lt;/property&gt;\n&lt;property name=\"position\"&gt;2&lt;/property&gt;\n&lt;/packing&gt;\n&lt;/child&gt;\n&lt;/object&gt;\n&lt;/child&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre> <code>Label</code><code>MessageDialog</code> <p></p> <pre><code>import gi\ngi.require_version(\"Gtk\",\"3.0\")\nfrom gi.repository import Gtk\nimport sys\n\n\nclass Application(Gtk.Application):\n    def __init__(self, name = \"World\", *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.name = name\n\n    def do_activate(self):\n        self.builder = Gtk.Builder.new_from_file('hwi.glade')\n        self.window = self.builder.get_object('window')\n        self.window.set_title(f\"Hello, {self.name}!\")\n        self.builder.connect_signals(self)\n\n        self.entry = self.builder.get_object('entry')\n        self.entry.set_text(self.name)\n\n        self.label = self.builder.get_object('label')\n\n        self.window.show_all()\n        self.window.present()\n\ndef on_button_clicked(self, button):\nself.label.set_text(f'Hello, {self.entry.get_text()}!')\nself.window.set_title(f'Hello, {self.entry.get_text()}!')\ndef on_window_destroy(self, arg):\n        Gtk.main_quit()\n\n    def run(self):\n        super().run()\n        Gtk.main()\n\nif __name__ == '__main__':\n    try:\n        app = Application(sys.argv[1])\n    except IndexError:\n        app = Application()\n    app.run()\n</code></pre> <p></p> <pre><code>import gi\ngi.require_version(\"Gtk\",\"3.0\")\nfrom gi.repository import Gtk\nimport sys\n\n\nclass Application(Gtk.Application):\n    def __init__(self, name = \"World\", *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.name = name\n\n    def do_activate(self):\n        self.builder = Gtk.Builder.new_from_file('hwi.glade')\n        self.window = self.builder.get_object('window')\n        self.window.set_title(f\"Hello, {self.name}!\")\n        self.builder.connect_signals(self)\n\n        self.entry = self.builder.get_object('entry')\n        self.entry.set_text(self.name)\n\n        self.label = self.builder.get_object('label')\n\n        self.window.show_all()\n        self.window.present()\n\ndef on_button_clicked(self, button):\ndialog = Gtk.MessageDialog(\nmessage_type=Gtk.MessageType.INFO,\ntext=f\"Hello, {self.entry.get_text()}\",\nparent=self.window,\n)\ndialog.add_button(\"O_K\", Gtk.ResponseType.OK)\ndialog.run()\ndialog.destroy()\ndef on_window_destroy(self, arg):\n        Gtk.main_quit()\n\n    def run(self):\n        super().run()\n        Gtk.main()\n\nif __name__ == '__main__':\n    try:\n        app = Application(sys.argv[1])\n    except IndexError:\n        app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Glade/#menu","title":"Menu","text":"<p>GTK objects are declared using either special predefined elements (e.g. menu) or an object element with the class name itself specified in the class attribute. These syntaxes do not appear to be entirely interchangeable.</p> Predefined element<code>object</code> element <pre><code>&lt;menu id=\"app-menu\"&gt;\n</code></pre> <pre><code>&lt;object class=\"GtkMenu\" id=\"app-menu\"&gt;\n</code></pre> <p>Here, each  menu item is described by one of three attribute, identifiable in the attribute XML tags:</p> <ul> <li><code>action</code> which names an action and class to handle the signal</li> <li><code>target</code> specifies the string that displays in the menu item</li> <li><code>label</code> whether or not the target attribute string should be translated</li> </ul> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;menu id=\"app-menu\"&gt;\n&lt;section&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;\nChange label\n      &lt;/attribute&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;win.change_label&lt;/attribute&gt;\n&lt;attribute name=\"target\"&gt;String 1&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;String 1&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;win.change_label&lt;/attribute&gt;\n&lt;attribute name=\"target\"&gt;String 2&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;String 2&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;/section&gt;\n&lt;/menu&gt;\n&lt;/interface&gt;\n</code></pre>"},{"location":"GTK/Glade/#examples","title":"Examples","text":"Hello, World!Basic example <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!-- Generated with glade 3.38.2 --&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.24\"/&gt;\n&lt;object class=\"GtkApplicationWindow\"&gt;\n&lt;property name=\"can-focus\"&gt;False&lt;/property&gt;\n&lt;child&gt;\n&lt;object class=\"GtkLabel\"&gt;\n&lt;property name=\"visible\"&gt;True&lt;/property&gt;\n&lt;property name=\"can-focus\"&gt;False&lt;/property&gt;\n&lt;property name=\"label\" translatable=\"yes\"&gt;Hello, World!&lt;/property&gt;\n&lt;/object&gt;\n&lt;/child&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;menu id=\"app-menu\"&gt;\n&lt;section&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;Change label&lt;/attribute&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;win.change_label&lt;/attribute&gt;\n&lt;attribute name=\"target\"&gt;String 1&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;String 1&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;win.change_label&lt;/attribute&gt;\n&lt;attribute name=\"target\"&gt;String 2&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;String 2&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;win.change_label&lt;/attribute&gt;\n&lt;attribute name=\"target\"&gt;String 3&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;String 3&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;/section&gt;\n&lt;section&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;win.maximize&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;Maximize&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;/section&gt;\n&lt;section&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;app.about&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;_About&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;item&gt;\n&lt;attribute name=\"action\"&gt;app.quit&lt;/attribute&gt;\n&lt;attribute name=\"label\" translatable=\"yes\"&gt;_Quit&lt;/attribute&gt;\n&lt;attribute name=\"accel\"&gt;&amp;lt;Primary&amp;gt;q&lt;/attribute&gt;\n&lt;/item&gt;\n&lt;/section&gt;\n&lt;/menu&gt;\n&lt;/interface&gt;\n</code></pre>"},{"location":"GTK/Glossary/","title":"\ud83d\udcd8 Glossary","text":"Action <p>Actions have prefixes that determine where they are sent for processing:</p> <ul> <li>Window-specific actions are specified with <code>win.</code> (i.e. <code>win.change_label</code>), which specifies that ApplicationWindow processes the signal.</li> <li>Application-wide actions are prefixed with <code>app.</code></li> </ul> <p>Create new actions with <code>Gio.SimpleAction</code></p> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gio\n\n# --snip--\n\nquit_action = Gio.SimpleAction.new(\"quit\", None)\nquit_action.connect(\"activate\", self.on_quit)\n</code></pre> <ul> <li>activate</li> <li>open</li> </ul> Callback Event handler for GTK signals Container <ul> <li>Decorator containers derive from Gtk.Bin and can hold only a single child, like ApplicationWindow, and are so called because they add functionality to the child widget.</li> <li>Layout containers derive directly from Gtk.Container and are used to arrange multiple child widgets.</li> </ul>"},{"location":"GTK/Glossary/#glib","title":"GLib","text":"<p>GLib is a bundle of three low-level system libraries written in C:</p> <ul> <li>GLib</li> <li>GObject</li> <li>GIO</li> </ul> <p>It originated in the GTK+ project but was abstracted away before the release of GTK+ version 2.</p>"},{"location":"GTK/Glossary/#gobject","title":"GObject","text":"GObject (GLib Object System) is a library written in C that provides an object-oriented API. Prior to being abstracted into its own library, the object system formed part of the GTK+ codebase. Pop-up menu Context menu Signal <p>A signal is a notification to the application that the user has performed an action.</p> <p>A signal must be connected to a callback method so that when the signal is emitted the method is executed. It is possible to connect signals at any point in applications, but it is considered good form to initialize callbacks before calling <code>gtk_main()</code> or <code>present()</code>.</p> <p>Signals in GTK are similar to events in other GUI frameworks, although the term \"events\" is also used in GTK to refer to special signals emitted by the X Windows System. GTK event handlers are methods that begin with <code>do_</code>, i.e. <code>do_startup</code>.</p> <ul> <li><code>handle-local-options</code></li> </ul>"},{"location":"GTK/Examples/GNOME-Tweaks/","title":"GNOME Tweaks","text":"<p>GnomeTweaks is the application class and is defined in gtweak/app.py.</p> <p>Window is the window class, and its constructor takes the application and liststore subclass instances as arguments.</p> <p><pre><code>class GnomeTweaks(Gtk.Application):\n    def do_activate(self):\n        if not self.win:\n            model = TweakModel()\n            self.win = Window(self, model)\n            self.win.show_all()\n        self.win.present()\n</code></pre> TweakModel inherits from Gtk.ListStore and stores tweak groups which correspond to the pages of settings in the app. These tweak groups are defined as classes in Python modules placed in gtweak/tweaks, each of them subclassing parent classes like GSettingsSwitchTweak and GetterSetterSwitchTweak, which are defined in gtweak/widgets.py.</p> <p>Each of the tweak group modules defines a top-level list named <code>TWEAK_GROUPS</code> with only a single element - an instance of ListBoxTweakGroup, which is also defined in widgets.py. ListBoxTweakGroup, in turn, is a subclass of Gtk.ListBox and TweakGroup (tweakmodel.py) by multiple inheritance.</p> <p>Some <code>TWEAK_GROUP</code>s like that of the Desktop group are only populated conditionally.</p> DesktopGeneral <pre><code>from gtweak.widgets import ListBoxTweakGroup, GSettingsSwitchTweak, Title\n\ndicons = GSettingsSwitchTweak(_(\"Show Icons\"),\"org.gnome.desktop.background\",\"show-desktop-icons\")\nhome = GSettingsSwitchTweak(_(\"Home\"),\"org.gnome.nautilus.desktop\",\n                            \"home-icon-visible\", depends_on=dicons,\n                            schema_filename=\"org.gnome.nautilus.gschema.xml\")\n\nTWEAK_GROUPS = []\n\nif home.loaded:\n    TWEAK_GROUPS.append(ListBoxTweakGroup(_(\"Desktop\"),\n        Title(_(\"Icons on Desktop\"), \"\", uid=\"title-theme\", top=True),\n        dicons,\n        home,\n        GSettingsSwitchTweak(_(\"Network Servers\"),\"org.gnome.nautilus.desktop\", \"network-icon-visible\", depends_on=dicons, schema_filename=\"org.gnome.nautilus.gschema.xml\"),\n        GSettingsSwitchTweak(_(\"Trash\"),\"org.gnome.nautilus.desktop\", \"trash-icon-visible\", depends_on=dicons, schema_filename=\"org.gnome.nautilus.gschema.xml\"),\n        GSettingsSwitchTweak(_(\"Mounted Volumes\"),\"org.gnome.nautilus.desktop\", \"volumes-visible\", depends_on=dicons, schema_filename=\"org.gnome.nautilus.gschema.xml\"),\n    ))\n</code></pre> <pre><code>TWEAK_GROUPS = [\n    ListBoxTweakGroup(_(\"General\"),\n        GSettingsSwitchTweak(_(\"Animations\"), \"org.gnome.desktop.interface\", \"enable-animations\"),\n        IgnoreLidSwitchTweak(),\n        # Don't show this setting in the Ubuntu session since this setting is in gnome-control-center there\n        GSettingsSwitchTweak(_(\"Over-Amplification\"), \"org.gnome.desktop.sound\", \"allow-volume-above-100-percent\",\n            desc=_(\"Allows raising the volume above 100%. This can result in a loss of audio quality; it is better to increase application volume settings, if possible.\"), loaded=_shell_not_ubuntu),\n    ),\n]\n</code></pre> <p>ListBoxTweakGroup is instantiated with a series of arguments, starting with its name and followed by individual tweaks or settings. These tweaks are also defined as classes in gtweak/widgets.py, although some like IgnoreLidSwitchTweak are defined inline with the <code>TWEAK_GROUP</code> lists where they are instantiated. I'm still not sure what the <code>_()</code> means, but it is apparently some function call.</p> <p>All tweaks share some features:</p> <ul> <li>Their names reflect the control used in their interface (\"Switch\", \"SpinButton\", \"ComboEnum\", etc) in the form \"GSettings...Tweak</li> <li>They subclass Gtk.Box, _GSettingsTweak, and _DependableMixin by multiple inheritance</li> <li>They instantiate a horizontally oriented Gtk.Box with a curious syntax. <pre><code>Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n</code></pre></li> <li>They instantiate _GSettingsTweak with a similar syntax <pre><code>_GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n</code></pre></li> <li>The rest of the widget is defined procedurally and added to self in the constructor as normal</li> </ul> <p>By far the most common tweak is GSettingsSwitchTweakValue.</p> GSettingsSwitchTweakGSettingsSwitchTweakValueGSettingsFontButtonTweakGSettingsRangeTweakGSettingsSpinButtonTweakGSettingsComboEnumTweakGSettingsComboTweak <pre><code>class GSettingsSwitchTweak(Gtk.Box, _GSettingsTweak, _DependableMixin):\n    def __init__(self, name, schema_name, key_name, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        _GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n\n        w = Gtk.Switch()\n        self.settings.bind(key_name, w, \"active\", Gio.SettingsBindFlags.DEFAULT)\n\n        self.add_dependency_on_tweak(\n                options.get(\"depends_on\"),\n                options.get(\"depends_how\")\n        )\n\n        vbox1 = Gtk.Box(orientation=Gtk.Orientation.VERTICAL)\n        vbox1.props.spacing = UI_BOX_SPACING\n        lbl = Gtk.Label(label=name)\n        lbl.props.ellipsize = Pango.EllipsizeMode.END\n        lbl.props.xalign = 0.0\n        vbox1.pack_start(lbl, True, True, 0)\n\n        if options.get(\"desc\"):\n            description = options.get(\"desc\")\n            lbl_desc = Gtk.Label()\n            lbl_desc.props.xalign = 0.0\n            lbl_desc.set_line_wrap(True)\n            lbl_desc.get_style_context().add_class(\"dim-label\")\n            lbl_desc.set_markup(\"&lt;span size='small'&gt;\"+GLib.markup_escape_text(description)+\"&lt;/span&gt;\")\n            vbox1.pack_start(lbl_desc, True, True, 0)\n\n        vbox2 = Gtk.Box(orientation=Gtk.Orientation.VERTICAL)\n        vbox2_upper = Gtk.Box()\n        vbox2_lower = Gtk.Box()\n        vbox2.pack_start(vbox2_upper, True, True, 0)\n        vbox2.pack_start(w, False, False, 0)\n        vbox2.pack_start(vbox2_lower, True, True, 0)\n\n        self.pack_start(vbox1, True, True, 0)\n        self.pack_start(vbox2, False, False, 0)\n        self.widget_for_size_group = None\n</code></pre> <pre><code>class GSettingsSwitchTweakValue(Gtk.Box, _GSettingsTweak):\n\n    def __init__(self, name, schema_name, key_name, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        _GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n\n        sw = Gtk.Switch()\n        sw.set_active(self.get_active())\n        sw.connect(\"notify::active\", self._on_toggled)\n\n        vbox1 = Gtk.Box(orientation=Gtk.Orientation.VERTICAL)\n        vbox1.props.spacing = UI_BOX_SPACING\n        lbl = Gtk.Label(label=name)\n        lbl.props.ellipsize = Pango.EllipsizeMode.END\n        lbl.props.xalign = 0.0\n        vbox1.pack_start(lbl, True, True, 0)\n\n        if options.get(\"desc\"):\n            description = options.get(\"desc\")\n            lbl_desc = Gtk.Label()\n            lbl_desc.props.xalign = 0.0\n            lbl_desc.set_line_wrap(True)\n            lbl_desc.get_style_context().add_class(\"dim-label\")\n            lbl_desc.set_markup(\"&lt;span size='small'&gt;\"+GLib.markup_escape_text(description)+\"&lt;/span&gt;\")\n            vbox1.pack_start(lbl_desc, True, True, 0)\n\n        vbox2 = Gtk.Box(orientation=Gtk.Orientation.VERTICAL)\n        vbox2_upper = Gtk.Box()\n        vbox2_lower = Gtk.Box()\n        vbox2.pack_start(vbox2_upper, True, True, 0)\n        vbox2.pack_start(sw, False, False, 0)\n        vbox2.pack_start(vbox2_lower, True, True, 0)\n\n        self.pack_start(vbox1, True, True, 0)\n        self.pack_start(vbox2, False, False, 0)\n        self.widget_for_size_group = None\n\n    def _on_toggled(self, sw, pspec):\n        self.set_active(sw.get_active())\n\n    def set_active(self, v):\n        raise NotImplementedError()\n\n    def get_active(self):\n        raise NotImplementedError()\n</code></pre> <pre><code>class GSettingsFontButtonTweak(Gtk.Box, _GSettingsTweak, _DependableMixin):\n    def __init__(self, name, schema_name, key_name, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        _GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n\n        w = Gtk.FontButton()\n        w.set_use_font(True)\n        self.settings.bind(key_name, w, \"font-name\", Gio.SettingsBindFlags.DEFAULT)\n        build_label_beside_widget(name, w, hbox=self)\n        self.widget_for_size_group = w\n</code></pre> <pre><code>class GSettingsRangeTweak(Gtk.Box, _GSettingsTweak, _DependableMixin):\n    def __init__(self, name, schema_name, key_name, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        _GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n\n        # returned variant is range:(min, max)\n        _min, _max = self.settings.get_range(key_name)[1]\n\n        w = Gtk.HScale.new_with_range(_min, _max, options.get('adjustment_step', 1))\n        self.settings.bind(key_name, w.get_adjustment(), \"value\", Gio.SettingsBindFlags.DEFAULT)\n\n        build_label_beside_widget(self.name, w, hbox=self)\n        self.widget_for_size_group = w\n</code></pre> <pre><code>class GSettingsSpinButtonTweak(Gtk.Box, _GSettingsTweak, _DependableMixin):\n    def __init__(self, name, schema_name, key_name, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        _GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n\n        # returned variant is range:(min, max)\n        _min, _max = self.settings.get_range(key_name)[1]\n\n        adjustment = Gtk.Adjustment(value=0, lower=_min, upper=_max, step_increment=options.get('adjustment_step', 1))\n        w = Gtk.SpinButton()\n        w.set_adjustment(adjustment)\n        w.set_digits(options.get('digits', 0))\n        self.settings.bind(key_name, adjustment, \"value\", Gio.SettingsBindFlags.DEFAULT)\n\n        build_label_beside_widget(name, w, hbox=self)\n        self.widget_for_size_group = w\n\n        self.add_dependency_on_tweak(\n                options.get(\"depends_on\"),\n                options.get(\"depends_how\")\n        )\n</code></pre> <pre><code>class GSettingsComboEnumTweak(Gtk.Box, _GSettingsTweak, _DependableMixin):\n    def __init__(self, name, schema_name, key_name, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        _GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n\n        _type, values = self.settings.get_range(key_name)\n        value = self.settings.get_string(key_name)\n        self.settings.connect('changed::'+self.key_name, self._on_setting_changed)\n\n        w = build_combo_box_text(value, *[(v, v.replace(\"-\", \" \").title()) for v in values])\n        w.connect('changed', self._on_combo_changed)\n        self.combo = w\n\n        build_label_beside_widget(name, w, hbox=self)\n        self.widget_for_size_group = w\n\n    def _values_are_different(self):\n        # to stop bouncing back and forth between changed signals. I suspect there must be a nicer\n        # Gio.settings_bind way to fix this\n        return self.settings.get_string(self.key_name) != \\\n            self.combo.get_model().get_value(self.combo.get_active_iter(), 0)\n\n    def _on_setting_changed(self, setting, key):\n        assert key == self.key_name\n        val = self.settings.get_string(key)\n        model = self.combo.get_model()\n        for row in model:\n            if val == row[0]:\n                self.combo.set_active_iter(row.iter)\n                break\n\n    def _on_combo_changed(self, combo):\n        val = self.combo.get_model().get_value(self.combo.get_active_iter(), 0)\n        if self._values_are_different():\n            self.settings.set_string(self.key_name, val)\n</code></pre> <pre><code>class GSettingsComboTweak(Gtk.Box, _GSettingsTweak, _DependableMixin):\n    def __init__(self, name, schema_name, key_name, key_options, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        _GSettingsTweak.__init__(self, name, schema_name, key_name, **options)\n\n        # check key_options is iterable\n        # and if supplied, check it is a list of 2-tuples\n        assert len(key_options) &gt;= 0\n        if len(key_options):\n            assert len(key_options[0]) == 2\n        self._key_options = key_options\n\n        self.combo = build_combo_box_text(\n                    self.settings.get_string(self.key_name),\n                    *key_options)\n        self.combo.connect('changed', self._on_combo_changed)\n        self.settings.connect('changed::'+self.key_name, self._on_setting_changed)\n\n        build_label_beside_widget(name, self.combo, hbox=self)\n        self.widget_for_size_group = self.combo\n\n    def _on_setting_changed(self, setting, key):\n        assert key == self.key_name\n        val = self.settings.get_string(key)\n        model = self.combo.get_model()\n        for row in model:\n            if val == row[0]:\n                self.combo.set_active_iter(row.iter)\n                return\n\n        self.combo.set_active(-1)\n\n    def _on_combo_changed(self, combo):\n        _iter = combo.get_active_iter()\n        if _iter:\n            value = combo.get_model().get_value(_iter, 0)\n            self.settings.set_string(self.key_name, value)\n\n    @property\n    def extra_info(self):\n        if self._extra_info is None:\n            self._extra_info = self.settings.schema_get_summary(self.key_name)\n            self._extra_info += \" \" + \" \".join(op[0] for op in self._key_options)\n        return self._extra_info\n</code></pre> <p>IgnoreLidSwitchTweak is unusual as a tweak that inherits from GetterSetterSwitchTweak, which inherits in turn from the Tweak base class that is actually in gtweak/tweakmodel.py</p> IgnoreLidSwitchTweakGetterSetterSwitchTweakTweak <pre><code>class IgnoreLidSwitchTweak(GetterSetterSwitchTweak):\n    def __init__(self, **options):\n        self._inhibitor_name = \"gnome-tweak-tool-lid-inhibitor\"\n        self._inhibitor_path = \"%s/%s\" % (gtweak.LIBEXEC_DIR, self._inhibitor_name)\n\n        self._dfile = AutostartFile(None,\n                                    autostart_desktop_filename = \"ignore-lid-switch-tweak.desktop\",\n                                    exec_cmd = self._inhibitor_path)\n\n        GetterSetterSwitchTweak.__init__(self, _(\"Suspend when laptop lid is closed\"), **options)\n\n    def get_active(self):\n        return not self._sync_inhibitor()\n\n    def set_active(self, v):\n        self._dfile.update_start_at_login(not v)\n        self._sync_inhibitor()\n\n    def _sync_inhibitor(self):\n        if (self._dfile.is_start_at_login_enabled()):\n            GLib.spawn_command_line_async(self._inhibitor_path)\n            return True\n        else:\n            bus = Gio.bus_get_sync(Gio.BusType.SESSION, None)\n            bus.call('org.gnome.tweak-tool.lid-inhibitor',\n                    '/org/gnome/tweak_tool/lid_inhibitor',\n                    'org.gtk.Actions',\n                    'Activate',\n                    GLib.Variant('(sava{sv})', ('quit', [], {})),\n                    None, 0, -1, None)\n            return False\n</code></pre> <pre><code>class GetterSetterSwitchTweak(Gtk.Box, Tweak):\n    def __init__(self, name, **options):\n        Gtk.Box.__init__(self, orientation=Gtk.Orientation.HORIZONTAL)\n        Tweak.__init__(self, name, options.get(\"description\", \"\"), **options)\n\n        sw = Gtk.Switch()\n        sw.set_active(self.get_active())\n        sw.connect(\"notify::active\", self._on_toggled)\n\n        build_label_beside_widget(name, sw, hbox=self)\n\n    def _on_toggled(self, sw, pspec):\n        self.set_active(sw.get_active())\n\n    def get_active(self):\n        raise NotImplementedError()\n\n    def set_active(self, v):\n        raise NotImplementedError()\n</code></pre> <pre><code>class Tweak(object):\n\n    main_window = None\n    widget_for_size_group = None\n    extra_info = \"\"\n\n    def __init__(self, name, description, **options):\n        self.name = name or \"\"\n        self.description = description or \"\"\n        self.uid = options.get(\"uid\", self.__class__.__name__)\n        self.group_name = options.get(\"group_name\", _(\"Miscellaneous\"))\n        self.loaded = options.get(\"loaded\", True)\n        self.widget_sort_hint = None\n\n        self._search_cache = None\n\n    def search_matches(self, txt):\n        if self._search_cache is None:\n            self._search_cache = string_for_search(self.name) + \" \" + \\\n                string_for_search(self.description)\n            try:\n                self._search_cache += \" \" + string_for_search(self.extra_info)\n            except:\n                LOG.warning(\"Error adding search info\", exc_info=True)\n        return txt in self._search_cache\n\n    def notify_logout(self):\n        self._logoutnotification = LogoutNotification()\n\n    def notify_information(self, summary, desc=\"\"):\n        self._notification = Notification(summary, desc)\n</code></pre>"},{"location":"GTK/Tasks/Boilerplate/","title":"Boilerplate","text":"Interface <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.40\"/&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;property name=\"title\"&gt;My GTK App&lt;/property&gt;\n&lt;property name=\"default-width\"&gt;300&lt;/property&gt;\n&lt;property name=\"default-height\"&gt;300&lt;/property&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre>  Rust Python gtk-rs<pre><code>use gtk4::prelude::*;\nuse gtk4::{Application, ApplicationWindow};\n\nfn main() {\nlet app = Application::builder()\n.application_id(\"com.example.learning-gtk\")\n.build();\n\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet window = ApplicationWindow::builder()\n.application(app)\n.default_width(300)\n.default_height(300)\n.title(\"My GTK App\")\n.build();\n\nwindow.present();\n}\n</code></pre> PyGTK<pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk  # (1)\n\nclass ApplicationWindow(Gtk.ApplicationWindow): # (2)\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs) # (3)\n        self.set_size_request(300,300)\n        self.set_title(\"My GTK App\")\n        self.show_all()\n        self.present()\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.learning-gtk') # (4)\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n\nif __name__ == '__main__':\n    app = Application() # (5)\n    app.run()\n    # (6)\n</code></pre> <ol> <li>Note that the gi module's <code>require_version()</code> function must be called before importing Gtk.</li> <li>The recommended way of using the PyGTK API is to subclass and modify the Application and ApplicationWindow classes. These were introduced in GTK+ versions 3.0 and 3.4 respectively and are meant to be used as base classes. PyGTK also offers an alternative Gtk.Window class, which like ApplicationWindow is a subclass of Gtk.Container, and which still appears in many tutorials.</li> <li>The ApplicationWindow subclass calls the superclass's constructor. The UI is composed by adding widgets to this subclass by calling <code>self.add()</code>. Typically a single Box container is added to the top-level container and controls are added to that container.</li> <li>The Application subclass also calls its superclass's constructor and exposes a <code>do_activate()</code> method that instantiates the ApplicationWindow subclass and assigns that object to <code>self.window</code> before calling <code>self.window.present()</code>. The Application subclass essentially acts as a wrapper around ApplicationWindow.</li> <li>At the script's entrypoint, the Application subclass itself is instantiated and its <code>run</code> method is called.</li> <li>In online tutorials that use Window, typically the Application wrapper class does not appear. The <code>Gtk.main()</code> method must be called somewhere in the script in order for the UI to appear.</li> </ol>"},{"location":"GTK/Tasks/Environment/","title":"Development environment","text":"Rust Python Red Hat<pre><code>dnf install gtk4-devel gcc\n</code></pre> Ubuntu<pre><code>apt install libgtk-4-dev build-essential\n</code></pre> Red Hat<pre><code>dnf install python3-venv python3-wheel\ndnf install gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl-devel tk-devel git python3-cairo-devel cairo-gobject-devel gobject-introspection-devel\npip install pygobject\n</code></pre> Ubuntu<pre><code>apt install python3-gi python3-gi-cairo gir1.2-gtk-3.0 libgirepository1.0-dev\npip install pygobject\n</code></pre>"},{"location":"GTK/Tasks/Hello-World/","title":"Hello, World!","text":""},{"location":"GTK/Tasks/Hello-World/#window-frame","title":"Window frame","text":"Rust Python <p>TODO</p> <p>At the moment, this example is broken because I don't know how to pass the string into the Application struct for string interpolation.</p> <pre><code>use gtk4::prelude::*;\nuse gtk4::{Application, ApplicationWindow};\n\nfn main() {\nlet name = String::new();\nif let Some(s) = 42std::env::args().nth(1) {\nname = s;\n} else {\nname = String::from(\"World\");\n};\n\nlet app = Application::builder()\n.application_id(\"com.example.learning-gtk\")\n.build();\napp.connect_activate(build_ui);\nprintln!(\"{}\", app.name);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet window = ApplicationWindow::builder()\n.application(app)\n.title(\"Hello, World!\")\n.default_height(300)\n.default_width(300)\n.build();\nwindow.present();\n}\n</code></pre> <pre><code>import sys\nimport gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, name, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_default_size(300,300)\n        self.set_title(f\"Hello, {name}!\")\n        self.show_all()\n\n\nclass Application(Gtk.Application):\n    def __init__(self, name):\n        super().__init__(application_id=\"com.example.learning-gtk\")\n        self.name = name\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, name=self.name)\n\n\nif __name__ == '__main__':\n    if len(sys.argv) &gt; 1:\n        app = Application(sys.argv[-1])\n    else:\n        app = Application(\"World\")\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Hello-World/#label","title":"Label","text":"Rust Python <pre><code>import gi\ngi.require_version(\"Gtk\",\"3.0\")\nfrom gi.repository import Gtk\nimport sys\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, name, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(200, 200)\nself.add(Gtk.Label(label=f\"Hello, {name}!\"))\nclass Application(Gtk.Application):\n    def __init__(self, name = \"World\", *args, **kwargs):\n        self.name = name\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, name, title = f\"Hello, {self.name}!\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Hello-World/#button-reveal","title":"Button reveal","text":"Interface <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.40\"&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;property name=\"title\"&gt;My GTK App&lt;/property&gt;\n&lt;property name=\"default-width\"&gt;300&lt;/property&gt;\n&lt;property name=\"default-height\"&gt;300&lt;/property&gt;\n&lt;child&gt;\n&lt;object class=\"GtkButton\" id=\"button\"&gt;\n&lt;property name=\"label\"&gt;Press me!&lt;/property&gt;\n&lt;property name=\"margin-top\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-bottom\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-start\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-end\"&gt;12&lt;/property&gt;  &lt;/object&gt;\n&lt;/child&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre>  Rust Python <pre><code>use gtk::prelude::*;\nuse gtk::{Application, ApplicationWindow, Button};\n\nfn main() {\nlet app = Application::builder()\n.application_id(\"org.gtk-rs.example\")\n.build();\n\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet builder = gtk::Builder::from_string(include_str!(\"window.ui\"));\nlet window: ApplicationWindow = builder\n.object(\"window\")\n.expect(\"Could not get object `window` from builder.\");\nlet button: Button = builder\n.object(\"button\")\n.expect(\"Could not get object `button` from builder.\");\n\nwindow.set_application(Some(app));\n\nbutton.connect_clicked(move |button| { // (1)\nbutton.set_label(\"Hello World!\");\n});\n\nwindow.set_child(Some(&amp;button));\nwindow.show_all();\nwindow.present();\n}\n</code></pre> <ol> <li>This <code>move</code> keyword appears to be unnecessary.</li> </ol> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        builder = Gtk.Builder.new_from_file('hw-button.ui')\n        self.window = builder.get_object('window')\n        self.button = builder.get_object('button')\n        self.button.connect('clicked', self.on_button_clicked)\n        self.window.connect('destroy', Gtk.main_quit)\n        self.window.show_all()\n        self.window.present()\n\n    def on_button_clicked(self, button):\n        self.button.set_label('Hello, World!')\n\n    def run(self):\n        super().run()\n        Gtk.main()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Hello-World/#interactive","title":"Interactive","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)\n        self.add(box)\n\n        question = Gtk.Label.new(\"What is your name?\")\n        box.add(question)\n\n        self.entry = Gtk.Entry(text=\"World\")\n        box.add(self.entry)\n\n        button = Gtk.Button.new_with_mnemonic(\"Greet\")\n        button.connect(\"clicked\", self.on_button_clicked, self)\n        box.add(button)\n\ndef on_button_clicked(self, button, parent):\ndialog = Gtk.MessageDialog(\nmessage_type=Gtk.MessageType.INFO,\ntext=f\"Hello, {parent.entry.get_text()}\",\nparent=parent,\n)\ndialog.add_button(\"OK\", Gtk.ResponseType.OK)\ndialog.run()\ndialog.destroy()\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Hello-World/#headerbar","title":"HeaderBar","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport sys\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_default_size(-1, -1)\n        # headerbar = Gtk.HeaderBar(title=f\"Hello, {name}!\", subtitle=\"HeaderBar example\", show_close_button=True)\nheaderbar = Gtk.HeaderBar()\nheaderbar.set_title(f\"Hello, World!\")\nheaderbar.set_subtitle(\"HeaderBar example\")\nheaderbar.set_show_close_button(True)\nself.set_titlebar(headerbar)\nbutton = Gtk.Button(label=\"Greet\")\n        button.connect(\"clicked\", self.on_button_clicked, self)\n        headerbar.add(button)\n\n        self.entry = Gtk.Entry(text=\"World\", name=\"entry\")\n        headerbar.add(self.entry)\n\n    def on_button_clicked(self, button, parent):\n        dialog = Gtk.MessageDialog(\n            message_type=Gtk.MessageType.INFO,\n            text=f\"Hello, {parent.entry.get_text()}!\",\n            parent=parent,\n        )\n        dialog.add_button(\"O_K\", Gtk.ResponseType.OK)\n        dialog.run()\n        dialog.destroy()\n\nclass HeaderBar(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id=\"org.example.headerbar\")\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = HeaderBar()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Image-Viewer/","title":"Image Viewer","text":"<pre><code>use gtk4::prelude::*;\nuse gtk4::{Application, ApplicationWindow, Box, Picture};\n\nfn main() {\nlet app = Application::builder()\n.application_id(\"org.gtk-rs.example\")\n.build();\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet img = Picture::for_filename(\"C:\\\\Users\\\\4472936\\\\Rust\\\\gtk\\\\pic.png\");\n\nlet container = Box::new( gtk::Orientation::Vertical,  12);\ncontainer.append(&amp;img);\n\nlet window = ApplicationWindow::builder()\n.application(app)\n.title(\"My GTK App\")\n.child(&amp;container)\n.build();\n\nwindow.present();\n}\n</code></pre>"},{"location":"GTK/Tasks/Starships/","title":"Starships","text":"<p>This task implements the list/details pattern.</p> <p></p>"},{"location":"GTK/Tasks/Starships/#hardcoded-data","title":"Hardcoded data","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        ships = ['USS Enterprise', 'USS Defiant', 'USS Voyager']\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,)))\n\n        column = Gtk.TreeViewColumn(\"Ship\", Gtk.CellRendererText(), text=0)\n        self.treeview.append_column(column)\n        for s in ships:\n            self.treeview.get_model().append((s,))\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Starships/#csv-import","title":"CSV import","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\nwith open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\nreader = csv.reader(f)\nself.headers = [h.title() for h in next(reader)]\nself.data = [r for r in reader]\nself.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n\nfor h in self.headers:\ncolumn = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\nself.treeview.append_column(column)\nfor r in self.data:\nself.treeview.get_model().append(r)\nself.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Starships/#sortable-columns","title":"Sortable columns","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        with open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\n            reader = csv.reader(f)\n            self.headers = [h.title() for h in next(reader)]\n            self.data = [r for r in reader]\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n        for h in self.headers:\n            column = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\ncolumn.set_sort_column_id(self.headers.index(h))\nself.treeview.append_column(column)\n\n        for r in self.data:\n            self.treeview.get_model().append(r)\n\n        self.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Starships/#event-handler","title":"Event handler","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        with open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\n            reader = csv.reader(f)\n            self.headers = [h.title() for h in next(reader)]\n            self.data = [r for r in reader]\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n        for h in self.headers:\n            column = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\n            column.set_sort_column_id(self.headers.index(h))\n            self.treeview.append_column(column)\n\n        for r in self.data:\n            self.treeview.get_model().append(r)\n\n        self.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\ndef on_row_activated(self, treeview, path, col):\nmodel = treeview.get_model()\nprint(f'Using path object as index to model: {model[path][:]}')\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Starships/#messagedialog","title":"MessageDialog","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        with open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\n            reader = csv.reader(f)\n            self.headers = [h.title() for h in next(reader)]\n            self.data = [r for r in reader]\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n        for h in self.headers:\n            column = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\n            column.set_sort_column_id(self.headers.index(h))\n            self.treeview.append_column(column)\n\n        for r in self.data:\n            self.treeview.get_model().append(r)\n\n        self.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\ndef on_row_activated(self, treeview, path, col):\nmodel = treeview.get_model()\ndialog = Gtk.MessageDialog(\nmessage_type=Gtk.MessageType.INFO,\ntext=model[path][:],\nparent = self\n)\ndialog.add_button(\"OK\", Gtk.ResponseType.OK)\ndialog.run()\ndialog.destroy()\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Starships/#dice-roller","title":"Dice roller","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport random\nfrom math import floor\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        scale_adj = Gtk.Adjustment.new(1, 0, 6, 1, 2, 0)\n        self.scale = Gtk.Scale.new(Gtk.Orientation.HORIZONTAL, scale_adj)\n        self.scale.set_digits(0)\n\n        button = Gtk.Button.new_with_label(\"Throw\")\n        button.connect(\"clicked\", self.on_button_clicked)\n        self.label = Gtk.Label.new()\n\n\n        box = Gtk.Box.new(Gtk.Orientation.VERTICAL,5)\n        box.pack_start(self.scale, False, True, 0)\n        box.pack_start(button, False, True, 0)\n        box.pack_start(self.label, False, True, 0)\n\n        self.add(box)\n        self.set_size_request(200,200)\n\n    def on_button_clicked(self, button):\n        dice = floor(self.scale.get_value())\n        results = [random.randrange(6) for i in range(dice)]\n        self.label.set_text(str(results))\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Starships/#menubar","title":"MenuBar","text":"Rust Python <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass AppWindow(Gtk.ApplicationWindow):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(250, -1)\n        menubar = Gtk.MenuBar.new()\n        self.add(menubar)\n\n        file = Gtk.MenuItem.new_with_label(\"File\")\n        menubar.append(file)\n        filemenu = Gtk.Menu.new()\n        file.set_submenu(filemenu)\n        new = Gtk.MenuItem.new_with_label(\"New\")\n        open = Gtk.MenuItem.new_with_label(\"Open\")\n        filemenu.append(new)\n        filemenu.append(open)\n\n        edit = Gtk.MenuItem.new_with_label(\"Edit\")\n        menubar.append(edit)\n        editmenu = Gtk.Menu.new()\n        edit.set_submenu(editmenu)\n        cut = Gtk.MenuItem.new_with_label(\"Cut\")\n        copy = Gtk.MenuItem.new_with_label(\"Copy\")\n        paste = Gtk.MenuItem.new_with_label(\"Paste\")\n        editmenu.append(cut)\n        editmenu.append(copy) \n        editmenu.append(paste)\n\n        help = Gtk.MenuItem.new_with_label(\"Help\")\n        menubar.append(help)\n        helpmenu = Gtk.Menu.new()\n        help.set_submenu(helpmenu)\n        contents = Gtk.MenuItem.new_with_label(\"Help\")\n        about = Gtk.MenuItem.new_with_label(\"About\")\n        helpmenu.append(contents)\n        helpmenu.append(about)\n\nclass Application(Gtk.Application):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Menu Bars\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"GTK/Tasks/Tasks/","title":"Tasks","text":""},{"location":"Health/","title":"\ud83d\udc8a Health","text":"Substance Effects Lowest cost Ashwagandha  &lt; 0.01 Alpha GPC  0.50 Bacopa Monnieri  0.10 Curcumin  0.13 D-aspartic acid  0.15 GABA  Kanna  0.40 L-Carnitine  0.08 L-Tyrosine  0.07 Lion's Mane  0.17 Quercetin  Resveratrol  0.12 Rhodiola  0.05 Rosemary  0.09 Taurine  Ubiquinol  0.11"},{"location":"Health/#todo","title":"\u2714\ufe0f\ufe0f TODO","text":"<ul> <li>Develop a dosage of adaptogens to use when sleep is disturbed.</li> <li>Incorporate notes and research from Reddit</li> </ul>"},{"location":"Health/#sale","title":"\ud83d\udcb8 Sale","text":"Product Discount"},{"location":"Health/#dietary-deficiencies","title":"\ud83e\udd57 Dietary deficiencies","text":"Substance Dosage (mg) Cheapest cost per dose Calcium  1,000 0.02 Magnesium  200 0.02 Potassium  2,000 0.01"},{"location":"Health/#nootropics","title":"\ud83e\udde0 Nootropics","text":"Supplement Dosage (g) Cost ($) Cost (sale) Alpha GPC  0.6 0.71 0.50 Bacopa  0.4 0.19 0.10 DMAE  0.8 0.23 0.23 Huperzine A  0.2 0.33 0.20 L-Theanine  0.2 0.30 0.22 L-Tyrosine  1.0 0.16 0.07 Lion's Mane  1.0 0.36 0.17 Kanna  0.5 0.80 0.40 Total 3.23 2.04 Gorilla Mind Smooth 2.93 <ul> <li>Alpha GPC</li> <li>Bacopa monnieri</li> <li>Curcumin</li> <li>DMAE</li> <li>Huperzine A</li> <li>L-Theanine</li> <li>L-Tyrosine</li> <li>Lions Mane</li> <li>Rhodiola</li> <li>Rosemary</li> <li>Saffron</li> <li>Vitamin B12</li> </ul>"},{"location":"Health/#antioxidants","title":"\ud83d\udc74 Antioxidants","text":"<p>In recent years, the mitochondrial free radical theory has emerged to explain the aging process.  In this theory, oxidative stress from free radicals, which many studies suggest cause a variety of health issues, cause mitochondrial dynsfunction and eventually aging.  Supplementation with antioxidants has been demonstrated to reduce these free radicals and improve health markers.</p> <p>Oxidative stress is a medical concept defined by the state of excess reactive oxygen species (ROS) and reactive nitrogen species (RNS).  These are endogenously produced but harmful to mitochondria because they react with lipids, proteins, and nucleic acids, progressively degrading cellular functions. or a reduction in antioxidants which detoxify them, resulting in generalized cellular damage. Oxidative stress figures prominently in the free radical theory of aging and has been linked to neurodegenerative diseases like Alzheimer's...</p> <p>Long-term effects on DNA from oxidative stress are similar to those caused by radiation exposure.</p> <p>Reactive oxygen species (ROS) include free radicals and peroxides that damage all components of the cell and can disrupt normal cellular signalling. These are produced by disturbances in the normal reduction-oxidation (redox) state of cells</p> <ul> <li>Alpha lipoic acid</li> <li>CoQ10</li> <li>Curcumin</li> <li>Resveratrol</li> <li>Vitamin C</li> <li>Vitamin D3</li> <li>Vitamin E</li> </ul>"},{"location":"Health/#hair-loss-prevention","title":"\ud83d\udc68\u200d\ud83e\uddb2 Hair loss prevention","text":"<ul> <li>Dutasteride</li> <li>Finasteride</li> <li>Minoxidil</li> </ul>"},{"location":"Health/#sleep-deprivation","title":"\ud83d\ude34 Sleep deprivation","text":"<ul> <li>In a double-blind placebo-controlled trial, 60 mg/kg bw of caffeine was enough to overcome the effects of 24 hours of sleep deprivation in a battery of anaerobic performance tests. (2018)</li> <li>Subjects given 5g of creatine four times a day for seven days experienced less of a decline in performance after 24 hours of sleep deprivation in a variety of cognitive performance measures. (2006 )</li> <li>After six weeks of administration with l-theanine (400 mg/day), boys diagnosed with ADHD experienced significantly improved sleep. (2011)</li> <li>Supplementation with magnesium (100 mg/day) was enough to eliminate the difference between the sleep-deprived arm and the control arm in subjects who were sleep-deprived for a month. (1998)</li> </ul>"},{"location":"Health/#bloodwork","title":"\ud83d\udc89 Bloodwork","text":"Recommended assay Hormone LC-MS-MS Total testosterone Equilibrium dialysis Free testosterone LC-MS-MS, estradiol sensitive Estradiol HPLC DHT Equilibrium dialysis Free DHT <ul> <li>For measuring total testosterone, LC-MS-MS is superior to ECLIA.</li> <li>For measuring free testosterone, equilibrium dialysis or equilibrium filtration is more accurate than EIA</li> <li>For measuring estradiol, LC-MS-MS is more sensitive than ECLIA</li> <li>For measuring DHT, high-pressure LC-MS-MS</li> </ul>"},{"location":"Health/#glossary","title":"Glossary \ud83d\udcd5","text":""},{"location":"Health/#acetylcholine","title":"Acetylcholine","text":"Acetylcholine (ACh) is an important neurotransmitter.  It is broken down by the cholinergic enzyme Acetylcholinesterase (AChE)."},{"location":"Health/#alpha-gpc","title":"Alpha-GPC","text":"<p>L-alpha-glycerolphosphorylcholine (Alpha GPC) is the highest quality and most bioavailable form of choline.  Unlike Alpha GPC, other forms of choline were found not to be able to cross the blood-brain barrier, preventing enhancement of cognitive performance.  It is not yet officially defined as one of the B vitamins, even though it is associated with them.</p> <p>An injectable prescription-only form of alpha-GPC exists called Delecit that is not available in the US.</p> Product $ mg $/600 mg Swanson Alpha-GPC 300 mg x 60 capsules (Swanson sale) $14.99 18,000 0.50 Swanson Alpha-GPC 300 mg x 60 capsules (Swanson) $19.99 18,000 0.67 NOW Supplements Alpha GPC 300mg x 60 capsules $21.44 18,000 0.71 Bulk Supplements Alpha-GPC 129.96 500,000 0.15 Bulk Supplements Alpha-GPC 84.96 250,000 0.20 Bulk Supplements Alpha-GPC 64.96 100,000 0.39"},{"location":"Health/#alpha-lipoic-acid","title":"Alpha lipoic acid","text":"<p>Alpha-lipoic acid (ALA or LA, also thioctic acid) is a powerful antioxidant that can replenish both vitamins C and E.  Vitamin E requires vitamin C or coenzyme Q to regenerate after being used up in the free radical reaction.</p> <ul> <li>A 2011 study found that obese subjects given doses of 1,000-1,800 mg for up to 20 weeks experienced a loss of around 3% of body weight.</li> <li>A 2015 literature review found that ALA is only marginally effective in combating obesity in conjunction with good diet and exercise.</li> </ul> <p>ALA exists in two enantiomeric forms: R and S. A 2002 study found that R-ALA has greater biopotency in several metabolic pathways.</p> Product $ mg $/300 mg BulkSupplements R-Alpha lipoic acid 100 g 111.96 100,000 0.33 BulkSupplements R-Alpha lipoic acid 500 g 481.96 500,000 0.29 Swanson R-Fraction ALA 300 mg x 30 capsules (Swanson sale)(sale) 20.4912.29 9,000 0.680.41 Swanson R-Fraction ALA 300 mg x 30 capsules (Amazon) 20.98 9,000 0.70 Doctor's Best R-Lipoic Acid 100 mg x 60 capsules 15.70 6,000 0.79 Nutricost ALA 300 mg x 240 capsules 19.89 72,000 0.08 <p>Anxiolytic</p> Apoptosis Programmed or controlled cell death; cf. necrosis"},{"location":"Health/#ashwagandha","title":"Ashwagandha","text":"<p>Withania somnifera or Ashwagandha is a traditional Ayurvedic herb used as a memory aid. </p> <ul> <li>It has been shown to increase serum testosterone in infertile men. (2009)</li> <li>In a double-blind, placebo-controlled crossover study, healthy men administered Ashwagandha (500 mg/day) experienced improved cognitive performance outcomes. (2014)</li> <li>A study that compared the difference in effect of 250 and 600 mg/day found that the higher dosage was associated with significantly greater stress and anxiety reduction and increased sleep quality. (2019)</li> </ul> Product $ g $/g Bulk Supplements Ashwagandha 1 kg 34.96 1,000.0 0.04 Swanson Ashwagandha Extract 450 mg x 60 capsules 3.214.59 27.0 0.120.17 Swanson Ultimate Ashwagandha 250mg x 60 capsules 3.997.99 15.0 0.260.53 NOW Supplements Ashwagandha 450 mg x 180 capsules 16.4628.99 81.0 0.200.35 NOW supplements Ashwagandha 450 mg x 90 capsules 17.90 40.5 0.44 Nutricost Ashwagandha Extract KSM-66 600 mg x 180 capsules 40.95 108 0.38"},{"location":"Health/#astragalus","title":"Astragalus","text":"Product $ g $/g Swanson Full Spectrum Astragalus 470 mg x 100 capsules 2.593.99 47.0 0.030.04 Gorilla Mind Astragalus extract 750mg x 90 capsules 20.00 67.5 0.14 Swanson Astragalus 20.39 120.0 0.17 Ayurveda A traditional system of herbal medicine originating in India (ref Bacopa)"},{"location":"Health/#bacopa","title":"Bacopa","text":"<p>Bacopa monnieri is an Ayurvedic herbal medicine.  Studies have substantiated its use in enhancing memory by reducing inflammation in the brain.</p> <p>The main nootropic constituents of Bacopa are believed to be dammarane types of triterpenoid saponins known as bacosides.  Most clinical studies focus on memory, to the omission of other facets of cognition like fluid intelligence, typically lasting 12 weeks.  The long-term effect of Bacopa is unknown, but animal models suggest protection from age-related neurodegeneration. (2013 :material-file-pdf:)</p> <p>There are several putative mechanisms of action:</p> <ul> <li>Anti-oxidant/neuroprotection</li> <li>Acetylcholinesterase inhbition</li> <li>Choline acetyltransferase activation</li> <li>Beta-amyloid reduction</li> <li>Increased cerebral blood flow</li> <li>Monoamine potentiation and modulation</li> </ul> <p>A mix of Bacopa monnieri, Lycopene, Astaxanthin, and vitamin B12) administered orally once a day to subjects aged 60 years old or more resulted in improved cognitive performance after 8 weeks. (2020)</p> <p>A neuropharmacological review found that the maximum efficacious dosage was 200 mg/kg. (2013) </p> Product $ M (g) $/g Bulk Supplements Bacopa 1 kg 212.96 1,000.0 0.21 Swanson Bacopa Monnieri 250 mg x 90 capsulessale 5.579.29 22.5 0.230.41 Bulk Supplements Bacopa 250 g 73.96 250.0 0.29 NOW Supplements Bacoba Extract 450 mg x 90 capsules 18.78 40.5 0.46"},{"location":"Health/#berberine","title":"Berberine","text":"Berberine complexed with hydroxypropyl-\u03b2-cyclodextrin was recommended by MPMD to deal with carb-dense meals. This is apparently a reference to the use of berberine as a GDA, a term that has recently gained currency in the fitness industry as a way to improve how glucose is processed in the body, or \"nutrient partitioning\". The science on this topic appears to be inconclusive at best."},{"location":"Health/#bioperine","title":"Bioperine","text":"Product $ mg $/10 mg Swanson Bioperine 10 mg x 60 capsules (35% off sale) 2.59 600 0.04 Swanson Bioperine 10 mg x 60 capsules 3.99 600 0.07 Swanson Bioperine 10 mg x 60 capsules 9.86 600 0.16"},{"location":"Health/#calcium","title":"Calcium","text":"<p>Your dietary intake of calcium is probably 300 mg with the largest provider being 4 eggs providing 100 mg (target is 1,000 mg)</p> <p>Most food sources of calcium are dairy.</p> <ul> <li>A cup of edamame may contain about 100 mg</li> <li>An ounce of almonds may contain 367 mg</li> </ul> Product $ g $/1,000 mg BulkSupplements Calcium citrate powder (1 kg) 17.96 1,000.0 0.02 Swanson Calcium Citrate &amp; Vitamin D 315 mg x 250 tablets 6.5910.99 78.8 0.080.14 Swanson Liquid Calcium &amp; Magnesium 300 mg x 100 softgels 3.896.49 30.0 0.130.21 Swanson Calcium Citrate Plus Magnesium 150 mg x 150 capsules 3.814.49 22.5 0.170.20 Amazon Elements Calcium plus Vitamin D 500 mg x 65 tablets 5.9910.99 32.5 0.190.34 Blue Diamond Almonds (BOGO sale) 9.00 2.5 3.52 Swanson Calcium Carbonate, Aspartate &amp; Citrate 500 mg x 100 tablets 2.74 50.0 0.05"},{"location":"Health/#choline","title":"Choline","text":"<p>Choline is a precursor to the neurotransmitter acetylcholine. It is endogenously produced and found in food. Many supplements contain choline because it is cheaply produced, but studies indicate it may not be able to cross the blood-brain barrier.</p> <p>Another product of choline is betaine. For individuals who have genetic polymorphisms like MTHFR and are thus far less able to produce B12 and folate, the pathway producing betaine compensates for this shortcoming, which results in deprivation of acetylcholine for cognition.</p> Cholinergic relating to or denoting nerve cells in which acetylcholine acts as a neurotransmitter Crossover trial A trial where subjects are randomly assigned to study arms where each arm consists of two consecutive bouts of treatment separated by a washout period. A concern with crossover trials is that there is a chance that subsequent rounds of treatment may be influenced by earlier ones."},{"location":"Health/#citrullus-lanatus","title":"Citrullus lanatus","text":"A late 2020 study found that mice given Cucumis melo and watermelon (Citrullus lanatus) seed extract experienced enhancement of memory and cognition."},{"location":"Health/#citrus-bergamot","title":"Citrus Bergamot","text":"Improves lipid profile. CoQ10 <p>Ubiquinone, also called Coenzyme Q10 (CoQ10), is a coenzyme family ubiquitous to animals and bacteria.  Ubiquinone is the most commonly found form in humans, an endogeneously produced lipid-soluble antioxidant that metabolizes into ubiquinol.  It is one of the most popular supplements and renowned for being a powerful antioxidant.  Doses are usually 100-200 mg/day, although there is no established upper limit for tolerance.</p> <ul> <li>A meta-analysis of 13 randomized controlled trials found that CoQ10 supplementation increased superoxide dismutase (SOD) and catalase (CAT) and decreased malondialdehyce (MDA) and diene. (2019)</li> <li>A meta-analysis of 19 randomized controlled trials found that CoQ10 supplementation significantly increased total antioxidant capacity (TAC), SOD, CAT, and glutathione peroxidase (GPx), as well as significantly decreased MDA. (2020)</li> <li>A 2021 study found that horses who were fed CoQ10 experienced persistent improvement in semen quality.</li> <li>Patients receiving from 300-1200 mg/day exhibited no difference in incidence of drug-related toxicities between placebo and treatment arms. (2002)</li> </ul> Creatine monohydrate <p>A 2018 review of six studies found that creatine can improve short-term memory and intelligence/reasoning in healthy individuals.</p> Product $ g $/5g BulkSupplements Creatine Monohydrate powder (1 kg) 19.96 1,000 0.10 Optimum Nutrition Creatine powder 4.41 lbs 42.49 2,000 0.11 Optimum Nutrition Creatine powder 1.32 lbs 15.74 600 0.13 Optimum Nutrition Creatine powder 10.5 oz 10.53 300 0.18 Swanson Creatine 1g x 180 capsules 2-pack 17.49 360 0.25 Optimum Nutrition Creatine capsules 150 x 2.5 g servings 26.13 375 0.35 Optimum Nutrition Creatine powder 2.64 lbs 35.94 1,200 0.15"},{"location":"Health/#cucumis-melo","title":"Cucumis melo","text":"<p>Muskmelon is a species of melon that includes honeydew and cantaloupe.</p> <p>A late 2020 study found that mice given Cucumis melo and Citrullus lanatus seed extract experienced enhancement of memory and cognition.</p>"},{"location":"Health/#curcumin","title":"Curcumin","text":"<p>Curcumin (diferuloylmethane) is the principal biologically active polyphenolic constituent of turmeric (Curcuma longa). It is a powerful antioxidant binding to COX-2 and 5-LOX and has been found to increased brain-derived neurotrophic factor (BDNF).</p> <ul> <li>Curcumin supplementation increases serum brain-derived neurotrophic fator (BDNF) (2020).</li> <li>A literature review found that (2020 :material-file-pdf:): <ul> <li>Curcumin can act as a neuroprotectant antioxidant by binding to COX-2 and 5-LOX.  </li> <li>Curcumin inhibits the activation of microglial cells and protects dopaminergic neurons against microglia-mediated neurotoxicity. </li> <li>Curcumin inhibits the caspase-3 apoptosis mediator, suggesting that it is an anti-apoptotic agent that would be useful in treating neurodegenerative diseases.</li> </ul> </li> <li>A meta-analysis found that curcumin can improve therapy for people with symptoms of depression and anxiety (2019).</li> <li>Curcumin has very poor bioavailability without co-administration of piperine. (1998)</li> <li>A systematic review and meta-analysis found that curcumin administration was associated with a significant reduction only in systeolic blood pressure, but not in diastolic, in studies with supplementation exceeding 12 weeks. (2019)</li> </ul> Product $ g $/g BulkSupplements Curcumin 1 kg 249.96 1,000.0 0.25 Swanson Curcumin Complex 350 mg x 120 capsules (sale) 14.2418.99 42.0 0.340.45 Amazon Elements turmeric Complex 316 mg x 65 capsules 14.99 20.5 0.73 D-Aspartic acid <p>D-Aspartic acid or D-Aspartate is an amino acid found in various tissues, including in the axon terminals and synaptic vesicles of neuronal tissue and endocrine glands. It is known to induce testosterone synthesis in the testis.</p> <ul> <li>A literature review concluded that exogenous D-Asp increases testosterone in animals. However, human studies which demonstrated conflicting results were noted for their short-term generation, small sample size, and other problems. (2017 :material-file-pdf:)</li> <li>Most studies used dosages of 2,600-3,000 mg/day (Healthline)</li> <li>Purported benefits of DAA are probably bunk.</li> </ul> Product $ g $/g Nutricost D-Aspartic Acid 750 mg x 180 capsules 14.99 135 0.11 Dihydrotestosterone (DHT) produced after testosterone is aromatized by 5-alpha-reductase."},{"location":"Health/#dmae","title":"DMAE","text":"<p>Dimethylaminoethanol (marketed as DMAE but appearing more commonly as deanol in scientific literature) is not a precursor to acetylcholine as is commonly asserted.  However it is hypothesized that it may increase acetylcholine levels by inhibiting choline metabolism.</p> <p>In a double-blind, placebo-controlled trial, children given 40 mg of Ritalin or 500 mg of deanol experienced similar improvements in psychometric tests. Deanol appeared to be more effective for those with learning disabilities.</p> Product $ mg $/750 mg BulkSupplements DMAE-bitartrate powder (500 g) 20.96 500,000 0.03 NOW Supplements DMAE 250 mg x 100 capsules 7.51 25,000 0.225"},{"location":"Health/#dutasteride","title":"Dutasteride","text":"Enantiomer molecules that are mirror images of one another Endothelium cells that line the interior surface of blood vessels and lymphatic vessels epithelium one of the four basic types of animal tissue ergogenic intended to enhance physical performance, stamina, or recovery excipient an inactive substance that serves as the vehicle or medium for a drug or other active substance."},{"location":"Health/#fenugreek","title":"Fenugreek","text":"<p>Several studies suggest that male subjects who took 500 mg fenugreek daily experienced increased testosterone and improved mood, energy, and libido.</p> Product $ g $/g Swanson Fenugreek seed 610 mg x 90 capsules 2.093.49 54.9 0.040.06 Swanson Fenugreek extract 500 mg x 90 capsules 6.9511.59 45.0 0.150.25 Swanson Fenugree extract featuring Testofen 18.39 36.0 0.51"},{"location":"Health/#finasteride","title":"Finasteride","text":"Propecia is the commercial brand name for finasteride."},{"location":"Health/#fish-oil","title":"Fish oil","text":"<p>Fish oil is a prominent source of the Omega-3 oils EPA and DHA.</p> Product $ g (\u03c9-3) $/g Swanson Super EPA &amp; DHA BOGO 20.39 92.8 0.21 <p>Follicle-Stimulating Hormone (FSH)</p> <p>free radical reaction</p>"},{"location":"Health/#gaba","title":"GABA","text":"Gamma aminobutyric acid (GABA) is considered an inhibitory neurotransmitter because it blocks certain brain signals and decreases activity in the nervous system. GABAergic receptors are targeted by clinically important drugs that treat anxiety, epilepsy, insomnia, and other pathophysiological disorders. (2015) Glutathione Glutathione is involved in many body processes and is a common therapy for patients with various ailments, including cancer, HIV, etc.  It is endogenously produced in the liver and can also be found in various foods. <p>Gonadotropin-Releasing Hormone (GnRH)</p> hepatic Related to the liver hirsutism a condition causing male-pattern hair growth in women."},{"location":"Health/#huperzine-a","title":"Huperzine A","text":"<p>Huperzine A is a lycopodium alkaloid derived from Huperzia serrata (toothed clubmoss or firmoss), which has been used therapeutically for neurological disorders. It suppresses the acetylcholinesterase enzyme which breaks down acetylcholine </p> <ul> <li>Huperzine A promoted neurogenesis in the hippocampus of mice in vitro and in vivo (2013)</li> <li>Huperzine A directly increased neurotrophic activity of rat astrocytes in vitro (2005)</li> </ul> Product $ mcg $/200 mcg BulkSupplements Huperzine A 10 g 29.96 100,000 0.06 BulkSupplements Huperzine A 100 g 325.96 1,000,000 0.07 Swanson Huperzine A 200 mcg x 30 capsules (Swanson) 9.895.93 6,000 0.330.20 Hypothalamic-pituitary-gonadal (HPG) axis An endocrine control mechanism involved in the regulation of testosterone in males and estrogen in females.  In this concept, the hypothalamus produces GnRH which binds to secretory cells of the anterior pituitary.  Binding of GnRH stimulates these cells to produce LH and FSH, which then produce different effects in the sexes: production of estrogen and inhibin in the ovaries of the female and testosterone and sperm in the testes of the male. International Unit (IU) A unit of measurement for the amount of a substance that varies based on the substance being measured. Isomer Each of several compounds with the same formula but a different arrangement of atoms and different properties"},{"location":"Health/#kanna","title":"Kanna","text":"<p>Kanna (Sceletium tortuosum) increases seratonin in the brain and improves mood.</p> Product $ mg $/200 mg Swanson Sceletium Tortuosum 50 mg x 60 capsules (Swanson BOGO sale) 11.99 6,000 0.40"},{"location":"Health/#l-arginine","title":"L-Arginine","text":"<p>L-Arginine is an amino acid widely used in pre-workout supplements because it enhances blood flow. It works by providing nitrogren to the nitric oxide synthase (NOS) enzyme to produce nitric oxide (NO), being metabolized to L-citrulline in the process.  L-citrulline, in turn, can be reconverted to L-arginine in the kidneys.  Both L-citrulline and L-arginine regulate nitrogen and ammonia in the blood.</p> <p>Bioavailability of l-arginine can vary up to 70%, but excessive dosages can cause gastrointestinal issues. L-citrulline, in contrast, has a bioavailability of practically 100%, which is why it is favored now.</p> <p>L-Arginine may help reduce blood pressure by producing nitric oxide, which relaxes blood vessels.</p> Product $ g $/g Swanson L-Arginine 850mg x 90 caps BOGO 6.59 153 0.04 Nature's Bounty L-Arginine 1000mg x 50 tablets 8.80 50 0.18 Bulk Supplements L-Arginine 1 kg 34.96 1,000 0.04"},{"location":"Health/#l-carnitine","title":"L-Carnitine","text":"<p>Several forms of L-carnitine are available:</p> <ul> <li>L-carnitine L-tartrate (LCLT) is a salt of L-carnitine that increases androgen receptor uptake. <ul> <li>Resistance-trained men given LCLT experienced an increase in AR content (2006)</li> <li>It is absorbed faster than other L-carnitine esters (2005)</li> </ul> </li> <li>Acetyl L-carnitine (ALCAR) is an ester of L-carnitine that can pass through the blood-brain barrier, and its acetyl group ensures that it is active in the central nervous system. It is a \"substrate\" for acetylcholine.</li> <li>L-carnitine fumarate is marketed as a weight loss booster under the name Carnishield</li> </ul> Product $ mg $/4000 mg Swanson L-Carnitine 500 mg x 100 tabs 7.48 50,000 0.60 Swanson Acetyl L-carnitine 500 mg x 240 caps (Swanson sale) 16.24 120,000 0.54 Swanson Acetyl L-carnitine 500 mg x 100 caps (Swanson sale) 7.69 50,000 0.62 Jarrow LCLT 500 mg x 100 capsules 19.39 50,000 1.55 Swanson L-Carnitine Fumarate 450 mg x 60 caps 10.99 27,000 1.63 NOW Foods Acetyl-L-Carnitine 500 mg x 50 caps 10.38 25,000 1.66 <p>Oral supplementation of carnitine is problematic because of the production of TMAO which has been associated with cardiovascular disease. Some studies indicate that dietary allicin from garlic can reduce the production of TMAO. (2015)</p> Product $ mg $/24 mg Swanson Allicin 12 mg x 100 tabs 8.60 1,200 0.17 <p>Injectable L-carnitine is a suitable lipolytic, especially when used in conjunction with methionine, inositol, and choline (MIC) and B vitamins.</p>"},{"location":"Health/#l-leucine","title":"L-Leucine","text":"<p>Leucine is a dietary amino acid marketed as directly stimulating muscle growth.</p> <ul> <li>Untrained peri- and postmenopausal women performing resistance training experienced no ergogenic effects supplementing with leucine. (2020)</li> <li>Young adult men experienced no ergogenic effects supplementing with leucine. (2019)</li> <li>Elderly men experienced no ergogenic effects from ong-term leucine supplementation (7.5g/d) (2009 :material-file-pdf:)</li> </ul>"},{"location":"Health/#l-theanine","title":"L-Theanine","text":"<p>An amino acid found in green tea, alone it can increase the feeling of well-being, but in combination with caffeine generally increases cognitive performance.</p> Product $ mg $/200 mg BulkSupplements L-Theanine powder (100 g) 17.96 100,000 0.04 Amazon Elements L-Theanine 200 mg x 60 capsules (sale) 10.22 12,000 0.17 Amazon Elements L-Theanine 200 mg x 60 capsules 13.49 12,000 0.22 Swanson Suntheanine L-Theanine 100 mg x 60 capsules (Swanson sale) 6.74 6,000 0.22 Swanson Suntheanine L-Theanine 100 mg x 60 capsules (Swanson) 8.99 6,000 0.30"},{"location":"Health/#l-tyrosine","title":"L-Tyrosine","text":"<p>L-Tyrosine is the most bioavailable form of Tyrosine, especially in comparison with N-acetyl-L-Tyrosine, and a precursor to the neurotransmitter dopamine, thyroxine, adrenaline and noradrenaline, and the catecholamines. It is converted by the enzyme tyrosine hydroxylase.</p> <p>L-Tyrosine is commonly believed to reduce and relieve stress and enhance cognitive performance.</p> <ul> <li>Tyrosine abolished fear expression, apparently because of its effect on the catecholaminergic system. (2019)</li> <li>A literature review of 15 studies found that tyrosine acutely counteracts decrements in working memory and information processing caused by cognitive load or bad weather. (2015)</li> </ul> Product g $ $/g Swanson L-Tyrosine 500 mg x 100 capsules  50.0 3.595.99 0.070.12 Jarrow L-Tyrosine 500 mg x 100 capsules 50.0 5.38 0.10 NOW Supplements L-Tyrosine 750 mg x 90 capsules 67.5 10.73 0.16 BulkSupplements L-Tyrosine 1 kg 1,000.0 28.96 0.29"},{"location":"Health/#lecithin","title":"Lecithin","text":"<p>Lecithin is a generic term designating any yellow-brownish fatty substances occurring in animl and plant tissues that are amphiphilic.</p> <p>Soy lecithin contains various compounds that reduce stress, including phosphatidylserine. </p> <p>Lecithin is widely assumed to be a provider of choline, although as such it is almost certainly inferior to Alpha GPC.</p>"},{"location":"Health/#lions-mane","title":"Lions Mane","text":"<p>A 2021 study found that compounds extracted from Hericium erinaceus demonstrated neurotrophic effects in isolation. In particular isohericerinol A stimulated neurogenesis by increasing Nerve Growth Factor (NGF) production.</p> Product $ g $/g BulkSupplements Lion's Mane 500 g 35.96 500 0.07 Swanson Lion's Mane 500 mg x 60 capsules (Swanson) 10.49 30 0.35 Lipid profile Ratio between HDL (good cholesterol) and LDL (bad cholesterol) Lipolysis The breakdown of fats and other lipids by hydrolysis to release fatty acids. The process of mobilizing stored energy during fasting or exercise. The metabolic pathway through which lipid triglycerides are hydrolyzed into a glycerol and three fatty acids. Lutein Lutein is a carotenoid closely related to beta-carotene, which gives carrots and pumpkins their orange color. Luteinizing Hormone (LH) n/a"},{"location":"Health/#maca","title":"Maca","text":"<p>Maca root (Lepidium meyenii) is a Peruvian vegetable with a long history in South American cuisine, and as an herb it is traditionally used to enhance fertility and sex drive.  Some studies suggest an ergogenic benefit to endurance activities. Maca, in particular black maca, improved learning and memory in rodents with memory impairment. A review found that it can improve sperm volume, and motility and the volume of semen in infertile and healthy men. Another review found that maca can help alleviate hot flashes and anxiety in menopausal women. (src)</p> <ul> <li>Dosage varies 1.5-5.0 g/day </li> </ul> Product $ m $/500 mg BulkSupplements Maca 1 kg 29.96 1,000 0.02 Swanson Maca 500 mg x 100 capsules 2.50 50 0.03"},{"location":"Health/#magnesium","title":"Magnesium","text":"<p>Recommended daily intake of magnesium is 420 mg, and you are short by approximately 150 mg.</p> Product $ mg $/200 mg BulkSupplements Magnesium Citrate powder (250 g) 11.96 250,000 0.010 Swanson Triple Magnesium Complex 400 mg x 300 caps (Amazon) 9.99 120,000 0.017 Swanson Triple Magnesium Complex 400 mg x 300 caps 11.99 120,000 0.020"},{"location":"Health/#melatonin","title":"Melatonin","text":"Melatonin may reduce blood pressure. Mini Mental State Examination (MMSE)  Scoring 20 or above corresponds to normal cognitive functions"},{"location":"Health/#minoxidil","title":"Minoxidil","text":"<p>Minoxidil is a potassium channel opener originally designed to lower blood pressure. </p> <p>Rogaine is one of many brand names offering 5% topical minoxidil.</p>"},{"location":"Health/#modafinil","title":"Modafinil","text":"Modafinil is a heavily abused sleep suppressant typically prescribed to narcolepsy patients but also said to be used by fighter pilots.  Myopathy Any disease that affects muscle tissue Necrosis Uncontrolled cell death as a result of shock; cf. apoptosis Nerve Growth Factor (NGF) Neurodegenerative disease Diseases that result in progressive degeneration or death of neuronal cells"},{"location":"Health/#niacin","title":"Niacin","text":"<p>Vitamin B3 or niacin comes in two forms: nicotinic acid and niacinamide (also called nicotinamide).</p> <p>Niacin is considered an antilipemic agent because can help regulate cholesterol by lowering LDL and raising HDL. In this context, daily dosages may range from as little as 250 mg up to a maximum of 6,000 mg.</p> <p>It has also been shown to increase NAD+ levels in people with systemic NAD+ deficiency.</p> <p>It is associated with side effects in some people, including hives and skin rashes.</p> Nicotinamide adenine dinucleotide (NAD+) <p>NAD+ is involved in many biological processes, and its level falls as a person ages.</p> <p>Niacin and nicotinamide riboside have both been shown to increase the serum concentrations of NAD+ in humans.</p>"},{"location":"Health/#nicotinamide-riboside","title":"Nicotinamide riboside","text":"<p>Nicotinamide riboside, also called niagen, is a B3 vitamin and a highly bioavailable precursor to NAD+.</p> <p>Nicotinamide riboside supplementation raises NAD+ levels, which also helps reduce systolic blood pressure.</p> Phenol An aromatic organic compound with the molecular formula C6H5OH. (wiki)"},{"location":"Health/#phosphatidylcholine","title":"Phosphatidylcholine","text":"<p>Phosphatidylcholine is a phospholipid that incorporates choline as a headgroup.</p> <ul> <li>Humans with cognitive disorders who were fed two forms of phosphatidylcholine (~100 mg) after breakfast experienced an improvement in their [MMSE][MMSE] scores so significant that their new scores rose above the diagnostic threshold for cognitive disorder. (2011)</li> <li>Administration of phosphatidylcholine to mice with impaired memory due to inbreeding raised their brain acetylcholine concentration to the level of unimpaired mice and resolved their poor memory function. However, phosphatidylcholine treatment did not affect memory or acetylcholine concentrations in normal mice. (1995)</li> <li>During a randomized, placebo-controlled clinical trial, prenatal supplementation of phosphatidylcholine resulted in improvement of cognitive performance of fetus (P50 inhibition). Delay in development as measured by this test is associated with schizophrenia and developmental problems. (2013)<ul> <li>This finding confirmed earlier research on the long-term benefit of prenatal choline supplementation in animals.</li> </ul> </li> </ul>"},{"location":"Health/#phosphatidylserine","title":"Phosphatidylserine","text":"<p>Phosphatidylserine (PtdSer or PS) is a phospholipid that supports a gamut of cognitive functions. It is found in the inner leaflet of neural cell membranes where it regulates the release of neurotransmitters acetylcholine, dopamine, and noradrenaline. Two sources of phosphatidylserine were available: bovine-cortex (BC-PtdSer) which has fallen out of favor due to the risk of transferring infections from prion-infected brains, and soy (S-PtdSer).</p> <ul> <li>In a randomized, double-blind trial, children diagnosed with ADHD but never having received drug treatment related to it experienced significantly improved ADHD symptoms and short-term memory after 2 months of phosphatidylserine supplementation (200mg/day).</li> <li>Exogenous dosages of 300-800 mg/d are absorbed efficiently, cross the blood-brain barrier, and reverses biochemical deterioration in nerve cells as a result of aging. (2015)</li> </ul> Product $ mg $/100 mg Swanson Phosphatidylserine 100 mg x 90 softgels(sale) 20.8913.57 9,000 0.230.15 Pleiotropic Having more than one effect, especially having multiple phenotypic expressions Polyphenol <p>A large family of naturally occurring organic compounds composed of multiple phenol units. There may be an association with polyphenol intake and reduced blood pressure.</p> <p>Supplements with polyphenolic compounds include resveratrol, curcumin, quercetin, and beetroot.</p>"},{"location":"Health/#potassium","title":"Potassium","text":"<p>Recommended adequate intake for potassium was set by the Food and Nutrition Board of the Institute of Medicine at 4700 mg/day. Your daily dietary intake is only 1600 mg/day.</p> <ul> <li>A banana may have 450 mg</li> <li>100g of broccoli may have 250 mg</li> <li>A cup of edamame (155 g) might have &gt;600 mg</li> <li> <p>100g of apricot (~15 pieces) provide almost 1,162 mg (or ~80 mg a piece)</p> </li> <li> <p>A systematic review and meta-analysis found that intervening to a point where potassium was 30 mmol/day produced the greatest decrease in systolic and diastolic blood pressure. (2020)</p> </li> </ul> <p>Both potassium bicarbonate and potassium citrate are alkaline sources of elemental potassium, found in dietary sources.</p> Product $ mg $/2,000 mg BulkSupplements Potassium Citrate powder (1 kg) 18.96 1,000,000 0.04"},{"location":"Health/#pygeum","title":"Pygeum","text":"Product $ g $/500mg BulkSupplements pygeum 1 kg 36.96 1,000 0.02 Swanson Pygeum 125 mg x 100 capsules(sale) 5.792.90 12.5 0.230.12"},{"location":"Health/#quercetin","title":"Quercetin","text":"<p>Quercetin is a polyphenolic antioxidant ubiquitous in plant food sources.</p> <ul> <li>A systematic review and meta-analysis found that taking at least 500 mg/day resulted in significant reduction of blood pressure. (Serban et al. 2016)</li> </ul> Product $ g $/g Nutricost Quercetin 440 mg x 240 capsules 31.95 105.6 0.30 Swanson Quercetin 475 mg x 60 capsules (25% off sale) 9.74 28.5 0.34 Jarrow Quercetin 500 mg x 100 capsules 18.99 50.0 0.38 Swanson Quercetin 800 mg x 30 capsules (BOGO) 19.38 48.0 0.40 Swanson Quercetin 475 mg x 60 capsules 12.99 28.5 0.45 Jarrow Quercetin 500 mg x 200 capsules 66.95 100.0 0.67"},{"location":"Health/#resveratrol","title":"Resveratrol","text":"<p>Resveratrol is a polyphenol and estrogenic antioxidant found in grape skin, peanuts, and other foods.  Red wine contains less than 13 mg of resveratrol per liter. (src) It is confirmed as a powerful antioxidant and may potentially enhance cognitive performance. </p> <ul> <li>A systematic review found that supplementation with resveratrol does not have an anti-obesity effect. In contrast, an earlier systematic review cited in this one did find that resveratrol supplementation had a positive effect on weight loss.</li> <li>A comprehensive review found that even moderate daily supplementation (0.5-1 g) is enough to inhibit estrogen metabolism and increase SHBG. (2020)</li> <li>Resveratrol has poor bio-availability and a short half-life (1.5 hours). (2019 :material-file-pdf:).</li> <li>Resveratrol upregulates SHBG expression in the liver. (2017)</li> <li>A literature review found that resveratrol intervention lowered total cholesterol, systolic blood pressure, and fasting glucose with more significant reductions when doses were higher than 300mg/day. (2016)</li> <li>A double-blind, randomized, placebo-controlled crossover study found that administration of resveratrol (150 mg/day) caused no changes in metabolic risk markers in overweight and obese subjects after 4 weeks with a 4-week washout period. (2015)</li> <li>Rats force-fed resveratrol at 20mg/kg daily experienced increased serum concentration of gonadotrophins and testosterone by stimulating the HPG axis.</li> </ul> Product $ mg $/100 mg BulkSupplements 100g 85.73 100,000 0.09 BulkSupplements 500g 323.48 500,000 0.06 Swanson Resveratrol 500 mg x 30 capsules (BOGO) 32.99 30,000 0.11 Swanson Resveratrol 250 mg x 30 capsules (Swanson BOGO sale) 17.99 15,000 0.12 Swanson Resveratrol 100 mg x 30 capsules (Swanson BOGO sale) 8.99 6,000 0.15"},{"location":"Health/#rhodiola","title":"Rhodiola","text":"Rhodiola rosea is an adaptogenic herb used in traditional medicine in Europe and Asia. <ul> <li>A 2018 meta study :material-file-pdf: examined 36 animal studies and concluded that rhodiola can improve learning and memory function, despite an earlier 2012 review that found that methodological problems with earlier experiments brought these findings into question.</li> <li>A clinical trial in 2000 found that young physicians experienced improvement in cognitive performance on a battery of cognitive tests called the Fatigue Test. The study concluded that rhodiola could reduce general fatigue under stressful conditions.</li> <li>A similar 2003 study found that young military cadets were able to resist fatigue better with rhodiola.</li> </ul> Product $ mg $/400 mg Swanson Rhodiola 400 mg x 100 capsules (Swanson sale) 4.79 40,000 0.05 Swanson Rhodiola 400 mg x 100 capsules (Swanson) 7.99 40,000 0.08 Swanson Rhodiola 400 mg x 100 capsules (Amazon) 10.89 40,000 0.11 Now Foods Rhodiola 500 mg x 60 capsules 18.25 30,000 0.24 Ritalin Ritalin is the brand name for the stimulant methylphenidate."},{"location":"Health/#rosemary","title":"Rosemary","text":"<p>Mark Moss with Northumbria University has published several studies on the cognitive benefits of various herbs, including peppermint, chamomile, rosemary, and lavender. The studies on rosemary in particular were motivated by traditional associations of rosemary with memory.</p> <ul> <li>Aromatherapy with rosemary oil resulted in improvement in cognitive performance (2017).</li> <li>Drinking rosemary water produced a small benefit to memory (2018)</li> <li>Cognitive benefit of rosemary aromatherapy was associated with concentration of 1,8-cineole. (2012)</li> <li>An interesting study contrasted the impact of aromatherapies of lavender and rosemary oils. Rosemary enhanced performance for overall quality of memory, but also impaired speed of memory compared to control. Lavender actually impaired performance of working memory. Rosemary boosted alertness in comparison to both control and lavender. Both lavender and rosemary enhanced contentment. (2003)</li> </ul> Product $ mg $/500 mg Swanson Rosemary Extract 500 mg x 60 capules (Swanson sale) 5.13 30,000 0.09 Swanson Rosemary Extract 500 mg x 60 capules (Swanson) 7.19 30,000 0.12 Swanson Rosemary Extract 500 mg x 60 capules (Amazon) 9.99 30,000 0.17 Saffron (Crocus sativus L.) A 2020 review found that there was some evidence that associated saffron with improvement in cognitive performance, especially in subjects with neurodegenerative disease. Sarcopenia Age-related loss of muscle mass and function"},{"location":"Health/#saw-palmetto","title":"Saw palmetto","text":"<p>Saw palmetto (Serenoa repens) is a dwarf palm tree native to southeast North America that has long been used as a medicinal herb by Native Americans. Studies suggest that it blocks the conversion of testosterone to [DHT][DHT], and may be effective as a treatment for androgenic alopecia. (src)</p> <ul> <li>Dosage may be 160-320 mg </li> </ul> Product $ g $/500mg BulkSupplements Saw Palmetto 1 kg 43.96 1,000 0.02 Swanson Saw Palmetto 540 mg x 250 capsulessale 15.995.69 135 0.060.02 Swanson Saw Palmetto 540 mg x 100 capsulessale 4.592.75 54 0.040.03 Squamous Referring to the shape of cells that are wide and flat, such as those found in the lining of the mouth, esophagus, and blood vessels (cf. cuboidal and columnar) Statin A family of drugs used for treating hyperlipidaemia with a recognized capacity to prevent cardiovascular disease event"},{"location":"Health/#taurine","title":"Taurine","text":"Dosages of taurine in studies are commonly 500 - 2,000 mg /day, however higher doses appear to be well-tolerated."},{"location":"Health/#theobromine","title":"Theobromine","text":"<p>Theobromine is a methylxanthine and stimulant found in the cacao plant and chocolate products: it is what gives dark chocolate its bitterness. Theobromine is believed to promote wakefulness and alertness and enhance cognition, among other benefits.</p> Product $ g $/g BulkSupplements Theobromine 46.96 250 0.19 BulkSupplements Theobromine 20.96 100 0.21 Thyroxine <p>Thyroxine, called T4 because it contains 4 iodine atoms, is the major thyroid hormone secreted by the thryoid gland.</p> <p>It is converted to triiodothyronine (T3) by the removal of an iodine atom mainly in the liver but also in the brain.</p> <p>Thyroxine production is regulated by TSH.</p> Tryptophan Tryptophan is a precursor of the neurotransmitters serotonin and melatonin."},{"location":"Health/#ubiquinol","title":"Ubiquinol","text":"<p>Ubiquinol (QH) is the fully reduced form of ubiquinone. Intense exercise depletes CoQ10, but supplementation with ubiquinol prevents this deprivation. </p> <p>Ubuiquinol is more bioavailable than CoQ10 by an order of magnitude. </p> <p>Like vitamin E, ubiquinol is a lipid-soluble antioxidant, which gives it the special task of protecting sensitive cell membranes. Ubiquinol is depleted before vitamin E because it reacts with radicals first, and it can also replenish depleted vitamins E and C. (2013)</p> <ul> <li>Healthy and well-trained fireman given 200mg/day ubiquinol for two weeks experienced increases in the biomarkers of bone formation and energy mobilization, suggesting ergogenic effects. (2020)</li> <li>CoQ10 was positively associated with antioxidant capacity, muscle mass, muscle strength, and muscle endurance in patients with osteoarthritis. (2020)</li> <li>Subjects with mild cognitive impairment who received 200 mg/day ubiquinol for a year experienced improved cerebral vasoreactivity compared to baseline and placebo, but no significant neurological improvement. (2021)</li> <li>In a double-blind, placebo-controlled study, ubiquinol supplementation increased physical perforrmance. (2013 :material-file-pdf:)</li> <li>Ubiquinol supplementation to mice reduced a variety of markers associated with fatigue and increased muscle and liver glycogen content, which provide energy during exercise. (2019)</li> <li>A systematic review and meta-analysis found that long-term supplementation with CoQ10 (most studies were 2-4 months while one was 13 months) at dosages varying from 34-225 mg/day can significantly reduce blood pressue. (2007)</li> </ul> Product $ mg $/100 mg Jarrow QH-absorb (Publix sale) 6.71 6,000 0.11 NOW Supplements Ubiquinol 100 mg x 120 softgels 38.69 12,000 0.32 Swanson Ubiquinol 100 mg x 120 softgels (2-pack) 79.99 24,000 0.33 Swanson Ubiquinol 100 mg x 120 softgels 42.99 12,000 0.36 Vascular resistance The resistance that must be overcome to push blood through the circulatory system   Vasoreactivity A &gt;= 30% decrease in pulmonary vascular resistance (PVR) with vasodilator compared to baseline VAT Visceral adipose tissue (VAT) is fat surrounding the intra-abdominal organs which has been associated with various medical pathologies; alongside subcutaneous adipose tissue (SAT), one of the two types of body fat tissue <p>Visceral obesity :     Abnormally high deposition of visceral adipose tissue (VAT)</p>"},{"location":"Health/#vitamin-b12","title":"Vitamin B12","text":"<p>Vitamin B12 (cobalamin, methylcobalamin) is a cofactor and precursor of neurotransmitters acetylcholine, dopamine, GABA, norepinephrine, and serotonin. </p> <ul> <li>Even mild B12 deficiency was associated with cognitive decline over 8 years.</li> <li>The BLAtwelve Study tested the effects of Bacopa monnieri, Lycopene, Astaxanthin, and Vitamin B12, finding that a mix of the four compounds administered orally once a day to subjects aged 60 years old or more experienced improved cognitive performance after 8 weeks.</li> </ul> Product $ mg $/mg Amazon Elements B12 5000 mcg x 65 lozenges 12.99 325 0.04 Swanson Ultra Vitamin B12 Triple Action 1000 mcg x 90 tabs 6.5910.99 90 0.070.12"},{"location":"Health/#vitamin-c","title":"Vitamin C","text":"<p>Vitamin C ( \"ascorbic acid\") is a water-soluble antioxidant that can interact directly with free radicals. Its efficacy as an antioxidant has been closely associated with that of Vitamin E, which it may regenerate by reducing the Vitamin E radical.</p> <ul> <li>A 2018 study suggested that Vitamin C could inhibit visceral adipocyte hypertrophy</li> <li>A long-term study published in 2008 found that there was no significant effect of vitamin C on cardiovascular health.</li> <li>The body tightly controls serum concentration of vitamin C. Dosages of 200-300 mg/day result in concentrations of 70 micromol/L, whereas dosages of 1.25 g/day produce concentrations of only 135 micromol/L.</li> </ul> Product $ M $/1,000 mg Swanson Vitamin C 1,000 mg x 250 capsules 8.0411.49 250 0.0320.045 Swanson Vitamin C 500 mg x 400 capsules 7.6910.99 200 0.0390.055 Amazon Elements Vitamin C 1000 mg x 300 tablets 17.99 300 0.06"},{"location":"Health/#vitamin-d3","title":"Vitamin D3","text":"<p>Vitamin D3 (cholecalciferol) can regulate lipid peroxidation as a form of neuroprotection by inducing the synthesis of parvalbumin, a protein that binds to Ca2+ (2020).</p> <ul> <li>Claims that Vitamin D3 can boost testosterone are unfounded (2017, 2019)</li> </ul> Product $ IU $/5,000 IU Swanson D3 5000 IU x 250 softgels (Swanson sale) 8.24 1,250,000 IU 0.03 Swanson D3 5000 IU x 250 softgels (Swanson) 10.99 1,250,000 IU 0.04 Amazon Elements D3 5000 IU x 180 softgels 9.34 900,000 IU 0.05"},{"location":"Health/#vitamin-e","title":"Vitamin E","text":"Vitamin E (alpha-tocopherol) is a lipid soluble antioxidant that interferes with the propagation of lipid radicals. Its efficacy as an antioxidant has been closely associated with that of Vitamin C."},{"location":"Health/#zinc","title":"Zinc","text":"<p>Men who received 30 mg of zinc a day showed increased levels of free testosterone .</p> <p>The tolerable upper intake level for adult men is 40 mg/day.</p> Product $ M $/30 mg Swanson Zinc Gluconate 30 mg a 250 tabs 3.144.49 7.5 0.010.02"},{"location":"Infrastructure/Certifications/","title":"\ud83e\udd47 Certifications","text":""},{"location":"Infrastructure/Certifications/#microsoft","title":"Microsoft","text":""},{"location":"Infrastructure/Certifications/#programming","title":"Programming","text":"Exam Name Links 70-483\u271d Programming in C# :material-file-pdf: :material-amazon: 70-484\u271d Essentials of developing Windows Store apps in C# :material-amazon: 70-485\u271d Advanced Windows Store app development using C# :material-amazon:"},{"location":"Infrastructure/Certifications/#azure-administrator-associate","title":"Azure Administrator Associate","text":"<p>Exams:</p> <ul> <li>AZ-104</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-ai-fundamentals","title":"Azure AI Fundamentals","text":"<p>Exams:</p> <ul> <li>AI-900</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-ai-engineer","title":"Azure AI Engineer","text":"<p>Exams:</p> <ul> <li>AI-100  \u271d</li> <li>AI-102</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-database-administrator-associate","title":"Azure Database Administrator Associate","text":"<p>Exams:</p> <ul> <li>DP-300</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-data-fundamentals","title":"Azure Data Fundamentals","text":"<p>Exams: </p> <ul> <li>DP-900</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-data-engineer-associate","title":"Azure Data Engineer Associate","text":"<p>Exams:</p> <ul> <li>DP-200</li> <li>DP-201</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-data-scientist-associate","title":"Azure Data Scientist Associate","text":"<p>Exams:</p> <ul> <li>DP-100</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-developer-associate","title":"Azure Developer Associate","text":"<p>Exams:</p> <ul> <li>MS-600</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-fundamentals","title":"Azure Fundamentals","text":"<p>Exams:</p> <ul> <li>AZ-900</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-security-engineer-associate","title":"Azure Security Engineer Associate","text":"<p>Exams:</p> <ul> <li>AZ-500</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-solutions-architect-expert","title":"Azure Solutions Architect Expert","text":"<p>Exams:</p> <ul> <li>AZ-303</li> <li>AZ-304</li> </ul>"},{"location":"Infrastructure/Certifications/#azure-stack-hub-operator-associate","title":"Azure Stack Hub Operator Associate","text":"<p>Exams:</p> <ul> <li>AZ-600</li> </ul>"},{"location":"Infrastructure/Certifications/#data-analyst-associate","title":"Data Analyst Associate","text":"<p>Exams:</p> <ul> <li>DA-100</li> </ul>"},{"location":"Infrastructure/Certifications/#devops-engineer-expert","title":"DevOps Engineer Expert","text":"<p>Exams:</p> <ul> <li>AZ-400</li> </ul>"},{"location":"Infrastructure/Certifications/#identity-and-access-administrator-associate","title":"Identity and Access Administrator Associate","text":"<p>Exams:</p> <ul> <li>SC-300</li> </ul>"},{"location":"Infrastructure/Certifications/#information-protection-administrator-associate","title":"Information Protection Administrator Associate","text":"<p>Exams:</p> <ul> <li>SC-400</li> </ul>"},{"location":"Infrastructure/Certifications/#microsoft-365-developer-associate","title":"Microsoft 365 Developer Associate","text":"<p>Exams:</p> <ul> <li>MS-600</li> </ul>"},{"location":"Infrastructure/Certifications/#microsoft-365-enterprise-administrator-expert","title":"Microsoft 365 Enterprise Administrator Expert","text":"<p>Exams:</p> <ul> <li>MS-100</li> <li>MS-101</li> </ul>"},{"location":"Infrastructure/Certifications/#microsoft-365-fundamentals","title":"Microsoft 365 Fundamentals","text":"<p>Exams:</p> <ul> <li>MS-900</li> </ul>"},{"location":"Infrastructure/Certifications/#microsoft-365-messaging-administrator-associate","title":"Microsoft 365 Messaging Administrator Associate","text":"<p>Exams:</p> <ul> <li>MS-203</li> </ul>"},{"location":"Infrastructure/Certifications/#microsoft-365-modern-desktop-administrator","title":"Microsoft 365 Modern Desktop Administrator","text":"<p>Exams:</p> <ul> <li>MD-100</li> <li>MD-100</li> </ul>"},{"location":"Infrastructure/Certifications/#microsoft-365-security-administrator-associate","title":"Microsoft 365 Security Administrator Associate","text":"<p>Exams:</p> <ul> <li>MS-500</li> </ul>"},{"location":"Infrastructure/Certifications/#microsoft-365-teams-administrator-associate","title":"Microsoft 365 Teams Administrator Associate","text":"<p>Exams:</p> <ul> <li>MS-700</li> </ul>"},{"location":"Infrastructure/Certifications/#power-platform-fundamentals","title":"Power Platform Fundamentals","text":"<p>Exams:</p> <ul> <li>PL-900</li> </ul>"},{"location":"Infrastructure/Certifications/#power-platform-app-maker-associate","title":"Power Platform App Maker Associate","text":"<p>Exams:</p> <ul> <li>PL-100</li> </ul>"},{"location":"Infrastructure/Certifications/#power-platform-developer-associate","title":"Power Platform Developer Associate","text":"<p>Exams:</p> <ul> <li>PL-400</li> </ul>"},{"location":"Infrastructure/Certifications/#power-platform-functional-consultant-associate","title":"Power Platform Functional Consultant Associate","text":"<p>Exams:</p> <ul> <li>PL-200</li> </ul>"},{"location":"Infrastructure/Certifications/#power-platform-solution-architect-expert","title":"Power Platform Solution Architect Expert","text":"<p>Exams:</p> <ul> <li>PL-600</li> </ul>"},{"location":"Infrastructure/Certifications/#security-compliance-and-identity-fundamentals","title":"Security, Compliance, and Identity Fundamentals","text":"<p>Exams:</p> <ul> <li>SC-900</li> </ul>"},{"location":"Infrastructure/Certifications/#security-operations-analyst-associate","title":"Security Operations Analyst Associate","text":"<p>Exams:</p> <ul> <li>SC-200</li> </ul>"},{"location":"Infrastructure/Cloud/","title":"\u2601\ufe0f Cloud","text":"Compute  Containers:fontawesome-solid-save: Storage  Network  Development  Big Data  IaaS Azure VMs  EC2 Compute Engine PaaS App Service  Elastic Beanstalk App Engine  Serverless Functions  Lambda  Cloud Functions  Cloud Run Individual containers ACI ECS  Kubernetes AKS EKS GKE Container registry Artifact Registry  Archive Glacier Backups Recovery Services Vault Backup Physical media Data Box Import/Export Service Snowball Transfer Appliance Private networks VNets VPC VPC Security rules Network Security Group (NSG) Security Group Firewall Rules DNS Azure DNS  Route 53  Cloud DNS  NoSQL Cosmos DB  DynamoDB  DocumentDB  Firestore Spanner  CI/CD Azure Devops CodeBuildCodeCommitCodeDeployCodePipeline Cloud Build  Messaging SNS  Pub/Sub  Computer Vision Computer Vision  Rekognition  Cloud Vision  Big Data Data Lake Store Redshift Athena  BigQuery BigTable  Dataprep Streaming data Event HubsService BusStream Analytics KinesisAthena  DataFlow Batch processing HDInsight  Batch  EMR Batch DataFlow Dataproc <p>Links TODO:</p> <ul> <li>Cloud Storage</li> <li>CloudWatch</li> <li>Azure Functions</li> <li>Glacier</li> <li>Google Cloud Storage (GCS)</li> <li>gcloud</li> <li>gsutil</li> <li>Simple Notification Service</li> </ul>"},{"location":"Infrastructure/Cloud/#administration","title":"\ud83d\udee0\ufe0f Administration","text":""},{"location":"Infrastructure/Cloud/#cost-management","title":"\ud83d\udcb0 Cost management","text":"<p>Azure quotas apply to subscriptions and are implemented with tags.</p> <ul> <li>Resource quotas trigger alarms when resource creation and consumption hit a threshold. These are not to be confused with resource limits which can stop resources from being created, whereas quotas can not.</li> <li>Spending quotas trigger alarms when spending has reached a threshold.</li> </ul> <p>Azure budgets can be viewed and administered in the Cost Management + Billing blade.  Users must have at least the Reader role at the subscription scope to view, and Contributor to create and manage, budgets. </p> <p>Resource locks  are used to apply restrictions across all users and roles and can be applied at subscription, resource group, or resource scopes. </p> <ul> <li>CanNotDelete</li> <li>ReadOnly effectively restricts all authorized users to the permissions granted by the Reader role<ul> <li>Storage account keys of a locked storage account cannot be listed because the list keys operation is handled through a POST request</li> <li>Visual Studio Server Explorer will not be able to display files for a locked App Service resource, because that interaction requires write access</li> <li>VMs in a locked resource group will not be able to be started or restarted, because those operations require a POST request</li> </ul> </li> </ul> <p>All child resources of the scope at which a lock is applied inherit the lock. A CanNotDelete lock applied to a DNS A record would also prevent the deletion of the DNS zone that the record resides in, as well as the resource group the zone resides in.</p> <p>Of the builtin roles, only two have access to the <code>Microsoft.Authorization/*</code> or <code>Microsoft.Authorization/locks/*</code> actions required to create or delete locks:</p> <ul> <li>Owner</li> <li>User Access Administrator</li> </ul> <p>Resource locks apply to the management plane of Azure, specifically operations sent to https://management.azure.com</p> <p>Managed applications create two resource groups to implement locks:</p> <ul> <li>One resource group to contain an overview of the service, which isn't locked</li> <li>Another resource group containing the infrastructure for the service, which is locked</li> </ul> <p>Sources:</p> <ul> <li> Move resources to a new resource group or subscription</li> <li>Some services have limitations or requirements when moving resources between groups (src)</li> <li>Source and destination subscriptions must be within the same [AAD][Azure AD] tenant</li> <li>Destination subscription must be registered for the resource provider of the resource being moved</li> <li>Account moving the resources must have at least the following permissions:<ul> <li>Microsoft.Resources/subscriptions/resourceGroups/moveResources/action</li> <li>Microsoft.Resources/subscriptions/resourceGroups/write</li> </ul> </li> </ul>"},{"location":"Infrastructure/Cloud/#iam","title":"IAM","text":"<p>All cloud providers offer IAM systems that are used to control access to resources, all of which establish a similar taxonomy of concepts.</p> <p>The type of user that is granted access to resources is referred to variously as a member  or a security principal .</p> <p>Bundles of specific permissions that can be assigned to users are called roles. All cloud providers offer the ability to define custom roles and come with many ready-to-use role definitions: predefined roles  or built-in roles . Roles form the basis of RBAC, which is the recommended model used by all cloud providers.</p> <p>Roles are associated to users by policies  and role assignments .</p>  gcloud <pre><code>gcloud projects get-iam-policy $project\n</code></pre> <p>The Cloud providers also still support legacy IAM systems which are deprecated.</p> <ul> <li>Classic  administrator roles included Account Administrator, Service Administrator and Co-Administrator</li> <li>Primitive roles  included Owner, Editor, and Viewer can still be applied to most GCP resources.</li> </ul>"},{"location":"Infrastructure/Cloud/#infrastructure","title":"Infrastructure","text":"<p>All cloud providers divide their global services into a hierarchy of geographically defined regions, each of which is in turn divided into availability zones (what AWS calls its Global Infrastructure).</p> <p>Azure datacenters contain multiple availability zones, and every Azure region has at least three availability zones.</p> <p>Azure services are also divided into geographies , generally coterminous with countries. Azure geographies are further divided into regional pairs . Each regional pair receives rolling updates one member at a time.</p> <p>Most services are regionally based, meaning the underlying hardware of that service's instance will exist in only a single Region. Some regions, like AWS GovCloud, have restricted access.</p> <p>Some AWS resources, however, are technically running on hardware that exists in a single Region, but presented as global. </p> <ul> <li>GCP regions </li> </ul> <p>Resources</p> <ul> <li>Services available on Free Tier</li> </ul>"},{"location":"Infrastructure/Cloud/#monitoring","title":"\ud83d\udc41\ufe0f Monitoring","text":"Azure Monitor Network Watcher  CloudWatch  Stackdriver  Trace"},{"location":"Infrastructure/Cloud/#resources","title":"Resources","text":"<p>Cloud providers exhibit some variety in how resources can be organized.</p> <p>All cloud providers support key-value tags, many of which can be applied to the same resource.</p> <p>Any Azure resource can only exist in a single resource group, which can contain resources from any region or subscription. However, resource groups may not contain other resource groups.</p> <p>GCP projects are equivalent to Azure resource groups, in that they are containers for and direct parents to resources. However, projects can be placed within folders, which do support nested hierarchies.</p> <p>AWS does not have an equivalent method of organizing resources.</p> <p>Azure subscriptions can be organized into Management Groups, and they can be nested in a hierarchy of management groups up to a maximum depth of six levels. In AWS the Organizational Unit (OU), which can organize user accounts (subscriptions) and the resources they contain in a nested hierarchy, appears to be equivalent.</p> <p>A pattern common to Azure is that of a service being implemented in two resource types, one of which determines important configuration settings shared by all instances of the service which are contained within it. This is the case for storage accounts, App Service, Azure Data Explorer clusters, etc.</p> Description Tenant Organization Organization Corresponds to a company or organization Management group Organizational Unit Logical container for user accounts and the resources created by that user Subscription Member account ? Credential associated with an individual Folder Organize resources and their parents in a nested hierarchy Resource group Project Logical container that is the direct parent to any resource, tied to a Region Tag Tag Label Key-value pairs that are used to organize resources <p>The resource hierarchy organizes GCP resources in 3 levels below Domain</p> <ul> <li>Domain<ul> <li>Organization corresponds to a company or organization. A single cloud identity is associated with a single organization and can have super admins</li> </ul> </li> </ul> <p>Billing Account tracks charges and billing account admins can set budgets.</p> <p>Payments Profile is a Google-level resource that is used to pay for all Google services.</p>"},{"location":"Infrastructure/Cloud/#support","title":"\ud83d\udee0\ufe0f Support","text":"<p>AWS offers various support plan tiers that provide 24/7 email, chat, and phone access to AWS cloud support engineers.</p> <ul> <li>Basic Support Plan</li> <li>Developer Support Plan (greater of $29 or 3% of monthly account usage)</li> <li>Business Support Plan</li> <li>Enterprise Support Plan (&gt;$15,000/mo.) offers a Technical Account Manager (TAM), a dedicated guide and advocate</li> </ul> <p>AWS documentation is available in several places:</p> <ul> <li>AWS documentation</li> <li>AWS Knowledge Center is a sprawling FAQ</li> <li>AWS security resources</li> <li>AWS forums</li> <li>Professional Services team makes white papers and webinars publicly available</li> </ul>"},{"location":"Infrastructure/Cloud/#tags","title":"Tags","text":"<p>Azure tags:</p> <ul> <li>Tag names have a limit of 512 characters (128 characters for storage accounts) </li> <li>Tag values have a limit of 256 characters. </li> <li>Resources and resource groups are limited to 15 tags. </li> <li>VMs cannot exceed 2048 characters for all tag names and values combined. </li> </ul>"},{"location":"Infrastructure/Cloud/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>All cloud providers support ways of provisioning resources declaratively.  Azure [ARM][ARM] templates are JSON, but [Bicep][Bicep] is a domain-specific language and command-line utility that can be used to generate templates from simpler, YAML-like syntax.</p>"},{"location":"Infrastructure/Cloud/#compute","title":"\ud83d\udda5\ufe0f Compute","text":""},{"location":"Infrastructure/Cloud/#iaas","title":"IaaS","text":"<p>All cloud providers offer Infrastructure as a Service (IaaS), whereby virtual machines can be provisioned with specific compute resources and base operating systems.</p> <p>AWS also offers configuration management services like [OpsWorks][OpsWorks] and [Systems Manager][Systems Manager]</p> <p>GCP virtual machines are referred to as instances, and are available in three general machine family types: general-purpose, memory-optimized, and compute-optimized. Machine type describes the different packaged configurations representing allocated compute resources, or what is called a SKU in Azure.</p>"},{"location":"Infrastructure/Cloud/#containers","title":"Containers","text":"<ul> <li> Build and package container artifacts</li> <li> Private container registry</li> </ul>"},{"location":"Infrastructure/Cloud/#serverless","title":"Serverless","text":""},{"location":"Infrastructure/Cloud/#storage","title":"Storage","text":""},{"location":"Infrastructure/Cloud/#archive","title":"Archive","text":""},{"location":"Infrastructure/Cloud/#backups","title":"Backups","text":"<p>Azure Backup are integrated into Portal and clickable from the VM blade.  You have to specify a Recovery Services vault and a Backup policy.  The policy can specify frequency of backups, and other settings. Using Backup service costs $10 per VM plus the cost of used storage.</p> <p>2 methods to restore data after backing up a VM to Azure Backup:</p> <ol> <li>Restore a recovery point as a new VM</li> <li>Restore access to files only</li> </ol>"},{"location":"Infrastructure/Cloud/#physical-media","title":"Physical media","text":"Data Box Import/Export Service Snowball Transfer Appliance <p> Uploading files to GCS</p>"},{"location":"Infrastructure/Cloud/#networking","title":"\ud83c\udfe2 Networking","text":"<p>All cloud providers offer an implementation of software-defined networking (SDN) that allows a logically isolated network to be defined as a block of IP addresses allocated from one of the private ranges (10.0.0.0/8, 192.168.0.0/16, or 172.16.0.0/12), what in AWS and GCP is referred to as a VPC and in Azure a VNet. In all providers, the network is confined to a single region and must have at least one IP segment called a subnet defined within it which must be a subset of the range used to define the virtual network itself.</p> <p>The smallest possible CIDR range for a subnet in Azure is 29, which provides 3 addresses for use (Azure reserves 5). In AWS, the smallest possible CIDR range is 28. In AWS, VPCs have a default range of 172.31.0.0/16 and subnets have a default subnet mask of /20.</p> <p>In Azure, subnets span Availability Zones, can only be deleted if empty, and their names, which are immutable, must be unique. In AWS, a subnet exists only within a single Availability Zone.</p> <p>VNet peering allows VMs in two separate virtual networks to communicate directly.  In all cloud providers, this is a one-way process which must be repeated in both directions in order to have two-way communication.</p> <p>In Azure, before the introduction of peering, virtual networks were connected using S2S VPN or by connecting to the same ExpressRoute circuit. It is not required for the peered networks to be in the same region (Global VNet peering), subscription, or tenant, although cross-tenant peering is not available in the Portal but must be configured from the command-line or ARM templates. VNet peering has to be disabled before moving a VNet, and a VNet can only be moved within the same subscription.</p> <ul> <li>There is a maximum of 100 peering connections per VNet</li> <li>Peerings cannot be moved to another resource group or subscription, so they must be disabled before moving peered VNets.</li> </ul> <p>Service endpoints facilitate restricting traffic from Azure services.  Service endpoint policies allow restricting traffic to the granularity of individual Azure service instances.</p> <p>An internet gateway is a VPC resource that allows EC2 instances to obtain a public IP address and access the Internet. In order to access the Internet, instances must be in a public subnet, one that contains a default route to the VPC's internet gateway.</p> <ul> <li>ExpressRoute is the main service used to connect Azure to on-premises networks, although P2S and S2S VPNs are also options.</li> <li>Direct Connect provides dedicated network connectivity to an AWS VPC through links offered through APN partners.</li> </ul> <p>In GCP, in addition to peering, a shared VPC can be created that is associated with multiple projects.</p> <p>Resources:</p> <ul> <li> Migrating to GCP? First Things First: VPCs</li> </ul>"},{"location":"Infrastructure/Cloud/#user-defined-routes","title":"User-defined routes","text":"<p>In Azure, a virtual appliance refers to a VM running a network application like a load-balancer, firewall, or router.  Service chaining refers to the process of deploying a network virtual appliance (NVA) into a hub network to route traffic between spokes using user-defined routes (UDR).  This is a method of reducing the complexity of pairing between individual spoke networks in complex hub-and-spoke architectures. AZ-103: 309</p> <ul> <li>In such a deployment, the peerings must be set to Allow Forwarded Traffic.</li> </ul> <p>Alternatively, two peered networks can share a single virtual network gateway, say to connect to an external network.</p> <ul> <li>The pairing connection to the network that contains the gateway must be set to Use Remote Gateways</li> <li>The pairing connection from the network containing the gateway must be set to Allow Gateway Transit</li> </ul>"},{"location":"Infrastructure/Cloud/#network-security","title":"Network security","text":"Network Security Group (NSG) Security Group Firewall Rules <p>Azure Network Security Groups (NSGs) are associated with network interfaces and contain an arbitrary number of security rules. Each rule has the following properties:</p> <ul> <li>Name</li> <li>Priority: number between 100 and 4096, lower numbers indicate a higher priority</li> <li>Source or destination: IP address, CIDR block, service tag, or application security group</li> <li>Protocol: <code>TCP</code>, <code>UDP</code>, <code>ICMP</code>, or <code>Any</code></li> <li>Direction: Inbound or outbound</li> <li>Port range; </li> <li>Action: allow or deny</li> </ul> <p>Service tags represent a group of IP address prefixes managed by Microsoft available for use in NSG rules:</p> <ul> <li><code>VirtualNetwork</code>: all CIDR ranges defined for the virtual network, all connected on-premises address spaces, peered VNets or VNets connected to a VNET gateway</li> <li><code>AzureLoadBalancer</code>: Virtual IP address of the host where Azure's health probes originate</li> <li><code>Internet</code>: IP address space that is outside the virtual network</li> <li><code>AzureCloud*</code>: IP address space for Azure, including all datacenter public IP addresses</li> <li><code>AzureTrafficManager*</code>: IP address space for the Azure Traffic Manager probe IP addresses</li> <li><code>Storage</code>:</li> </ul> <p>NSG flow logging ,which saves the 5-tuple of all packets, is available as a low-cost way to monitor traffic. Flow logs record all IP flows going in and out of an NSG and are collected per NSG rule. They are charged per GB of logs collected and include a free tier of 5 GB/month.</p> <p>In AWS VPCs, Security Groups are similar to firewall rules that regulate inbound and outbound traffic of an instance. Outbound traffic is unrestricted by default, and every VPC contains a default security group.</p> <p>A network access control lists (NACLs), also like a firewall, contains inbound and outbound rules but operates on the subnet. By default, a NACL allows all inbound and outbound traffic.</p> <p>In GCP, each VPC has a set of firewall rules that control traffic not only into and out of the VPC, but between instances in the same VPC. Each rule can be tagged, and individual instances with the same tags inherit those rules.</p> <p>Resources:</p> <ul> <li> Protect your Google Cloud Instances with Firewall Rules</li> </ul>"},{"location":"Infrastructure/Cloud/#dns","title":"DNS","text":"Azure DNS  Route 53  Cloud DNS"},{"location":"Infrastructure/Cloud/#cdn","title":"CDN","text":"<p>Users can use Azure CDN as a cache, reducing load from website.  Content is cached by the CDN until its time-to-live (TTL) elapses, which can be controlled in the HTTP response from the origin server.</p> <p>Permanently removing content from the CDN requires it be first removed from the origin servers, meaning if the content is in a storage account it should be set to private or deleted from the storage, or the container itself should be deleted.  Cached copies may remain in the CDN endpoint until the TTL has expired, unless it is purged.</p> <p>There are 4 pricing tiers available within Azure CDN:</p> <ul> <li>Azure CDN Standard from Microsoft does not offer dynamic site acceleration (DSA) (cf. Azure Front Door Service)</li> <li>Azure CDN Standard from Akamai</li> <li>Azure CDN Standard from Verizon</li> <li> <p>Azure CDN Premium from Verizon, for which caching is configured using a rules engine.</p> </li> <li> <p>AWS</p> <ul> <li>CloudFront</li> </ul> </li> <li>GCP<ul> <li>CDN</li> </ul> </li> </ul>"},{"location":"Infrastructure/Cloud/#load-balancing","title":"Load-balancing","text":"<ul> <li>Azure<ul> <li>Load Balancer</li> <li>Application Gateway</li> </ul> </li> <li>AWS<ul> <li>Elastic Load Balancer</li> </ul> </li> <li>GCP<ul> <li>Load balancing</li> </ul> </li> </ul>"},{"location":"Infrastructure/Cloud/#development","title":"\ud83d\udc68\u200d\ud83d\udcbb Development","text":""},{"location":"Infrastructure/Cloud/#nosql","title":"NoSQL","text":"<p>NoSQL databases differ from relational databases in that they do not obey the principle of data normalization. That is, the same data can be stored in more than one place.</p> <p>This is an advantage for databases that are optimized for reads as opposed to writes, because fewer queries are needed to retrieve information. However, when changing information that is duplicated in several places, write operations will be more laborious and prone to error. NoSQL databases are also horizontally scalable because the information can be sharded horizontally more easily than relational database, which are only vertically scalable (meaning scaling them requires larger and larger computers) and can only be sharded vertically. (src)</p>"},{"location":"Infrastructure/Cloud/#big-data","title":"Big Data","text":""},{"location":"Infrastructure/Cloud/#history","title":"History","text":"<p>Beginning in 2000, Amazon began developing Merchant.com, a planned e-commerce service that was intended to be the base upon which other enterprises would develop online shopping sites. At the time, Amazon's development environment was a jumbled mess, and in the effort to consolidate and organize the enterprise into a set of well-documented APIs.</p> <p>Despite these changes, software development remained sluggish, and an investigation discovered that individual teams were procuring storage, compute, and database resources independently. AWS originated out of the effort to consolidate these resources across the enterprise and remove this bottleneck.</p> <p>Azure was announced in 2008 and publicly released in 2010 after earlier experiments in cloud computing like Whitehorse and RedDog.  In fact, references to the \"classic\" model predating the Azure Resource Manager (ARM) actually refer to RedDog: the \"classic\" portal was also known as \"RedDog Front-End\".</p>"},{"location":"Infrastructure/Cloud/#glossary","title":"\ud83d\udcd8 Glossary","text":"Apigee The Apigee API platform is a management service that allows developers to deploy, monitor, and secure their APIs and generates API proxies. App Engine <p>App Engine allows developers to deploy applications developed in popular programming languages to a serverless environment. It is available in two environment types: Standard and Flexible.</p> <ul> <li>Standard environment is the original App Engine environment, consisting of a preconfigured, language-specific runtime like Java, Python, PHP, Node.js, or Go.</li> <li>Flexible environment is similar to [GKE][GKE] in that it can run a customized container.</li> </ul> <p>App Engine is designed to support applications implemented as a microservices architecture. There are four components:</p> <ul> <li>The application is the top-level container that houses all other components.</li> <li>Services are versioned and provide a specific function.</li> <li>Versions are produced every time a service is updated.</li> <li>Every version runs on an instance.</li> </ul> <p>Each version of a service runs on its own instance, whose size can be determined by specifying the instance class. Instances can be dynamic or resident.</p> <ul> <li>Resident instances run continually and can be added or removed manually.</li> <li>Dynamic instances support autoscaling based on load.</li> </ul> <p>App Engine has three modes of scaling:</p> <ul> <li>Automatic scaling creates an instance with a specified request rate, response latency, and application metrics.</li> <li>Basic scaling creates instances only when requests are received</li> <li>Manual scaling supports operational continuity regardless of load level.</li> </ul> App Engine Deployer Read-only access to all application configuration and settings. App Engine Service Admin Read-only access to all application configuration and settings. Write access to module-level and version-level settings. Cannot deploy a new version. App Service <p>An App Service plan resource determines the billable compute resources available for the App Services applications managed by it. A plan acts as a container for multiple web applications sharing the same server farm (\"workers\"), and for this reason Windows and Linux apps can't be mixed in the same App Service plan. \"Web app\" is the legacy name for Azure App Service.</p> <p>App Service SSL certificates need to be deleted from each App Service before moving it to a new resource group.</p> Application Gateway <p>Azure Application Gateway is used to load balance a large-scale set using more than 100 instances in place of Azure Load Balancer. AZ-103: p. 223</p> <p>Application Gateway supports session affinity to save user state using browser cookies.</p> <p>Unlike Azure Load Balancer, which operates at OSI layer 4 and has limited security capabilities, Application Gateway operates at OSI layer 7 and provides Web Application Firewall (WAF) functioanlity to block attacks like SQL injection, cross-site scripting, and header injection. HTTPS is also only available with layer 7 load balancers like Application Gateway.</p> Athena Athena is a serverless AWS service that allows SQL queries to be run against data stored in a [S3][S3] bucket. Athena works closely with [AWS Glue][AWS Glue] to extract schema information and crawl data sources. Before running for the first time, you must provide a path to a S3 bucket to store query results. AWS CLI AWS CLI is version 1 is maintained for legacy compatibility purposes. AWS Developer Tools <p>A collection of tools that provide CI services:</p> <ul> <li>CodeCommit</li> <li>CodeBuild</li> <li>CodeDeploy</li> <li>CodePipeline</li> </ul> AWS Glue AzCopy AzCopy can be used to copy files to File storage. Azure Bastion <p>Azure Bastion is a PaaS service deployed within a VNet that allows connectivity to a VM from the Portal.  Once deployed in a VNet, RDP/SSH is available to all VMs in that VNet.  This session is streamed to your local device over an HTMLS session using the browser.</p> <ul> <li>It is not deployed per VM, but once per VNet to its own dedicated subnet, at least /27 or larger</li> <li>No public IP is necessary on the VM, the connection from Bastion to the VM is to the private IP. However, the Bastion itself does require a public IP.</li> <li>Bastion can now span peered VNets</li> </ul> <p>IPv6 support is limited in Azure.  IPv6 addresses are not added to VMs by default and  must be explicitly defined by adding an endpoint to each VM to be using it.  Routing by IPv6 is also not supported, so load balancers have to be deployed.</p> Bicep  <p>Project Bicep is a domain-specific language and command-line utility that can be used to generate [ARM][ARM] templates.</p> <p> Project Bicep \u2013 Next generation ARM Templates</p> Azure Container Instances <p>Azure Container Instances (ACI) allows a simpler way of running isolated containers in smaller-scale deployments than Azure Kubernetes Service.</p> <p>The top-level resource in ACI is the container group, a collection of containers that get scheduled on the same host machine.  These containers share a lifecycle, resources, local network, and storage volumes, and is equivalent to a Kubernetes pod.  Container groups can be deployed to a subnet that already hosts a container group or an empty one, but it may not be deployed to a subnet that already has other resources like VMs.</p> Azure Data Explorer <p>Azure Data Explorer (ADX) has two architectural elements:</p> <ul> <li>Data Management</li> <li>Engine</li> </ul> <p>ADX does not hold large tables in a single table, rather it automatically shards them into Extents</p> Azure DevOps <p>Azure DevOps used to be known as Visual Studio Team Services and Team Foundation Server.</p> <p>Install DevOps CLI <pre><code>az extension add --name azure-devops\n</code></pre></p> Azure DNS <p>Azure DNS supports private zones, which provide name resolution for VMs on a VNet and between VNets without having to create a custom DNS solution.</p> <p>Time-to-live for DNS record sets is provided in seconds.</p> <p>Azure DNS alias records allow other Azure resources to be referenced from the DNS zone, rather than static IP addresses or domain names.  This allows these records to be automatically updated or deleted when the underlying Azure resource is changed.</p> <ul> <li>An A alias record set is a special type of record set that allows you to create an alternative name for a record set in your domain zone or for resources in your subscription.</li> <li>A CNAME alias record set can only point to another CNAME record set. Custom domains can be used by implementing CNAME DNS records, which are used in DNS to map alias domain names to the \"canonical\" name.</li> </ul> Azure File Service <p>Azure File Service allows you to create one or more file shares in the cloud (up to 5 TB per share), similar to a regular Windows File Server.  It supports the SMB protocol, so you can connect directly to a file share from outside of Azure, if traffic to port 445 is allowed through the LAN and ISP. It can also be mapped within Windows.</p> <p>A clever use of a file share is as persistent storage for the Azure Cloud Shell. src</p> Azure File Sync <p>Azure File Sync extends Azure File Service to allow on-premises file services to be extended to Azure while maintaining performance and compatibility, communicating over TCP 443 over SSL, and not IPSec. </p> <p>Use cases include:</p> <ul> <li>Replace on-premises file servers</li> <li>Easily replicate data on-premises to make it available during lift-and-shift migrations</li> <li>Simply cloud development and management</li> </ul> <p>Azure File Sync works using an Azure File Sync agent, available as an MSI package for Windows Server 2012R2, 2016, and 2019, to register file servers as endpoints to an Azure File Sync Group.  After installation, Azure credentials for a subscription must be provided. AZ-103: 153</p> <p>In order to create an Azure File Sync, first a Storage Sync Service resource must be created, which works like a container to hold one or more sync groups.  Every sync group has only a single cloud endpoint, referring to a storage account, but can have more than one server endpoint.  Any server can only be registered to a single Storage Sync Service, and servers synced to different Storage Sync Service resources cannot sync with each other.</p> <p>Cloud tiering is an optional feature in Azure File Sync in which frequently accessed files are cached in the on-prem file servers, while less commonly accessed files are tiered to Azure Files. This is done by enabling Cloud Tiering, then selecting a free space policy, a percentage which indicates the amount of free space to maintain on the server endpoint's volume. When a user does access one of these tiered files, that file is downloaded to the on-prem cache and made available locally from that point on. This frees up local storage.</p> <ul> <li>Cloud tiering cannot be used with server endpoints on the system volume</li> <li>Although server endpoints can be configured with different free space policies, the most restrictive setting takes effect</li> <li>For tiered files, the file will be partially downloaded as needed</li> <li>Although a mount point can be a server endpoint, there can be no mount points inside a server endpoint</li> </ul> <p>When a filename collision occurs between the file share and file server, the file on the server has its filename appended with the server's name.</p> Azure Policy <p>Azure Policy is a service that can create, assign, and manage policies to enforce governance. Policy definitions, authored in JSON, implement policy by describing desired behavior for Azure resources when they are created or updated. AZ-103: p. 72</p> <p>To implement policy, a policy definition is created first, then a policy assignment assigns it to a scope. Policy definitions can be packaged together using initiative definitions and applied to a scope using initiative assignments</p> <p>RBAC roles deny by default and allow explicitly. But Azure Policy allows by default and denies explicitly</p> <p>Policies can be applied at the management group, subscription, or resource group scope, with all child resources and resource groups being affected.</p> <p>Every policy definition has a single effect, which includes:</p> <ul> <li>Audit: create a warning event in the log</li> <li>Modify: used to add, update, or remove properties or tags on a resource during creation or update.</li> <li>Append</li> <li>AuditIfNotExists</li> <li>Deny</li> <li>DeployIfNotExists</li> <li>Disabled</li> </ul> <p>The order of evaluation of effects is: Disabled, Append, Deny, Audit (\"DADA\")</p> Azure VMs <p>Virtual Machines represent Azure's IaaS offering.</p> <p>A dedicated host group has to be created and placed in a resource group and associated with a location and availability zone and assigned a fault domain. A host then has to be created, a size specified, and associated with a host group. Any VM intended to run on the host has to be created in the same location and availability zone and associated with the host in the Advanced tab.</p> <p>Azure spot instances are available at deep discounts.</p> <p>3 types of disk are available to Azure VMs:</p> <ul> <li>Operating System Disk (OS Disk)</li> <li>Temporary Disk</li> <li>Data Disk</li> </ul> <p>Azure VM image types include:</p> <ul> <li>Managed images (recommended), which remove the dependency of the VM to the image, at least within the same region.  Copying a VM to another region still requires the managed image to be copied first.</li> <li>Unmanaged images, which required the VM to be created in the same storage account as that of the image.  VM copies required the image to be copies first.</li> </ul> <p>VM images are captured from an existing VM that has been generalized (prepared), removing unique settings (hostname, security IDs, personal information, user accounts, domain join information, etc) but not customizations (software installations, patches, additional files, folders), using <code>sysprep.exe</code> for Windows machines or Microsoft Azure Linux Agent (<code>waagent</code>) for Linux machines.</p> <p>VM images in AWS are called Amazon Machine Images (AMI).</p> Azure VPN <p>Virtual network gateways in Azure are of two types: VPN gateways and ExpressRoute gateways. Any virtual network can have only a single gateway of each type.</p> <p>VPN gateways send encrypted traffic between the virtual network and an on-premises location. VPN Gateways must be deployed into their own dedicated subnet (named \"GatewaySubnet\") with a minimum size of CIDR /29, although a CIDR /27 address block is recommended. VPN connections between an on-premises network and a VNet are only possible if the network ranges do not overlap.</p> <p>VPN gateways can be classified by the topology of the connection:</p> <ul> <li>Site-to-Site (S2S) connections require an on-premises VPN device associated with a public IP address.</li> <li>Multi-Site connections require a RouteBased VPN type. </li> <li>Point-to-Site (P2S) allows individual computers to securely connect to a VNet without need for a VPN device, which is useful for telecommuting, and can use SSTP, OpenVPN, or IKEv2. There are several authentication considerations.</li> <li>VNet-to-VNet connections are also possible, but VNet peering may be preferable if the virtual networks meet certain requirements.</li> </ul> Site-to-SiteMulti-SitePoint-to-SiteVNet-to-VNet <p></p> <p></p> <p></p> <p></p> <p>VPN gateways can also be classified on VPN type. </p> <ul> <li>Route-based VPNs (previously called \"dynamic routing gateways\") require routes to be defined in a routing table to direct packets into tunnel interfaces.</li> <li>Policy-based VPNs (previously called \"static routing gateways\" in the classic deployment model) can only be used on the Basic gateway SKU and offer only a single S2S tunnel.</li> </ul> Route-basedPolicy-based <p></p> <p></p> <p>There is a profusion of Gateway SKUs that determine the maximum connections, throughput, and availability of other features like BGP and zone-redundancy available for each topology.</p> <p>Every Azure VPN gateway consists of two instances in an active-standby configuration. During failover, a brief interruption of 10-15 seconds for planned maintenance or up to 60-90 seconds in the case of unplanned disruption, may occur. But the gateway can be configured to be active-active, which will establish S2S VPN tunnels to both gateway instances with traffic being routed through both tunnels simultaneously. There will still be only a single connection resource, but the on-premises VPN device must be configured to establish both of these tunnels. The most highly available arrangement would use multiple VPN devices with the VPN gateway in active-active configuration, creating 4 IPsec tunnels that evenly carry Azure traffic. </p> Active-StandbyActive-ActiveDual redundancy <p></p> <p></p> <p></p> Bigquery Petabyte-scale analytics database service for data warehousing. BigQuery can be executed using the bq command-line utility. BigTable <p>GCP realtime database used for Big Data. BigTable can be executed using the cbt command-line utility. BigTable evolved out of Google's need to ensure access to petabytes of data in its web search business line. It was described in a 2006 research paper that ended up launching the entire NoSQL industry. In 2015 it was made available as a service to cloud customers. src</p> <p>BigTable doesn't support secondary indexes. </p> Billing Account Administrator GCP predefined role that grants permissions to manage self-service accounts but not to create new ones. Billing Account Creator Predefined GCP role that grants permissions to create new self-service accounts. Billing Account User GCP predefined role that enables user to link projects to a billing account. Billing Account Viewer GCP predefined role that grants permissions to view transactional and billing data associated to a GCP account. Cloud AutoML GCP service that allows developers without machine learning experience to develop machine learning models. Cloud Device Administrator : Azure built-in role that grants users full access to manage devices in Azure AD.  Cloud Functions GCP serverless compute offering suited to running short-running logic, such as calling other APIs in response to an event. Cloud IAM <p>GCP's identity and access management platform.</p> <p>Permissions include:</p> <ul> <li>roles/container.admin</li> <li>roles/container.clusterAdmin</li> <li>roles/container.clusterViewer</li> <li>roles/container.developer</li> <li>roles/container.hostServiceAgentUser</li> </ul> <p>Predefined roles include:</p> <ul> <li>App Engine Deployer</li> <li>App Engine Service Admin</li> <li>Billing Account Administrator</li> <li>Billing Account Creator</li> <li>Billing Account User</li> <li>Billing Account Viewer</li> <li>Compute Engine Admin</li> <li>Compute Engine Network Admin</li> <li>Compute Engine Security Admin</li> <li>Compute Engine Viewer</li> <li>Compute Service Agent</li> <li>Folder Admin</li> <li>Project Creator</li> <li>Shared VPC Admin</li> </ul> Cloud Machine Learning Engine Platform for building and deploying scalable machine learning systems to production. Cloud Natural Language Processing GCP tool for analyzing human languages and extracting information from text. Cloud Run <p>Google Cloud Run is built on a native open standard that will allow using the same container on other cloud providers. It bills down to the nearest 100 ms interval. Cloud Run provides an HTTPS endpoint to the container.</p> <p>Cloud Run can also run on your own K8S cluster running on [GKE][GKE], recommended for workloads that have a consistently high level of traffic, since you are billed for the provisioned cluster resources. However, resources like CPU, GPU, and other items can be customized.</p> Cloud Vision Image analysis platform for annotating images with metadata, extracting text, or filtering content. CloudFormation <p>AWS declarative automation service, which can use JSON or YAML-format templates. These resources are placed into a named stack, a container that organizes the resources described by the template, and the stack name must be unique to the account. This allows provisioned resources to be easily managed, since the stack contains a record of events, and to be quickly destroyed by deleting the stack.</p> <p>CloudFormation Designer allows templates to be viewed as a diagram of resources.</p> CloudFront <p>AWS CDN offering that helps deliver static and dynamic content worldwide. CloudFront caches content in edge locations, of which there are more than 150 spread out across 6 continents. Edge locations may not be chosen arbitrarily, rather there are three options:</p> <ul> <li>US, Canada, and Europe</li> <li>US, Canada, Europe, Asia, and Africa</li> <li>All edge locations</li> </ul> <p>In order to make content available on CloudFront, you must create a distribution, which defines the type and origin of the content to cache. There are two types of distribution:</p> <ul> <li>A Web distribution is used for static and dynamic content, including streaming video, accessible via HTTP or HTTPS. Its origin can be a web server or a public S3 bucket.</li> <li>Real-Time Messaging Protocol (RTMP) distribution delivers streaming audio or video. The media player and media files must be stored in S3 buckets.</li> </ul> CloudTrail <p>AWS service that logs actions against AWS resources. These events are divided into API and non-API actions.</p> <ul> <li>API actions include creating, modifying, or deleting resources.</li> <li>Non-API actions include everything else, like logging into the management console.</li> </ul> <p>Events are also classified as management events and data events</p> <ul> <li>Management events (also control plane operations) are operations that a principal attempts to execute against an AWS resource.</li> <li>Data events are S3 object-level activity and Lambda function executions. These are treated separately from management events because they tend to be higher volume.</li> </ul> CloudWatch <p>Amazon CloudWatch collects logs, metrics, and events from AWS resources and non-AWS on-premises servers and presents a dashboard for visual analysis. All AWS resources automatically send their metrics to CloudWatch Metrics, which stores the data for up to 15 months. CloudWatch alarms can be configured for single metrics.</p> <p>Applications and AWS services have to be configured to send log events to CloudWatch Logs, and they are stored indefinitely by default although retention settings can be configured. Log events from the same source are organized into a log stream. Log streams are then organized into log groups. Metric filters extract metric data from log events.</p> <p>CloudWatch Events is a feature that monitors for changes in AWS resources as a result of API operations.</p> Cloudyn Previously a standalone service available in Azure, now deprecated because its functionality has been incorporated natively into other sections of the Cost Management + Billing blade. CodeCommit AWS private git repo service. CodeDeploy AWS service for automatically deploying applications to AWS compute resources or on-prem servers. CodeDeploy can pull source code from [S3][S3] and repos from GitHub or Bitbucket but notably not CodeCommit (ref. CodePipeline). CodePipeline AWS service for orchestrating and automating every stage of software development. It defines a series of stages, two of which are required - source and deployment - but other stages like testing or approval can be incorporated. Cognito AWS service that integrates with identity providers like Amazon, Google, Microsoft, and Facebook to add user access control to an application. Compute Engine <p>Compute Engine is GCP's IaaS offering. An instance group is a collection of VM instances that you can manage as a single entity. </p> <p>Two types:</p> <ul> <li>Managed instance groups operate applications like web front-ends across a group of identical VMs created with a template. They provide high availability, healing, scaling, and automatic updates.</li> <li> <p>Unmanaged instance groups allow you to manually load balance a group of VMs. VMs can be added or removed at will.</p> </li> <li> <p> Getting started with GCE</p> </li> </ul> Compute Engine Admin Predefined GCP role that grants full control of Compute Engine resources. Compute Engine Network Admin Predefined GCP role that grants full control of Compute Engine networking resources. Compute Engine Security Admin Predefined GCP role that grants full control of Compute Engine security resources. Compute Engine Viewer Predefined GCP role that grans read-only access to all Compute Engine resources, but exclusive of data stored on disks, images, and snapshots. Compute Service Agent Predefined GCP role that grants Compute Engine Service Account access to assert service account authority. Computer Vision subfield of artificial intelligence concerned with developing the capability of computers to recognize objects in images and to understand visual information. Container Instances Azure Container Instances (ACI) is a PaaS service that facilitates deployment of individual containers. CosmosDB <p>Azure NoSQL offering. Cosmos DB started as Project Florence in 2010 to address shortcomings with SQL Server in supporting highly available services like Xbox.  In 2015 the product was relaunched as Document DB, then renamed Cosmos DB in 2017.</p> <p>An emulator is available for Cosmos DB here.  A Cosmos DB account can be used for free for 30 days, and does not require an Azure subscription.</p> <p>Throughput is measured and billed in Request Units (RU) per second. The minimum manually provisioned throughput level is 400 RU/sec.</p> <p>There are three throughput provisioning offers:</p> <ul> <li>Manual, where a static throughput level is provisioned. This is best for highly predictable workloads.</li> <li>Autoscaling, where Azure will automatically scale throughput based on usage, reducing it down to a minimum of 10% of the provisioned throughput.</li> <li>Serverless, where you pay for only the RUs you need. This throughput provisioning model is ideal for small demonstration projects. This feature is forthcoming.</li> </ul> <p>The cost of using a CosmosDB database can be approximated using the Capacity calculator.  In general, these are reasonable back-of-hand estimates for common operations to estimate costs:</p> <ul> <li>Read item: 1 RU</li> <li>SQL query: ~2.8 RU</li> <li>Create item: 10 RU</li> </ul> <p>There are various choices of API for Cosmos DB accounts which affect the data model used for databases.</p> <ul> <li>SQL API is the Core API, and works off JSON documents and SQL query syntax</li> <li>MongoDB API uses BSON documents (binary encoded JSON) and MongoDB query syntax</li> <li>Table API and uses Key-Value database design reflects API of Azure Table Storage</li> <li>Gremlin API is a graph database using a flat store of vertices and edges</li> <li>Cassandra API is columnar, and unlike most NoSQL databases does specify a schema</li> </ul> Consistency <p>Uniformity of data across replicas in a distributed database.</p> <p>Consistency levels  describe how and when data is replicated to provide varying consistency guarantees.</p> <ul> <li>Strong consistency is the strongest consistency model and requires synchronous replication after every change to database, increasing latency for each write.</li> <li>Session consistency is unique, in that it offers consistent prefix to databases that support a single session or an application with a single token. </li> <li>Eventual consistency is the weakest consistency model and provides no ordering guarantees. Consistent prefix offers read throughput, availability, and write latency comparable to eventual consistency while guaranteeing global order.</li> <li>Bounded staleness implies asynchronous replication and offers guarantees on the number of versions (K) or time interval (T) reads lag behind writes, referred to as the staleness window.  As the staleness window approaches, Azure will delay writes by providing back pressure on writes. <ul> <li>Outside the staleness window, data is guaranteed to be globally consistent. </li> <li>Outside the region in which the writes were made, Azure guarantees total global order or consistent prefix, which means, the global order is maintained.</li> </ul> </li> </ul> StrongSessionEventualBounded staleness <p></p> <p></p> <p></p> <p></p> <p>Horizontal partitioning is what allows Cosmos DB to scale-out massively to provide high availability and elasticity.  Partitions can be thought of as physical fixed-capacity data buckets that back every container.  A partition split occurs when a new physical partition is brought online, resulting in half of the documents existing on a previously existing partition being moved to the new one. Cosmos DB automatically and transparently splits horizontal partitions to achieve elasticity. Logical partitions, determined by the partition key which is set at container creation, group individual documents in ways that are kept on the same physical partition.  It is recommended to have a high number of logical partitions, so that CosmosDB has greater flexibility partitioning documents. The partition key is immutable, so the correct choice of partition key is an important architectural consideration. Even distribution of documents is ideal to avoid hot partitions, where some partitions have much greater activity than others, due to uneven distribution of documents. Any partition may not be greater than 20 GB in size. Physical partitions have 4 replicas within a region.</p> <p>There are several common partitioning patterns:</p> <ul> <li>Partitioning on <code>/id</code>, which results in every document existing in its own logical partition. This pattern is write-optimized and ideal for IoT applications. Any SQL query for more than one document would be cross-partition by necessity, so direct reads using the <code>/id</code> value would be far more economical.</li> <li>Partitioning small lookup lists on a <code>/type</code> property. This will keep lists of related items used for lookups in the same partition.</li> <li>Optimizing for queries by organizing multiple types of document according to a key data-point. For example, customer data could be kept in the same partition as that customer's orders, avoiding cross-partition queries.</li> </ul> Cost Management Contributor Azure built-in role that grants access to the Cost Management blade. Cost Management Reader Azure built-in role that grants access to the Cost Management blade. Data Box <p>Microsoft-provided appliance that allows for the transfer of large volumes of data to Azure, available only to EA, CSP, and Microsoft Partner Network Sponsorship offer types.</p> <p>Workflow</p> <ol> <li>Order: Use Portal to order a data box by creating a Data Box resource</li> <li>Receive: Connect Data Box to network</li> <li>Copy data: Mount file shares and copy data to the device.</li> <li>Return: to Microsoft</li> <li>Upload: Microsoft will upload the data and securely erase it from the device</li> </ol> Offering Capacity Storage saccounts Data Box Disk 35 TB 1 Data Box 100 TB 10 Data Box Heavy 1,000 TB 10 Dataflow GCP streaming data framework for defining both batch and stream processing pipelines. Dataprep GCP managed service that allows analysts to visually explore, clean, and prepare data for later analysis. Dataproc GCP service that manages the creation of data science clusters and data analysis jobs. DynamoDB: NoSQL database known for fast (1-9 ms) query times. <p>DynamoDB measures capacity in Read Capacity Units (RCU) and Write Capacity Units (WCU).</p> <ul> <li>1 RCU = 1 record at most 4 KB in size</li> <li>1 WCU = 1 record at most 1 KB in size</li> </ul> <p>DynamoDB offers the choice between strongly consistent and eventually consistent (half the cost) reads. </p> <p>DynamoDB offers two types of indexes: </p> <ul> <li>Global Secondary Index allows you to create a completely new aggregation of data. GSI updates are eventually consistent, with asynchronous updates populated after an update response is passed to the client.</li> <li>Local Secondary Index (LSI) alternate sort key attribute that allows only sorting</li> </ul> <p>DynamoDB Streams (changelog for the DynamoDB table) interfaces with AWS Lambda to implement complex queries, computed values like sum, average, maximum, etc.  These are implemented in a different processing space than the DynamoDB table itself, so that it does not affect the table.</p> <p>AWS Lambda has an invocation role which defines what Lambda can see (triggered upon a change to the table as reported in DynamoDB Streams) and an execution role which defines what it can do.</p> <p>Elastic Container Service</p> <p>Elastic Kubernetes Service</p> <p>Elastic Beanstalk:  AWS PaaS offering.</p> Elastic File System: Scalable file system for AWS Linux instances that allows multiple instances to be attached to a single EFS volume to share files. EFS volumes are highly available, spanning multiple Availability Zones in a single VPC. <p>Elastic MapReduce: AWS's managed Big Data analysis service, supporting Apache Hadoop, Apache Spark, HBase, Presto, and Flink.</p> Enterprise Agreement <p>Azure customers on an Enterprise Agreement can add up-front commitments to Azure then be billed annually.  If the committed spend is exceeded, the overage is billed at the same EA rate.  EA customers can create spending quotas and set notification thresholds through the EA Portal.</p> <p>3 portals used to manage Azure subscriptions</p> <ol> <li>EA Portal (ea.azure.com) available only to customers with an Enterprise Agreement</li> <li>Account Portal</li> <li>Azure Portal, includes Azure Cost Management</li> </ol> ExpressRoute There are four main architectures used with ExpressRoute <ul> <li>Any-to-any connection is used to integrate on-premises WANs using IPVPN.</li> <li>Co-location with cloud exchange is used to order virtual cross-connections to the Azure cloud through the co-location provider's Ethernet exchange.</li> <li>Point-to-point Ethernet connection is used to configure on-premises data center connectivity to Azure through individual point-to-point links</li> </ul> Firebase: GCP NoSQL database offering known for its client libraries. Firebase Auth offers a free user interface for applications, Firebase UI. Firestore was released from beta in early 2019 and combines and improves upon functionality of previous products named Cloud Datastore and Firebase Realtime Database. <p>Firestore is organized into documents, which consist of key-value pairs and are similar to JSON objects, and collections.  JSON-like objects are called maps and keys are called fields in Firestore.  Collections can contain only documents, but documents can contain sub-collections.  Root can only contain collections. So navigating deeper and deeper into the information store will involve alternating between collections and documents. </p> <p>Firestore features a compatibility mode that emulates the behavior of Datastore in accessing Firestore's storage layer while removing some of Datastore's limitations.</p> <p>Queries in Firestore can only be used to find documents stored in one specific collection or sub-collection. However a collection group query, meaning one that spans multiple collections, began to be supported in 2019. Complex relational queries are not possible (in a single query), and query results are usually returned based on equality or greater-than/less-than comparisons. The field has to be specified as having a scope of \"Collection group\" within GCP, and there is a limit of (about) 200 for these queries. </p> <p>An index is created for every field in every document added to a collection, which results in very fast query times that are proportional to the number of results, not records searched.  This structure ensures that equality searches are highly performant, as are comparison searches using greater-than or less-than. But this implementation creates bizarre limitations to Firestore's querying capabilities: There is no native way to perform wildcard searches or <code>OR</code> queries.  For common instances of such queries, Google recommends adding a field that contains the value for each record </p> <p>Inequality searches present a challenge for Firestore. For some queries that combine conditions on more than one field (i.e. restaurants within a certain range of a location), Firebase will create a \"composite index\" (only within the index, the document itself is not affected) automatically to facilitate searches on those fields.</p> <p>Unlike Firebase, which charges based on the volume of data stored, Firestore charges based on number of operations performed and records returned.</p> <p>Folder Admin: Predefined GCP role that allows folders to be created at an Organization.</p> <p>Front Door: Azure offering that works like Azure Load Balancer for web apps.</p> Glacier: AWS storage service that offers long-term archival at low cost. <p>One or more files are stored in an archive, typically a .zip or .tar file containing multiple files. Archives can range from 1 B to 40 TB in size.</p> <p>Archives are stored in a Glacier vault, a region-specific container analogous to S3 buckets. Vaults must have regionally unique names, but there is no need for a globally unique name.</p> <p>Glacier vaults can be created and deleted using the Glacier service console. But uploading, downloading, or deleting archives must be done through the AWS CLI or an application using the SDK. Some third-party applications can also interact with Glacier.</p> Google Cloud Identity Google's IDaaS provider."},{"location":"Infrastructure/Cloud/#gke","title":"GKE","text":"<p>Clusters have two modes of operation, Standard and Autopilot , that offer a more configurable and a more managed experience respectively.</p> <p>In GKE, clusters are billed at a flat fee of $0.10 per cluster hour .  The GKE free tier provides $74.40 in monthly credits per billing account, available to Autopilot and Standard zonal clusters but not Standard regional  clusters. Note that there are 744 hours in a 31-day month, and the free tier monthly credit corresponds to exactly this amount of usage for a single cluster.</p> Import/Export Service <p>Azure service that allows the physical shipment of disks procured by the user to Azure for import into a storage account , which can be placed into blob or file storage. This service requires the use of a Windows computer with BitLocker and .NET Framework and is dependent on the WAImportExport.exe  utility.</p> <ol> <li>Procure 2.5-inch or 3.5-inch SATA (not SAS) disks</li> <li>Connect the disks to a Windows machine.</li> <li>Create a volume and encrypt it using BitLocker</li> <li>Install the Azure Import/Export tool (WAImportExport.exe) on the disks. </li> <li>Copy files</li> <li>Create an import job in the Azure Portal</li> </ol> Kinesis AWS service for ingestion and processing of streaming data, such as access logs, video, audio, and telemetry. Kubeflow Cloud-native platform for machine learning based on Google\u2019s internal machine learning pipelines."},{"location":"Infrastructure/Cloud/#kusto","title":"Kusto","text":"<p>Case-sensitive query language developed by Microsoft and used in several Azure services:</p> <ul> <li>Azure Data Explorer </li> <li>Log Analytics </li> <li>Sentinel </li> <li>Application Insights </li> <li>Microsoft Defender ATP</li> </ul> Lightsail offers blueprints that will automatically provision all compute, storage, database, and network resources needed for a deployment. Macie AWS service that automatically finds and classifies sensitive data stored in AWS using machine learning to recognize sensitive data such as PII or trade secrets. Microsoft Azure Recovery Services Azure agent for backing up Windows machines only, but can also be installed on instances of other cloud providers like AWS. MARS can be configured to protect the entire system, volumes, or individual files and folders. <p>Monitor</p> Neptune AWS graph database. Network Performance Monitor Azure Log Analytics network monitoring solution for hybrid networks, providing 3 services: - Performance Monitor monitors connectivity between various points in both Azure and on-prem networks - Service Connectivity Monitor monitors outbound connectivity from network nodes to external TCP services, monitoring performance metrics like latency, response time, and packet loss - ExpressRoute monitors end-to-end connectivity between on-prem network and Azure over ExpressRoute Network Watcher Network Watcher appears like a normal resource in a resource group, but it is deployed as a single instance per Azure region. <p>Network Watcher monitoring and diagnostic tools:</p> <ul> <li>IP Flow Verify</li> <li>Next Hop</li> <li>Packet Captures link a Network Watcher resource, a target VM, a storage account, and a filter that specifies the characteristics of network traffic (source and destination IP addresses and ports as well as protocol) to capture, as well as a time limit.</li> <li>Network Topology</li> </ul> OpsWorks <p>OpsWorks is AWS's declarative configuration management service that uses the Chef and Puppet configuration management platforms and comes in three varieties:</p> <ul> <li>OpsWorks for Puppet Enterprise</li> <li>OpsWorks for Chef Automate</li> <li>OpsWorks Stacks</li> </ul> Project direct parent of all other GCP resources, consisting of a project name, project ID, and project number. Project Creator Predefined GCP role given to all users currently assigned to a project. Pub/Sub GCP messaging service, allowing services and applications to communicate. Recovery Services Vault <p>Azure resource used to centrally manage the backup and recovery.</p> <ul> <li>A Backup  protection policy defines how a backup plan is implemented. These are most easily created through the Portal.</li> <li>A vault can only back up data from other resources that exist in its region.</li> </ul> Rekognition AWS deep learning-based image recognition service. Resource Policy Contributor Azure built-in role that includes access to most Policy operations and should be considered privileged. Route 53 <p>AWS managed DNS service. Like any other DNS system, it relies on resource records defined in a  zone.</p> <p>Route 53 can also provide name resolution for private domain names, used on private networks. Private hosted zones provide DNS resolution for a single domain name within multiple VPCs.</p> <p>But when a resource record must be changed dynamically to work around failures or route users to an underutilized server, routing policies can be used.</p> <ul> <li>Simple policy is the default for new resource records and maps a domain name to a single value (i.e. an IP address).</li> <li>Weighted policy distributes traffic across multiple resources according to a predefined ratio.</li> <li>Latency policy sends users to resources in their closest Region.</li> <li>Failover policy allows a secondary resource to be marked for routing when the primary resource is unavailable.</li> <li>Geolocation policy routes users based on their specific continent, country, or state.</li> <li>Multivalue answer policy allows even distribution of traffic across multiple resources by randomizing the order of returned records.</li> </ul> <p>All routing policies except Simple can use health checks to modulate routing action. All health checks occur every 10 or 30 seconds and can check one of three resources:</p> <ul> <li>Endpoint makes a test connection to a TCP port</li> <li>CloudWatch alarm can be set off in case of high latency or other metrics.</li> <li>Calculated monitors the status of other health checks.</li> </ul> <p>Route 53 also offers the Route 53 Traffic Flow visual editor that allows you to create a diagram to represent the desired routing. The diagram isn't translated to individual resource records but rather represents a single policy record which costs 50 USD/month each. In addition to the routing policies above, Traffic Flow also offers the Geoproximity routing policy that directs users to a geographic location based on how close they are.</p> Simple Storage Service <p>AWS storage service. S3 stores objects in a container called a bucket. Each bucket must have a globally unique name and exposes a HTTP endpoint (at https://$BUCKET.s3.amazonaws.com/)</p> <p>Each object is associated with a key. Keys are equivalent to filenames, and the bucket is equivalent to a flat filesystem. However, directories can be simulated by placing slashes in the key.</p> <ul> <li>Bucket policies (applied to buckets) and user policies (applied to IAM principals) can be used to modulate accessibility. Public or anonymous access to an object can only be granted by bucket policies. Bucket and object ACLs are legacy access control methods that are still usable.</li> <li>S3 buckets store data unencrypted, although encryption at rest is available in two options:<ul> <li>Server-side encryption: S3 encrypts uploaded objects before storing them, and decrypts it again before delivery.</li> <li>Client-side encryption: User must encrypt data prior to uploading and decrypt it after downloading.</li> </ul> </li> </ul> <p>S3 offers various storage classes that differ in their availability and durability, the percent likelihood that an object within it will not be lost over the course of a year.</p> <p>Frequently accessed objects:</p> <ul> <li><code>STANDARD</code></li> <li><code>REDUCED_REDUNDANCY</code></li> </ul> <p>Infrequently accessed objects</p> <ul> <li><code>STANDARD_IA</code></li> <li><code>ONEZONE_IA</code></li> <li><code>GLACIER</code></li> </ul> <p><code>INTELLIGENT_TIERING</code> automatically moves objects to the most cost-effective storage tier based on access patterns.</p> <p>Storage Gateway is an on-premises VM that provides a connection to S3 for on-premises infrastructure.</p> <ul> <li>File gateway lets you use NFS and SMB file shares to transfer data to S3. Data is stored in S3 and cached locally.</li> <li>Volume gateway can be used as an iSCSI target by on-premises servers. Two configuration variants exist:<ul> <li>Stored volumes: All data is stored locally and asynchronously backed up to S3 as EBS snapshots. A stored volume can range from 1 GB to 16 TB in size.</li> <li>Cached volumes: Data is stored in S3 and frequently used data is cached locally. A cached volume can range from 1 GB to 32 TB in size.</li> </ul> </li> <li>Tape gateway is configured as an iSCSI target by a backup application. Virtual tapes range from 100 GB to 2.5 TB in size. These tapes are asynchronously transferred to a virtual tape library (VTL) backed by S3 and removed when the upload is complete. Recovery requires downloading the virtual tape again.</li> </ul> <p> Cloud Storage in Minutes with AWS Storage Gateway</p> Sentinel <p>Azure cloud-native SIEM and SOAR soluation that can collect data from many sources and present it to security analysts, who can run Kusto queries against the dataset. Azure Sentinel can ingest data from on-premises devices using one of several types of connector, categorized by the type of data ingestion:</p> <ul> <li>Native connectors integrate directly with other Microsoft security products, like Azure AD, M365, and Azure Security Center</li> <li>Direct connectors are configured from their source location, such as AWS CloudTrail, Azure Firewall, and Azure Front Door </li> <li>API connectors are implemented by security providers, like Azure Information Protection (AIP), Barracuda Web Application Firewall (WAF), and Microsoft WAF</li> <li>Agent-based connectors, using the Log Analytics agent, make it possible to ingest data from any source that can stream logs in Common Event Format (CEF), such as Windows and Linux machines.</li> </ul> <p>Analytic rules are rules that users create to help detect threats and anomalies in an environment:</p> <ul> <li>Scheduled rules run on a predetermined schedule</li> <li>Microsoft Security</li> <li>Machine learning behavior analytic rules can (currently) only be created from templates provided by Microsoft using proprietary ML algorithms</li> </ul> Simple Queue Service AWS service that can broker messages between components of highly decoupled applications. Snowball <p>Physical appliance designed to move large amounts of data to the cloud. The largest Snowball device can store 72 TB of information.</p> <p>Snowball Edge refers to a family of options similar to Snowball but with compute power to run EC2 instances and Lambda functions locally. All Snowball Edge options feature a QSFP+ network interface that is capable of speeds up to 100 Gbps. Snowball Edge devices can also be clustered together.</p> <ul> <li>Storage Optimized provides up to 80 TB of storage and 24 vCPUs.</li> <li>Compute Optimized provides up to 39.5 TB of storage and 52 vCPUs.</li> <li>Compute Optimized with GPU is similar to Compute Optimized but includes an NVIDIA GPU, making it useful for ML and HPC applications.</li> </ul> Spanner GCP managed scaleable database service. Stackdriver GCP service that collects metrics, logs, and event data from applications and infrastructure and integrates the data so DevOps engineers can monitor, assess, and diagnose operational problems. Super administrator Unique GCP role associated with the root Organization which has powers that exceed that of other administrative users. Storage accounts <p>Azure storage accounts are managed through [Azure Resource Manager][ARM] and management operations are authenticated and authorized using [Azure Active Directory][Azure AD]. </p> <p>There are four services provided within each storage account:</p> <ol> <li>Blobs provides a highly scalable service for storing arbitrary data objects, such as text or binary data. There can be multiple containers within a storage account, and a container can have its own folder structure. There are three types of blob: page, block, and append blobs.</li> <li>Tables provides a NoSQL-style store for storing structured data. Tables in Azure storage do not require a fixed schema, thus different entries in the same table can have different fields</li> <li>Queues provides reliable message queueing between application components</li> <li>Files provides managed file shares that can be used by VMs or on-premises servers</li> </ol> <p>Options that must be selected when creating a storage account:</p> <ul> <li>Performance tier<ul> <li>Standard supports all storage services and uses magnetic disks to provide cost-efficient and reliable storage</li> <li>Premium only supports page blobs with the locally-redundant (LRS) replication option, uses high-performance SSD disks</li> </ul> </li> <li>Account kind<ul> <li>General-purpose V2: only kind to support ZRS</li> <li>General-purpose V1: does not support various access tiers.</li> <li>Blob storage: specialized storage account used to store block and append blobs</li> </ul> </li> <li>Replication mode: Storage accounts can be freely moved between the following replication modes, except ZRS, in which case it is recommended to copy data to a new account.<ul> <li>Locally-redundant storage (LRS): makes 3 local sychronous within the same Azure facility (zone)</li> <li>Zone-redundant storage (ZRS): makes 3 synchronous copies across multiple availability zones; available for general-purpose v2 storage accounts at Standard performance tier only. </li> <li>Geographically-redundant storage (GRS): makes 3 local synchronous copies plus 3 additional asynchronous copies (typically within 15 minutes, but no SLA) to a second data center far away from the primary region</li> <li>Read-access geographically redundant storage (RA-GRS): makes 3 local synchronous copies plus 3 additional asynchronous copies to a second data center far away from the primary region, which has only read-only access</li> </ul> </li> <li>Access tier: Both Blob and StorageV1 can be upgraded to StorageV2, a process which is irreversible. <ul> <li>Hot blob storage access tier optimized for the frequent access of objects in the storage account</li> <li>Cool blob storage access tier optimized for storing large amounts of data that is infrequently accessed and stored for at least 30 days</li> <li>Archive blob storage access tier designed for long-term storage of infrequently-used data that can tolerate several hours of retrieval latency, remaining in the Archive tier for at least 180 days. It is stored offline and can take up to 15 hours for it to be \"rehydrated\" to the Cool or Hot tier before it can be accessed.</li> <li>Premium providing high-performance access for frequently-used data on SSD, only available from the Block Blob storage account type.</li> </ul> </li> </ul> <p>Every storage account service exposes its own Internet-facing endpoint, which must be secured in one of several ways.  A firewall can be implemented by using network rules to limit traffic to particular networks. The storage firewall controls IP addresses and VNets can access the storage account and applies to all storage account services.</p> <p>Access can be restricted to specific VNets by creating a Virtual Network Service Endpoint, however this still uses the public IP address. Private Link allows similar functionality using private IPs.  MS Docs <p>Public access to blobs can be restricted at the container level on container creation. By default, no public read access is enabled for anonymous users, but users with RBAC rights or with the storage account name and key can have access. This can be done through ARM APIs, the Portal, or Azure Storage Explorer. Container access levels:</p> <ul> <li>No public read access: container and blobs can only be accessed by storage account owner  (default for new containers)</li> <li>Public read-only access for blobs only (container data is not available, and anonymous clients cannot enumerate the blobs within the container)</li> <li>Full public read-only access: all container and blob data can be read by anonymous requests:</li> </ul> <p>Access can also be switched between Shared Key-based authentication (relying on storage account keys) and Azure AD authentication, where a RBAC role determines access to a Container.  Authorize access to blobs and queues using Azure Active Directory</p> <p>Access keys grant full access to all data in all services of a storage account and represent the simplest and most powerful control over access.  Access keys are typically used by applications for access to Azure storage, either through a Shared Access Signature (SAS) token or directly accessing the storage itself with the name and key.</p> <p>Storage account keys were implemented early in the history of Azure and grant full access to the entire storage account. However, it is considered an anti-pattern to distribute this key; a SAS token should be generated for every stored item to be distributed. </p> <p>Because storage account keys provide write access, a storage account with a ReadOnly resource lock will not enumerate its storage account keys, and users with Read permission will not be able to retrieve the keys either.</p> Systems Manager <p>AWS service for imperative configuration management. Systems Manager relies on several types of script:</p> <ul> <li>Command documents use normal shell commands and can be run periodically or on a trigger, so long as the instance to be managed has the required agent.</li> <li>Automation documents allow administration of AWS resources, similar in effect to using the Management Console or the AWS CLI.</li> </ul> Trusted Advisor <p>AWS service allows a visual check of resource configurations to ensure compliance with best practices, available only to Business and Enterprise Support plans.  It offers several categories</p> <ul> <li>Cost optimization</li> <li>Performance</li> <li>Security</li> <li>Fault tolerance</li> <li>Service limits</li> </ul> User Access Administrator <p>Azure built-in role that grants the permissions necessary to assign a user administrative access at the subscription scope.</p> <p>Permissions:</p> <ul> <li><code>Microsoft.Authorization/roleAssignments/write</code></li> <li><code>Microsoft.Authorization/roleAssignments/delete</code></li> </ul> User Administrator Azure built-in role that grants the power to manage all aspects of users and groups, including resetting passwords for limited admins. VM Agent <p>Microsoft Azure Virtual Machine Agent (VM Agent) manages VM interaction with the Azure Fabric Controller and comes preinstalled with Windows images from the Marketplace.  It can also be installed on a custom image.</p> <p>VM Agent supports the VMSnapshot extension, which is added when backups are enabled.  This extension takes a snapshot of the storage at the block level and sends it to the RSV configured.  For Windows VMs, this extension leverable the Volume Shadow Copy service.</p> Microsoft Azure Linux Agent Azure agent that manages VM interaction with the Azure Fabric Controller on Linux VMs. WAImportExport.exe <p>CLI tool associated with Azure Import/Export service that requires a Windows computer with .NET Framework and BitLocker.  There are two versions:</p> <ul> <li>Version 1 is recommended for blob storage</li> <li>Version 2 is recommended for files storage.</li> </ul> <p>Check disks required for selected blobs</p> <pre><code>WAImportExport.exe PreviewExport \n    /sn:&lt;Storage account name&gt; \n    /sk:&lt;Storage account key&gt; \n    /ExportBlobListFile:&lt;Path to XML blob list file&gt; \n    /DriveSize:&lt;Size of drives used&gt;\n</code></pre> <p>Various flags in <code>WAImportExport.exe</code> allow an XML-format \"blob list\" file to be used to specify files, or as output.</p> AllRootBlob in rootContainersPatternPattern in container <p>Export all blobs in the storage account</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;  &lt;BlobList&gt;\n&lt;BlobPath&gt;/&lt;/BlobPath&gt;\n&lt;/BlobList&gt;\n</code></pre> <p>Export all blobs in the root container</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;  &lt;BlobList&gt;  &lt;BlobPath&gt;/$root&lt;/BlobPath&gt;\n&lt;/BlobList&gt;\n</code></pre> <p>Export blob \"logo.bmp\" in the root container</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;  &lt;BlobList&gt;  &lt;BlobPath&gt;$root/logo.bmp&lt;/BlobPath&gt;\n&lt;/BlobList&gt;\n</code></pre> <p>Export all blobs in container \"music\"</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;  &lt;BlobList&gt;  &lt;BlobPath&gt;/music/&lt;/BlobPath&gt;\n&lt;/BlobList&gt;\n</code></pre> <p>Export all blobs in any container that begins with \"book\"</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;  &lt;BlobList&gt;  &lt;BlobPath&gt;/book&lt;/BlobPath&gt;\n&lt;/BlobList&gt;\n</code></pre> <p>Export all blobs in container \"music\" that begin with prefix \"love\"</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;  &lt;BlobList&gt;  &lt;BlobPath&gt;/music/love&lt;/BlobPath&gt;\n&lt;/BlobList&gt;\n</code></pre> WebJobs <p>a feature of Azure App Service that enables you to run a program or script in the same instance as a web app, API app, or mobile app, at no additional cost and supported only on Windows App Service plans.  There are two types:</p> <ul> <li>Continuous webjobs default to running on all instances of the linked web app (although it can be configured to run on only one)</li> <li>Triggered webjobs run only when triggered or on a schedule and on only a single instance of the linked web app selected by Azure.</li> </ul>"},{"location":"Infrastructure/Network/","title":"Networking","text":""},{"location":"Infrastructure/Network/#ipv6","title":"IPv6","text":"<p>Various address types are associated with IPv6 ranges:</p> <ul> <li>Global Unicast: unique address that may be used on the public Internet</li> <li>Unique Local (FD00::/8): equivalent to RFC 1918 private ranges in IPv4, and not routable on the Internet</li> <li>Link Local (FE80::/10): equivalent to loopback addresses and automatically generated by IPv6 devices. This is enabled by the command <code>ipv6 enable</code></li> <li>Multicast (FF00::/8): equivalent to broadcast, where a packet is sent to a group of subscribed devices<ul> <li>FF02::1: all devices</li> <li>FF02::2: all routers</li> </ul> </li> <li>Anycast: allows multiple devices to share the same IPv6 address</li> </ul> EUI-64 Generates an IPv6 host address from the device's MAC address SLAAC IPv6 device learns its prefix information automatically over the local link from another device (i.e. router). The device can then generate its own host portion using EUI-64 Because SLAAC cannot provide additional information such as DNS addresses, it is typically used alongside stateless DHCP. <p>Permit router to run IPv6-related routing protocols like EIGRP for IPv6 or OSPF version 3.</p> <pre><code>ipv6 unicast-routing\n</code></pre>"},{"location":"Infrastructure/Network/#switching","title":"Switching","text":"<p>When a switch receives an Ethernet frame, it examines the destination MAC address and compares it to its MAC address table. This table is continuously updated by the switch as it learns new addresses and discards or ages old ones.</p> <p>MAC address table</p> <pre><code>S1&gt;show mac address-table\n</code></pre> <p>When it finds an unknown destination, it proceeds with frame flooding where a frame is sent out all ports for the unknown MAC address's VLAN. If it knows the destination MAC, it transmits the frame on the appropriate port.</p> <p>Collisions no longer occur in modern networks because switches create a separate collision domain for each connection with a host, a condition called microsegmentation. In older half duplex networks, technologies like CSMA/CD were used to negotiate the possibility of collisions. Modern Cisco devices perform autonegotiation to resolve a common duplex and speed.</p> <p>Ethernet frames have a common format:</p> <ul> <li>Preamble (7 bytes) is a pattern of alternating 1's and 0's for synchronization</li> <li>Start Frame Delimiter (SFD) (1 byte)</li> <li>Destination MAC (6 bytes)</li> <li>Source MAC (6 bytes)</li> <li>Type (2 bytes) identifies IPv4 or IPv6</li> <li>Data and Pad ranges in size from 46 to 1500 bytes. Padding is necessary if the frame would otherwise be less than the minimum 46 bytes.</li> <li>Frame Check Sequence (FCS) (4 bytes) is for error-checking</li> </ul> <p>Larger frame sizes are possible with baby giants (1600 bytes) and jumbo frames (9216 bytes).</p> <p>Interfaces</p> <p></p> Display stateBring up <pre><code>Switch&gt;show interfaces status\n</code></pre> <pre><code>Switch&gt;enable\nSwitch#configure terminal\nSwitch(config)#interface fa0/1\nSwitch(config-if)#no shutdown\nSwitch(config-if)#end\n</code></pre> <p>Basic administration</p> <p>Change hostname <pre><code>Switch(config)#hostname SW2\n</code></pre></p> <p>Set banner message <pre><code>Switch(config)#banner motd #Hello, world!#\n</code></pre></p> <p>Restart <pre><code>Switch#reload\n</code></pre></p> <p>Display configuration</p> CurrentSaved <pre><code>Switch#show running-config\n</code></pre> <pre><code>Switch#show startup-config\n</code></pre> <p>Display contents of NVRAM <pre><code>Switch&gt;show flash:\n</code></pre></p> <p>Configure router IP</p> IPv4IPv6EUI-64SLAAC <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ip address 0.10.10.1 255.255.255.0\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre> <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ipv6 address 2001:aaaa:bbbb::1/64\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre> <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ipv6 address 2001:aaaa:bbbb::/64 eui-64\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre> <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ipv6 address autoconfig\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre>"},{"location":"Infrastructure/Network/#vlan","title":"VLAN","text":"<p>A VLAN is a broadcast domain created on a switch that corresponds to a TCP/IP subnet</p> <p>All non-trunk ports on a Cisco switch are assigned to VLAN 1 by default. And in order to be part of a VLAN, an interface must be set to access mode.</p> <p>The Native VLAN or VLAN 1 is intended to ensure that management traffic (i.e. CDP) can still flow between devices even if a link loses its status as a trunk. It is considered best practice to tag the Native VLAN or use an unused VLAN for this purpose, for security.</p> <p>Display VLAN assignments</p> <pre><code>SW1#show vlan brief\n</code></pre> <p>Configure VLAN settings</p> Name a VLANData VLANVoice VLAN <pre><code>SW1#configure terminal\nSW1(config)#vlan 30\nSW1(config-vlan)#name WEST\nSW1(config-vlan)#do show vlan brief\n</code></pre> <pre><code>SW1#configure terminal\nSW1(config)#interface gi0/1\nSW1(config-if)#switchport mode access\nSW1(config-if)#switchport access vlan 20\nSW1(config-if)#end\nSW1#show vlan brief\n</code></pre> <pre><code>SW1#configure terminal\nSW1(config)#interface gi0/2\nSW1(config-if)#switchport mode access\nSW1(config-if)#switchport access vlan 30\nSW1(config-if)#switchport voice vlan 50\nSW1(config-if)#end\nSW1#show vlan brief\nSW1#show interface gi0/2 switchport\n</code></pre>"},{"location":"Infrastructure/Network/#vtp","title":"VTP","text":"<p>VTP is a Cisco protocol that facilitates VLAN creation and management across many switches using interswitch links called trunks.</p> <p>There are three VTP Operating Modes:</p> <ul> <li>Server (default) permits you to create and modify VLANs on the local device.</li> <li>Transparent disables VTP.</li> <li>Client allows switches to inherit the VLAN information from a server. You cannot create VLANs locally on a VTP Client device.</li> </ul> <p>Display VTP mode</p> <pre><code>SW1#show vtp status\n</code></pre>"},{"location":"Infrastructure/Network/#trunking","title":"Trunking","text":"<p>802.1Q trunk links are the modern way of sharing traffic between switches by injecting a 4-byte tag value in the existing frame between the Source MAC address and Type fields rather than fully re-encapsulating the frame to add a VLAN marking as was the case in ISL.</p> <p></p> <p>Without configuring trunking, the interfaces are in access mode.</p> SW1SW3 <code>SW1#show interfaces gi0/1 switchport</code> <pre><code>Name: GigabitEthernet0/1\nSwitchport: Enabled \nAdministrative Mode: dynamic auto\nOperational Mode: static access\nAdministrative Trunking Encapsulation: dot1q \nOperational Trunking Encapsulation: native\nNegotiation of Trunking: false\nAccess Mode VLAN: 1\nTrunking Native Mode VLAN: 1 (default) \nAdministrative Native VLAN tagging: enabled\nVoice VLAN: none\nAdministrative private-vlan host-association: none\nAdministrative private-vlan mapping: none\nAdministrative private-vlan trunk native VLAN: none\nAdministrative private-vlan trunk Native VLAN tagging: enabled\nAdministrative private-vlan trunk encapsulation: dot1q\nAdministrative private-vlan trunk normal VLANs: none\nAdministrative private-vlan trunk private VLANs: none\nOperational private-vlan: none\nTrunking VLANs Enabled: All\nPruning VLANs Enabled: none\nCapture Mode Disabled\nCapture VLANs Allowed: ALL\n\nProtected: false\nUnknown unicast blocked: disabled\nUnknown multicast blocked: disabled\nAppliance trust: none\n</code></pre> <code>SW3#show interfaces gi0/2 switchport</code> <pre><code>Name: GigabitEthernet0/1\nSwitchport: Enabled \nAdministrative Mode: dynamic auto\nOperational Mode: static access\nAdministrative Trunking Encapsulation: dot1q \nOperational Trunking Encapsulation: native\nNegotiation of Trunking: false\nAccess Mode VLAN: 1\nTrunking Native Mode VLAN: 1 (default) \nAdministrative Native VLAN tagging: enabled\nVoice VLAN: none\nAdministrative private-vlan host-association: none\nAdministrative private-vlan mapping: none\nAdministrative private-vlan trunk native VLAN: none\nAdministrative private-vlan trunk Native VLAN tagging: enabled\nAdministrative private-vlan trunk encapsulation: dot1q\nAdministrative private-vlan trunk normal VLANs: none\nAdministrative private-vlan trunk private VLANs: none\nOperational private-vlan: none\nTrunking VLANs Enabled: All\nPruning VLANs Enabled: none\nCapture Mode Disabled\nCapture VLANs Allowed: ALL\n\nProtected: false\nUnknown unicast blocked: disabled\nUnknown multicast blocked: disabled\nAppliance trust: none\n</code></pre> <p>Now the interface of one switch is configured as a trunk, and because the adminstrative mode of either is \"dynamic\", the facing interface accepts the change.</p> <p>Configure interface as trunk</p> <pre><code>SW1#configure terminal\nSW1(config)#interfaces gi0/2\nSW1(config-if)#switchport mode trunk\n</code></pre> <p>There are several ways of confirming the trunk status:</p> statusswitchporttrunk SW1#show interfaces status <pre><code>Interface  Name  Status      Vlan   Duplex  Speed   Type                             \nFa0/1            connected   1      a-full  a-100   media type is 10/100BaseTX       \nFa0/2            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/3            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/4            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/5            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/6            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/7            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/8            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/9            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/10           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/11           connected   1      a-full  a-100   media type is 10/100BaseTX       \nFa0/12           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/13           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/14           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/15           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/16           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/17           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/18           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/19           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/20           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/21           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/22           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/23           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/24           notconnect  1      auto    auto    media type is 10/100BaseTX       \nGi0/1            connected   1      a-full  a-1000  media type is 10/100/1000BaseTX  \nGi0/2            connected   trunk  a-full  a-1000  media type is 10/100/1000BaseTX  \nvlan1            connected   1      auto    auto    media type is 10/100/1000BaseTX  \n</code></pre> SW1#show interfaces gi0/2 switchport <pre><code>Name: GigabitEthernet0/2\nSwitchport: Enabled \nAdministrative Mode: dynamic auto\nOperational Mode: trunk\nAdministrative Trunking Encapsulation: dot1q \nOperational Trunking Encapsulation: native\nNegotiation of Trunking: false\nAccess Mode VLAN: 1\nTrunking Native Mode VLAN: 1 (default) \nAdministrative Native VLAN tagging: enabled\nVoice VLAN: none\nAdministrative private-vlan host-association: none\nAdministrative private-vlan mapping: none\nAdministrative private-vlan trunk native VLAN: none\nAdministrative private-vlan trunk Native VLAN tagging: enabled\nAdministrative private-vlan trunk encapsulation: dot1q\nAdministrative private-vlan trunk normal VLANs: none\nAdministrative private-vlan trunk private VLANs: none\nOperational private-vlan: none\nTrunking VLANs Enabled: All\nPruning VLANs Enabled: none\nCapture Mode Disabled\nCapture VLANs Allowed: ALL\n\nProtected: false\nUnknown unicast blocked: disabled\nUnknown multicast blocked: disabled\nAppliance trust: none\n</code></pre> SW1#show interfaces trunk <pre><code>Port        Mode         Encapsulation  Status        Native vlan\nGi0/2       on           802.1q         trunking      1\n\nPort        Vlans allowed on trunk\nGi0/2       1-4094\n\nPort        Vlans allowed and active in management domain\nGi0/2       1\n\nPort        Vlans in spanning tree forwarding state and not pruned\nGi0/2       1\n</code></pre> <p>On SW3, the three commands produce similar output, except for the interface's Administrative Mode.</p> statusswitchporttrunk <code>SW3#show interfaces status</code> <pre><code>Interface  Name  Status      Vlan   Duplex  Speed   Type                             \nFa0/1            disabled    1      auto    auto    media type is 10/100BaseTX       \nFa0/2            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/3            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/4            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/5            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/6            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/7            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/8            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/9            notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/10           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/11           connected   1      a-full  a-100   media type is 10/100BaseTX       \nFa0/12           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/13           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/14           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/15           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/16           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/17           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/18           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/19           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/20           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/21           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/22           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/23           notconnect  1      auto    auto    media type is 10/100BaseTX       \nFa0/24           notconnect  1      auto    auto    media type is 10/100BaseTX       \nGi0/1            connected   trunk  a-full  a-1000  media type is 10/100/1000BaseTX  \nGi0/2            notconnect  1      auto    auto    media type is 10/100/1000BaseTX  \nvlan1            connected   1      auto    auto    media type is 10/100/1000BaseTX \n</code></pre> <code>SW3#show interfaces gi0/2 switchport</code> <pre><code>Name: GigabitEthernet0/2\nSwitchport: Enabled \nAdministrative Mode: trunk\nOperational Mode: trunk\nAdministrative Trunking Encapsulation: dot1q \nOperational Trunking Encapsulation: native\nNegotiation of Trunking: false\nAccess Mode VLAN: none\nTrunking Native Mode VLAN: 1 (default) \nAdministrative Native VLAN tagging: enabled\nVoice VLAN: none\nAdministrative private-vlan host-association: none\nAdministrative private-vlan mapping: none\nAdministrative private-vlan trunk native VLAN: none\nAdministrative private-vlan trunk Native VLAN tagging: enabled\nAdministrative private-vlan trunk encapsulation: dot1q\nAdministrative private-vlan trunk normal VLANs: none\nAdministrative private-vlan trunk private VLANs: none\nOperational private-vlan: none\nTrunking VLANs Enabled: \nPruning VLANs Enabled: none\nCapture Mode Disabled\nCapture VLANs Allowed: ALL\n\nProtected: false\nUnknown unicast blocked: disabled\nUnknown multicast blocked: disabled\nAppliance trust: none\n</code></pre> <code>SW3#show interfaces trunk</code> <pre><code>Port        Mode         Encapsulation  Status        Native vlan\nGi0/1       on           802.1q         trunking      1\n\nPort        Vlans allowed on trunk\nGi0/1       1-4094\n\nPort        Vlans allowed and active in management domain\nGi0/1       1\n\nPort        Vlans in spanning tree forwarding state and not pruned\nGi0/1       1\n</code></pre> <p>Encapsulation method is 802.1Q by default, although it can be explicitly specified.</p> <p> </p> <pre><code>SW1(config-if)#switchport trunk encapsulation dot1q\nSW1(config-if)#switchport mode trunk\n</code></pre>"},{"location":"Infrastructure/Network/#stp","title":"STP","text":"<p>The classic version of STP is PVST+, which is slower to converge than RSTP. Cisco's implementation of RSTP is called RPVST+.</p> <p>STP</p> <pre><code>Switch#show spanning-tree\n</code></pre> <p>PortFast is a STP feature that speeds up the process of moving a port from blocking to forwarding and is used exclusively on ports connected to servers and workstations.</p> <p>PortFast</p> <pre><code>Switch(config-if)#spanning-tree portfast\n</code></pre> <p>BPDU Guard is a related feature that can detect if a switch was mistakenly connect to a PortFast port and error disable the port for safety and security.</p> <p>BPDU Guard</p> <pre><code>Switch(config-if)#spanning-tree bpduguard enable\n</code></pre> <p>Confirming PortFast and BPDU Guard</p> <pre><code>Switch#show spanning-tree interface gi0/3 detail\n</code></pre>"},{"location":"Infrastructure/Network/#cdp","title":"CDP","text":"<p>CDP allows Cisco devices to communicate about each other to directly connected neighbors. VoIP in particular is reliant on CDP, however CDP messages cannot be passed from router to router through a switch.</p> <p>It is also considered a security issue, since it is enabled by default on Cisco routers and switches on all interfaces and devices may share information with an unauthorized neighbor.</p> <p>Disable CDP on a device</p> <pre><code>Switch(config)#no cdp run\n</code></pre> <p>Enable CDP on an individual interface</p> <pre><code>Switch(config)#cdp run\nSwitch(config)#interface gi1/0\nSwitch(config-if)#cdp enable\n</code></pre> <p>LLDP is an open standard similar to CDP, but it is not enabled by default</p> <p>Enable LLDP</p> <pre><code>Switch(config)#lldp run\nSwitch(config)#interface gi1/0\nSwitch(config-if)#lldp transmit\nSwitch(config-if)#lldp receive\n</code></pre>"},{"location":"Infrastructure/Network/#etherchannel","title":"EtherChannel","text":"<p>EtherChannel aggregates multiple physical links to have them act as as a single one, providing redundancy and increased bandwidth. It is often brought up in the context of STP because although STP does not permit redundant links it will also not block any one of the links within an EtherChannel bundle or port-channel interface.</p> <p>Other aggregation technologies that make multiple switches act as one logical device:</p> <ul> <li>Switch stacking is used in the access layer and uses special stacking ports and cables.</li> <li>Chassis aggregation is used in the distribution and core layers to aggregate only two switches with Ethernet interfaces. It is more complex to setup but is also more functional.</li> </ul> <p>Configure EtherChannel</p> <p>EtherChannel can be configured using PAgP (<code>desirable</code>), LACP (<code>active</code>), statically (<code>on</code>), or at Layer 3. Because PAgP is the default, all other methods require the interfaces to be shutdown first.</p> PAgPLACPStatic <p><pre><code>SW1(config)#interface range gi0/2 , gi1/1\nSW1(config-if-range)#channel-group 2 mode desirable\n</code></pre> <pre><code>SW2(config)#interface range gi0/1 , gi0/3\nSW2(config-if-range)#channel-group 2 mode desirable\n</code></pre></p> <p><pre><code>SW1(config)#interface range gi0/2 , gi1/1\nSW1(config-if-range)#shutdown\nSW1(config-if-range)#channel-group 3 mode active\n</code></pre> <pre><code>SW2(config)#interface range gi0/2 , gi1/0\nSW2(config-if-range)#channel-group 3 mode active\n</code></pre> <pre><code>SW3(config)#interface range gi0/2 , gi1/0\nSW3(config-if-range)#no shutdown\n</code></pre></p> <p><pre><code>SW1(config)#interface range gi0/1 , gi0/3\nSW1(config-if-range)#shutdown\nSW1(config-if-range)#channel-group 1 mode on\n</code></pre> <pre><code>SW2(config)#inteface range gi0/1 , gi1/0\nSW2(config-if-range)#channel-group 1 mode on\n</code></pre> <pre><code>SW1(config)#interface range gi0/1 , gi0/3\nSW1(config-if-range)#no shutdown\n</code></pre></p> <p>Verify EtherChannels</p> <pre><code>SW1#show etherchannel summary\n</code></pre>"},{"location":"Infrastructure/Network/#routing","title":"Routing","text":"<p>The routing table of a Cisco router has various sources, including many protocols of varying reliability. Each source is associated with:</p> <ul> <li>A letter code (i.e. R for RIP, etc)</li> <li>Administrative distance, a numeric value which reflects Cisco's measure of the source's trustworthiness. A lower value indicates higher trustworthiness, and the maximum value of 255 indicates an unusable route. The administrative values associated with each routing protocol must be memorized for the CCNA exam.</li> <li>For dynamic routing protocols a metric is also provided whose significance varies with protocol.  For example, with RIP the metric signifies hop count.</li> </ul> <p>Administrative distance and metric are delimited by a forward slash and appear within square brackets following the prefix.</p> <p>Display routing table</p> <pre><code>R1#show ip route\n</code></pre> <p>Configure static route</p> <pre><code>R1(config)#ip route 0.0.0.0 0.0.0.0 10.10.10.2\n</code></pre> <p>Set Gateway of Last Resort</p> <code>ip default-gateway</code><code>ip default-network</code><code>route</code> <pre><code>ip default-gateway\n</code></pre> <pre><code>ip default-network\n</code></pre> <pre><code>ip route 0.0.0.0 0.0.0.0\n</code></pre> <p>Configure router IP</p> IPv4IPv6EUI-64SLAAC <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ip address 0.10.10.1 255.255.255.0\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre> <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ipv6 address 2001:aaaa:bbbb::1/64\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre> <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ipv6 address 2001:aaaa:bbbb::/64 eui-64\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre> <pre><code>R1(config)#interface fa0/0\nR1(config-if)#ipv6 address autoconfig\nR1(config-if)#no shutdown\nR1(config-if)#end\n</code></pre>"},{"location":"Infrastructure/Network/#inter-vlan-routing","title":"Inter-VLAN routing","text":"<p>A multilayer switch possesses a routing engine (RE) to route between VLANs. Without an RE, a Router on a stick configuration is necessary.</p> <p>Configure ROAS</p> <p>A subinterface can be configured by specifying a VLAN number after a period on the physical interface, then associating an IP range with it. Theese IP addresses can be used as default gateway addresses hosts will use in respective subnets.</p> <p>ROAS can be configured with or without setting an IP address on the interface.</p> IPNo IP <pre><code>R1(config-if)#ip address 10.1.0.1 255.255.255.0\nR1(config-if)#interface gi0/1.10\nR1(config-subif)#encapsulation dot1q 10\nR1(config-subif)#ip address 10.1.10.1 255.255.255.0\nR1(config-subif)#end\nR1(config)#inteface gi0/1.20\nR1(config-subif)#encapsulation dot1q 20\nR1(config-subif)#ip address 10.1.20.1 255.255.255.0\nR1(config-subif)#end\n</code></pre> <pre><code>R1(config-if)#interface gi0/1.10\nR1(config-subif)#encapsulation dot1q 10\nR1(config-subif)#ip address 10.1.10.1 255.255.255.0\nR1(config-subif)#end\nR1(config)#inteface gi0/1.20\nR1(config-subif)#encapsulation dot1q 20\nR1(config-subif)#ip address 10.1.20.1 255.255.255.0\nR1(config-subif)#end\n</code></pre> <pre><code>SW1(config)#interface gi0/1\nSW1(config-if)#switchport trunk encapsulation dot1q\nSW1(config-if)#switchport mode trunk\n</code></pre> <p>Verify ROAS</p> <code>show ip interface brief</code> <pre><code>R1#show ip interface brief\n</code></pre> <p>=== \"`show vlans``</p>"},{"location":"Infrastructure/ansible-xfer/","title":"Ansible","text":"<p>The architecture of an environment managed by Ansible features several concepts:</p> <ul> <li>Controller host which contains playbooks which are executed</li> <li>Managed hosts which are controlled using SSH</li> </ul>"},{"location":"Infrastructure/ansible-xfer/#tasks","title":"Tasks","text":"Hello, World!<pre><code>---\n- name: Hello, World! playbook\nhosts: all\ntasks:\n- name: Hello, World! play\ncommand: echo Hello, World!\n... # (1)\n</code></pre> <ol> <li>Ad-hoc<pre><code>ansible all -m command -a \"echo Hello, World!\"\n</code></pre></li> </ol>"},{"location":"Infrastructure/ansible-xfer/#configuration","title":"Configuration","text":"ansible.cfg<pre><code>[privilege_escalation]\nbecome=yes\nbecome_method=sudo\nbecome_user=root\nbecome_ask_pass=no\nremote_user=ansible\n\n[defaults]\ninterpreter_python=auto_silent\ndeprecation_warnings=False\n</code></pre> Display non-default settings<pre><code>ansible-config dump --only-changed\n</code></pre>"},{"location":"Infrastructure/ansible-xfer/#documentation","title":"Documentation","text":"ansible-doc<pre><code># List currently installed modules\nansible-doc -l\n\n# Get module-specific information\nansible-doc $MODULE\n\n# Get example code\nansible-doc -s $MODULE\n</code></pre> Verify YAML syntax<pre><code>ansible-playbook --syntax-check $FILE\n</code></pre>"},{"location":"Infrastructure/ansible-xfer/#files","title":"Files","text":"Create file<pre><code>---\n- name: Create file\nhosts: all\ntasks:\n- name: Create file\ncopy:\ndest: /etc/motd\ncontent: \"Hello, World!\\n\" # (1)\n...\n</code></pre> <ol> <li>Alma Linux 9 requires an additional package to be installed to handle SELinux contexts: <pre><code># This package is incorrectly identified as \"libselinux-python\" in the Ansible error displayed on the controller host\ndnf install python3-libselinux\n</code></pre></li> </ol> Delete file<pre><code>---\n- name: Delete file\nhosts: all\ntasks:\n- name: Delete file\nfile:\npath: /etc/motd\nstate: absent\n...\n</code></pre>"},{"location":"Infrastructure/labbing/","title":"Labbing","text":""},{"location":"Infrastructure/labbing/#hyper-v","title":"Hyper-V","text":"<p>A NAT network can be configured in Hyper-V for use with VMs.</p> <p>NAT network limit</p> <p>There is only a single NAT network allowed per host.</p> <p>A new internal virtual switch is created, with a gateway explicitly configured.</p> <pre><code>New-VMSwitch -Name Ansible -Type Internal\nNew-NetIPAddress -IPAddress 192.168.2.1 -PrefixLength 24 -InterfaceIndex 14 # (1)\nNew-NetNat -Name Ansible -InternalIPInterfaceAddressPrefix 192.168.2.0/24\n</code></pre> <ol> <li>Only a single NetIPAddress can be assigned to the interface</li> </ol> <p>WinNAT does not allocate IP addresses to endpoints, so IP addresses must be statically configured within each individual guest.</p> <pre><code>ip address add 192.168.2.100 dev eth0\nip route add 192.168.2.0/24 dev eth0\nip route add default via 192.168.2.1 dev eth0\n</code></pre> <p>WinNAT also does not provide DNS services, so the host's DNS will have to be inspected and used.</p> WiFi complications <p>Documentation for VirtualBox states that WLAN adapters do not support promiscuous mode and therefore the Bridge networking option operates differently when using the computer's WiFi adapter. This potentially may be the cause of odd behavior when using External networking in Hyper-V...</p> <p>Static IP configuration varies by the network management toolset and backend presenton a system.  Ubuntu systems use Netplan whereas other distributions most commonly use Network Manager.</p> NetplanNetwork Manager <pre><code>network:\nversion: 2\nethernets:\neth0:\naddresses:\n- 192.168.2.100/24\ngateway4: 192.168.2.1\nnameservers:\naddresses:\n- 192.168.1.1\nsearch: []\n</code></pre> <pre><code>[connection]\nid=Ethernet\nuuid=abcdef01-2345-6789-0abc-def012345678\ntype=ethernet\ninterface-name=eth0\n\n[ethernet]\n\n[ipv4]\naddress1=192.168.2.100/24,192.168.2.1\ndns=10.40.7.2\nmethod=manual\n\n[ipv6]\naddr-gen-mode=stable-privacy\nmethod=auto\n</code></pre> <p>WSLv2 distros will not be able to access Hyper-V guests unless forwarding is enabled on both IP interfaces for the Hyper-V NAT as well as WSL</p> <pre><code>Set-NetIpInterface -ifIndex $NAT -Forwarding Enabled\nSet-NetIpInterface -ifIndex $WSL -Forwarding Enabled # (1)\n</code></pre> <ol> <li>The setting for the WSL interface appears not to be persistent.</li> </ol> <p>History</p> <p>Traditionally, network interfaces on Linux were configured in /etc/network/interfaces</p>"},{"location":"Infrastructure/vmware/","title":"VMware","text":"<p>vSphere is a suite of core infrastructure solutions for managing and monitoring a virtual infrastructure. The term was coined in 2009 with the release of VMware Virtual Infrastructure 4.</p> <p>VMware vCenter Server server is the management layer of multiple ESXi hosts, allowing clusters to be created and enabling features like vSphere HA and vSphere DRS. It comes as either a Windows application or a virtual appliance running on a stripped-down version of SUSE Linux.</p> <p>vCenter includes the Platform Services Controller (PSC) which consolidates several previously separate components, such as the SSO, Inventory Service, and Certificate Management. This can be installed on the same host as vCenter, or separately as either a Windows application or Linux appliance.</p>"},{"location":"Infrastructure/vmware/#processes","title":"Processes","text":"<pre><code>- **hostd** ESXi host agent\n- **vpxa** vCenter agent\n</code></pre>"},{"location":"Infrastructure/vmware/#powercli","title":"PowerCLI","text":"Setup<pre><code>Install-Module -Name VMware.PowerCLI # (1)\nSet-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser # (2)\nSet-PowerCLIConfiguration -InvalidCertificateAction Fail -Scope AllUsers\n</code></pre> <ol> <li>If the Hyper-V module is installed, the -AllowClobber option must be provided.</li> <li>Allow local scripts to be run, but not those downloaded from the web or email.</li> </ol> Decommission servers<pre><code>Connect-VIServer -Server $viserver # (1)\n\n$servers = Import-CSV $args[0]\n\nforeach ($server in $servers) {\n    $VM = Get-VM -Name $server.Name\n    Stop-VM $VM -Confirm -ErrorAction SilentlyContinue\n    New-TagAssignment -Entity $VM -Tag (Get-Tag -Name TPA_Decomm) # (3)\n    Set-NetworkAdapter -NetworkAdapter (Get-NetworkAdapter -VM $VM) -StartConnected $false -Confirm\n    Move-VM -VM $VM -Destination DECOMMISSION # (2)\n}\n</code></pre> <ol> <li>Connect-VIServer establishes a connection to a vCenter Server system, checking certificates according to the policy set by Set-PowerCLIConfiguration.  The connection can be destroyed with Disconnect-VIServer</li> <li>If the destination folder is under a parent, then apparently the best that can be done is to retrieve the Folder object first, specifying the parent folder to -Location: <pre><code>Move-VM -VM $VM -Destination (Get-Folder Linux -Location PROD)\n</code></pre></li> <li>Remove tag assignment<pre><code>Remove-TagAssignment (Get-TagAssignment -Entity $VM -Tag (Get-Tag -Name TPA_Decomm))\n</code></pre></li> </ol>"},{"location":"Infrastructure/Cloud/GCP/","title":"Google Cloud Platform","text":""},{"location":"Infrastructure/Cloud/GCP/#gcloud","title":"gcloud","text":"<p>Adding repo</p> UbuntuFedora <pre><code>deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\n</code></pre> <p>To be saved in /etc/yum.repos.d/google-cloud-sdk.repo <pre><code>[google-cloud-sdk]\nname=Google Cloud SDK\nbaseurl=https://packages.cloud.google.com/yum/repos/cloud-sdk-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=0\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\nhttps://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\n</code></pre></p> <p>Initialize  <pre><code>gcloud init\n</code></pre></p> <p>In GCP, APIs are enabled per project.</p> <p>List all APIs</p> <pre><code># Enabled APIs only\ngcloud services list # Including disabled APIs\ngcloud services list --available\n</code></pre> <p>Enable API</p> <pre><code>gcloud services enable compute.googleapis.com container.googleapis.com\n</code></pre> <p>Display all available regions and zones</p> <pre><code>gcloud compute regions list\ngcloud compute zones list\n</code></pre> <p>Set default region and zone</p> <pre><code>gcloud config set compute/region us-east1 # Moncks Corner, South Carolina\ngcloud config set compute/zone us-east1-c\n</code></pre>"},{"location":"Infrastructure/Cloud/GCP/#storage","title":"Storage","text":"Create disk<pre><code>gcloud compute disks create my-disk --size=10GB --zone=us-east1-b\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/","title":"Tasks","text":"<p>Cloud APIs  are equivalent to Azure resource providers . Unlike Azure, which automatically registers resource providers on use, Cloud APIs must be enabled per project.</p> <p>GCP</p> <pre><code>gcloud services enable container.googleapis.com\n</code></pre> <p>Azure</p> <pre><code>az provider register -n Microsoft.ContainerService\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#display-all-available-regions","title":"Display all available regions","text":"<p>GCP</p> <pre><code>gcloud compute regions list\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#install-cli-utility","title":"Install CLI utility","text":"Prerequisites Signing key Repo Install <p>GCP</p> <pre><code>apt install apt-transport-https ca-certificates gnupg\n</code></pre> <p>Azure</p> <pre><code>apt install apt-transport-https ca-certificates curl  lsb-release gnupg\n</code></pre> <p>GCP</p> <pre><code>curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | \nsudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -\n</code></pre> <p>Azure</p> <pre><code>curl -sL https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor |\nsudo tee /etc/apt/trusted.gpg.d/microsoft.gpg &gt; /dev/null\n</code></pre> <p>GCP</p> <pre><code>echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | \nsudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n</code></pre> <p>Azure</p> <pre><code>echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $(lsb_release -cs) main\" |\nsudo tee /etc/apt/sources.list.d/azure-cli.list\n</code></pre> <p>GCP</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install google-cloud-sdk\n</code></pre> <p>Azure</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install azure-cli\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#kubernetes","title":"Kubernetes","text":""},{"location":"Infrastructure/Cloud/Tasks/#clusters","title":"Clusters","text":"Create Read List Update Delete <p>GCP</p> <pre><code>gcloud container clusters create $name --num-nodes=1    # Standard mode\ngcloud container clusters create-auto $name             # Autopilot mode\n</code></pre> <p>Azure</p> <pre><code>az aks create -g $group -n $name --node-count 1 --enable-addons monitoring --generate-ssh-keys\n</code></pre> <p>GCP</p> <pre><code>gcloud container clusters describe $name\n</code></pre> <p>Azure</p> <pre><code>\n</code></pre> <p>GCP</p> <pre><code>gcloud container clusters list\n</code></pre> <p>Azure</p> <pre><code>az aks list\n</code></pre> <p>GCP</p> <pre><code>\n</code></pre> <p>Azure</p> <pre><code>\n</code></pre> <p>GCP</p> <pre><code>gcloud container clusters delete $name\n</code></pre> <p>Azure</p> <pre><code>az aks delete -g $group -n $name\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#add-context-to-kubeconfig","title":"Add context to kubeconfig","text":"<p>GCP</p> <pre><code>gcloud container clusters get-credential $name\n</code></pre> <p>Azure</p> <pre><code>az aks get-credentials -g $group -n $name\n</code></pre> <pre><code>Get-AzAKSCredentials\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#storage","title":"Storage","text":""},{"location":"Infrastructure/Cloud/Tasks/#create-a-10gb-disk","title":"Create a 10GB disk","text":"<p>GCP</p> <pre><code>gcloud compute disks create my-disk --size=10GB --zone=us-east1-a\n</code></pre> <p>Azure</p> <pre><code>\n</code></pre> <pre><code>\n</code></pre> <p>AWS</p> <pre><code>\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#administration","title":"\ud83d\udee0\ufe0f Administration","text":"<p>Display subscription ID</p> <pre><code>Get-AzSubscription\n</code></pre> <pre><code>az account show\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#cli","title":"\ud83d\udda5\ufe0f CLI","text":"<p>Initialize CLI utility</p> <pre><code>gcloud init\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#iam","title":"IAM","text":"<p>Add guest user</p> <pre><code>New-AzureADMSInvitation \n    -InvitedUserEmailAddress $EMAIL \n    -SendInvitationMessage $True \n    -InviteRedirectUrl \"http://myapps.onmicrosoft.com\"\n</code></pre> <p> </p> <p>Assign a role</p> <pre><code># At the organization level\ngcloud organizations add-iam-policy-binding $ORG_ID\n--member=\"user:$EMAIL\"\n--role=\"roles/compute.xpnAdmin\"\n</code></pre> <pre><code># At the folder level\ngcloud beta resource-manager-folders add-iam-policy-binding $FOLDER_ID\n--member=\"user:$EMAIL\"\n--role=\"roles/compute.xpnAdmin\"\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#cost-management","title":"\ud83d\udcb0 Cost management","text":"<p>To view resource quotas for a subscription, go to the subscription in Azure Portal and open the Usage + quotas blade. From there you can select resources and then click the Request Increase button.</p> <p>View current usage of vCPU quotas</p> <pre><code>Get-AzVMUsage\n</code></pre> <p>View current usage of storage service</p> <pre><code>Get-AzStorageUsage\n</code></pre> <p>Create a budget</p> <p>To create a budget, open Cost Management + Billing, then Subscriptions, select a subscription, then click Budgets.  Then click + Add, which produces a Create budget blade.  The created budget can be seen in the Budgets blade.  PowerShell commands used with budgets:</p> <ul> <li><code>Get-AzResourceGroup</code> retrieve Resource Group object</li> <li><code>Set-AzResourceGroup</code> apply a tag to a resource group with no preexisting tags</li> <li><code>.Tags</code> method that retrieves Tag collection from a resource group</li> <li><code>.Add()</code> method used to add tags to a resource group that already has tags.</li> </ul>"},{"location":"Infrastructure/Cloud/Tasks/#monitoring","title":"Monitoring","text":"<p>VM extension</p> <pre><code>Set-AzVMExtension -ResourceGroupName ExamRefRG -Location \"West Europe\" -VMName VM1 -Name networkWatcherAgent -Publisher Microsoft.Azure.NetworkWatcher -Type NetworkWatcherAgentWindows -TypeHandlerVersion 1.4\n</code></pre> <pre><code>az vm extension set --vm-name VM1 --resource-group ExamRefRG --publisher Microsoft.Azure.NetworkWatcher --version 1.4 --name NetworkWatcherAgentWindows --extension-instance-name NetworkWatcherAgent\n</code></pre> <p>Start packet capture</p> <pre><code>$nw = Get-AzResource | Where ResourceType -eq \"Microsoft.Network/networkWatchers\" -and Location -eq \"WestEurope\"\n$networkWatcher = Get-AzNetworkWatcher -Name $nw.Name -ResourceGroupName $nw.ResourceGroupName\n$storageAccount = Get-AzStorageAccount -Name examref-storage -ResourceGroupName ExamRefRG\n\n$filter1 = New-AzPacketCaptureFilterConfig -Protocol TCP -RemoteIPAddress \"1.1.1.1-255.255.255.255\" -LocalIPAddress \"10.0.0.3\" -LocalPort \"1-65535\" -RemotePort \"20;80;443\"\n$filter2 = New-AzPacketCaptureFilterConfig -Protocol UDP\n$vm = Get-AzVM ` -Name VM1 -ResourceGroupName ExamRefRG\n\nNew-AzNetworkWatcherPacketCapture -NetworkWatcher $networkWatcher -TargetVirtualMachineId $vm.Id -PacketCaptureName \"PacketCaptureTest\" -StorageAccountId $storageAccount.id -TimeLimitInSeconds 60 -Filter $filter1, $filter2\n</code></pre> <pre><code>filter='[ { \"protocol\": \"TCP\", \"remoteIPAddress\": \"1.1.1.1-255.255.255.255\", \"localIPAddress\":\"10.0.0.3\", \"remotePort\":\"20\" } ]'\naz network watcher packet-capture create --name PacketCaptureTest2 --resource-group ExamRefRG --vm VM1 --time-limit 300 --storage-account examref-storage --filters $filter\n</code></pre> <p>Check status of packet capture</p> <pre><code>Get-AzNetworkWatcherPacketCapture -NetworkWatcher $networkWatcher -PacketCaptureName \"PacketCaptureTest\"\n</code></pre> <pre><code>az network watcher packet-capture show-status --name PacketCaptureTest --location WestEurope\n</code></pre> <p>Stop packet capture</p> <pre><code>Stop-AzNetworkWatcherPacketCapture -NetworkWatcher $networkWatcher -PacketCaptureName \"PacketCaptureTest\"\n</code></pre> <pre><code>az network watcher packet-capture stop --name PacketCaptureTest --location WestEurope\n</code></pre> <p>Use IP Flow Verify to test outbound connectivity from source VM and port to destination. If any configured filtering rules block traffic between the endpoints, it will return the name of the offending NSG.</p> <pre><code>Test-AzNetworkWatcherIPFlow\n</code></pre> <pre><code>az network watcher test-ip-flow\n</code></pre> <p>Next Hop</p> <pre><code>Get-AzNetworkWatcherNextHop\n</code></pre> <pre><code>az network watcher show-next-hop\n</code></pre> <p>Use Network Topology</p> <pre><code>Get-AzNetworkWatcherTopology\n</code></pre> <pre><code>az network watcher show-topology\n</code></pre> <p>Capture SFTP traffic</p> <pre><code>$r = Get-AzResource | where ResourceType -eq \"Microsoft.Network/networkWatchers\" -and Location -eq \"EastUS\"\n$nw = Get-AzNetworkWatcher -Name $r.Name -ResourceGroupName $r.ResourceGroupName\n$s = Get-AzStorageAccount -ResourceGroupName \"Diagnostics-RG\" -Name \"Diagnostics-Storage\"\n$filter = New-AzPacketCaptureFilterConfig -Protocol TCP -RemoteIPAddress \"1.1.1.1-255.255.255.255\" -LocalIPAddress \"10.0.0.4\" -LocalPort \"1-65535\" -RemotePort \"22\"\n\nNew-AzNetworkWatcherPacketCapture -NetworkWatcher $nw -TargetVirtualMachineId $vm.ID -PacketCaptureName \"Capture SFTP traffic\" -StorageAccountId $s.Id -TimeLimitInSeconds 60 -Filter $filter\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#resources","title":"Resources","text":"<p>Create resource group</p> <pre><code>New-AzGroup -Location $location -Name $rgName\n</code></pre> <pre><code>az group create -l $location -n $rgName </code></pre> <p>Register resource provider in subscription <pre><code>az provider register --namespace 'Microsoft.PolicyInsights'\n</code></pre></p> <p>Move resources</p> <pre><code>$webapp = Get-AzResource -ResourceGroupName OldRG -ResourceName ExampleSite\n$plan = Get-AzResource -ResourceGroupName OldRG -ResourceName ExamplePlan\n\nMove-AzResource -DestinationResourceGroupName NewRG -ResourceId $webapp.ResourceId, $plan.ResourceId\n</code></pre> <pre><code>webapp=$(az resource show -g OldRG -n ExampleSite --resource-type \"Microsoft.Web/sites\" --query id --output tsv)\nplan=$(az resource show -g OldRG -n ExamplePlan --resource-type \"Microsoft.Web/serverfarms\" --query id --output tsv)\n\naz resource move --destination-group newgroup --ids $webapp $plan\n</code></pre> <p>Create lock on a resource</p> <pre><code>New-AzResourceLock \n    -LockName LockSite\n    -LockLevel CanNotDelete \n    -ResourceGroupName $rg \n    -ResourceName $r \n    -ResourceType Microsoft.Web/sites \n</code></pre> <pre><code>az lock create --name LockSite\n    --lock-type CanNotDelete --resource-group $rg --resource-name $r --resource-type Microsoft.Web/sites </code></pre> <p>Create lock on a resource group</p> <pre><code>New-AzResourceLock \n    -LockName LockGroup \n    -LockLevel CanNotDelete \n    -ResourceGroupName $rg\n</code></pre> <pre><code>az lock create --name LockGroup --lock-type CanNotDelete --resource-group $rg\n</code></pre> <p>Display resource lock</p> <pre><code>Get-AzResourceLock -ResourceName $r -ResourceType Microsoft.Web/sites -ResourceGroupName $rg\n</code></pre> <pre><code>az lock list --resource-group $rg --resource-name $r --namespace Microsoft.Web --resource-type sites --parent \"\"\n</code></pre> <p>Delete resource lock</p> <pre><code>$lockId = (Get-AzResourceLock -ResourceGroupName $rg -ResourceName $r -ResourceType Microsoft.Web/sites).LockId\n\nRemove-AzResourceLock -LockId $lockId\n</code></pre> <pre><code>lockid=$(az lock show --name LockSite --resource-group $rg --resource-type Microsoft.Web/sites --resource-name $r --output tsv --query id)\naz lock delete --ids $lockid\n</code></pre> <p>Sources</p> <ul> <li>Manage Azure Resource Manager resource groups by using Azure PowerShell</li> <li>Manage Azure Resource Manager resource groups by using Azure CLI</li> <li>Resource providers</li> <li>Lock resources to prevent unexpected changes</li> <li>AZ-103: <code>1.3</code>, p. 76</li> </ul>"},{"location":"Infrastructure/Cloud/Tasks/#tags","title":"Tags","text":"<p>List all resources by tag</p> <pre><code>(Get-AzResource -Tag @{ CostCode=\"1001\"}).Name\n# List all resources by tag name, with no value\n(Get-AzResource -TagName CostCode).Name\n</code></pre> <pre><code>az resource list --tag Dept=Finance\n</code></pre> <p>List resource groups by tag</p> <pre><code>(Get-AzResourceGroup -Tag @{ CostCode=\"1001\" }).ResourceGroupName\n</code></pre> <pre><code>az group list --tag CostCode=1001\n</code></pre> <p>Enumerate a resource's tags</p> <pre><code>$r = Get-AzResource -Name $resourceName -ResourceGroup rg\nGet-AzTag -ResourceId $r.id\n\n# Resource group\n$rg = Get-AzResourceGroup -Name $rgName\nGet-AzTag -ResourceId $rg.ResourceId\n\n# Subscription\n$s = (Get-AzSubscription -SubscriptionName \"Example Subscription\").Id\nGet-AzTag -ResourceId \"/subscriptions/$s\"\n</code></pre> <pre><code>az resource show -n $resourceName -g $rgName --query tags\n\n# Resource group\naz group show -n $rgName --query tags\n</code></pre> <p>Tag resource</p> <pre><code>$r = Get-AzResource -ResourceName hrvm1 -ResourceGroupName rg\n$r.Tags.Add(\"Owner\", \"user@contoso.com\")\nSet-AzResource -Tag $r.Tags -ResourceId $r.ResourceId -Force\n</code></pre> <p>Resource group</p> <pre><code>$tags = @{\"Dept\"=\"Finance\"; \"Status\"=\"Normal\"}\n$rg = Get-AzResourceGroup -Name demoGroup\nNew-AzTag -ResourceId $rg.ResourceId -tag $tags\n</code></pre> <pre><code>$tags = (Get-AzResourceGroup -Name rg).Tags\n$tags.Add(\"Owner\", \"user@contoso.com\")\nSet-AzResourceGroup -Tag $tags -Name rg\n</code></pre> <pre><code>jsonrtag=$(az group show -n rg --query tags)\nrt=$(echo $jsonrtag | tr -d '\"{},' | sed 's/: /=/g')\naz group update -n rg --tags $rt Owner=user@contoso.com\n</code></pre> <p>Remove specific tags</p> <pre><code>$tags = @{\"Project\"=\"ECommerce\"; \"Team\"=\"Web\"}\nUpdate-AzTag -ResourceId $resource.id -Tag $tags -Operation Delete\n</code></pre> <p>Remove all tags</p> <pre><code>$s = (Get-AzSubscription -SubscriptionName \"Example Subscription\").Id\nRemove-AzTag -ResourceId \"/subscriptions/$s\"\n\n# Alternatively\nSet-AzResourceGroup -Tag @{} -Name rg\n</code></pre> <p>Apply tags to resource, overwriting</p> <p><pre><code>$tags = @{\"Dept\"=\"Finance\"; \"Status\"=\"Normal\"}\nNew-AzTag -ResourceId $resource.id -Tag $tags\n</code></pre> <pre><code>Set-AzResource -ResourceId $r.ResourceId -Tag @{ CostCode=\"1001\"; Environment=\"Production\" } -Force\n</code></pre></p> <pre><code>az resource tag --tags 'Dept=IT' 'Environment=Test' -g $rgName -n examplevnet --resource-type \"Microsoft.Network/virtualNetworks\"\n</code></pre> <p>Apply tags to resource group</p> <pre><code>Set-AzResourceGroup -Name rg -Tag @{CostCode=1001; Environment=Production}\n</code></pre> <pre><code>az group update -n $rgName --tags 'Environment=Test' 'Dept=IT'\n\n# Alternatively\naz group update -n $rgName --set tags.Environment=Production tags.CostCode=1001\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#compute","title":"Compute","text":""},{"location":"Infrastructure/Cloud/Tasks/#kubernetes_1","title":"\u2693 Kubernetes","text":"<p>Create Kubernetes cluster</p> <p><pre><code>New-AzAKS -ResourceGroupName $g -Name $n\n    -NodeCount 2\n    -NetworkPlugin azure\n    -NodeVmSetType VirtualMachineScaleSets\n    -WindowsProfileAdminUserName azureuser\n    -WindowsProfileAdminUserPassword $Password\n    -KubernetesVersion 1.16.7 \n    # PowerShell does not offer an option to generate SSH keys for access to the cluster; `ssh-keygen` must be used.\n</code></pre> -  Create a Windows Server container on an AKS cluster</p> <p><pre><code>az aks create -g $g -n $n\n--node-count 2 --network-plugin azure --vm-set-type VirtualMachineScaleSets --windows-admin-username azureuser --windows-admin-password $PASSWORD\n--generate-ssh-keys --enable-addons monitoring </code></pre> -  Create a Windows Server container on an AKS cluster </p> <p>Add a pool of nodes</p> <pre><code>New-AzAksNodePool -ResourceGroupName $rgName -Name npwin -ClusterName $clusterName \n    -OsType Windows \n    -KubernetesVersion 1.16.7\n</code></pre> <pre><code>az aks nodepool add -g $g -n $n --cluster-name $clusterName\n--os-type Windows\n    --node-count 1\n</code></pre> <p>Persistent volume claim</p> <p><pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\nname: azure-managed-disk\nspec:\naccessModes:\n- ReadWriteOnce\nstorageClassName: managed-premium\nresources:\nrequests:\nstorage: 5Gi\n</code></pre> -  Source</p> <p>Provision Azure Disk</p> StandardPremium <pre><code>kind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\nname: managed-disk-forapp\nprovisioner: kubernetes.io/azure-disk\nreclaimPolicy: Retain\nparameters:\nstorageaccounttype: default\nkind: Managed\n</code></pre> <pre><code>kind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\nname: managed-disk-forapp\nprovisioner: kubernetes.io/azure-disk\nreclaimPolicy: Retain\nparameters:\nstorageaccounttype: Premium_LRS\nkind: Managed\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#functions","title":"Functions","text":"<p>Deploy <pre><code>gcloud functions deploy hello_get --runtime python37 --trigger-http\n</code></pre> Test <pre><code>gcloud functions describe hello_get\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Tasks/#storage_1","title":"Storage","text":"<p>Create storage account</p> Azure Portal <p>Click Create a resouce, then Storage, then Storage account. Choose a globally unique name for the account, containing lower-case characters and digits only.</p> <pre><code>New-AzStorageAccount -ResourceGroupName ExamRefRG -Name mystorage112300 -SkuName Standard_LRS -Location WestUS -Kind StorageV2 -AccessTier Hot\n</code></pre> <pre><code>az storage account create --name $accountName --resource-group $resourceGroup -location $location --sku $sku\n</code></pre> <p>Change access tier of storage account</p> <p>=== \"Azure PowerShell</p> <pre><code>```powershell\nSet-AzStorageAccount -ResourceGroupName RG -Name $accountName -AccessTier Cool -Force\n```\n</code></pre> <p>Change replication mode of storage account</p> <pre><code>Set-AzStorageAccount -ResourceGroupName $resourceGroup -Name $accountName -SkuName $type\n</code></pre> <p>Renew storage account keys</p> <p>=== \"Azure </p> <pre><code>```powershell\nNew-AzStorageAccountKey\n```\n</code></pre> <pre><code>az storage account keys renew\n</code></pre> <p>Create Azure Key Vault</p> <pre><code>New-AzKeyVault -VaultName $vaultName -ResourceGroupName $g -Location $location \n$key = Add-AzKeyVaultKey -VaultName $vaultName -Name $keyName -Destination 'Software' \n$storageKey = Get-AzStorageAccountKey -ResourceGroupName $g -Name $storageAccount \n$secretvalue = ConvertTo-SecureString $storageKey[0].Value -AsPlainText -Force\n$secret = Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue  $secretvalue\n</code></pre> <pre><code>az keyvault create --name $vaultName --resource-group $g --location $location\naz keyvault key create --vault-name \"$vaultName\" --name $keyName --protection \"software\"\naz keyvault secret set --vault-name \"$vaultName\" --name \"$secretName\" --value \"$secretValue\"\n</code></pre> <p>Create key in Azure Key Vault</p> <pre><code>$key = Add-AzKeyVaultKey -VaultName $vaultName -Name $keyName -Destination 'Software'\n$storageKey = Get-AzStorageAccountKey -ResourceGroupName $g -Name $storageAccount \n$secretvalue = ConvertTo-SecureString $storageKey[0].Value -AsPlainText -Force\n\n$secret = Set-AzKeyVaultSecret -VaultName $vaultName -Name $secretName -SecretValue $secretvalue\n</code></pre> <pre><code>az keyvault key create --vault-name $vaultName --name $keyName --protection \"software\"\naz keyvault secret set --vault-name $vaultName --name $secretName --value $secretValue\n</code></pre> <p>Create Azure sync group</p> <p>Specify name of sync group in dialog after creating an Azure File Sync</p> <p>Change storage class</p> <p><code>$STORAGE_CLASS</code> can be <code>multi_regional</code>, <code>regional</code>, <code>nearline</code>, or <code>coldline</code> <pre><code>gsutil rewrite -s $STORAGE_CLASS gs://$PATH_TO_OBJECT\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Tasks/#file-shares","title":"File shares","text":"<p>Deploy Azure File Sync</p> <pre><code># Create Storage Sync Service\n$storageSync = New-AzStorageSyncService -ResourceGroupName $g -Name $storageSyncName -Location $l\n\n# Create Azure File Share\n$storageKey = Get-AzStorageAccountKey -ResourceGroupName $g -Name $storageAccount \n$context = New-AzStorageContext -StorageAccountName $storageAccount -StorageAccountKey $storageKey.Value[0]\n\nNew-AzStorageShare -Name $shareName -Context $context\n</code></pre> <pre><code># Creating a Storage Sync Service resource is only possible in PowerShell or Portal\nconstring=$(az storage account show-connection-string -n $storageAccountName)\naz storage share create --name $shareName --quota 2048 --connection-string $constring\n</code></pre> <p>Create sync group</p> <pre><code>$syncgroup = New-AzStorageSyncGroup -Name $syncgroupname -ParentObject $storageSync\n</code></pre> <p>Create cloud endpoint</p> <pre><code>New-AzStorageSyncCloudEndpoint -Name $shareName -ParentObject $syncgroup -StorageAccountResourceId $storageAccount.Id -AzureFileShareName $shareName\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#network-access","title":"Network access","text":"<p>Display the status of the default NetworkRule for a storage account</p> <pre><code>Get-AzStorageAccountNetworkRuleSet -ResourceGroupName $rgName -AccountName $n | Select-Object DefaultAction\n</code></pre> <pre><code>az storage account show -$rgName -n $n --query networkRuleSet.defaultAction\n</code></pre> <p>Set default rule</p> <pre><code>Update-AzStorageAccountNetworkRuleSet -ResourceGroupName $g -Name $n -DefaultAction Deny\nUpdate-AzStorageAccountNetworkRuleSet -ResourceGroupName $g -Name $n -DefaultAction Allow\n</code></pre> <pre><code>az storage account update -g $g -n $n --default-action Deny\naz storage account update -g $g -n $n --default-action Allow\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#networking","title":"Networking","text":"<p>Create virtual network with a specific prefix and subnet</p> <pre><code>$subnet = New-AzVirtualNetworkSubnetConfig \n    -Name $subnetName \n    -AddressPrefix \"10.0.0.0/24\"\n$vnet = New-AzVirtualNetwork -Name $name -ResourceGroupName $rgName -Location $l \n    -AddressPrefix \"10.0.0.0/16\" \n    -Subnet $subnet\n</code></pre> <pre><code>az network vnet create -g $rgName -n $name\n--address-prefix \"10.0.0.0/16\"\n--subnet-name $subnetName\n--subnet-prefix \"10.0.0.0/24\"\n</code></pre> <pre><code>gcloud networks create $name --subnet-mode=custom\ngcloud beta compute networks subnets create $subnetName\n--network=$name\n--region=$l\n--range=\"10.0.0.0/16\"\n--enable-private-ip-google-access\n    --enable-flow-logs\n</code></pre> <p>Create peering</p> <pre><code>Add-AzVirtualNetworkPeering \n    -Name 'peering1' \n    -VirtualNetwork $net1 \n    -RemoteVirtualNetworkId $net2.Id\n\nAdd-AzVirtualNetworkPeering \n    -Name 'peering2' \n    -VirtualNetwork $net2 \n    -RemoteVirtualNetworkId $net1.Id\n</code></pre> <pre><code>az network vnet peering create -n 'peering1' -g $g --vnet-name net1 --allow-vnet-access --remote-vnet net2\n\naz network vnet peering create -n 'peering2' -g $g --vnet-name net2 --allow-vnet-access --remote-vnet net1\n</code></pre> <pre><code>gcloud compute networks peerings create \"peering1\"\n--network net1\n    --peer-project $p\n--peer-network net2\n    --auto-create-routes\n\ngcloud compute networks peerings create \"peering2\"\n--network net1\n    --peer-project $p\n--peer-network net1\n    --auto-create-routes\n</code></pre> <p>Check peering</p> <pre><code>Get-AzVirtualNetworkPeering -ResourceGroupName $rg -VirtualNetworkName $vnetName\n</code></pre> <pre><code>az network vnet peering list --resource-group $rg --vnet-name VNet1\naz network vnet peering list --resource-group $rg --vnet-name VNet2\n</code></pre> <p>User-defined routes</p> <pre><code># Create the route table resource\n$routeTable = New-AzRouteTable -Name $routeTableName -ResourceGroupName ExamRefRG\n\n# Add a route to route table object\nAdd-AzRouteConfig \n    -RouteTable $routeTable \n    -Name $routeName \n    -AddressPrefix 10.3.0.0/16 \n    -NextHopType VirtualAppliance \n    -NextHopIpAddress 10.2.20.4\nSet-AzRouteTable -RouteTable $routeTable\n\n# Associate route table with subnet\nSet-AzVirtualNetworkSubnetConfig -VirtualNetwork $vnet -Name Default -AddressPrefix $subnet.AddressPrefix \n    -RouteTable $routeTable\n\n# Commit changes\nSet-AzVirtualNetwork -VirtualNetwork $vnet\n\n# Get effective routes for a NIC\nGet-AzEffectiveRouteTable -NetworkInterfaceName $nicName -ResourceGroupName $rgName\n</code></pre> <pre><code># Create route table resource\naz network route-table create --name $routeTableName --resource-group $rgName # Add route to route table\naz network route-table route create --resource-group $rgName --route-table-name $routeTableName --name $routeName --address-prefix 10.3.0.0/16 --next-hop-type VirtualAppliance --next-hop-ip-address 10.2.20.4\n\n# Associate route table with subnet\naz network vnet subnet update --name defualt --vnet-name Vnet1 --resource-group $rgName --route-table rt\n\n# Get effective routes for NIC\naz network nic show-effective-route-table --name $nicName --resource-group $rgName\n</code></pre> <p>Create NSG</p> <pre><code>$nsgRules = @()\n$nsgRules += New-AzNetworkSecurityRuleConfig -Name \"AllowingWinRMHTTP\" -Description \"To Enable PowerShell Remote Access\" -Access Allow -Protocol Tcp -Direction Inbound -Priority 103 -SourceAddressPrefix Internet -SourcePortRange * -DestinationAddressPrefix * -DestinationPortRange 5985\n$nsgRules += New-AzNetworkSecurityRuleConfig -Name \"AllowingWinRMHTTPS\" -Description \"To Enable PowerShell Remote Access\" -Access Allow -Protocol Tcp -Direction Inbound -Priority 104 -SourceAddressPrefix Internet -SourcePortRange * -DestinationAddressPrefix * -DestinationPortRange 5986\n$nsg = New-AzNetworkSecurityGroup -Name \"wscore-nsg\" -ResourceGroupName \"RG\" -Location \"East US\" -SecurityRules $nsgRules\n</code></pre> <p>View rules</p> <pre><code>Get-AzEffectiveNetworkSecurityGroup -NetworkInterfaceName $nicName -ResourceGroupName $rgName\n</code></pre> <pre><code>az network nic list-effective-nsg --name $nicName --resource-group $rgName\n</code></pre> <p>Create Bastion</p> <p>Connecting to a VM requires at least Reader role privileges on the VM, its NIC, and on the Bastion itself.</p> <pre><code>New-AzBastion -ResourceGroupName $rgName -Name $n -PublicIpAddress $pip -VirtualNetwork $vnet\n</code></pre> <pre><code>az network bastion create -g $rgName -n $n -l $l --public-ip-address $pip  --vnet-name $vnetName\n</code></pre> <p>Create virtual appliance</p> <p>IP forwarding must be enabled on the VM's NIC, then applications installed on the VM can begin accepting packets destined for other IP addresses.</p> <p> </p>"},{"location":"Infrastructure/Cloud/Tasks/#cdn","title":"CDN","text":"<p>Create new profile</p> Azure Portal <p></p> <ol> <li>Click Create a resource </li> <li>Click Web</li> <li>Click CDN, opening the CDN profile blade</li> <li>Specify name for the profile, name of the resource group, region, and pricing tier.</li> <li>Click Create</li> </ol> <p>AZ-103: p. 140</p> <p>Create endpoint</p> Azure Portal <p></p> <p>Add an endpoint to a CDN profile (Portal) 1. Open the CDN Profile 2. Click + Endpoint button 3. Specify unique name, configuration for origin settings such as type, host header, and origin port for HTTP and HTTPS. 4. Click Add button</p> <p>AZ-103: p. 141</p> <p>Publish content in a CDN endpoint</p> Azure Portal <ol> <li>Create a new CDN profile</li> <li>Add an endpoint to the profile</li> </ol>"},{"location":"Infrastructure/Cloud/Tasks/#dns","title":"DNS","text":"<p>Create DNS zone</p> <pre><code>New-AzDnsZone \n    -Name examref.com \n    -ResourceGroupName ExamRefRG\n</code></pre> <pre><code>az network dns zone create --name examref.com --resource-group ExamRefRG\n</code></pre> <p>Create empty A record</p> <pre><code>New-AzDnsRecordSet -Name www -RecordType A -ZoneName examref.com -ResourceGroupName ExamRefRG -Ttl 3600 -DnsRecords (New-AzDnsRecordConfig -IPv4Address \"1.2.3.4\")\n</code></pre> <pre><code>az network dns record-set a create --name www --zone-name examref.com --resource-group ExamRefRG --ttl 3600\n</code></pre> <p>Create multiple records</p> <pre><code>$records = @()\n$records += New-AzDnsRecordConfig -IPv4Address \"1.2.3.4\"\n$records += New-AzDnsRecordConfig -IPv4Address \"5.6.7.8\"\nNew-AzDnsRecordSet -Name \"@\" -RecordType A -ZoneName examref.com -ResourceGroupName ExamRefRG -Ttl 3600 -DnsRecords $records\n</code></pre> <pre><code>az network dns record-set a add-record --record-set-name www --zone-name examref.com --resource-group ExamRefRG --ipv4-address 1.2.3.4\naz network dns record-set a add-record --record-set-name www --zone-name examref.com --resource-group ExamRefRG --ipv4-address 5.6.7.8\n</code></pre> <p>Remove record</p> <pre><code>$recordset = Get-AzDnsRecordSet -Name www -RecordType A -ZoneName examref.com -ResourceGroupName ExamRefRG\nAdd-AzdnsRecordConfig -RecordSet $recordset -IPv4Address \"5.6.7.8\"\nRemove-AzDnsRecordConfig -RecordSet $recordset -IPv4Address \"1.2.3.4\"\nSet-AzDnsRecordSet -RecordSet $recordset\n</code></pre> <pre><code>az network dns record-set a remove-record --record-set-name www --zone-name examref.com --resource-group ExamRefRG --ipv4-address 1.2.3.4\n</code></pre> <p>Read records</p> <pre><code>Get-AzDnsRecordSet -ZoneName examref.com -ResourceGroupName ExamRefRG\n</code></pre> <pre><code>az network dns record-set list --zone-name examref.com --resource-group ExamRefRG -o table </code></pre> <p>Create a virtual network with custom DNS settings</p> <pre><code>New-AzVirtualNetwork -Name VNet1 -ResourceGroupName $rgName -Location $location \n    -AddressPrefix 10.1.0.0/16 -Subnet (New-AzVirtualNetworkSubnetConfig -Name Default -AddressPrefix 10.1.0.0/24)\n    -DNSServer 10.0.0.4,10.0.0.5 \n</code></pre> <pre><code>az network vnet create --name VNet1 --resource-group $rgName --address-prefixes 10.0.0.0/16 --dns-servers 10.0.0.4 10.0.0.5\n</code></pre> <p>Modify the DNS server configuration of an existing VNET</p> <pre><code>$vnet = Get-AzVirtualNetwork -Name $vnetName -ResourceGroupName $rgName\n$vnet.DhcpOptions.DnsServers.Clear()\n$vnet.DhcpOptions.DnsServers.Add(\"10.10.200.1\")\n$vnet.DhcpOptions.DnsServers.Add(\"10.10.200.2\")\nSet-AzVirtualNetwork -VirtualNetwork $vnet\n</code></pre> <pre><code>az network vnet update --name $vnetName --resource-group $rgName --dns-servers 10.10.200.1 10.10.200.2\n</code></pre> <p>Restart the VMs in the VNet to pick up the DNS change</p> <pre><code>$vm = Get-AzVM -Name VNet1-VM -ResourceGroupName ExamRefRG\nRestart-AzVM -ID $vm.Id\n</code></pre> <p>Update the DNS settings on a NIC</p> <pre><code>$nic = Get-AzNetworkInterface -Name VM1-NIC -ResourceGroupName ExamRefRG\n$nic.DnsSettings.DnsServers.Clear()\n$nic.DnsSettings.DnsServers.Add(\"8.8.8.8\")\n$nic.DnsSettings.DnsServers.Add(\"8.8.4.4\")\n</code></pre> <p>Commit the DNS change, causing the VM to restart</p> <pre><code>Set-AzNetworkInterface -NetworkInterface $nic\n</code></pre> <p>Remove custom DNS servers from a VNET</p> <pre><code>az network vnet update --name VNet1 --resource-group ExamRefRG --remove DHCPOptions.DNSServers\n</code></pre> <p>Set custom DNS servers on a NIC</p> <pre><code>az network nic update --name VM1-NIC --resource-group ExamRefRG --dns-servers 8.8.8.8 8.8.4.4\n</code></pre>"},{"location":"Infrastructure/Cloud/Tasks/#load-balancing","title":"Load balancing","text":"<p>Create public load balancer</p> <p>Creating a load balancer in PowerShell requires defining objects which are all passed to <code>New-AzLoadBalancer</code> as objects: - Frontend IP    - Public Ip Address resource (if public)   - Private IP address specified as a string (if internal) - Backend address pool - Health probe - Load balancing rule</p> <p>By contrast, in Azure CLI, the load balancer can be defined first with <code>az network lb create</code> before adding a probe and rule, passing the name of the load balancer to <code>--lb-name</code>.</p> <pre><code>$publicIP = New-AzPublicIpAddress -Name ExamRefLB-IP -ResourceGroupName $g -Location $location -AllocationMethod Static \n$frontendIP = New-AzLoadBalancerFrontendIpConfig -Name frontend -PublicIpAddress $publicIP\n$beAddressPool = New-AzLoadBalancerBackendAddressPoolConfig -Name backend\n$healthProbe = New-AzLoadBalancerProbeConfig -Name -RequestPath '/' -Protocol http -Port 80\n\n$lbrule = New-AzLoadBalancerRuleConfig -Name -FrontendIpConfiguration $frontendIP -BackendAddressPool $beAddressPool -Probe $healthProbe -Protocol Tcp -FrontendPort 80 -BackendPort 80\n$lb = New-AzLoadBalancer -ResourceGroupName -Name -Location -FrontendIpConfiguration $frontendIP -LoadBalancingRule $lbrule -BackendAddressPool $beAddressPool -Probe $healthProbe\n</code></pre> <pre><code>az network public-ip create --name ExamRefLB-IP --resource-group ExamRefRG --location --allocation-method Static\naz network lb create --name ExamRefLB --resource-group ExamRefRG --location --backend-pool-name backend --frontend-ip-name frontend --public-ip-address ExamRefLB-IP\naz network lb probe create --resource-group ExamRefRG --name HealthProbe --lb-name ExamRefLB --protocol http --port 80 --path / --interval 5 --threshold \n\naz network lb rule create --name ExamRefRule --lb-name ExamRefLB --resource-group ExamRefRG --protocol Tcp --frontend-port 80 --backend-port 80 --frontend-ip-name ExamRefFrontEnd --backend-pool-name backend --probe-name HealthProbe\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/ARM/","title":"ARM","text":"<p>Azure Resource Manager (ARM) is the interface for managing and organizing cloud resources. ? </p> <p>An ARM template is a JSON file that precisely defines all ARM resources in a deployment. An ARM template can be deployed into a resource group as a single operation.</p> <p>ARM templates are typically adapted from existing Azure Quickstart templates, which are contributed by the community and hosted on a gallery. The Azure Resource Manager Visualizer assists users in seeing what the template will do before actually deploying.</p> <p>The Custom Script Extension is a way to run scripts on Azure VMs and represents one of the ways to automate configuration of new deployments. ?</p> <p>If you explort a deployment to a template, only the resources deployed in that deployment will be templatized. In the case of a complex deployment that had several phases, the ultimate result of the deployment can be obtained by exporting the template from the resource group.</p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#structure","title":"Structure","text":"<p>A template must have at least the following sections.</p> <ul> <li><code>$schema</code></li> <li><code>contentVersion</code></li> <li><code>resources</code></li> </ul> <p>A template may have the following optional sections</p> <ul> <li><code>parameters</code></li> <li><code>variables</code></li> <li><code>functions</code></li> <li><code>outputs</code></li> </ul> <pre><code>{\n\"$schema\": \"http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",\n\"contentVersion\": \"\",\n\"parameters\": {  },\n\"variables\": {  },\n\"functions\": [  ],\n\"resources\": [  ],\n\"outputs\": {  }\n}\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/ARM/#resources","title":"Resources","text":"<p>Create a public IP address.</p> <pre><code>{ \"type\": \"Microsoft.Network/publicIPAddresses\",\n\"apiVersion\": \"2018-08-01\",\n\"name\": \"[variables('publicIPAddressName')]\",\n\"location\": \"[parameters('location')]\",\n\"properties\": {\n\"publicIPAllocationMethod\": \"Dynamic\",\n\"dnsSettings\": {\n\"domainNameLabel\": \"[parameters('dnsLabelPrefix')]\" } } }\n</code></pre> <p>Create a storage account <pre><code>{ \"type\": \"Microsoft.Storage/storageAccounts\",\n\"apiVersion\": \"2019-06-01\",\n\"name\": \"[variables('storageAccountName')]\",\n\"location\": \"[parameters('location')]\",\n\"sku\": {\n\"name\": \"[parameters('storageAccountType')]\"\n},\n\"kind\": \"StorageV2\",\n\"properties\": {} }\n</code></pre></p> <p>Create a Azure Data Explorer cluster <pre><code>\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#parameters","title":"Parameters","text":"<pre><code>\"adminUsername\": {\n\"type\": \"string\",\n\"metadata\": {\n\"description\": \"Username for the Virtual Machine.\" }},\n\"adminPassword\": {\n\"type\": \"securestring\",\n\"metadata\": {\n\"description\": \"Password for the Virtual Machine.\" }}\n</code></pre> <p>Simple storage account <pre><code>{ \"storageAccountType\": {\n\"type\": \"string\",\n\"defaultValue\": \"Standard_LRS\",\n\"allowedValues\": [\n\"Standard_LRS\",\n\"Standard_GRS\",\n\"Standard_ZRS\",\n\"Premium_LRS\" ],\n\"metadata\": {\n\"description\": \"Storage Account type\" }},\n\"location\": {\n\"type\": \"string\",\n\"defaultValue\": \"[resourceGroup().location]\",\n\"metadata\": {\n\"description\": \"Location for all resources.\" }}}\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#variables","title":"Variables","text":"<p><pre><code>{ \"nicName\": \"myVMNic\",\n\"addressPrefix\": \"10.0.0.0/16\",\n\"subnetName\": \"Subnet\",\n\"subnetPrefix\": \"10.0.0.0/24\",\n\"publicIPAddressName\": \"myPublicIP\",\n\"virtualNetworkName\": \"MyVNET\" }\n</code></pre> Simple storage account <pre><code>{ \"storageAccountName\": \"[concat('store', uniquestring(resourceGroup().id))]\" },\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#functions","title":"Functions","text":"<p>Create a globally unique name, useful for some resources that require it. <code>concat</code> is a built-in function. <pre><code>[ { \"namespace\": \"contoso\",\n\"members\": {\n\"uniqueName\": {\n\"parameters\": [\n{\n\"name\": \"namePrefix\",\n\"type\": \"string\"\n}\n],\n\"output\": {\n\"type\": \"string\",\n\"value\": \"[concat(toLower(parameters('namePrefix')), uniqueString(resourceGroup().id))]\" }}}}\n]\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#outputs","title":"Outputs","text":"<p><pre><code>\"outputs\": {\n\"hostname\": {\n\"type\": \"string\",\n\"value\": \"[reference(variables('publicIPAddressName')).dnsSettings.fqdn]\"\n}\n}\n</code></pre> Standard storage account <pre><code>{\n\"$schema\": \"http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\",\n\"contentVersion\": \"\",\n\"parameters\": {  },\n\"variables\": {  },\n\"functions\": [  ],\n\"resources\": [  ],\n\"outputs\": {\n\"storageAccountName\": {\n\"type\": \"string\",\n\"value\": \"[variables('storageAccountName')]\"\n}\n}\n}\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#tasks","title":"Tasks","text":"<p> Deploy a VM quickstart template</p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#create-a-resource-group","title":"Create a resource group","text":"<p>Create a resource group  <pre><code>RESOURCEGROUP=learn-quickstart-vm-rg\nLOCATION=eastus\naz group create --name $RESOURCEGROUP --location $LOCATION\n</code></pre> Create template parameters</p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#validate-template","title":"Validate template","text":"<p><pre><code>USERNAME=azureuser\nPASSWORD=$(openssl rand -base64 32)\nDNS_LABEL_PREFIX=mydeployment-$RANDOM\n</code></pre> <pre><code>az deployment group validate --resource-group $RESOURCEGROUP --template-uri \"https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/101-vm-simple-windows/azuredeploy.json\" --parameters adminUsername=$USERNAME --parameters adminPassword=$PASSWORD --parameters dnsLabelPrefix=$DNS_LABEL_PREFIX\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#deploy-template","title":"Deploy template","text":"<p><pre><code>USERNAME=azureuser\nPASSWORD=$(openssl rand -base64 32)\nDNS_LABEL_PREFIX=mydeployment-$RANDOM\n</code></pre> <pre><code>az deployment group create --name MyDeployment --resource-group $RESOURCEGROUP --template-uri \"https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/101-vm-simple-windows/azuredeploy.json\" --parameters adminUsername=$USERNAME --parameters adminPassword=$PASSWORD --parameters dnsLabelPrefix=$DNS_LABEL_PREFIX\n</code></pre> Verify deployment <pre><code>az deployment group show --name MyDeployment --resource-group $RESOURCEGROUP\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/ARM/#arm","title":"ARM","text":"<p>? <pre><code>{\n\"name\": \"[concat(variables('vmName'), '/', 'ConfigureIIS')]\",\n\"type\": \"Microsoft.Compute/virtualMachines/extensions\",\n\"apiVersion\": \"2018-06-01\",\n\"location\": \"[parameters('location')]\",\n\"properties\": {\n\"publisher\": \"Microsoft.Compute\",\n\"type\": \"CustomScriptExtension\",\n\"typeHandlerVersion\": \"1.9\",\n\"autoUpgradeMinorVersion\": true,\n\"settings\": {\n\"fileUris\": [\n\"https://raw.githubusercontent.com/MicrosoftDocs/mslearn-welcome-to-azure/master/configure-iis.ps1\"\n]\n},\n\"protectedSettings\": {\n\"commandToExecute\": \"powershell -ExecutionPolicy Unrestricted -File configure-iis.ps1\"\n}\n},\n\"dependsOn\": [\n\"[resourceId('Microsoft.Compute/virtualMachines/', variables('vmName'))]\"\n]\n}\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/","title":"Azure AD","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#azure-ad","title":"Azure AD","text":"<p>Azure AD has its own set of roles which apply to Azure AD resources and which are distinct from those of Azure RBAC.</p> <p>The terms tenant and directory are deeply connected and often confused with one another. </p> <ul> <li>A tenant refers to an instance of Azure AD that is tied to a subscription, and refers to the organization.</li> <li>Each tenant is associated with a dedicated and trusted directory that includes the tenant's users, groups, and apps.</li> </ul> <p>Roles:</p> <ul> <li>Global Administrator can manage access to administrative features in AAD and can grant administrator roles to other users. An AAD Global Administrator can also temporarily elevate their own access to the Azure RBAC role of User Access Administrator in order to manage all Azure subscriptions and management groups. Whoever signs up for the directory is automatically assigned this role.</li> <li>Device administrator</li> </ul> <p>In order to make sure AD users can change their password either locally or in the cloud, Azure AD has to be upgraded to Premium. Enterprise State Roaming allows users to securely synchronize user settings and application settings to Azure.</p> <p>Self-Service Password Reset (SSPR) is supported for all users. SSPR registration can be configured by group or for all domain users, but not individual users.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#b2b","title":"B2B","text":"<p>Business-to-business (B2B) collaboration allows you to invite guest users into your own (What is guest user access in Azure Active Directory B2B?)</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#joining-a-device","title":"Joining a device","text":"<p>When you join a device to an Azure AD tenant's domain, Azure AD creates local administrator accounts on the device for: - The user joining the device - The Azure AD global administrator - The Azure AD device administrator</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#sspr","title":"SSPR","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#tasks","title":"Tasks","text":"<p>Sources: - Portal - PowerShell</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#add-users-in-bulk","title":"Add users in bulk","text":"<p>Import members by first navigating to the group to which they will be added, then importing from a CSV. A template is available.</p> Azure Portal <p> </p> <p>Sources:</p> <ul> <li>Bulk create users in Azure Active Directory</li> <li>Bulk add group members in Azure Active Directory</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#licenses","title":"Licenses","text":"<p>Note: The user to be licensed must first have a Usage location set.</p> Azure Portal <p> </p> <p>Use the ISO 3166-1 A2 two-letter country or region code to set this value in PowerShell <pre><code>Set-AzureADUser -UsageLocation 'US'\n</code></pre></p> Azure Portal <p> </p> <p>Sources</p> <ul> <li>Assign or remove licenses in the Azure Active Directory Portal</li> <li>Configure Microsoft 365 user account properties with PowerShell</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#enable-mfa","title":"Enable MFA","text":"<p>Create a Conditional Access policy to enforce MFA with specified users.</p> Azure Portal <p> </p> <p>Enable [SSPR][SSPR]</p> Azure Portal <p> </p>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#add-custom-domain-name","title":"Add custom domain name","text":"<p>AZ-103: 410 </p>"},{"location":"Infrastructure/Cloud/Azure/Azure-AD/#sources","title":"Sources","text":"<ul> <li>Tutorial: Secure user sign-in events with Azure Multi-Factor Authentication</li> <li>How to manage the local administrators group on Azure AD joined devices</li> <li>Password policies and account restrictions in Azure AD</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-App-Service/","title":"Azure App Service","text":"<p>Web applications must be organized under an App Service Plan resource. App service plans have various pricing tiers:</p> <ul> <li>Free/Shared: uses a shared infrastructure with minimal storage. No options for deploying different staged versions, routing of traffic, or backups</li> <li>Basic: Dedicated compute for app, including avaiilability of SSL and manual scaling of app instance number.</li> <li>Standard: Daily backups, automatic scaling of app instances, deployment slots, and user routing with Traffic Manager</li> <li>Premium: more frequent backups, increased storage, and greater number of deployment slots and instance scaling options.</li> </ul> <pre><code>az appservice plan create -g $g -n $p\n--is-linux\n\naz webapp list-runtimes --linux\n\naz webapp create -n $n -g $g --plan $p\n</code></pre> Deploy from GitHub<pre><code>az appservice plan create -g $rg -n $p\n--sku FREE\n\naz webapp create -g $rg -n $webappname --plan $p\n\naz webapp deployment source config -g $rg -n $webappname --repo-url $gitrepo --branch master --manual-integration\n\n# Web app will be available at http://$webappname.azurewebsites.net\n</code></pre> Deploy image from Azure Container Registry<pre><code>az webapp create -g $g -n $n\n--plan $p --deployment-container-image-name $registry.azurecr.io/$image:latest\n\naz webapp config appsettings set -g $g -n $n --settings \"WEBSITES_PORT=8000\"\n\n# Service principal ID\n$p = az webapp identity assign -g $g -n $n -o tsv\n    --query principalId $s = az account show -o tsv\n    --query id # Grant web app permission to access the container registry\naz role assignment create --assignee $p --scope /subscriptions/$s/resourceGroups/$g/provides/Microsoft.ContainerRegistry/registries/$registry\n\n# Deploy image\naz webapp config container set -g $g -n $n --docker-custom-image-name $registry.azurecr.io/$image:latest --docker-registry-server-url https://$registry.azurecr.io\n\naz webapp restart -n $n -g $g\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/","title":"Azure Backup","text":"<p>Azure Backup can backup on-prem servers, cloud-based VMs, and virtualized workloads like SQL Server and Sharepoint.  However Azure SQL databases are already backed up by an automatic service by default. AZ-103 p. 159</p> <p>On-prem machines can be backed up using several agents AZ-103 p. 162</p> <ul> <li>MARS Agent</li> <li>System Center Data Protection Manager (DPM) or Microsoft Azure Backup Server (MABS) can be used as backup servers. The backup server can then be backed up to a Recovery Services vault</li> </ul> <p>Azure VMs can be backed up</p> <ul> <li>Directly using an extension on the Azure VM Agent, which comes preinstalled on Marketplace images</li> <li>Specific files and folders on a VM can be backed up by running the MARS agent</li> <li>To the MABS running in Azure, which can then be backed up to a Recovery Services vault</li> </ul> <p>Storage accounts can be backed up, but not blob storage. Blob storage is already replicated locally, which provides fault-tolerance. Instead, you can use snapshots.</p> <p>When installed, the <code>Get-AzVM</code> command exposes a <code>ProvisionVMAgent</code> property with a boolean value under <code>OSProfile.WindowsConfiguration</code>.</p> <ul> <li></li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/#containers","title":"Containers","text":"<p>There appear to be resources that house items to be protected that can be enumerated.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/#reports","title":"Reports","text":"<p>Log Analytics workspaces must be located in the same region as the Recovery Services vault in order to store Backup reports.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/#pre-checks","title":"Pre-Checks","text":"<p>Azure Backup pre-checks complete with various statuses that indicate potential problems</p> <ul> <li>Passed: VM configuration is conducive for successful backups</li> <li>Warning: Issues that might lead to backup failures</li> <li>Critical: Issues that will lead to backup failures</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/#tasks","title":"Tasks","text":"<p>Create Recovery Services Vault</p> Azure PortalAzure PowerShellAzure CLI <p></p> <pre><code>New-AzRecoveryServicesVault -Name $n -ResourceGroupName $rgName -Location $l\n</code></pre> <pre><code>az backup vault create --name $n --resource-group $rgName --Location $l\n</code></pre> <p>Enable MFA</p> <p>This requires MFA to be enabled.</p> Azure Portal <p> </p> <p>Enable multi-factor authentication for the Recovery services vault by going to the vault in the Portal, then Properties &gt; Security settings: Update &gt; Choose Yes in the dropdown. An option to generate a security PIN will appear in this same blade.</p> <p>Recover files</p> Azure Portal <p> </p> <p>Download the executable (for Windows VMs) or PowerShell script (for Linux VMs). A Python script is generated when downloading to a Linux machine.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/#configure-backup-reports","title":"Configure Backup reports","text":"<p>Sources - Configure Azure Backup reports</p> <p>A Log Analytics workspace must exist.</p> <ol> <li>Turn on diagnostics in the Recovery Services vault</li> <li>Select Archive to a storage account (NOT Send to Log Analytics), providing a storage account to store information needed for report.</li> <li>Select <code>AzureBackupReport</code> under log section, which will collect all needed data models and information for the backup report.</li> <li>Connect to Azure Backup in PowerBI using a service content pack.</li> </ol> <p></p> <p>Define new backup protection policy</p> Azure PowerShell <pre><code>$SchPol = Get-AzRecoveryServicesBackupSchedulePolicyObject -WorkloadType \"AzureVM\" \n$SchPol.ScheduleRunTimes.Clear()\n$Dt = Get-Date\n$SchPol.ScheduleRunTimes.Add($Dt.ToUniversalTime())\n$RetPol = Get-AzRecoveryServicesBackupRetentionPolicyObject -WorkloadType \"AzureVM\" \n$RetPol.DailySchedule.DurationCountInDays = 365\nNew-AzRecoveryServicesBackupProtectionPolicy -Name \"NewPolicy\" -WorkloadType AzureVM -RetentionPolicy $RetPol -SchedulePolicy $SchPol\n</code></pre> <p>Configure VM backup</p> Azure PowerShellAzure CLI <pre><code>$policy = Get-AzRecoveryServicesBackupProtectionPolicy -Name \"DefaultPolicy\"\nEnable-AzRecoveryServicesBackupProtection -ResourceGroupName $g -Name $n -Policy $policy\n</code></pre> <pre><code># GRS by default\naz backup protection enable-for-vm -g $g -v $v --vm vm --policy-name DefaultPolicy\n\n# LRS\naz backup vault backup-properties set -n $v -g $g --backup-storage-redundancy \"LocallyRedundant\"\n</code></pre> <p>Initiate VM backup</p> Azure PowerShell <pre><code>$backupcontainer = Get-AzRecoveryServicesBackupContainer\n    -ContainerType \"AzureVM\"\n    -FriendlyName \"myVM\"\n\n$item = Get-AzRecoveryServicesBackupItem\n    -Container $backupcontainer\n    -WorkloadType \"AzureVM\"\n\nBackup-AzRecoveryServicesBackupItem -Item $item\n</code></pre> <p><code>--container-name</code>/<code>-c</code> appears to accept the name of the VM itself.</p> Azure CLI <pre><code>az backup protection backup-now -g myResourceGroup -n myRecoveryServicesVault --container-name myVM\n    --item-name myVM\n    --retain-until 18-10-2017\n    --backup-management-type AzureIaasVM\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/#list-containers","title":"List containers","text":"<p><code>-BackupManagementType</code> accepts the following values - <code>AzureVM</code> - <code>MARS</code> - <code>AzureWorkload</code> - <code>AzureStorage</code></p> <p><code>-ContainerType</code> accepts: - <code>AzureVM</code> - <code>Windows</code> - <code>AzureSQL</code> - <code>AzureStorage</code> - <code>AzureVMAppContainer</code></p> <pre><code>$v = Get-AzRecoveryServicesVault -ResourceGroupName $rg -Name vault\nGet-AzRecoveryServicesBackupContainer -ContainerType Windows -BackupManagementType MARS -VaultId $v.ID\n</code></pre> <p>This returns a list of JSON objects. <code>--backup-management-type</code> accepts the following values: - <code>AzureIaasVM</code> - <code>AzureStorage</code> - <code>AzureWorkload</code> <pre><code>az backup container list -g $g -v $v --backup-management-type AzureIaasVM\n</code></pre> Preserve only the \"name\" attribute of the first item, which itself is a semicolon-delimited string of values. (Start backup now) <pre><code>az backup container list -g $g -v $v --backup-management-type AzureIaasVM --query [0].name\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Backup/#sources","title":"Sources","text":"<ul> <li>AZ-103: <code>2.4</code></li> <li> <p>AZ-104: <code>5.2</code></p> </li> <li> <p>Azure Backup architecture and components</p> </li> <li>Azure Virtual Machine Agent overview</li> <li>Understanding and using the Azure Linux Agent</li> <li>Restore files from VM</li> <li>Back up a VM - Azure CLI, PowerShell</li> <li><code>Get-AzRecoveryServicesBackupContainer</code></li> <li><code>New-AzRecoveryServicesBackupProtectionPolicy</code></li> <li><code>az backup container list</code></li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-File-Service/","title":"Azure File Service","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-File-Service/#mount-azure-file-share","title":"Mount Azure File Share","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-File-Service/#windows","title":"Windows","text":"<p>Connect to and mount an Azure File Share (Windows File Explorer)</p> <ol> <li>Right-click on This PC</li> <li>Click Map Network Drive option</li> <li>Specify drive letter to be used </li> <li>Specify folder: <code>\\\\&lt;storageAccount&gt;.files.core.windows.net\\&lt;shareName&gt;</code></li> <li>Click Finish</li> <li>In the dialog box that opens login with the username: <code>AZURE\\&lt;storageName&gt;</code></li> <li>Password should be access key for the storage account</li> </ol> <p><pre><code>net use x \\\\erstandard01.file.core.windows.net\\logs /u:AZURE\\erstandard01 &lt;accessKey&gt;\n</code></pre> Automatically reconnect after reboot in Windows <pre><code>cmdkey /add:storageAccountName.file.core.windows.net /user:AZURE\\storageAccountName /pass:storageAccountKey\n</code></pre></p> <pre><code>$storageKey = (Get-AzStorageAccountKey -ResourceGroupName $g -Name $storageNAme).Value[0]\n$acctKey = ConvertTo-SecureString -String $storageKey -AsPlainText -Force\n$credential = New-Object System.Management.Automation.PSCredential -ArgumentList \"Azure\\$storageName\", $acctKey\nNew-PSDrive -Name \"Z\" -PSProvider FileSystem -Root \"\\\\$storageName.file.core.windows.net\\$shareName\" -Credential $credential\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-File-Service/#linux","title":"Linux","text":"<p>Mounting to <code>/logs</code> <pre><code>sudo mount -t cifs //$storageAccount.file.core.windows.net/logs /logs -o \"vers=3.0,username=$storageAccount,password=$storageAccountKey,dir_mode=0777,file_mode=0777,sec=ntlmssp\"\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-File-Service/#sources","title":"Sources:","text":"<ul> <li>Deploy Azure File Sync</li> <li>AZ-103: p. 148</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/","title":"Azure IAM","text":"<p>Azure methods of administering access to resources can be divided into two groups</p> <ul> <li>Role-Based Access Controls (RBAC) are supported only by Azure Portal and the ARM APIs.  RBAC is configured by selecting a role and associating it with a security principal, such as a user, group, or service identity.  Child reosurces inherit the roles of their parents (\"role inheritance\").</li> <li>Classic subscription administrators</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#classic-subscription-administrators","title":"Classic subscription administrators","text":"<p>Classic subscription administrators have full access to a subcription.  They can access resources through Azure Portal, ARM APIs (PowerShell and CLI), and classic deployment model APIs.  By default, the account that is used to sign up for a subscription is automatically set as both Account Administrator and Service Administrator.  There can only be one Account Administrator per account and only 1 Service Administrator per subscription.  Co-Administrators have the same access as Service Administrators, and there can be 200 of them per subscription, but cannot change the association of subscriptions to directories.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#roles","title":"Roles","text":"<p>Components of a role assignment include:</p> <ul> <li>Security principal: objects associated with a role definition and a scope to apply RBAC to azure resources (i.e. a user, group, service principal, or managed identity which is an application registration that is managed automatically by Azure and an Azure service)<ul> <li>User principal: identity associated with a user or group of users.</li> <li>Service principal: identity associated with an application.</li> </ul> </li> <li>Role definition: list of permissions which define what actions can or cannot be performed against a resource. In addition to the 4 foundational built-in roles, there are many other built-in roles and custom roles can be defined using a JSON file.</li> <li>Scope</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#scopes","title":"Scopes","text":"<p>There are four scopes at which RBAC can be applied:</p> <ul> <li>Management group</li> <li>Subscriptions</li> <li>Resource groups</li> <li>Resources</li> </ul> <p></p> <p>Azure RBAC roles can be used to grant rights to 2 types of principals:</p> <ul> <li>User principal: identity associated with a user or group of users.</li> <li>Service principal: identity associated with an application.</li> </ul> <p>RBAC roles can also be applied to a subscription through Management Groups, which represent the recommended practice for ensuring consistent application of tenant-wide security. Management groups form a hierarchy where each child inherits policy from its single parent while having additional controls. There is a single Management Group at the root of the hierarchy, associated with the Azure AD tenant (which is associated, in turn, with a subscription) that cannot be moved or deleted. </p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#role-assignments","title":"Role assignments","text":"<p>Current assignments for classic admins can be seen in the Properties blade of a subscription in Azure Portal. Co-Administrator assignments can be added by opening the Access Control (IAM) blade of a subscription, then clicking the Add co-administrator button.</p> <p>RBAC roles are supported only by Azure Portal and the ARM APIs.  Access policy is applied to a scope, which includes subscriptions, resource groups, or resources: a policy applied to a subscription is said to be at the \"subscription scope\".  Policy can also be applied to Management Groups, which is an additional scope above subscription.  In this way, several subscriptions can inherit a single policy through a Management Group.</p> <p>RBAC roles can also be applied to a subscription through Management Groups, which represent the recommended practice for ensuring consistent application of tenant-wide security.  Management groups form a hierarchy where each child inherits policy from its single parent while having additional controls.  There is a single Management Group at the root of the hierarchy, associated with the Azure AD tenant (which is associated, in turn, with a subscription) that cannot be moved or deleted. </p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#role-definitions","title":"Role definitions","text":"<p>Custom roles configure two types of privileges and are specified by two different properties of the definition JSON file: Management and Data. This provides safety from allowing unrestricted access to data.</p> <p>The values of these properties is an array of strings, each of which follows the format <code>Company.ProviderName/ResourceType/Action</code> where <code>action</code> can be of values <code>read</code>, <code>write</code>, <code>action</code>, <code>delete</code>, or <code>*</code>.</p> Privilege Property that defines allowed permissions Property that defines denied permissions Management <code>Actions</code> <code>NotActions</code> Data <code>DataActions</code> <code>NotDataActions</code> UnrestrictedNetwork resources (read only) <pre><code>\"Actions\": [\n\"*\"\n]\n</code></pre> <pre><code>\"Actions\": [\n\"Microsoft.Network/*/read\"\n]\n</code></pre> <p>Example role definitions:</p> Contributor <pre><code>{\n\"Name\": \"Contributor\",\n\"Id\": \"b24988ac-6180-42a0-ab88-20f7382dd24c\",\n\"IsCustom\": false,\n\"Description\": \"Lets you manage everything except access to resources.\",\n\"Actions\": [\n\"*\"\n],\n\"NotActions\": [\n\"Microsoft.Authorization/*/Delete\",\n\"Microsoft.Authorization/*/Write\",\n\"Microsoft.Authorization/elevateAccess/Action\",\n\"Microsoft.Blueprint/blueprintAssignments/write\",\n\"Microsoft.Blueprint/blueprintAssignments/delete\"\n],\n\"DataActions\": [],\n\"NotDataActions\": [],\n\"AssignableScopes\": [\n\"/\"\n]\n}\n</code></pre> <p>Some built-in roles:</p> <ul> <li>Owner has full access to all resources and can delegate access. Service Administrator and Co-Administrators are assigned this role at the subscription scope.</li> <li>Contributor can create and manage all resources (full read/write privileges), but cannot delegate access.</li> <li>Reader can view resources.</li> <li>[Cost Management Contributor][Cost Management Contributor]</li> <li>[Cost Management Reader][Cost Management Reader]</li> <li>[Resource Policy Contributor][Resource Policy Contributor]</li> <li>[User Administrator][User Administrator]</li> <li>[User Access Administrator][User Access Administrator]</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#tasks","title":"Tasks","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#create-assignment","title":"Create assignment","text":"<p>Assign the Owner role to a user at the subscription scope</p> <ul> <li>Navigate to resource group &gt; Access Control (IAM) &gt; Role Assignments tab &gt; Add &gt; Add Role Assignment</li> <li> <p>Open Subscription &gt; Access Control (IAM) &gt; Add Role Assignment&gt; select a Role &gt; Select target principal</p> </li> <li> <p>Access control (AIM) pane &gt; Add &gt; Add role assignment</p> </li> <li>Select a role in the Role dropdown and a user in the Select field. Then Save</li> </ul> Azure PortalPowerShellAzure CLI <p></p> <pre><code># Resource group scope\nNew-AzRoleAssignment \n    -SignInName \"rbacuser@example.com\" \n    -RoleDefinitionName \"Virtual Machine Contributor\" \n    -ResourceGroupName ExamRefRG\n\n# Subscription scope\nNew-AzRoleAssignment \n    -SignInName \"rbacuser@example.com\" \n    -RoleDefinitionName \"Owner\" \n    -Scope \"/subscriptions/$subId\"\n</code></pre> <pre><code># Resource group scope\naz role assignment create --assignee \"rbacuser@example.com\" --role \"Virtual Machine Contributor\" --resource-group ExamRefRG\n\n# Subscription scope\naz role assignment create --assignee \"rbacuser@example.com\" --role \"Owner\" --subscription $subId\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#delete-assignment","title":"Delete assignment","text":"<p>Navigate to resource group &gt; Access Control (IAM) &gt; Role Assignments tab &gt; Select one or more security principals &gt; Remove</p> <p>Remove RBAC assignments from a user</p> Azure PowerShell <pre><code>Remove-AzRoleAssignment -SignInName \"cloudadmin@opsgility.onmicrosoft.com\" -RoleDefinitionName \"Virtual Machine Contributor\" -ResourceGroupName ExamRefRG\n\nRemove-AzRoleAssignment -SignInName $u -ResourceGroupName $rgName -RoleDefinitionName \"Virtual Machine Contributor\" \n</code></pre> <p>Azure AD group <pre><code>$g = Get-AzADGroup -SearchString \"Cloud Admins\"\nRemove-AzRoleAssignment -ObjectId $g.Id -ResourceGroupName $rg -RoleDefinitionName \"Virtual Machine Contributor\" \n</code></pre></p> <p><pre><code>az role assignment delete --assignee $u --resource-group $rg --role \"Virtual Machine Contributor\" </code></pre> Azure AD group <pre><code>g=$(az ad group list --query \"[?displayName=='Cloud Admins'].objectId\" -o tsv)\naz role assignment delete --role \"Virtual Machine Contributor\" -\u2013assignee-object-id $g --resource-group $rg\n</code></pre></p> <p>Read assignment</p> Azure PowerShellAzure CLI <pre><code>Get-AzRoleDefinition -Name \"Virtual Machine Contributor\" | ConvertTo-Json\n</code></pre> <pre><code>az role definition list -n \"Virtual Machine Contributor\"\n</code></pre> <p>List custom roles available for assignment</p> Azure PowerShellAzure CLI <pre><code>Get-AzRoleDefinition | Where-Object { $_.IsCustom -eq $true }\n</code></pre> <pre><code>az role definition list --custom-role-only -o table\n</code></pre> <p>View all role assignments in a subscription <pre><code>az role assignment list --all\n</code></pre></p> <p>Create role definition</p> Azure PowerShell <pre><code>New-AzRoleDefinition -InputFile \"C:\\ARM_templates\\customrole1.json\"\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#configure-cost-center-quotas-and-tagging","title":"Configure cost center quotas and tagging","text":"<p>Grant an AD group RBAC rights</p> Azure PowerShell <pre><code>$group = Get-AzADGroup -SearchString \"Cloud Admins\"\nNew-AzRoleAssignment -ObjectId $group.Id -RoleDefinitionName \"Virtual Machine Contributor\" -ResourceGroupName ExamRefRG\n</code></pre> <p>Remove RBAC assignments from a group</p> Azure PowerShell <pre><code>$adGroup = Get-AzADGRoup -SearchString \"Cloud Admins\"\nRemove-AzRoleAssignment \n    -ResourceGroupName $rgName\n    -ObjectId $adGroup.Id \n    -RoleDefinitionName \"Virtual Machine Contributor\" \n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#elevate-permissions","title":"Elevate permissions","text":"<p>For Azure AD Global Administrators who want to temporarily elevate permissions </p> <ol> <li>Sign into Azure portal as an Azure AD Global Administrator.?</li> <li>Navigate to Azure Active Directory &gt; Properties. At the bottom of the page, under \"Access management for Azure resources\" click Yes then Save. </li> <li>Sign out and sign in again.</li> <li>Assign roles</li> <li>Revoke elevated access by returning to Azure Active Directory &gt; Properties and selecting No under \"Access management for Azure resources\".</li> </ol> <p>Sources</p> <ul> <li>Elevating global administrator access</li> <li>Understand Azure role definitions</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-IAM/#sspr","title":"SSPR","text":"<p>Administrator accounts are treated differently from other user accounts for SSPR and have a \"strong default two-gate password reset policy\", which requires two pieces of authentication data and foregoes the use of security questions.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/","title":"Azure IaaS","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#high-availability","title":"High availability","text":"<p>These high-availability options are mutually exclusive:</p> <ul> <li>Availability zones protect from datacenter-level failures by providing physical and logical separation between VM instances. Zones have independent power sources, network, and cooling, and there are at least 3 zones in every region.</li> <li>Availability sets offer redundancy for VMs in the same application tier, ensuring at least one VM is available in the case of a host update or problem. Each VM is assigned a fault domain (representing separate physical racks in the datacenter) and an update domain (representing groups of VMs and underlying physical hardware that can be rebooted at the same time for host updates). Availability sets have a maximum of 20 update domains and 3 fault domains. </li> </ul> <p>VM scale sets (VMSS) support the ability to dynamically add and remove instances. By default, a VMSS supports up to 100 instances or up to 1000 instances if deployed with the property <code>singlePlacementGroup</code> set to false (called a large-scale set). A placement group is a concept similar to an availability set in that it assigns fault and upgrade domains. By default, a scale set consists of only a single placement group, but disabling this setting allows the scale set to be composed of multiple placement groups. If a custom image is used instead of one in the gallery, the limit is actually 300 instances.</p> Create availability set<pre><code>az vm availability-set create -n $n -g $g --platform-fault-domain-count 3 --platform-update-domain-count 10\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#load-balancers","title":"Load balancers","text":"<p>Load balancers redistribute traffic from a frontend pool to a backend pool using rules.  Health probes determine the health of the VMs in the backend pool: if they don't respond then new connections won't be sent.  By default, Azure Load Balancer stores rules in a 5-tuple:</p> <ol> <li>Source IP address</li> <li>Source port</li> <li>Destination IP address</li> <li>Destination ports</li> <li>IP Protocol number</li> </ol> <p>Azure Load Balancers come in 2 pricing tiers:</p> <ol> <li>Basic which is free</li> <li>Standard which is charged based on the number of rules and the data that is processed.</li> </ol> <p>Both boot and guest OS diagnostics can be enabled on or after VM creation.</p> <p>Azure VMs have built-in extensions that enable configuration management. 2 most common extensions for configuration management:</p> <ul> <li>Windows PowerShell Desired State Configuration (DSC) allows you to define the state of a VM using PowerShell Desired State Configuration language </li> </ul> <p>A VM may have more than one Network Interface Card (NIC), but they must belong to the same region as the VM itself. All NICs on a VM must also be attached to the same VNet.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#tasks","title":"Tasks","text":"Deploy VM from image<pre><code>az vm create -g $g -n $n  --image $imageName # (1)\n</code></pre> <ol> <li>Specify a legacy unmanaged image<pre><code>az vm create -g $g -n $n --image $osDiskUri --generate-ssh-keys\n</code></pre></li> </ol> Windows Server Core<pre><code>az vm create -n $vmName -g $rg -l $vmLocation --image \"MicrosoftWindowsServer:WindowsServer:2016-Datacenter-Server-Core:2016.127.20190603\" --admin-username aztestadmin\n    --admin-password $password\n--nics socrates-nic\n</code></pre> Display status of VMs<pre><code>az vm list -g $g -o table\n</code></pre> Invoke a command on a VM<pre><code># Enumerate available values for command-id\naz vm run-command list\n\naz vm run-command invoke -g $g -n $n\n--command-id RunPowerShellScript --scripts @script.ps1 --parameters 'arg1=somefoo' 'arg2=somebar'\n</code></pre> Resize VM<pre><code>az vm list-vm-resize-options -g $g -n $n --output table\n\naz vm resize -g $g -n $n --size Standard_DS3_v2\n</code></pre> Create container registry<pre><code>az acr create -g $g -n $n\n--sku Basic --admin-enabled true\n</code></pre> Add NIC<pre><code>az network nic create -g $g -n $n --vnet-name $ExamRefVNET --subnet $subnetName\n\naz vm nic add -g $g --vm-name $vmName --nics $nicName --primary-nic\n</code></pre> <pre><code>az vm redeploy -g $g -n $n\n</code></pre> Create managed VM<pre><code>az vm deallocate -g $g --name $vmName\naz vm generalize -g $g --name $vmName\naz image create -g $g --name $imageName --source $vmName </code></pre> Create scale set<pre><code>az vmss create -g $g -n $n --image UbuntuLTS --authentication-type password --admin-username $userName --admin-password $password\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#create","title":"Create","text":"<p><pre><code>$subnets = @()\n$subnet1Name = \"Subnet1\"\n$subnet2Name = \"Subnet2\"\n$subnet1AddressPrefix = \"10.0.0.0/24\"\n$subnet2AddressPrefix = \"10.0.1.0/24\"\n$vnetAddressSpace = \"10.0.0.0/16\"\n$vnetName = \"ExamRefVNET\"\n\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n</code></pre> Create a virtual network <pre><code>$subnets = @()\n$subnets += New-AzVirtualNetworkSubnetConfig -Name $subnet1Name -AddressPrefix $subnet1AddressPrefix\n$subnets += New-AzVirtualNetworkSubnetConfig -Name $subnet2Name -AddressPrefix $subnet2AddressPrefix\n$vnet = New-AzVirtualNetwork -Name $vnetName -Location $location -AddressPrefix $vnetAddressSpace -Subnet $subnets\n$pip = New-AzPublicIpAddress -Name $ipName -ResourceGroupName $g -Location $location -AllocationMethod Dynamic -DomainNameLabel $dnsName\n$nsgRules = @()\n$nsgRules += New-AzNetworkSecurityRuleConfig -Name \"RDP\" -Description \"RemoteDesktop\" -Protocol Tcp -SourcePortRange \"*\" -DestinationPortRange \"3389\" -SourceAddressPrefix \"*\" -DestinationAddressPrefix \"*\" -Access Allow -Priority 110 -Direction Inbound\n$nsg = New-AzNetworkSecurityGroup -ResourceGroupName $resourceGroupName -Name \"ExamREfNSG\" -SecurityRules $nsgRules -Location $location\n$nic = New-AzNetworkInterface -Name $nicNAme -ResourceGroupName $resourceGroupName -Location $location -SubnetId $vnet.Subnets[0].Id -PublicIpAddressId $pip.Id -NetworkSecurityGroupId $nsg.Id\nAdd-AzVMNetworkInterface -VM $vm -NetworkInterface $nic\n$vm = New-AzVMConfig -VMName $vmName -VMSize $vmSize\nSet-AzVMOperatingSystem -Windows -ComputerName $vmName -Credential $cred -ProvisionVMAgent -VM $vm\nSet-AzVMSourceImage -PublisherName $pubName -Offer $offerName -Skus $skuName -Version \"latest\" -VM $vm\nSet-AzVMOSDisk -CreateOption fromImage -VM $vm\nNew-AzVM -ResourceGroupName $resourceGroupName -Location $location -VM $vm\n</code></pre></p> <pre><code>az group create --name $g --location $location\nvmName=\"myUbuntuVM\"\nimageName=\"UbuntuLTS\"\naz vm create --resource-group $g --name $vmName --image $imageName --generate-ssh-keys\n</code></pre> <p>Create a virtual network</p> <pre><code>vnetName=\"ExamRefVNET\"\nvnetAddressPrefix=\"10.0.0.0/16\"\naz network vnet create --resource-group $g -n ExamRefVNET --address-prefixes $vnetAddressPrefix -l $location\ndnsRecord=\"examrefdns123123\"\nipName=\"ExamRefIP\"\naz network public-ip create -n $ipName -g $g --allocation-method Dynamic --dns-name $dnsRecord -l $location\nnsgName=\"webnsg\"\naz network nsg create -n $nsgName -g $g -l $location\n</code></pre> <p>Create a NSG rules to allow inbound SSH and HTTP</p> <pre><code>az network nsg rule create -n SSH --nsg-name ... --priority 100 -g ... --access Allow --description \"SSH Access\" --direction Inbound --protocol Tcp --destination-address-prefix \"*\" --destination-port-range 22 --source-address-prefix \"*\" --source-port-range \"*\"\naz network nsg rule create -n HTTP --nsg-name ... --priority 101 -g ... --access Allow --description \"Web Access\" --direction Inbound --protocol Tcp --destination-address-prefix \"*\" --destination-port-range 80 --source-address-prefix \"*\" --source-port-range \"* \n</code></pre> <p><pre><code># Create a network interface\nnicname=\"WebVMNic1\"\naz network nic create -n $nicname -g $g --subnet $Subnet1Name --network-security-group $nsgName --vnet-name $vnetName --public-ip-address $ipName -l $location\n</code></pre> <pre><code># Retrieve a list of marketplace images\naz vm image list --all\n</code></pre> <pre><code># Retrieve form factors available in each region\naz vm list-sizes --location ...\n</code></pre> <pre><code># Create the VM\nimageName=\"Canonical:UbuntuServer:16.04-LTS:latest\"\nvmSize=\"Standard_DS1_V2\"\nuser=demouser\nvmName=\"WebVM\"\naz vm create -n $vmName -g $g -l $location --size $vmSize --nics $nicname --image $imageName --generate-ssh-keys\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#vhd","title":"VHD","text":"<p>Add a new disk to a VM</p> PowerShellAzure CLI <pre><code>$dataDiskName = \"MyDataDisk\"\n$location=\"WestUS\"\n$diskConfig = New-AzDiskConfig -SkuName Premium_LRS -Location $location -CreateOption Empty -DiskSizeGB 128\n$dataDisk1 = New-AzDisk -DiskName $dataDiskName -Disk $diskConfig -ResourceGroupNAme ExamRefRG\n$vm = Get-AzVM -Name ExamRefVM -ResourceGroupName ExamRefRG\n$vm = Add-AzVMDataDisk -VM $vm -Name $dataDiskName -CreateOption Attach -ManagedDiskId $dataDisk1.Id -Lun 1\n\nUpdate-AzVM -VM $vm -ResourceGroupName ExamRefRG\n</code></pre> <pre><code>az vm disk attach -g ExamRefRG --vm-name ExamRefVM --name myDataDisk --new --size-gb 128 --sku Premium_LRS\n</code></pre> <p>Modify host cache setting</p> PowerShellAzure CLI <pre><code>$vm = Get-AzVM -ResourceGroupName $g -Name $vmName\nSet-AzVMDataDisk -VM $vm -Lun 0 -Caching ReadOnly\nUpdate-AzVM -ResourceGroupName $g -VM $vm\n</code></pre> <pre><code>az vm disk attach --vm-name $vmName --resource-group $g --size-gb 128 --disk $diskName --caching ReadWrite -new\naz vm unmanaged-disk attach\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#diagnostics","title":"Diagnostics","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#enable-on-deployment","title":"Enable on deployment","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#enable-after-deployment","title":"Enable after deployment","text":"<p> <code>Set-AzVmDiagnosticsExtension</code></p> <p>Enable diagnostics using a storage account specified in a XML configuration file <pre><code>Set-AzVMDiagnosticsExtension -ResourceGroupName \"ResourceGroup01\" -VMName \"VirtualMachine02\" -DiagnosticsConfigurationPath \"diagnostics_publicconfig.xml\"\n</code></pre> Providing storage account name absent in config, or overriding it if present <pre><code>Set-AzVMDiagnosticsExtension -ResourceGroupName \"ResourceGroup1\" -VMName \"VirtualMachine2\" -DiagnosticsConfigurationPath diagnostics_publicconfig.xml -StorageAccountName \"MyStorageAccount\"\n</code></pre> Explicitly providing storage account name and key <pre><code>Set-AzVMDiagnosticsExtension -ResourceGroupName \"ResourceGroup01\" -VMName \"VirtualMachine02\" -DiagnosticsConfigurationPath \"diagnostics_publicconfig.xml\" -StorageAccountName \"MyStorageAccount\" -StorageAccountKey $storage_key\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#arm-templates","title":"ARM templates","text":"<p>Deploy a named ARM template</p> PowerShellAzure CLI <pre><code>New-AzResourceGroupDeployment -Mode Complete -Name simpleVMDeployment -ResourceGroupName ExamRefRG\n</code></pre> <pre><code>az group deployment create --name simpleVMDeployment --mode Complete --resource-group ExamRefRG\n</code></pre> <p>Export a resource group to an ARM template</p> PowerShellAzure CLI <pre><code>Save-AzResourceGroupDeploymentTemplate -ResourceGroupName ExamRefRG -DeploymentName simpleVMDeployment\n</code></pre> <pre><code>az group deployment export --name simpleVMDeployment --resource-group ExamRefRG\n</code></pre> <p>Create from existing resource group</p> <pre><code>Export-AzResourceGroup -ResourceGroupName ExamRefRG\n</code></pre> <p>Pass a template file during deployment</p> <pre><code>New-AzResourceGroupDeployment -Name MyDeployment -ResourceGroupName ExamRefRG -TemplateFile C:\\MyTemplates\\AppTemplate.json\n</code></pre> <pre><code>az group export --name ExamRefRG\n</code></pre> <pre><code>az group deployment create --name MyDeployment --resource-group ExamRefRG --template-file AppTemplate.json --parameters @dev-env.json\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#view-all-available-sizes-in-a-location","title":"View all available sizes in a location","text":"<p>Move a resource to another resource group or subscription (PowerShell) <pre><code>$resourceID = Get-AzResource -ResourceGroupName ExamRefRG | Format-Table -Property ResourceId\n\nMove-AzResource -DestinationResourceGroupName ExamRefDestRG -ResourceId $resourceID\nMove-AzResource -DestinationSubscriptionId $subscriptionID -DestinationResourceGroupName ExamRefDestRG -ResourceId $resourceID\n</code></pre></p> <p>Move a resource to another resource group or subscription (Azure CLI) <pre><code>az resource list -g ExamRefRG\naz resource move --destination-group ExamRefDestRG --ids $resourceID\naz resource move --destination-group ExamrefDestRG --destination-subscription-id $subscriptionID --ids $resourceID\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#dsc","title":"DSC","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#package","title":"Package","text":"<p>Package a DSC script into a zip file <pre><code>Publish-AzVMDscConfiguration -ConfigurationPath .\\ContosoWeb.ps1 -OutputArchivePath .\\ContosoWeb.zip\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#apply","title":"Apply","text":"<p>Publish a packaged DSC script to a storage account <pre><code>$g = \"ExamRefRG\"\n$location =- \"WestUS\"\n$vmName = \"ExamRefVM\"\n$storageName = \"dscstorageer1\"\n$configurationName = \"Main\"\n$archiveBlob = \"ContosoWeb.ps1.zip\"\n$configurationPath = \".\\ContosoWeb.ps1\"\n\nPublish-AzVMDscConfiguration -ConfigurationPath $configurationPath -ResourceGroupName $g -StorageAccountName $storageName\nSet-AzVmDscExtension -Version 2.76 -ResourceGroupName $g -VMName $vmName -ArchiveStorageAccountNAme $storageName -ArchiveBlobName $archiveBNlob -AutoUpdate:$false -ConfigurationName $configurationName\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-IaaS/#dedicated-host","title":"Dedicated host","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/","title":"Azure Load Balancer","text":"<p>Azure Load Balancers are used to distribute inbound traffic across a pool of backend servers running in a VNet.  They are defined by connecting a frontend and backend pool configurations with rules. - Backend Address Pool - Health Probe, specifying port and interval, can be of types TCP, HTTP, and (Standard SKU only) HTTPS   - HTTP and HTTPS probes will return an unhealthy status if a HTTP status code other than 200 is received. - Load Balancer Rule defines how a frontend address and port is mapped to the destination port and address on the backend</p> <p>Load Balancers are available in Basic and Standard SKUs.</p> <ul> <li>Standard load balancers require a Standard Public IP unless they are intended for internal use only.  Standard Public IPs do not allow any inbound communication by default and must have network security rules configured. Only Standard Health Probes support HTTPS.</li> <li>Basic backend SKUs must be comprised of either a single VM, VMs in the same availability set, or a VM scale set. Basic </li> </ul> <p>By default, Azure Load Balancer is set to timeout idle TCP connections after 4 minutes, but this can be configured.</p> <p>Azure load balancing rules route based on a 5-tuple hash, calculated from source and destination IP addresses and ports, as well as protocol. This means that traffic from any IP address will typically go to the same backend node, resulting in a modicum of affinity that can be configured.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#frontend","title":"Frontend","text":"<p>A frontend is defined by a 3-tuple composed of an IP address, a transport protocol, and a port number. Multiple frontends can be assigned to a load balancer to serve multiple websites or services.</p> <p>There are two modes:</p> <ul> <li>Internal, where the frontend references a subnet and an IP address from that subnet is allocated statically or dynamically</li> <li>Public, where a Public IP Address resource is used to receive inbound traffic.  If the LB is at Standard SKU, then the IP must also be at Standard.</li> </ul> <p>If the backend resources of a load balancer don't have instance-level public IP (ILPIP) addresses, they establish outbound connectivity via the frontend IP of the public load balancer. </p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#backend","title":"Backend","text":"<p>Any VM can only be a member of the backend pool of a single internal load balancer and simultaneously a single external load balancer.  But a VM may not be a member of more than one external load balancer, nor more than one internal load balancer.</p> <p>Basic SKU Backend pools must comprise either a single VM or VMs in the same availability set or scale set. Only Standard SKU backends can accept VMs in a single VNet that are not explicitly assigned to an availability set.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#outbound-connections","title":"Outbound connections","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#floating-ip","title":"Floating IP","text":"<p>Floating IP is Azure's term for Direct Server Return (DSR), which refers to the ability of nodes normally behind a load balancer to respond directly to client requests without overburdening the load balancer with return traffic. This prevents the load balancer from becoming a bottleneck.</p> <p>Technically, Azure Load Balancer always operates in a DSR flow topology even if Floating IP is not enabled, using the VMs' own IP addresses. When enabled, Floating IP changes the IP address mapping to the Frontend IP address of the load balancer.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#tasks","title":"Tasks","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#create-internal-load-balancer","title":"Create internal load balancer","text":"<pre><code>$ip = \"10.0.0.20\"\n$frontendIP = New-AzLoadBalancerFrontendIpConfig -Name frontend -PrivateIpAddress $ip\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#add-to-backend-address-pool","title":"Add to backend address pool","text":"<p>The process in PowerShell, counterintuitively, is actually to modify the VM's NIC to add a reference to the backend pool. AZ-103: p. 365</p> <p><pre><code>$vm = Get-AzVM -Name VM1 -ResourceGroupName $g\n$vmnic = Get-AzNetworkInterface -ResourceGroupName $g | where {$_.VirtualMachine.Id -eq $vm.Id}\n$lb = Get-AzLoadBalancer -Name ExamRefLB -ResourceGroupName $g\n$backend = Get-AzLoadBalancerBackendAddressPoolConfig -Name ExamRefBackEndPool -LoadBalancer $lb\n\n# All IP configuration settings of the NIC have to be reapplied, there is no support for incremental changes\n$ipconfig = Get-AzNetworkInterfaceIpConfig -Name ipconfig1 -NetworkInterface vm1nic\nSet-AzNetworkInterfaceIpConfig -Name ipconfig1 -NetworkInterface $vm1nic -SubnetId $ipconfig.Subnet.Id -LoadBalancerBackendAddressPoolId $backend.Id\nSet-AzNetworkInterface -NetworkInterface $vm1nic\n</code></pre> Azure CLI supports incremental update of the NIC, which makes this command simpler than its PowerShell equivalent. <pre><code>az network nic ip-config address-pool add --resource-group ExamRefRG --address-pool ExamRefBackEndPool --lb-name ExamRefLB --nic-name vm1-nic --ip-config-name ipconfig1\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#configure-tcp-reset","title":"Configure TCP reset","text":"<p>TCP timeout values should be greater than that used for TCP keepalives. A new load balancing rule config object can have idle timeout set on declaration. <pre><code>New-AzLoadBalancerRuleConfig -Name \"MyLBRule\" -FrontendIpConfiguration $fe -BackendAddressPool $be -Probe $hp -Protocol TCP -FrontendPort 80 -BackendPort 80 `\n  -IdleTimeoutInMinutes 15 -EnableTcpReset\n</code></pre> These can be manually changed on the load balancing object as well <pre><code>$lb = Get-AzLoadBalancer -Name \"myLoadBalancer\" -ResourceGroup \"myResourceGroup\"\n$lb.LoadBalancingRules[0].IdleTimeoutInMinutes = '15'\n$lb.LoadBalancingRules[0].EnableTcpReset = 'true'\nSet-AzLoadBalancer -LoadBalancer $lb\n</code></pre> <pre><code>az network lb rule update -g $g -n MyLBRule --lb-name myLoadBalancer --idle-timeout 15 --enable-tcp-reset true\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Load-Balancer/#specify-affinity","title":"Specify affinity","text":"<p>In the Azure Portal, affinity is specified in the Session persistence dropdown.</p> <p>In Azure PowerShell and CLI, the option is the load distribution named parameter - <code>New-AzLoadBalancerRuleConfig</code><code>-LoadDistribution</code> - <code>az network lb rule create</code><code>--load-distribution</code></p> <p>Sources:</p> <ul> <li>Multiple frontends for Azure Load Balancer</li> <li>SNAT for outbound connections</li> <li>Azure Load Balancer Floating IP configuration</li> <li>AZ-103: p. 358</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/","title":"Azure Monitoring","text":"<p>A robust monitoring strategy implementing proactive notifications helps to increase uptime and optimize performance. Azure offers Azure Monitor and Azure Advisor.</p> <ul> <li>Azure Monitor brings a unified alerting experience to Azure, with a single pane of glass for interacting with metrics, the Activity Log, Log Analytics, service and resource health and service-specific insights. <ul> <li>Alerts can be filtered by subscription (maximum of 5), resource group (maximum of 1), resource type (available selections depend on resources deployed to selected group) time range (past hour, past day, past week, and past 30 days), and other criteria.</li> <li>Azure Monitor can create alert rules that are built on target resources or resource type and that proactively notify you of the health of resources and can also leverage action groups that automate actions to take in certain conditions.</li> </ul> </li> <li>Azure Advisor is a free, personalized guide to Azure best practices that provides recommendations to help you optimize resources.  Azure Advisor offers personalized recommendations across 4 domains: High availability, Security, Performance, and Cost</li> </ul> Feature Logs Metrics Retention Stored in Log Analytics (2 years) Stored in Monitor for 93 days, but metrics can be sent to Log Analytics and Storage accounts as well Properties Varying properties for each log, with support for rich data types such as date and time Fixed set of properties (or attributes): time, type, resource, value, and (optionally) dimensions. Data availability Triggered by an event, requiring time to process before they are available for querying Gathered at intervals and available for immediate querying. <p>Virtual machines can be one of the most expensive resources in a cloud implementation, and there are several ways to reduce their cost</p> <ul> <li>Deallocate compute when not needed</li> <li>Delete unused virtual machines and allocate them only on demand</li> <li>Right-size VMs so that you don't overuse resources</li> </ul> <p>Advisor can also identify</p> <ul> <li>ExpressRoute circuits that have been \"Not Provisioned\" for more than 30 days</li> <li>Gateways that have been idle for more than 90 days</li> </ul> <p>There are two monitoring data streams:</p> <ul> <li>Metrics are the numerical time series data produced by resources and services within Azure. They are collected at 1-minute intervals, identified by a metric name and namespace (category). Metrics can be one-dimensional or have up to 10 dimensions.<ul> <li>Metrics have the following properties:<ul> <li>Time the value was collected</li> <li>Type of measurement made</li> <li>Resource associated with value</li> <li>Value</li> </ul> </li> <li>Metrics can be stored in:<ul> <li>Azure Monitor for 93 days</li> <li>Log Analytics for 2 years</li> <li>Storage account, where they are treated according to the retention policy and storage limits of the account.</li> </ul> </li> </ul> </li> <li>Logs come in various types</li> <li>Diagnostics logs (including resource logs and tenant logs) are a type of log data that can be configured to send data to other locations, such as a Storage account or Log Analytics workspace. Diagnostics logs have to be enabled for each resource to be monitored through the Portal by enabling Diagnostics Settings, and not all resource types support diagnostic logs. Of those that do, not all resources support a retention policy or sending metric data.</li> <li>Azure Activity logs is a subscription level log that captures events that range from operational data (i.e. resource creation, deletion) to service health events for a subscription, but lacks resource-level detail..</li> <li>Guest telemetry can relay logs from VMs with the use of diagnostics agents</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#log-analytics","title":"Log Analytics","text":"<p>A Log Analytics workspace is a form of abstracting the process of log collection and is used to collect and aggregate logs. Like any other resource, it must be associated with a location and a resource group. Any Azure resource can only report logs to a single workspace, but Azure Monitor allows multiple workspaces to be queried simultaneously. The logs can be queried through Log Analytics or Monitor. Because a workspace is a resource, RBAC can be applied to control access to it. </p> <p>Log Analytics is based on Azure Data Explorer and uses Kusto.</p> <p>Log Analytics pricing is divided into data ingestion and data retention: - Under Pay-As-You-Go data ingestion the first 5 GB per month are free and further data is charged at a rate of $2.76/GB/month - Capacity Reservations offer a discount on Pay-as-you-go by charging a fixed amount per day ($219.52/day for 100 GB), with further discounts at higher tiers - Data retention is free for any amount of data up to 31 days, and 90 days for Azure Sentinel-enabled workspaces</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#operational-insights","title":"Operational Insights","text":"<p>Log Analytics was previously named Operational Insights, which was named System Center Advisor prior to 2014.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#application-insights","title":"Application Insights","text":"<p>Application Insights is a platfrom separate from Log Analytics which is intended to monitor web applications.</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#alerts","title":"Alerts","text":"<p>Alerts can be created from the Alerts pane in the Monitor blade: </p> <p>Most resource blades also have Alerts in the resource menu under Monitoring.</p> <p>Alert rules, which are used to generate alerts, contain - Target resource, any Azure resource that generates signals, defines the scope and signals available for the alert. - Signal (i.e. metric or Activity Log) emitted by target resource. Signals are of 3 types:    1. Metrics   2. Log search queries    3. Activity logs - Conditional logic for alert combines the signal and a logical test to trigger alert. - Action Group determines what will happen when the alert is trigged. Action groups are themselves resources, and thus located in a subscription and resource group, and have:   - Name   - Short name is used to identify the Action Group in emails and notifications and is limited to 12 characters   - Actions define the configuration for a specific action type.  - Severity (0-4)</p> <p>Alerts can have 3 states:</p> <ul> <li>New and not reviewed</li> <li>Acknowledged issue is being actioned by an admin</li> <li>Closed issue that generated the alerts has been resolved and the alert has been marked as closedAlerts have many notification options, including email, SMS, mobile app, voice, and integration with automation. </li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#actions","title":"Actions","text":"<p>A single action group can trigger multiple actions. Available types include: Email/SMS/Push/Voice, Azure Function, Logic App, Webhook, ITSM, and Automation Runbook</p> <ul> <li>IT Service Management Connector up to 10 ITSM actions can be configured with an ITSM connection</li> <li>Supported providers include ServiceNow, System Center Service Manager, Provance, and Cherwell  Connect Azure to ITSM tools using ITSMC</li> <li>Webhooks</li> <li>Runbook runs in Azure Automation Service Runbooks</li> </ul> <p>The maximum number of alert notifications per hour: - Email: 60 - Voice: 12 - SMS: 12</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#vms","title":"VMs","text":"<p>\"Virtual Machine Insights\" (or \"Azure Monitor for VMs\") is the successor to older monitoring workflow that used \"guest OS diagnostics\" in conjunction with Metrics Explorer. It requires a log analytics workspace. Diagnostic settings, conventionally, was the feature that would be enabled to allow Azure to collect metrics and logs from VMs, including event logs and performance counters.</p> <p>Two primary views: - Performance is a successor to the old Metrics Explorer - Map (originally \"Service Map\")</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#tasks","title":"Tasks","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#enable-diagnostics-on-a-vm","title":"Enable diagnostics on a VM","text":"<p>Sources: - <code>az vm diagnostics set</code></p> <pre><code>\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#diagnostics-log-collection-with-a-storage-account","title":"Diagnostics log collection with a storage account","text":"<p>Browse to the resource itself. Alternatively, open Azure Monitor and then the Diagnostics Settings blade. From there you can view all eligible resouce types and view status of log collection.  <pre><code>$resource = Get-AzResource -Name $resourceName -ResourceGroupName $resourceGroupName\n$storage = Get-AzResource -Name $resourceName -ResourceGroupName $resourceGroupName\nSet-AzDiagnosticSetting -ResourceId $resource.ResourceId -StorageAccountId $storage.ResourceId -Enabled $true\n</code></pre> <pre><code>resourceId=$(az resource show -resource-group $resourceGroupName -name $resourceName --resource-type $resourceType --query id --output tsv)\naz monitor diagnostic-settings create --name $diagnosticName --storage-account $storageId --resource $resouceId --resource-group $resourceGroup \\\n--logs '[ {\n    \"category\": &lt;categoryName&gt;,\n    \"enabled\": true,\n    \"retentionPolicy\": {\n      \"days\": &lt;numberOfDays&gt;,\n      \"enabled\": true } } ] '\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#diagnostics-log-streaming-to-an-event-hub","title":"Diagnostics log streaming to an Event Hub","text":"<p><pre><code>$rule = Get-AzServiceBusRule -ResourceGroup $resourceGroupName -Namespace $namespace -Topic $topic -Subscription $subscription -Name $ruleName\nSet-AzDiagnosticSetting -ResourceId $resource.ResourceId -ServiceBusRuleId $rule.Id -Enabled $true\n</code></pre> <pre><code>resourceId=$(az resource show -resource-group $resourceGroupName -name $resourceName --resource-type $resourceType --query id --output tsv)\naz monitor diagnostic-settings create --name $diagnosticName --event-hub $eventHubName --event-hub-rule $eventHubRuleId --resource $resourceId \\\n--logs '[{\n    \"category\": &lt;categoryName&gt;,\n    \"enabled\": true }]'\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#diagnostics-log-collection-in-a-log-analytics-workspace","title":"Diagnostics log collection in a Log Analytics workspace","text":"<p>The PowerShell module that allows interaction with Log Analytics still refers to the service's old name.</p> <p><pre><code>$workspace = Get-AzOperationalInsightsWorkspace -Name $logAnalyticsName -ResourceGroupName $g\nSet-AzDiagnosticSetting -ResourceId $r.ResourceId -WorkspaceId $workspace.ResourceId -Enabled $true\n</code></pre> <pre><code>az monitor diagnostic-settings create --name $diagnosticName --workspace $logAnalyticsName --resource $rid --resouce-group $g \\\n--logs '[{\n    \"category\": &lt;categoryName&gt;,\n    \"enabled\": true }]'\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#create-an-alert-rule","title":"Create an alert rule","text":"<p>Sources: - Create, view, and manage activity log alerts by using Azure Monitor</p> <p></p> <p></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#create-log-analytics-workspace","title":"Create Log Analytics workspace","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Monitoring/#sources","title":"Sources","text":"<ul> <li>AZ-103: <code>1.2</code></li> <li> <p>AZ-104: <code>5.1</code></p> </li> <li> <p>Azure Monitor for VMs</p> </li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-Policy/","title":"Azure Policy","text":"<p>Azure Policy is a service that can create, assign, and manage policies to enforce governance.  RBAC roles deny by default and allow explicitly. But Azure Policy allows by default and denies explicitly.</p> <p>To implement policy, a policy definition is created first, then a policy assignment assigns it to a scope. </p> <pre><code>az policy definition create --name 'allowedVMs' --description 'Only allow virtual machines in the defined SKUs' --mode ALL --rules '{...}' --params '{...}'\n\naz policy assignment create --policy 'allowedVMs' --name 'deny-non-compliant-vms' --scope '/subscriptions/&lt;Subscription ID&gt;' -p # (1)\n\naz policy assignment delete --name 'deny-non-compliant-vms'\n</code></pre> <ol> <li>A scope can be a management group, subscription, or resource group, with all child resources and resource groups being affected.</li> </ol> <p>Policy definitions can be packaged together using initiative definitions and applied to a scope using initiative assignments.</p> <p>Every policy definition has a single effect, which includes:</p> <ul> <li>Audit: create a warning event in the log</li> <li>Modify: used to add, update, or remove properties or tags on a resource during creation or update.</li> <li>Append</li> <li>AuditIfNotExists</li> <li>Deny</li> <li>DeployIfNotExists</li> <li>Disabled</li> </ul> <p>The order of evaluation of effects is: Disabled, Append, Deny, Audit (\"DADA\")</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/","title":"Azure Storage","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#dns","title":"DNS","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#storage-account-access","title":"Storage account access","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#sas-token","title":"SAS token","text":"<p>SAS tokens are generated from a storage account key; if the key is invalidated then so are all SAS tokens generated from it. The user delegation SAS token itself is meant to be appended to the end of the blob's URI.CloudSkills: 40:00</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#tasks","title":"Tasks","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#add-endpoints-to-azure-file-sync-group","title":"Add endpoints to Azure File Sync Group","text":"<ol> <li>Register a server to the sync group by installing Azure File Sync agent on each server. When installing, you sign in with your subscription's credentials, then register the server by providing the Subscription, Resource Group, and Storage Sync Service names.</li> <li>Click Add Server Endpoint. This will display a dropdown of all servers with the agent installed and associated with the sync service.</li> </ol> <p>Upload blob</p> Azure CLIAzure AzCopy <pre><code>az storage blob upload --container-name $containerName --account-name $accountName --account-key $accountKey --file $file --name $blobName\n</code></pre> <pre><code>AzCopy copy localFilePath https://storageAccount.blob.core.windows.net/destinationContainer/path/to/blob?SASToken\n</code></pre> <p>Download a blob from a container</p> Azure AzCopy <pre><code>AzCopy copy https://storageAccount.blob.core.windows.net/sourceContainer/path/to/blob?SASToken localFilePath\n</code></pre> <p>Copy a blob from one container to another</p> Azure AzCopy <pre><code>AzCopy /Source:https://sourceblob.blob.core.windows.net/sourcecontainer/ /Dest:https://deststorage.blob.core.windows.net/destcontainer/ /SourceKey:sourcekey /DestKey:destkey /Pattern:disk1.vhd\n</code></pre> <p><pre><code>$blobCopyState = Start-AzStorageBlobCopy -SrcBlob $blobName -SrcContainer $srcContainer -Context $srcContext -DestContainer $destContainer -DestBlob $vhdName -DestContext $destContext\n$srcStorageKey = Get-AzStorageAccountKey -ResourceGroupName $sourceg -Name $srcStorageAccount\n$destStorageKey = Get-AzStorageAccountKey -ResourceGroupName $destg -Name $destStorageAccount\n$srcContext = New-AzStorageContext -StorageAccountName $srcStorageAccount -StorageAccountKey $srcStorageKey.Value[0]\n$destContext = New-AzStorageContext -StorageAccountNAme $destStorageAccount -StorageAccountKey $destStorageKey.Value[0]\n\n# Create new container in destination account\nNew-AzStorageContainer -Name $destContainer -Context $destContext\n\n# Make the copy\n$copiedBlob = Start-AzStorageBlobCopy -SrcBlob $blobName -SrcContainer $srcContainer -Context $srcContext -DestContainer $destContainer -DestBlob $blobName -DestContext $destContext\n</code></pre> <pre><code>az storage blob copy start --account-name $destStorageAccount --account-key $destStorageKey --destination-blob $blobName --source-account-name $srcStorageAccount --source-container $srcContainer --source-blob $blobName --source-account-key $srcStorageKey\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#monitor-progress-of-the-async-blob-copy","title":"Monitor progress of the async blob copy","text":"<p><pre><code>$copiedBlob | Get-AzStorageBlobCopyState\n</code></pre> <pre><code>az storage blob show --account-name $destStorageAccount --account-key $destStorageKey --container-name $destContainer --name $blobName\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#create-sas-token","title":"Create SAS token","text":"<p><pre><code>$storageKey = Get-AzStorageAccountKey -ResourceGroupName $g -Name $accountName\n$context = New-AzStorageContext -StorageAccountName $accountName -StorageAccountKey $storageKey[0].Value\n$startTime = Get-Date\n$endTime = $startTime.AddHours(4)\n\nNew-AzStorageBlobSASToken -Container $container -Blob $blob -Permission \"rwd\" -StartTime $startTime -ExpiryTime $startTime.AddHours(4) -Context $context\n</code></pre> <pre><code>az storage blob generate-sas --account-name \"storageAccount\" --account-key $storageAccountKey --container-name $container --name $blobName --permissions r --expiry \"2019-05-31\"\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#create-container","title":"Create container","text":"<p><pre><code>$storageKey = Get-AzStorageAccountKey -Name $storageAccount -ResourceGroupName $resourceGroup\n$context = New-AzStorageContext -StorageAccountName $storageAccount -StorageAccountKey $storageKey.Value[0]\nSet-AzCurrentStorageAccount -Context $context\n\nNew-AzStorageContainer -Name $container -Permission Off\n</code></pre> Upload file as blob to new container</p> Azure PowerShellAzure CLI <pre><code>Set-AzStorageBlobContent -File $localFile -Container $container -Blob $blobName\n</code></pre> <pre><code>az storage container create --account-name $storageaccount --name $containername --public-access off\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#ensure-app-services-backup-vault-and-event-hub-have-access-to-a-storage-account","title":"Ensure App Services, backup vault, and event hub have access to a storage account","text":"<pre><code>Get-AzVirtualNetwork -ResourceGroupName RG01 -Name VNET01 |\nSet-AzVirtualNetworkSubnetConfig -Name VSUBNET01 -AddressPrefix 10.0.0.0/24 -ServiceEndpoint Microsoft.Storage |\nSet-AzVirtualNetwork\n\n$subnet = Get-AzVirtualNetwork -ResourceGroupName RG01 -Name VNET01 |\nGet-AzVirtualNetworkSubnetConfig -Name VSUBNET01\nAdd-AzStorageAccountNetworkRule -ResourceGroupName VNET01 -Name Storage01 -VirtualNetworkResourceId $subnet.Id\nUpdate-AzStorageAccountNetworkRuleSet -ResourceGroupName RG01 -Name STORAGE01 -Bypass Azure.Services\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#troubleshoot-azure-file-sync","title":"Troubleshoot Azure File Sync","text":"<p>Several procedures to be used when Azure File Sync is having issues</p> <p>Collect logs to troubleshoot issues with Azure File Sync agent installation <pre><code>StorageSyncAgent.msi /l*v AFSInstaller.log\n</code></pre> Remove the server from registered sync group Error message \"This server is already registered during registration\" <pre><code>Import-Module \"C:\\Program Files\\Azure\\StorageSyncAgent\\StorageSync.Management.ServerCmdlets.dll\"\nReset-StorageSyncServer\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#monitoring-using-log-analytics","title":"Monitoring using Log Analytics","text":"<p>Access Activity Log data (Portal) 1. Find Management + Governance in All Services 2. Open Activity Log 3. Click Logs icon at top of Activity Log view to select an existing Log Analytics (OMS) workspace or create a new one</p>"},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#storage-account-endpoints","title":"Storage account endpoints","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-Storage/#virtual-network-service-endpoint","title":"Virtual network service endpoint","text":"<p>Sources - AZ-103 p. 112 - Configure Azure Storage firewalls and virtual networks</p> <p></p> <ol> <li>Specify <code>Microsoft.Storage</code> in the service endpoint settings of the VNet subnet</li> <li>Configure which VNets can access a particular storage account</li> </ol> <p>Display virtual network rules</p> Azure PowerShellAzure CLI <pre><code>Get-AzStorageAccountNetworkRuleSet -ResourceGroupName $rgName -AccountName $n | Select-Object VirtualNetworkRules\n</code></pre> <pre><code>az storage account network-rule list -g $rgName -n $n --query virtualNetworkRules\n</code></pre> <p>Enable service endpoint for Azure Storage on an existing virtual network and subnet.</p> Azure PowerShellAzure CLI <pre><code>Get-AzVirtualNetwork -ResourceGroupName $rgName -Name $n | Set-AzVirtualNetworkSubnetConfig -Name \"mysubnet\" -AddressPrefix \"10.0.0.0/24\" -ServiceEndpoint \"Microsoft.Storage\" |   Set-AzVirtualNetwork\n</code></pre> <pre><code>az network vnet subnet update -g $rgName --vnet-name $n --name \"mysubnet\" --service-endpoints \"Microsoft.Storage\"\n</code></pre> <p>Add network rule for VNet and subnet</p> Azure PowerShellAzure CLI <pre><code>$subnet = Get-AzVirtualNetwork -ResourceGroupName $ng -Name $nn | Get-AzVirtualNetworkSubnetConfig -Name \"mysubnet\"\n\nAdd-AzStorageAccountNetworkRule -ResourceGroupName $sg -Name $sn -VirtualNetworkResourceId $subnet.Id\n</code></pre> <pre><code>subnetid=$(az network vnet subnet show -g $ng --vnet-name $nn -n \"mysubnet\" --query id --output tsv)\naz storage account network-rule add -g $sg -n $sn --subnet $subnetid\n</code></pre> <p>Remove network rule</p> <pre><code>```powershell\n$subnet = Get-AzVirtualNetwork -ResourceGroupName $ng -Name $nn | \n    Get-AzVirtualNetworkSubnetConfig -Name \"mysubnet\"\n\nRemove-AzStorageAccountNetworkRule -ResourceGroupName $sg -Name $sn -VirtualNetworkResourceId $subnet.Id\n```\n</code></pre> <p>Bypass network rules to allow access for Azure services like Event Hub and Recovery Services Vault</p> Azure PowerShellAzure CLI <pre><code># Display exceptions for the storage account network rules\nGet-AzStorageAccountNetworkRuleSet -ResourceGroupName $g -Name $n | Select-Object Bypass\n# Configure exceptions to storage account network rules\nUpdate-AzStorageAccountNetworkRuleSet -ResourceGroupName $g -Name $n -Bypass AzureServices,Metrics,Logging\n</code></pre> <pre><code># Display exceptions for the storage account network rules\naz storage account show -g $g -n $n --query networkRuleSet.bypass\n# Configure exceptions to storage account network rules\naz storage account update -g $g -n $n --bypass Logging Metrics AzureServices\n</code></pre> <ul> <li>Configure Azure Storage firewalls and virtual networks</li> <li>AZ-103: p. 107, 114, 127</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/","title":"Azure VPN","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/#authentication","title":"Authentication","text":"<p>Azure P2S VPN connections support several authentication methods:</p> <ul> <li>Azure AD authentication (Windows 10 only)</li> <li>RADIUS server</li> <li>VPN Gateway native certificate authentication</li> </ul> <p>The VPN gateway acts as a pass-through forwarding authentication messages between the connecting device and the RADIUS server. The RADIUS server can be deployed on-premises or in the Azure VNet, and two such servers can be deployed for high availability.</p> <ul> <li>If deployed on-premises, a S2S VPN to the site is required, and ExpressRoute is not usable.</li> <li>AD domain authentication requires a RADIUS server that integrates with the AD server.</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/#tasks","title":"Tasks","text":""},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/#create-local-network-gateway","title":"Create local network gateway","text":"<p><pre><code>$localnw = New-AzLocalNetworkGateway -Name LocalNetGW -ResourceGroupName ExamRefRG -Location \"West Europe\" -GatewayIpAddress \"53.50.123.195\" -AddressPrefix \"10.5.0.0/16\" \n</code></pre> Create VPN connection <pre><code>$gateway = Get-AzVirtualNetworkGateway -Name VPNGW1 -ResourceGroupName ExamRefRG\n$conn = New-AzVirtualNetworkGatewayConnection -Name OnPremConnection -ResourceGroupName ExamRefRG -Location 'West Europe' -VirtualNetworkGateway1 $gateway -LocalNetworkGateway2 $localnw -ConnectionType IPsec -SharedKey \"abc123\"\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/#create-a-vpn-gateway","title":"Create a VPN Gateway","text":"<p><pre><code>$rg = ExamRefRG\n</code></pre> Create gateway subnet in VNet1 Gateway subnets are normal subnets with the name \"GatewaySubnet\" <pre><code>$vnet1 = Get-AzVirtualNetwork -Name VNet1 -ResourceGroupName $rg\n$vnet1.Subnets += New-AzVirtualNetworkSubnetConfig -Name GatewaySubnet -AddressPrefix 10.1.1.0/27\n$vnet1 = Set-AzVirtualNetwork -VirtualNetwork $vnet1\n</code></pre> Create VPN gateway in VNet1 <pre><code>$gwpip = New-AzPublicIpAddress -Name VNet1-GW-IP -ResourceGroupName $rg -Location 'North Europe' -AllocationMethod Dynamic\n$gwsubnet = Get-AzVirtualNetworkSubnetConfig -Name 'GatewaySubnet' -VirtualNetwork $vnet1\n$gwipconf = New-AzVirtualNetworkGatewayIpConfig -Name GwIPConf -Subnet $gwsubnet -PublicIpAddress $gwpip\n$vnet1gw = New-AzVirtualNetworkGateway -Name VNet1-GW -ResourceGroupName $rg -Location 'North Europe' -IpConfigurations $gwipconf -GatewayType Vpn -VpnType RouteBased -GatewaySku VpnGw1\n</code></pre></p> <p>Create gateway subnets in VNet2 and VNet3 <pre><code>az network vnet subnet create --name GatewaySubnet --vnet-name VNet1 --resource-group ExamRefRG --address-prefixes 10.1.1.0/27\naz network public-ip create --name VNet1-GW-IP --resource-group ExamRefRG --location NorthEurope\naz network vnet-gateway create --name VNet1-GW --resource-group ExamRefRG --gateway-type vpn --sku VpnGw1 --vpn-type RouteBased --vnet VNet1 --public-ip-addresses VNet1-GW-IP --location NorthEurope\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/#create-a-vpn-gateway-and-vnet-peering","title":"Create a VPN gateway and VNet peering","text":"<p>Create gateway subnets in VNet2 and VNet3 <pre><code>$vnet2 = Get-AzVirtualNetwork -Name VNet2 -ResourceGroupName ExamRefRG\n$vnet2.Subnets += New-AzVirtualNetworkSubnetConfig -Name GatewaySubnet -AddressPrefix 10.2.1.0/27\n$vnet2 = Set-AzVirtualNetwork -VirtualNetwork $vnet2\n$vnet3 = Get-AzVirtualNetwork -Name VNet3 -ResourceGroupName ExamRefRG\n$vnet3.Subnets += New-AzVirtualNetworkSubnetConfig -Name GatewaySubnet -AddressPrefix 10.3.1.0/27\n$vnet3 = Set-AzVirtualNetwork -VirtualNetwork $vnet3\n</code></pre> Create VPN gateway in VNet2 <pre><code>$gwpip2 = New-AzPublicIpAddress -Name VNet2-GW-IP -ResourceGroupName ExamRefRG -Location $vnet2.Location -AllocationMethod Dynamic\n$gwsubnet2 = Get-AzVirtualNetworkSubnetConfig -Name 'GatewaySubnet' -VirtualNetwork $vnet2\n$gwipconf2 = New-AzVirtualNetworkGatewayIpConfig -Name GwIPConf2 -Subnet $gwsubnet2 -PublicIpAddress $gwpip2\n$vnet2gw = New-AzVirtualNetworkGateway -Name VNet2-GW -ResourceGroupNAme ExamRefR -Location $vnet2.Location -IpConfigurations $gwipconf2 -GatewayType Vpn -VpnType RouteBased -GatewaySku VpnGw1\n</code></pre> Create VPN gateway in VNet3 <pre><code>$gwpip3 = New-AzPublicIpAddress -Name VNet3-GW-IP -ResourceGroupName ExamRefR -Location $vnet3.Location -AllocationMethod Dynamic\n$gwsubnet3 = Get-AzVirtualNetworkSubnetConfig -Name 'GatewaySubnet' -VirtualNetwork $vnet3\n$gwipconf3 = New-AzVirtualNetworkGatewayIpConfig -Name GwIPConf3 -Subnet $gwsubnet3 -PublicIpAddress $gwpip3\n$vnet3gw = New-AzVirtualNetworkGateway -Name VNet3-GW -ResourceGroupNAme ExamRefRG -Location $vnet3.Location -IpConfigurations $gwipconf3 -GatewayType Vpn -VpnType RouteBased -GatewaySku VpnGw1\n</code></pre> Create connections <pre><code>New-AzVirtualNetworkGatewayConnection -Name VNet2-to-VNet3 -ResourceGroupName ExamRefRG -Location $vnet2.Location -VirtualNetworkGateway1 $vnet2gw -VirtualNetworkGateway2 $vnet3gw -ConnectionType VNet2VNet -SharedKey \"secretkey123\"\nNew-AzVirtualNetworkGatewayConnection -Name VNet3-to-VNet2 -ResourceGroupName ExamRefRG -Location $vnet3.Location -VirtualNetworkGateway1 $vnet3gw -VirtualNetworkGateway2 $vnet2gw -ConnectionType VNet2VNet -SharedKey \"secretkey123\"\n</code></pre></p> <p>Create gateway subnets in VNet2 and VNet3 <pre><code>az network vnet subnet create --name GatewaySubnet --vnet-name VNet2 --resource-group ExamRefRG --address-prefixes 10.2.1.0/27\naz network vnet subnet create --name GatewaySubnet --vnet-name VNet3 --resource-group ExamRefRG --address-prefixes 10.3.1.0/27\n</code></pre> Create public IP addresses for use by VPN gateways <pre><code>az network public-ip create --name VNet2-GW-IP --resource-group ExamRefRG --location NorthEurope\naz network public-ip create --name VNet3-GW-IP --resource-group ExamRefRG --location WestEurope\n</code></pre> Create VPN gateways in VNet2 and VNet 3 <pre><code>az network vnet-gateway create --name VNet2-GW --resource-group ExamRefRG --gateway-type vpn --sku VpnGw1 --vpn-type RouteBased --vnet VNet2 --public-ip-addresses VNet2-GW-IP --location NorthEurope\naz network vnet-gateway create --name VNet3-GW --resource-group ExamRefRG --gateway-type vpn --sku VpnGw1 --vpn-type RouteBased --vnet VNet3 --public-ip-addresses VNet3-GW-IP --location WestEurope\n</code></pre> Create connections between VPN gateways <pre><code>az network vpn-connection create --name VNet2-to-VNet3 --resource-group ExamRefRG --vnet-gateway1 VNet2-GW --vnet-gateway2 VNet3-GW --shared-key secretkey123 --location NorthEurope\naz network vpn-connection create --name VNet3-to-VNet2 --resource-group ExamRefRG --vnet-gateway1 VNet3-GW --vnet-gateway2 VNet2-GW --shared-key secretkey123 --location WestEurope\n</code></pre></p>"},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/#use-vpn-troubleshoot","title":"Use VPN Troubleshoot","text":"<p>Get the Network Watcher resource <pre><code>$nw = Get-AzResource | Where ResourceType -eq Microsoft.Network/networkWatchers -and Location -eq WestEurope\n$networkWatcher = Get-AzNetworkWatcher -Name $nw.Name -ResourceGroupName $nw.ResourceGroupName\n</code></pre></p> <p>Get the connection to troubleshoot <pre><code>$connection = Get-AzVirtualNetworkGatewayConnection -Name Vnet1-to-Vnet2 -ResourceGroupName ExamRefRG\n</code></pre></p> <p>Start VPN Troubleshoot</p> <pre><code>Start-AzNetworkWatcherResourceTroubleshooting -NetworkWatcher $networkWatcher -TargetResourceId $connection.Id -StorageId $sa.Id -StoragePath \"$($sa.PrimaryEndpoints.Blob)$($sc.name)\"\n</code></pre> <p>Create a storage account and container for logs</p> <pre><code>az storage account create --name examrefstorage --location westeurope --resource-group ExamRefRG --sku Standard_LRS\naz storage account keys list --resource-group ExamRefRG --account-name examrefstorage\naz storage container create --account-name examrefstorage --account-key {storageAccountKey} --name logs\n</code></pre> <p>Start VPN Troubleshoot</p> <pre><code>az network watcher troubleshooting start --resource-group ExamRefRG --resource Vnet1-to-Vnet2 --resource-type vpnConnection --storage-account examrefstorage --storage-path https://examrefstorage.blob.core.windows.net/logs --output json\n</code></pre>"},{"location":"Infrastructure/Cloud/Azure/Azure-VPN/#create-s2s-vpn","title":"Create S2S VPN","text":"<p>AZ-103: 395 <pre><code>$lgwip = 53.50.123.195\n$key = \"abc123\"\n</code></pre> <pre><code>$lgw = New-AzLocalNetworkGateway -ResourceGroupName $g -Name $n -Location $l -GatewayIpAddress $lgwip -AddressPrefix \"10.5.0.0/16\"\n$vgw = Get-AzVirtualNetworkGateway -ResourceGroupNAme -Name\nNew-AzVirtualNetworkGatewayConnection -ResourceGroupName $g -Name $n -Location $l -VirtualNetworkGateway1 $vgw -LocalNetworkGateway2 $lgw -ConnectionType IPsec -SharedKey $key\n</code></pre> <pre><code>az network local-gateway create --gateway-ip-address $lgwip --name LocalNetGW --resource-group ExamRefRG --local-address-prefixes 10.5.0.0/16\naz network vpn-connection create --name OnPremConnection --resource-group ExamRefRG --vnet-gateway1 VPNGW1 --location WestEurope --shared-key $key --local-gateway2 LocalNetGW\n</code></pre></p> <p>Sources</p> <ul> <li>VPN Gateway design</li> <li>Connect Azure VPN gateways to multiple on-premises policy-based VPN devices</li> <li>About VPN Gateway configuration settings</li> <li>Highly available cross-premises and VNet-to-VNet connectivity</li> <li>ExpressRoute connectivity models</li> <li>Connect a computer to a virtual network using P2S and RADIUS authentication: PowerShell</li> </ul>"},{"location":"Infrastructure/Cloud/Azure/Kusto/","title":"Kusto","text":"<p>In Kusto documentation <code>T</code> typically refers to the Table being queried: <pre><code>T\n| where Predicate\n</code></pre></p> <p><code>&lt;&gt;</code> is equivalent to <code>!=</code> <pre><code>SecurityEvent\n| where Level &lt;&gt; 8\n| where EventID==4672\n</code></pre></p> <p>Select columns to include, rename, or drop</p> <pre><code>T\n| project\n    X=C,                       // Rename column C to X\n    A=2*B,                     // Calculate a new column A from the old B\n    C=strcat(\"-\",tostring(C)), // Calculate a new column C from the old C\n    B=2*B                      // Calculate a new column B from the old B\n</code></pre> <pre><code>StormEvents\n| extend label = case (\n  DamageProperty &lt; 1000, \"Storm\",\n  DamageProperty &gt; 1000 and DamageProperty &lt; 10000, \"Disaster\",\n  \"Catastrophe\" )\n| summarize count() by label\n</code></pre> <p>The SecurityEvent table provided as part of the [Log Analytics][Log Analytics] workspace trainingg dataset contains event viewer logs typical of what a security analyst would analyze, with the following columns:</p> <ul> <li>TimeGenerated</li> <li>Account</li> <li>AccountType (Machine or User)</li> <li>Computer</li> <li>EventSourceName</li> <li>Channel</li> <li>CommandLine</li> </ul> <p>Find logons, producing number of logins per Computer for computers with names beginning with \"App\" <pre><code>SecurityEvent\n| where TimeGenerated between (ago(14d)..ago(7d))\n| where EventID == 4624\n| where Computer startswith \"App\"\n| summarize count() by Computer\n</code></pre></p> <pre><code>SecurityEvent\n| where EventID == 4688\n| summarize count() by CommandLine, Computer\n</code></pre> id title director year length_minutes 1 Toy Story John Lasseter 1995 81 2 A Bug's Life John Lasseter 1998 95 3 Toy Story 2 John Lasseter 1999 93 4 Monsters, Inc. Pete Docter 2001 92 5 Finding Nemo Andrew Stanton 2003 107 6 The Incredibles Brad Bird 2004 116 7 Cars John Lasseter 2006 117 8 Ratatouille Brad Bird 2007 115 9 WALL-E Andrew Stanton 2008 104 10 Up Pete Docter 2009 101 11 Toy Story 3 Lee Unkrich 2010 103 12 Cars 2 John Lasseter 2011 120 13 Brave Brenda Chapman 2012 102 14 Monsters University Dan Scanlon 2013 110 <p>Find the title of each film <pre><code>Movies \n| project title\n</code></pre> Number of reporting computers each hour AZ-103: 53 <pre><code>Heartbeat \n| summarize dcount(ComputerIP) by bin(TimeGenerated, 1h) \n| render timechart\n</code></pre> List top 10 VMs with most error events over the past day MeasureUp <pre><code>Event\n| where (EventLevelName == \"Error\")\n| where (TimeGenerated &gt; ago(1days))\n| summarize ErrorCount = count() by Computer\n| top 10 by ErrorCount desc\n</code></pre></p> <p>Render a SQL query as KQL</p> <pre><code>EXPLAIN\nSELECT name FROM greeks;\n</code></pre> <p>Count instances of a value</p> <pre><code>movies | summarize movies_directed = count() by director\n</code></pre> <p>Create a new column dynamically from others</p> <pre><code>movies | extend age = 2020 - year | project name, age;\n</code></pre> <p>Hide secrets from the queries log</p> <pre><code>print h\"Hello world!\";\n.show \n</code></pre> <p>Kusto clusters can be provisioned and Kusto databases created and manipulated using both PowerShell and Azure CLI.</p> <p>The Azure CLI <code>kusto</code> module will not be supported after 01/01/2021.</p> <pre><code>az extension add -n kusto\n</code></pre> <p>Create cluster</p> Azure PowerShellAzure CLI <pre><code>New-AzKustoCluster -ResourceGroupName testrg -Name testnewkustocluster -Location 'East US' -SkuName Standard_D11_v2 -SkuTier Standard -EnableDoubleEncryption true\n</code></pre> <pre><code>az kusto cluster create --name --resource-group --sku\n</code></pre> <pre><code>az kusto database create\n</code></pre> <p>Create table</p> <p>Connect to database <pre><code>#connect cluster('jasper.eastus').database('test');\n</code></pre></p> <p>Create table <pre><code>.create table starships (Name:string, Registry:string, Class:string, Crew:int32)\n</code></pre></p> <p>Ingest data <pre><code>.ingest into table T h'https://raw.githubusercontent.com/jasper-zanjani/dogfood/master/csv/greeks.csv' with (ignoreFirstRecord=true)\n</code></pre> Alternatively, define a new <code>datatable</code> inline</p> <p><pre><code>let starships = datatable(Name:string,Class:string,Registry:string,Crew:int)\n[\n\"USS Enterprise\", \"Constitution\",\"NCC-1701\",203,\n\"USS Constitution\",\"Constitution\",\"NCC-1700\",204,\n\"USS Defiant\",\"Defiant\",\"NX-74205\",50,\n\"USS Voyager\",\"Intrepid\",\"NCC-74656\",141,\n\"USS Enterprise\",\"Galaxy\",\"NCC-1701-D\",6000,\n\"USS Reliant\",\"Miranda\",\"NCC-1864\",35\n];\n</code></pre> Search for a word</p> <p><pre><code>starships | search  \"enterprise\";\n</code></pre> <pre><code>search in (SecurityEvent) \"Cryptographic\"\n| take 10;\n</code></pre></p> <p>Datetime  values support a menagerie of functions</p> <pre><code>print datetime(2015-01-01) # 2015-01-01 00:00:00.0000\nprint format_datetime(datetime(2015-01-01), \"yyyy\") # 2015\n</code></pre> <p>Concatenate values from other columns.</p> <pre><code>StormEvents\n| project EpisodeId, where_storm = strcat(EventType, \" in \", State);\n</code></pre> <p>Export data <pre><code>.export async to sql ['dbo.StormEventTypeTable']\n</code></pre></p> <p>Sources</p> <ul> <li>Azure Data Explorer documentation </li> <li>How to start with Microsoft Azure Data Explorer  </li> <li>KQL quick reference </li> <li>SQL to Kusto cheat sheet  </li> <li>Kusto.Explorer </li> <li>Azure Sentinel webinar parts 1, 2  , 3</li> <li>KQL syntax: <code>count</code>, <code>take</code></li> </ul>"},{"location":"Language/Anki/","title":"Anki cards","text":"<p>For language-learning purposes, it appears the best approach to use with Anki is to routinely watch media and extract audio clips of interest, for the purpose of producing a cloze note with a transcript.</p> <ol> <li>Download audio and create a clip.</li> <li>Drag and drop the clip into a new note.</li> <li>Paste the template HTML to make use of the text message format, if desired.</li> <li>Copy and paste the transcription appropriately.</li> <li>Create cloze items.</li> </ol>"},{"location":"Language/Anki/#audio","title":"Audio","text":"<pre><code>[sound:clip.mp3]\n</code></pre> <p>Anki will autoplay these clips by default, though this behavior can be disabled in deck options.</p>"},{"location":"Language/Anki/#message-bubbles","title":"Message bubbles","text":"<p>This CSS was found here. Some changes were incorporated to make it compatible with Anki Night mode.</p> Basic pattern<pre><code>&lt;div class=\"imessage\"&gt;\n    &lt;p class=\"from-them\"&gt;\n\n    &lt;/p&gt;\n    &lt;p class=\"from-me\"&gt;\n        &lt;span class=\"translation\"&gt;&lt;/span&gt;\n    &lt;/p&gt;\n&lt;/div&gt;\n</code></pre> <pre><code>.imessage\np.from-them Oi, td bem?\n    p.from-me {{c1::Td}} sim\n// (1)!\n</code></pre> <pre><code>.imessages\np.from-them Me dijiste que si esperaba ser pagada y te dije que no\n    p.from-me {{c1::Podr\u00eda}} {{c2::haberte}} pagado por tus salarios perdidos \n        span.translation I could have paid your for your lost wages  \n// (1)!\n</code></pre>"},{"location":"Language/Japanese/","title":"Japanese","text":"<p>NO and KOTO are both used to nominalize clauses and verbs in different contexts.</p> no<pre><code>\u53cb\u9054\u304c\u8a71\u3057\u3066\u3044\u308b\u306e\u304c\u805e\u3053\u3048\u307e\u3057\u305f\u3002# (1)\n</code></pre> <ol> <li>\"I heard my friends talking.\"</li> </ol> koto<pre><code>\u4eca\u5e74\u306e\u76ee\u6a19\u306f\u3001\u8a66\u9a13\u306b\u5408\u683c\u3059\u308b\u3053\u3068\u3067\u3059\u3002 # (1)\n</code></pre> <ol> <li>\"My goal this year is to pass the exam.\"</li> </ol>"},{"location":"Language/Japanese/#ime","title":"IME","text":"<p>Typing in Japanese is done by applications known as IME (input method editor). The preedit or composition string refers to the string composed by the user using an IME, which can then be converted or rendered in the desired script.</p> <p>For example, a user may input the string \"watasinonamaehanakanodesu\", which is rendered as the following preedit: <pre><code>\u308f\u305f\u3057\u306e\u306a\u307e\u3048\u306f\u306a\u304b\u306e\u3067\u3059\n</code></pre></p> <p>By pressing the convert key Tab, the IME then opens a menu that allows the preedit to be converted to a mixture of hiragana and kanji: <pre><code>\u79c1\u306e\u540d\u524d\u306f\u4e2d\u91ce\u3067\u3059\n</code></pre></p> <p>Some conventions date from ancient practice and are silently assumed now.</p> <p>For example, the convention that F6 produces hiragana and F7 katakana is associated with ATOK, a Japanese IME with roots in the 1980s.</p> <p>Microsoft's IME is built-in to Windows, but on Linux there are multiple IMEs available. Mozc appears to be the most popular, but fcitx5 is installed by default on Garuda and offers Mozc-like functionality.</p>"},{"location":"Language/Japanese/#furigana","title":"Furigana","text":"<p>In HTML, furigana can be placed with the ruby and rt HTML tags, which are supported by Anki:</p> <p>In order to render: \u76ee\u6a19\u3082\u304f\u3072\u3087\u3046 (objective) <pre><code>&lt;ruby&gt;\u76ee\u6a19&lt;rt&gt;\u3082\u304f\u3072\u3087\u3046&lt;/rt&gt;&lt;/ruby&gt; \n</code></pre></p>"},{"location":"Language/Portuguese/","title":"Angolan Portuguese","text":"<p>Sound changes from Brazilian Portuguese:</p>"},{"location":"Language/Portuguese/#t-t","title":"t\u0283 -&gt; t","text":"Minist\u00e9rio da Justi\u00e7a"},{"location":"Language/Portuguese/#d-d","title":"d\u0292 -&gt; d","text":"sa\u00fade"},{"location":"Language/Spanish/","title":"Spanish","text":"Greetings <pre><code>graph TD\nF[Saludos] --&gt; A;\nF --&gt; C;\nF --&gt; E;\nA[Qu\u00e9 lo que?] --&gt; B[Tranquilo];\nC[Dame luz?] --&gt; B;\nA --&gt; D[T\u00f3 frio];\nC --&gt; D;\nE[Como te sien?] --&gt; B;\nE --&gt; D;\nE --&gt; G[Bacano];\nA --&gt; H[Normal];\nC --&gt; H;\nE --&gt; H;\nA --&gt; I[Manso];\nC --&gt; I;\nE --&gt; I;</code></pre> <p>Note that Qu\u00e9 lo que often appears in chat as 'klk' or 'qlok' Both men and women can be addressed as manito/manita, loco/loca, i.e. \"Qu\u00e9 lo que manito?\", etc.</p>"},{"location":"Language/Spanish/#vocabulary","title":"Vocabulary","text":""},{"location":"Language/Spanish/#b","title":"B","text":"<ul> <li>bajarle dos to lower the intensity or speed of something </li> <li>baquear<ul> <li>Qui\u00e9n te t\u00e1 baqueando ese poloch\u00e9?</li> </ul> </li> <li>boca abajo prone</li> <li>brindar to present, offer</li> <li>bultero flaky, someone who makes plans but does not follow through; a braggart, someone who exaggerates personal accomplishments</li> </ul>"},{"location":"Language/Spanish/#c","title":"C","text":"<ul> <li>celar to become jealous (cf. celoso) A veces me digo \"no seas celosa Tatiana\" pero como no me llamo Tatiana pues celo cuando me da mi gana</li> <li>chancear a alguien give somebody a chance, court someone</li> <li>cherchoso teasing or mocking person</li> <li>chin a little bit</li> <li>chulo: very handsome; a man who is knowingly in a relationship with a woman who is a prostitute, and who is supported by her</li> <li>chuqui to be irritable, angry (also chucky) i.e. andar chuqu\u00ed en la calle to party in the streets</li> <li>cocotazo a smack on the head</li> <li>cogerse la llamada to pick up a phone call: Cogeme la llamada que t\u00fa eres m\u00eda todav\u00eda</li> <li>comer como una lima nueva describing someone who eats a lot</li> <li>cualto money, payment</li> <li>cuernos ponerse los cuernos to cheat on a partner </li> </ul>"},{"location":"Language/Spanish/#d","title":"D","text":"<ul> <li>dame banda expression used to end the current topic of discussion out of exasperation: \"leave me alone, do what you want\"</li> <li>dar galleta slap the face</li> <li>dar mente a algo to mind, worry about something Pero no le de mente a eso beb\u00e9</li> <li>de d\u00eda estar de d\u00eda \"to be daytime\" (Est\u00e1 de d\u00eda en tu pa\u00eds?)</li> <li>desodorante deodorant</li> <li>diligencia hacer diligencia when said by a woman, euphemism for prostitution</li> <li>domingo 7 pregnancy outside of marriage, especially one abandoned by the father, no me dejes con un domingo 7 y te vallas por ray jjj \"don't knock me up and leave haha\"</li> </ul>"},{"location":"Language/Spanish/#e","title":"E","text":"<ul> <li>entre dos estar entre dos to be feeling poorly</li> <li>estuche case, i.e. \"contact lens case\"</li> </ul>"},{"location":"Language/Spanish/#f","title":"F","text":"<ul> <li>flow swag, style, attractive manner of dress mangar este flow</li> <li>fresco a person who is cheeky or rude, typically regarding sexual topics, i.e. lo bloqu\u00e9 por frescos</li> </ul>"},{"location":"Language/Spanish/#g","title":"G","text":"<ul> <li>guayar to bump, grind</li> </ul>"},{"location":"Language/Spanish/#j","title":"J","text":"<ul> <li>jablador (also hablador) liar; boastful or braggart</li> <li>josear (also josiar, jociar)  to hustle</li> <li>jeva woman, partner</li> </ul>"},{"location":"Language/Spanish/#l","title":"L","text":"<ul> <li>laja something highly used and worn out, i.e. estoy buscando una laja de esas</li> <li>llevarse son 17 que me llevas \"You're 17 [years] older than me\"</li> </ul>"},{"location":"Language/Spanish/#m","title":"M","text":"<ul> <li>macorisano someone from San Francisco de Macoris</li> <li>mangar to pinch, grab, obtain; have sexual relations with someone</li> <li>molote mob</li> <li>motoconcho small motorcycle used for taxi service</li> </ul>"},{"location":"Language/Spanish/#n","title":"N","text":"<ul> <li>nama only, merely, just (preverbal): Me quiere pre\u00f1a? Pa que salga bonito Tu no lo va a mantener ni naa Nama e paa que salga peluche</li> <li>nevera refrigerator</li> <li>ni modo \"no way\", ni modo que voy a decir</li> <li>nina nothing more, nothing at all (sentence final)</li> </ul>"},{"location":"Language/Spanish/#p","title":"P","text":"<ul> <li>paquetero a liar, braggart</li> <li>parar to end up in a place without intending to do so</li> <li>pariguayo lame guy who can't get girls</li> <li>pasola scooter</li> <li>pedazo place, corner, or neighborhood of a city</li> <li>peluch\u00e9 pretty, attractive: Me quiere pre\u00f1a? Pa que salga bonito Tu no lo va a mantener ni naa Nama e paa que salga peluche</li> <li>pica pollo fried chicken</li> <li>planta compliment for a woman</li> <li>poloch\u00e9 t-shirt</li> <li>popola pussy (cf. toto, creta)</li> <li>pre\u00f1ar to impregnate: Me quiere pre\u00f1a? Pa que salga bonito Tu no lo va a mantener ni naa Nama e paa que salga peluche</li> </ul>"},{"location":"Language/Spanish/#r","title":"R","text":"<ul> <li>rebajar to lose weight</li> <li>romper to exceed expectations, to draw attention (?)</li> <li>rulay loose</li> </ul>"},{"location":"Language/Spanish/#s","title":"S","text":"<ul> <li>se fue la luz end of discussion</li> <li>shi (also chi) tisk (dental click), in DR an expression of tenderness: yo no le digo shi a nadie, lo sient. soy un ser oscuro.</li> </ul>"},{"location":"Language/Spanish/#t","title":"T","text":"<ul> <li>teteo party, (cf. tetear)</li> <li>tigueraje slang; assertiveness</li> <li>tiguere a streetwise and capable guy; guy, dude (usage is similar to vaina but with people)</li> <li>tirarse to send a text message: \"Hay que tirarme por privado.\"</li> <li>trote pasar trote to pass a great ordeal</li> <li>tollo a mismanaged mess due to incompetence \"el dia de Carnaval en Monte Plata es un tollo\"</li> <li>toto pussy (cf. creta)</li> </ul>"},{"location":"Language/Spanish/#v","title":"V","text":"<ul> <li>vaca \"ven ac\u00e1\"</li> <li>vaina stuff, thing; whatever; etc</li> <li>vale well, quite Yo me sent\u00ed vale rara \"I felt pretty weird\"</li> <li>votar to stop liking someone: \ud83d\ude0c Tengo que mantenerme para que no me votes \ud83d\ude02</li> </ul>"},{"location":"Language/Spanish/#y","title":"Y","text":"<ul> <li>y eso? \"why?\"</li> </ul>"},{"location":"Language/Spanish/#resources","title":"Resources","text":"<p>Videos</p> <ul> <li>Qu\u00e9 caus\u00f3 la ca\u00edda del Imperio otomano, la superpotencia que se expandi\u00f3 por tres continentes</li> <li>Crisis en Hait\u00ed: un pa\u00eds perdido en su laberinto</li> </ul>"},{"location":"Language/Spanish/#counterfactuals","title":"Counterfactuals","text":"<ul> <li>Me habr\u00eda gustado salir contigo. \"I would have liked to go with you...\"</li> <li>If it weren't for you, I wouldn't have had a vacation</li> <li>If I went out with you I would have wanted to be with your friend too</li> <li>Podr\u00eda haberte pagado por tus salarios perdidos</li> <li>Si te hubiera robado yo ser\u00eda para ti una chica mala o buena?\ud83e\udd14</li> <li>C\u00f3mo quisiera salir de ac\u00e1 y recostarme en tus brazos</li> <li>I don't know if I told you this or not</li> <li>(In response to a news story about a polaymorous man) hubiera esperado que un negrito con tanto dinero hubiera podido conseguir mujeres menos feas</li> <li>(Responding to a request for money for a stranger) Qu\u00e9 yo gano con eso? \u00bfEsperabas que te regalara ese dinero?</li> </ul>"},{"location":"Language/Spanish/#themes","title":"Themes","text":""},{"location":"Language/Spanish/#body-measurements","title":"Body measurements","text":"<ul> <li>Cuanto mides en altura?</li> <li>Cuanto pesas?</li> <li></li> </ul>"},{"location":"Linux/","title":"Overview","text":"<p>SystemD is the de facto Linux init system on modern distributions.</p> <p>A process runs in its own user address space, a protected space which can't be disturbed by other users</p> <ul> <li>all processes on a Linux system are child processes of a common parent: the init process which is executed by the kernel at boot time (PID 1)</li> <li>every Linux process inherits the environment (PATH variable, etc) and other attributes of its parent process</li> </ul> <p>Every process has a parent; a process can spawn children in a process that is actually made of two separate system calls.</p> <ul> <li>Shell-internal commands (cd, echo, etc. and variable assignments) do not spawn child processes</li> <li>Shell scripts are executed by spawning a sub-shell, which becomes the script's parent</li> <li>External commands are spawned as children of the parent as described above</li> </ul> <p>Bootloaders like GRUB (GRand Unified Bootloader) turn on power supplies and scan buses and interfaces to locate the kernel image and the root filesystem.  LILO (LInux LOader) is also another bootloader that can be found on older Linux systems.</p> <p>Microcontrollers may be listening when the system is nominally off; they typically have their own BIOS and kernels and are inaccessible from the main system:</p> <ul> <li>Baseboard Management Controller (BMC) responds to wake-on-LAN (WOL)</li> <li>Intel Management Engine (IME) x64 software suite for remote management of systems; firmware is based on <code>Minix</code> and runs on the Platform Controller Hub processor, not the main CPU</li> <li>System Management Mode (SMM) launches UEFI software</li> </ul> <p>Linux kernel is typically named vmlinux (or vmlinuz when compressed). Kernel ring buffer contains messages related to the Linux kernel. A ring buffer is a data structure that is always the same size; old messages are discarded as new ones come in, once the buffer is full. <code>dmesg</code> is used to see its contents, and the messages are also stored in <code>/var/log/dmesg</code></p> <p>Kernel modules can be loaded, listed, or removed from the running kernel.</p>"},{"location":"Linux/#security","title":"Security","text":"<p>Similar to DLL files on Windows systems, .so (\"shared object\") library files on Linux allow code to be shared by various processes.  They are vulnerable to injection attacks. </p> Library injection vulnerability <p>One file in particular, linux-vdso.so.1, finds and locates other shared libraries and is mapped by the kernel into the address space of every process.  This library-loading mechanism can be exploited through the use of the environment variable <code>LD_PRELOAD</code>, which is considered the most convenient way to load a shared library in a process at startup.  If defined, this variable is read by the system and the library is loaded immediately after linux-vdso.so.1 into every process that is run. </p> <p>This attack can be detected using the osquery tool.  This tool represents the system as a relational database which can then be queried, in particular against the process_envs table.</p> <p>Filesystem access control lists (FACL) allow you to grant permissions to more than one group, i.e. in cases where more than one department of a corporation needs access to the same files. They are made up of access control entries (ACE).  FACL permissions will be indicated in a <code>ls -l</code> command by the presence of a \"+\" after the symbolic notation for the traditional UGO permissions.  Acl is a dependency of <code>systemd</code>.</p> <p>To enable it, add \",acl\" to options in <code>fstab</code> file, then mount/unmount disk. If enabling FACL on root partition, system has to be rebooted.</p>"},{"location":"Linux/#glossary","title":"Glossary","text":""},{"location":"Linux/#alsa","title":"ALSA","text":"<p>Advanced Linux Sound Architecture (ALSA) replaced the earlier \"Open Sound System\". (src)</p> <p>ALSA kernel modules are designed to offer an interface that \"corresponds to that of the hardware\" to keep the modules simple, and similar cards will offer a similar interface.  ALSA kernel modules offer two interfaces: operational and configuration</p> <p>Operational interface are exposed at /dev/, with 3 main types of devices:</p> <ul> <li>PCM devices, for recording or playing digitized sound samples, come in two varieties - output and input - and are numbered from 0, which is generally for analog multichannel sound.</li> <li>CTL or controls are for manipulating the internal mixer and routing of the card. Controls come in 3 types;<ul> <li>Playback controls are associated with an output device or copy (input-to-output) routes</li> <li>Capture controls are associated with an input device or copy (output-to-input) routes</li> <li>Feature controls drive features of the card or mixer, usually just a switch to enable or disable the feature, though some also have levels. The Master Volume control is the most typical example, which allows control of the internal amplifier feature of the card. A more interesting example is that of a 3D spatializer that can be represented by a switch to enable or disable it as well as two levels.</li> </ul> </li> <li>MIDI to control the MIDI port, if it exists</li> <li>Optionally, sequencer devices may also exist if the card has a builtin sound synthesizer with an associated timer device</li> </ul> <p>Configuration interfaces are exposed at /proc/asound/ tree (ref <code>amixer</code>)</p> <p>Cards have input or output sockets, and the mixer is controlled by the CTL device and routes sound samples among devices and sockets.</p> <p>Typical channel assignments - 0: front left - 1: front right - 2: rear left - 3: rear right</p> Berkeley Software Distribution (BSD) <p>BSD began in the 70s and was based on AT&amp;T original code.  First source distributions required user to purchase a source license from AT&amp;T, since much of the BSD source was derivative of UNIX.</p> <p>Berkeley finally released a \"wholly-BSD\" product as Network Release 1 in 1989, which satisfied vendor demand for the TCP/IP networking code for PC.</p> <p>Work immediately began to reconstruct the remaining functionality of UNIX, which was completed in Network Release 2, released in 1991, which was based entirely on Berkeley code. Eventually this resulted in the 386BSD distribution, which then spawned five interrelated BSD distros: BSDI (now Wind River), NetBSD, FreeBSD, OpenBSD, and Darwin/Mac OS X</p> <p>Unix System Laboratories (USL) sued BSDI after BSDI attempted to market its product as a real UNIX, and other BSD distributions were affected by disputed code.  Ultimately 3 out of the 18,000 files that made up the Network Release 2 distribution were removed, which became known as BSD-lite, released in 1994.  This legal dispute was partly to blame for Linux's rapid ascent in popularity. </p>"},{"location":"Linux/#distributions","title":"Distributions","text":"<ul> <li>Alpine Linux is a security-oriented, lightweight Linux distribution used in containers and hardware.</li> <li>Clear Linux is a rolling release distro from Intel with a custom package management system based on bundles, collections of packages that contain everything an application requires, including dependencies.  Clear's update process also has the ability to do delta downloads, preserving bandwidth.  It does not provide access with unusual licenses, like ZFS, Chrome, or FFmpeg.</li> <li>SUSE<ul> <li>OpenSUSE Leap is a rebuild of SUSE Linux Enterprise Server, similar to how CentOS was historically a rebuild of RHEL.</li> <li>SUSE Linux Enterprise Server (SLES) (\"slee\") is SUSE's fixed-release distribution of Linux intended for enterprises, and as such is comparable to Red Hat's RHEL.</li> </ul> </li> </ul> display manager Basically display managers are the login screens, while the GUI manipulated during normal use represents the desktop environment (i.e. GNOME, KDE, XFCE, etc). initrd (\"initial RAM disk\") A temporary file system that's loaded into memory when the system boots"},{"location":"Linux/#pipewire","title":"Pipewire","text":"Pipewire is a media server intended to facilitate audio and video handling in Linux as a replacement for PulseAudio and JACK. It exposes a graph-based processing engine that abstracts audio and video devices."},{"location":"Linux/#pulseaudio","title":"PulseAudio","text":"<p>PulseAudio is a sound server for POSIX OSes and a fixture on many Linux distributions.</p> <p>PulseAudio is built around sources and sinks (i.e. devices) connected to source outputs and sink inputs (streams)</p> <ul> <li>Source is an input device that produces samples, usually running a thread with its own event loop, generating sample chunks which are posted to all connected source outputs</li> <li>Source output is a recording stream which consumes samples from a source</li> <li>Sink is an output device that consumes samples, usually running a thread with its own event loop mixing sample chunks from connect sink inputs</li> <li>Sink input is a playback stream, connected to a sink and producing samples for it</li> </ul> qmail <p>MTA designed as a drop-in replacement for Sendmail, notable for being the first to be \"security-aware\".  Its various modular subcomponents run independently and are mutually untrustful.  It uses SMTP to exchange messages with other MTAs. </p> <p>It was written by Dan Bernstein, a professor of mathematics famous for litigating against the US government with regard to export controls on encryption algorithms.  qmail was deprecated and removed from Arch repos in 2005.</p> SMB Client/server protocol developed in the early 1980s by Intel, Microsoft, and IBM that has become the native protocol for file and printer sharing on Windows. It is implemented in the Samba application suite."},{"location":"Linux/#wsl","title":"WSL","text":"<p>Windows Subsystem for Linux (WSL) is shipped with Windows and tied to the Windows release cycle. Windows ships from a single massive codebase, of which WSL is part.  WSL was written mostly in C and and has 3 million monthly active users.</p> <p>WSL implements user services to connect to WSL distros and to run Windows-native applications like CMD.exe.  WSL implements a 9P Protocol file server to provide seamless integration of the virtualized Linux filesystem and that of the Windows host.</p> <p>WSL 1 worked under a translation architecture where system calls were translated to NT kernel calls. This meant that applications that used system calls that were newer or more difficult to implement, like GUI applications or Docker, did not run on v1. </p> <p>WSL2 shifted to a lighweight virtualization model using the Linux kernel. Now Docker runs on WSL2 and GUI applications can run by using an X server.</p> <p>WSL v1 is available on Azure VMs if nested virtualization is enabled. WSL2 support is forthcoming.</p> <p>VHDs for WSL distributions are available at <code>%LOCALAPPDATA%\\Packages\\&lt;PackageFamilyName&gt;\\LocalState</code> where <code>&lt;PackageFamilyName&gt;</code> reflects the name of the Microsoft Store package of the distro, i.e.:</p> <ul> <li>CanonicalGroupLimited.Ubuntu20.04onWindows_79rhkp1fndgsc</li> <li>TheDebianProject.DebianGNULinux_76v4gfsz19hv4</li> </ul> <pre><code># Install distro\nwsl.exe --install -d Ubuntu-20.04\n\n# Remove distro\nwsl.exe --unregister Ubuntu-20.04\n</code></pre> <p>By default, WSL appears to copy the Windows native hosts file at %SystemRoot%\\System32\\drivers\\etc\\hosts to the distro's /etc/hosts file.</p>"},{"location":"Linux/Concurrency/","title":"Concurrency","text":""},{"location":"Linux/Concurrency/#glossary","title":"Glossary","text":""},{"location":"Linux/Concurrency/#linearizability","title":"Linearizability","text":"<p>In concurrent programming, an operation is linearizable if it consists of an ordered list of callbacks that may be extended by adding response events such that:</p> <ul> <li>The extended list is serializable</li> <li>The serializable sequential history is a subset of the original unextended list</li> </ul>"},{"location":"Linux/Concurrency/#lock","title":"Lock","text":"<p>When a thread wants a lock already owned by another thread, the thread is blocked and must wait until the lock becomes free.</p> <ul> <li>Spinning locks are suitable for very short timeframes</li> <li>Sleeping locks, including mutexes</li> </ul> <p>The Linux kernel also provides CPU local locks</p>"},{"location":"Linux/Concurrency/#mutex","title":"Mutex","text":"In the Linux kernel, mutex refers to a particular locking primitive that enforces serialization on shared memory systems."},{"location":"Linux/Concurrency/#serializability","title":"Serializability","text":"In transaction processing, a transaction schedule is serializable if its outcome is equal to the outcome of its individual transactions executed serially. Because transactions are normally executed concurrently, this is the major correctness criterion for concurrent transactions."},{"location":"Linux/Concurrency/#spinlock","title":"Spinlock","text":"A lock that causes a thread trying to acquire it to simply wait in a loop (\"spin\") while repeatedly checking whether the lock is available."},{"location":"Linux/Concurrency/#transaction","title":"Transaction","text":"In computer science, transactions are individual, indivisible operations that must succeed or fail as a complete unit. Transaction processing guards against hardware and software errors that might leave a transaction partially completed. These operations are executed on databases or modern filesystems to ensure the system is in a consistent state."},{"location":"Linux/Containers/","title":"Containers","text":"<p>Containers run applications in an isolated namespace, meaning it only has access to resources that are made available to it by the container runtime. Resource governance means that a container has access only to a specified number of processor cycles, system memory, and other resources. Containers allow applications to be packaged with their dependencies in container images, which will run the same regardless of underlying operating system or infrastructure and are downloaded from container registries like Docker Hub. Container registries are not to be confused with repositories, which are subcomponents of registries.</p>"},{"location":"Linux/Containers/#cgroups","title":"Cgroups","text":"History <p>\"Task Control Groups\" were first merged into kernel 2.6.24 with the ability for multiple hierarchies to be created. The logic behind the creation of multiple hierarchies was to enable maximum flexibility in policy creation. However, because a controller could only belong to a single hierarchy, after some years this began to be seen as a design flaw.</p> <p>This motivated a redesign into a single unified cgroup hierarchy, and v2 was merged in 3.16 and made stable in 4.5.</p> <p>Control groups or  cgroups are a Linux kernel feature that isolates, labels, and manages resources (CPU time, memory, and network bandwidth) for a collection of tasks (processes).</p> <p>Cgroup subsystems (also called controllers or resource controllers in documentation) represent a single resource (i.e. io, cpu, memory, devices).</p> <ul> <li>freezer suspends or resumes tasks in a cgroup</li> <li>net_cls tags network packets with a class identifier that allows the Linux traffic controller to identify packets originating from a particular cgroup task</li> <li>net_prio allows network traffic to be prioritized per interface</li> <li>ns the namespace subsystem</li> </ul> <p>Since cgroups v2, all mounted controllers reside in a single unified hierarchy. A list of these is generated by the Linux kernel at /proc/cgroups.</p> <p>You can confirm that the cgroup2 filesystem is mounted at /sys/fs/cgroup <pre><code>mount -l | grep cgroup -\n</code></pre></p>"},{"location":"Linux/Containers/#kubernetes","title":"Kubernetes","text":"History <p>Kubernetes was first announced by Google in mid-2014.  It had been developed by Google after deciding to open-source the Borg system, a cluster and container management system that formed the automation infrastructure that powered the entire Google enterprise. Kubernetes coalesced from a fusion between developers working on Borg and Compute Engine. Borg eventually evolved into Omega.</p> <p>By that time, Amazon had established a market advantage and the developers decided to change their approach by introducing a disruptive technology to drive the relevance of the Compute platform they had built.  They created a ubiquitous abstraction that could run better than anyone else.</p> <p>At the time, Google had been trying to engage the Linux kernel team and trying to overcome their skepticism.  Internally, the project was framed as offering \"Borg as a Service\", although there were concerns that Google was in danger of revealing trade secrets.</p> <p>Google ultimately donated Kubernetes to the Cloud Native Computing Foundation.</p> <p>Kubernetes's heptagonal logo is an allusion to when it was called \"Project 7\" as a reference to Star Trek's Borg character 7 of 9.</p> <p>Kubernetes (Greek for \"helmsman\", \"pilot\", or \"captain\" and \"k8s\" for short) has emerged as the leading container orchestrator in the industry since 2018.  It provides a layer that abstracts infrastructure, including computers, networks, and other computers, for applications deployed on top.</p> <p>Kubernetes can be visualized as a system built from layers, with each higher layer abstracting the complexity of the lower levels. One server serves as the master, exposing an API for users and clients, assigning workloads, and orchestrating communication between other components. The processes on the master node are also called the control plane. Other machines in the cluster are called nodes or workers and accept and run workloads using available resources.  A Kubernetes configuration files is called a kubeconfig.</p> <p>Kubernetes resources or objects, each associated with a URL, represent the configuration of a cluster. Resource and object are often used interchangeably, but more precisely the resource refers to the URL path that points to the object, and an object may be accessible through multiple resources. Every object type in the Kubernetes API has a controller (i.e. deployment controller, etc.) that reads desired state from the Spec section of the manifest and reports its actual state by writing to the Status section.</p> <p>An object's manifest, presented in JSON or YAML, represents its declarative configuration, and contains four sections:</p> <ul> <li>type metadata, specifying the type of resource</li> <li>object metadata, specifying name and other identifying information</li> <li>spec: desired state of resource</li> <li>state: produced strictly by the resource controller and represents the current status of resource</li> </ul> <p>An explanation of each field available in the API of any object type can be displayed on the command-line <pre><code>kubectl explain nodes\nkubectl explain no.spec\n</code></pre></p> Display the manifest of a node<pre><code>kubectl get node $NODE -o yaml\nkubectl describe node kind-worker-2\n</code></pre> <p>A pod is the most atomic unit of work which encompasses one or more tightly-coupled containers that will be deployed together on the same node. All containers in a pod share the same Linux namespace, hostname, IP address, network interfaces, and port space. This means containers in a pod can communicate with each other over localhost, although care must be taken to ensure individual containers do not attempt to use the same port. However their filesystems are isolated from one another unless they share a Volume.</p> <p>Every Pod occupies one address in a shared range, so communication between Pods is simple.</p> <p>Compute resources of containers can be limited at pod.spec.containers.resources.</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: nginx\nspec:\ncontainers:\n- image: nginx\nname: nginx\nresources:\nrequests:\nmemory: \"64Mi\"\ncpu: \"500m\"\nlimits:\nmemory: \"128Mi\"\ncpu: \"500m\"\n</code></pre> <p>Kubernetes can monitor Pod health by using probes, which can be categorized by how they measure health:</p> <ul> <li>Readiness: i.e. Is the container ready to serve user requests?</li> <li>Liveness: i.e. Is the container running as intended?</li> </ul>"},{"location":"Linux/Containers/#tasks","title":"Tasks","text":""},{"location":"Linux/Containers/#gke","title":"GKE","text":"<p>Google Kubernetes Engine nodes are actually Google Compute Engine VMs. Create GKE cluster<pre><code>gcloud container clusters create hello-cluster --num-nodes=1    # Standard cluster\ngcloud compute instances list # (1)\ngcloud container clusters create-auto hello-cluster # (2)\ngcloud container clusters describe hello-cluster\n</code></pre></p> <ol> <li>If a default zone is set, an Autopilot cluster won't be able to be created without explicitly specifying --region.</li> </ol> <p>Save a Kubernetes cluster's credentials to a kubeconfig. <pre><code>gcloud container clusters get-credentials my-cluster\n</code></pre></p>"},{"location":"Linux/Containers/#windows-server","title":"Windows Server","text":"<p>Windows Server 2016 supports Windows Server Containers and Hyper-V Containers, which create a separate copy of the operating system kernel for each container. The \"Containers\" feature must be installed on Windows Server 2016 hosts, and to create Hyper-V containers the Hyper-V role must also be installed (although the Hyper-V management tools are not necessary if VMs are not going to created). Windows container hosts need to have Windows installed to C:.</p> <p>Nano Server once could serve as Docker hosts, but no longer; Nano Servers are now intended to be deployed as containers themselves.</p> <p>The Powershell Docker module has been deprecated for years.</p>"},{"location":"Linux/Containers/#commands","title":"Commands","text":""},{"location":"Linux/Containers/#cgconfigservice","title":"cgconfig.service","text":"cgconfig, which is a part of the libcgroup package, can be used to run at start time to reestablish predefined cgroups."},{"location":"Linux/Containers/#kubectl","title":"kubectl","text":"Show available contexts<pre><code>kubectl config get-contexts\n</code></pre> Switch to a different context<pre><code>kubectl config use-context $NAMESPACE\nkubectl config use $NAMESPACE\n</code></pre> Display resources<pre><code>kubectl get nodes\nkubectl get pods\nkubectl get deployments\n</code></pre> <pre><code>kubectl describe nodes/gke-*4ff6f64a-6f4v\n</code></pre> Execute a command on a pod with only a single container, returning output<pre><code>kubectl exec $pod -- env\n</code></pre> Get a shell to a running container<pre><code>kubectl exec --stdin --tty $pod -- /bin/bash\n</code></pre> <p>When a pod contains more than one container, the container must be specified with -c/--container.  <pre><code>kubectl exec --stdin --tty $pod --container $container -- /bin/bash\n</code></pre></p> <pre><code>kubectl run nginx --image=nginx\nkubectl delete pod nginx\n</code></pre> <pre><code>kubectl create deployment nginx --image=nginx\n</code></pre> <p>Number of replicas can be set on creation of a deployment by specifying an argument to --replicas <pre><code>kubectl create deployment nginx --image=nginx --replicas=4\n</code></pre></p> <p>Replica count is set in an existing deployment by scaling <pre><code>kubectl scale deploy/nginx --replicas=2\n</code></pre></p> <p>Expose a port <pre><code>kubectl expose deployment/nginx --port=80 --type=LoadBalancer\n</code></pre></p> <p>List Kubernetes objects</p> <pre><code>kubectl api-resources\n</code></pre> <p>Get a description of a resource</p> <pre><code>kubectl explain nodes.status.addresses.address\n</code></pre>"},{"location":"Linux/Containers/#podman","title":"podman","text":"<p>On RHEL, podman can be installed as a package or as part of a module <pre><code>dnf module install container-tools\n</code></pre></p> <p>With few exceptions, podman exposes a command-line API that closely imitates that of Docker.</p> Arch Linux <p>On Arch, /etc/subuid and /etc/subgid have to be set. These are colon-delimited files that define the ranges for namespaced UIDs and GIDs to be used by each user.  Conventionally, these ranges begin at 100,000 (for the first, primary user) and contain 65,536 possible values. <pre><code>terry:100000:65536\nalice:165536:65536\n</code></pre></p> <p>Then podman has to be migrated <pre><code>podman system migrate\n</code></pre></p> <p>Podman supports pulling from various repos using aliases that are defined in /etc/containers/registries.conf.d. RHEL and derivative distributions support additional aliases, some of which reference images that require a login.</p> <p>For example, Red Hat offers a Python 2.7 runtime from the RHSCL (Red Hat Software Collections) repository on registry.access.redhat.com, which does not require authentication. However, Python 3.8 is only available from registry.redhat.io, which does. Interestingly, other Python runtimes are available from the ubi7 and ubi8 repos from unauthenticated registries.</p> <p>Container images are stored in ~/.local/share/containers/storage. <pre><code>podman pull rhscl/httpd-24-rhel7 # (1)\n</code></pre></p> <ol> <li>Alias to registry.access.redhat.com/rhscl/httpd-24-rhel7</li> </ol> <p>The Z option is necessary on SELinux systems (like RHEL and derivatives) and tells Podman to label the content with a private unshared label. On systems running SELinux, rootless containers must be explicitly allowed to access bind mounts. Containerized processes are not allowed to access files without a SELinux label. <pre><code>podman run -d -v=/home/jasper/notes/site:/usr/share/nginx/html:Z -p=8080:80 --name=notes nginx\npodman run -d -v=/home/jasper/notes/site:/usr/local/apache2/htdocs:Z -p=8080:80 --name=notes httpd-24\n</code></pre></p> <p>Mapped ports can be displayed <pre><code>podman port -a\n</code></pre></p> <p>Output a SystemD service file from a container to STDOUT (this must be redirected to a file) <pre><code>podman generate systemd notes \\\n--restart-policy=always   \\\n--name                    \\ # (3)\n--files                   \\ # (2)\n--new                     \\ # (1)\n</code></pre></p> <ol> <li>Yield unit files that do not expect containers and pods to exist but rather create them based on their configuration files.</li> <li>Generate a file with a name beginning with the prefix (which can be set with --container-prefix or --pod-prefix) and followed by the ID or name (if --name is also specified)</li> <li>In conjunction with --files, name the service file after the container and not the ID number.</li> </ol>"},{"location":"Linux/Containers/#systemd-cgls","title":"systemd-cgls","text":"systemd-cgls recursively shows the contents of the selected cgroup hierarchy in a tree."},{"location":"Linux/Containers/#glossary","title":"Glossary","text":"apiVersion <p>Kubernetes object field found in Type metadata.</p> <p>apiVersion is typically v1, but for some object types the API group is specified, i.e. for Deployments:  <pre><code>apiVersion: apps/v1\n</code></pre></p>"},{"location":"Linux/Containers/#dockerfile","title":"Dockerfile","text":"<p>A Docker image consists of read-only layers, each of which represents an instruction that incrementally the changes the image being built up.  Dockerfiles can be used to construct new images using <code>docker build</code>. The build process can be optimized by placing multiple commands in the same <code>RUN</code> instruction. Dockerfiles are named simply \"Dockerfile\" with no extension or variation.</p> Node on AlpineWindows Server NanoWindows Server Core <pre><code>FROM alpine\nRUN apk update &amp;&amp; apk add nodejs\nCOPY . /app\nWORKDIR /app\nCMD [\"node\",\"index.js\"]\n</code></pre> <pre><code>FROM microsoft/windowsservercore\nRUN powershell -command install-windowsfeature dhcp -includemanagementtools\nRUN powershell -configurationname microsoft.powershell -command add-dhcpserverv4scope -state active -activatepolicies $true -name scopetest -startrange 10.0.0.100 -endrange 10.0.0.200 -subnetmask 255.255.255.0\nRUN md boot\nCOPY ./bootfile.wim c:/boot/\nCMD powershell\n</code></pre> <pre><code>FROM microsoft/windowsservercore\nMAINTAINER @mike_pfeiffer\nRUN powershell.exe -Command Install-WindowsFeature Web-Server\nCOPY ./websrc c:/inetpub/wwwroot\nCMD [ \"powershell\" ]\n</code></pre> Deployment A uniformly managed set of Pod instances, all based on the same container image. The Deployment controller enables release capabilities, the deployment of new Pod versions with no downtime. Exposing a Deployment creates a Service. Desired State Management The Desired State Management system is used by Kubernetes to describe a cluster's desired state declaratively. emptyDir Ephemeral Kubernetes volume type that shares the Pod's lifetime and where data is stored in RAM. emptyDir volumes can use tmpfs file systems. ENTRYPOINT <p>Rarely used Docker declaration. When ENTRYPOINT is present, the CMD declaration becomes the default argument passed to the command in ENTRYPOINT.</p> <p>The Kubernetes --command flag (<code>pod.spec.containers.command</code> resource) can override the contents of ENTRYPOINT.</p> etcd Distributed key-value data store Event Kubernetes object type that contains information about what happened to the object. Events are deleted one hour after creation by default. <pre><code>kubectl get events\nkubectl get ev\n</code></pre> Unlike most other objects, Event manifests have no spec or status sections."},{"location":"Linux/Containers/#helm","title":"Helm","text":"<p>Helm is a package manager for Kubernetes. </p> <p>Helm packages are refered to as charts. Charts are a collection of files and directories that adhere to a specification. A chart is packed when tarred and gzipped.</p> <ul> <li>Chart.yaml contains metadata</li> <li>templates/ contains Kubernetes manifests potentially annotated with templating directives</li> <li>values.yaml provides default configuration</li> </ul> <p>It is managed using the helm CLI utility.</p> Create a new chart<pre><code>helm create foo\n</code></pre> <p>There is no longer a default Helm repository, although there are many available at the Artifact Hub</p> kind Kubernetes object field found in the Type metadata which specifies the type of resource, i.e. Node, Deployment, Service, Pod, etc. kubeconfig YAML configuration file located at $HOME/.kube/config by default. A colon-delimited list of kubeconfigs can be specified by setting the <code>KUBECONFIG</code> environment variable. A kubeconfig can be explicitly specified with the --kubeconfig flag. Label <p>Labels are key-value pairs that are attached to Kubernetes objects.</p> <p>Config for a Pod with two labels: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: label-demo\nlabels:\nenvironment: production\napp: nginx\nspec:\ncontainers:\n- name: nginx\nimage: nginx:1.14.2\nports:\n- containerPort: 80\n</code></pre></p> Master node <p>A master node runs 3 processes, called master (control plane) components: </p> <ul> <li>kube-apiserver exposes a RESTful API and serves as a glue between other Kubernetes components</li> <li>kube-scheduler determines how to balance container workloads across nodes using an algorithm</li> <li>kube-controller-manager performs cluster operations like managing nodes and making changes to desired status</li> </ul> millicore (m)  One-thousandth of a vCPU or a CPU core and the preferred measurement unit of compute resources in Kubernetes (i.e. 128m = 12.8% of a CPU core and 2000m = 2 CPU cores)."},{"location":"Linux/Containers/#namespaces","title":"Namespaces","text":"<p>Namespaces wrap global system resources (mount points, network devices, hostnames) in an abstraction that makes it appear to processes within that namespace that they have their own isolated instance of that resource.</p> <p>Process IDs in the same namespace can have access to one another, whereas those in different namespaces cannot.  Spawning a process in a new namespace prevents it from seeing the host's context, so an interactive shell like <code>zsh</code> spawned in its own namespace will report its PID as <code>1</code>, even though the host will assign its own PID. </p> Node <p>A node or worker is any container host that accepts workloads from the master node.  Each node is equipped with a container runtime like Docker, which it uses to create and destroy containers according to instructions from the master server.</p> <p>Each node runs 2 processes:</p> <ul> <li>kubelet communicates with Kubernetes cluster services</li> <li>kube-proxy handles container network routing using iptables rules</li> </ul> PersistentVolume A PersistentVolume is a piece of storage in the cluster that has been provisioned using Storage Classes. PersistentVolumeClaim  A PersistentVolumeClaim requests either Disk or File storage of a particular StorageClass, access mode, and size. It is bound to a PersistentVolume once an available storage resource has been assigned to the pod requesting it. Pod <p>A pod is the most basic unit that K8s deals with, representing one or more tightly-coupled containers that should be controlled as a single application (typically one main container with subsidiary helper containers).  Every container should have only a single process, so if several processes need to communicate they should be implemented as separate containers in a pod.</p> <p>A pod's containers should:</p> <ul> <li>operate closely together</li> <li>share a lifecycle</li> <li>always be scheduled on the same node</li> </ul> Replica An instance of a Pod ReplicaSet ... Selector <p>A label selector provides a way to identify a set of objects and is the core grouping primitive supported by Kubernetes. It can be made of multiple requirements that are comma-separated, all of which must be satisfied.</p> <p>There are two types of selector:</p> <ul> <li>Equality-based  admits the operators =, !=, and ==.</li> <li>Set-based  admits the operators in, notin, and exists.</li> </ul> Equality-based selectorSet-based selector <pre><code>environment = production\ntier != frontend\n</code></pre> <pre><code>environment in (production, qa)\ntier notin (frontend, backend)\npartition\n!partition\n</code></pre> Service A Service is an abstraction over a logical set of Pods and a policy by which to access them, i.e. a microservice. Because Pods are mortal, the Service controller keeps track of Pod addresses and publishes this information to the consumers of Services, a function called service discovery. tmpfs RAM-backed file system used in Docker containers Volume <p>A volume is a special directory in the Docker host that can be mounted to the container that is used to achieve persistent storage.</p> <p>In Azure, a volume represents a way to store, retrieve, and persist data across pods and through the application lifecycle.  In the context of Azure, Kubernetes can use two types of data volume:</p> <ul> <li>Azure Disks using Azure Premium (SSDs) or Azure Standard (HDDs).</li> <li>Azure Files using a SMB 3.0 share backed by an Azure Storage account.</li> </ul> <p>In Kubernetes, Volumes are an abstraction of file systems accessible from within a Pod's containers.</p> <ul> <li>Network storage device, such as <code>gcePersistentVolume</code> </li> <li><code>emptyDir</code>, where the data is stored in RAM using Docker's tmpfs file system</li> <li><code>hostPath</code>, where the volume is located within the node's file system. Because pods are expected to be created and destroyed on any node (which may themselves be destroyed and recreated), hostPath volumes are discommended.</li> </ul> <p>Volumes are declared in .spec.volumes and mounted into containers in .spec.containers[*].volumeMounts.</p> emptyDirhostPathgcePersistentDisk <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: alpine\nspec:\nvolumes:\n- name: data\nemptyDir:\n\n\ncontainers:\n- name: alpine\nimage: alpine\nvolumeMounts:\n- mountPath: \"/data\"\nname: \"data\"\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: alpine\nspec:\nvolumes:\n- name: data\nhostPath:\npath: /var/data\n\ncontainers:\n- name: alpine\nimage: alpine\nvolumeMounts:\n- mountPath: \"/data\"\nname: \"data\"\n</code></pre> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\nname: alpine\nspec:\nvolumes:\n- name: data\ngcePersistentDisk:\npdName: my-disk\nfsType: ext4\ncontainers:\n- name: alpine\nimage: alpine\nvolumeMounts:\n- mountPath: \"/data\"\nname: \"data\"\n</code></pre> Worker :material-kubernetes see Node"},{"location":"Linux/Databases/","title":"Databases","text":"<ul> <li>Azure Data Studio</li> <li>Cosmos DB emulator</li> </ul>"},{"location":"Linux/Databases/#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL configs postgresql.conf and pg_hba.conf are stored where the PostgreSQL database cluster was initialized with initdb. This directory can be initialized anywhere, but the default in Red Hat systems is /var/lib/pgsql/data.</p>"},{"location":"Linux/Databases/#tasks","title":"Tasks","text":""},{"location":"Linux/Databases/#setup-postgresql","title":"Setup PostgresQL","text":"Arch Red Hat Ubuntu <pre><code>pacman -S postgresql\nsu - postgres -c 'initdb --pgdata /var/lib/postgres/data' # (1)\nsystemctl enable postgresql --now\n</code></pre> <ol> <li>On Arch, this step appears to be necessary before the postgresql service can be enabled. initdb requires a directory to be explicitly specified using --pgdata or alternatively the PGDATA environment variable.</li> </ol> <pre><code>dnf install libpq-devel mariadb-devel postgresql postgresql-server\npostgresql-setup --initdb # (1)\nsystemctl enable postgresql --now\n</code></pre> <ol> <li>This command facilitates initialization of the database cluster, which defaults to /var/lib/pgsql/data, similar to using initdb.</li> </ol> <pre><code>apt install libpq-dev\n</code></pre> <pre><code>systemctl start postgresql\nsudo -u postgres psql\n</code></pre> Role setup<pre><code>CREATE ROLE username LOGIN INHERIT -- (1)\nCREATEDB -- (5)\nPASSWORD 'password'; -- (3)\nGRANT postgres TO username; -- (2)\nCREATE DATABASE username; -- (4)\nexit\n</code></pre> <ol> <li>Create a new user or \"role\". Like SSH, psql by default will use the currently logged-in username, which does not exist on a fresh installation.</li> <li>Grant group membership to the newly created user.</li> <li>Manually set a password for the newly created user. Single quotes are necessary here, as double quotes will cause an error. After role creation<pre><code>ALTER USER username WITH PASSWORD 'password' ;\n</code></pre></li> <li>The default database which is logged into is also named after the currently logged-in user.  Also the built-in command createdb can be used from the command-line.</li> <li>Database creation is a restricted operation granted by an attribute. After role creation<pre><code>ALTER USER username WITH CREATEDB;\n</code></pre></li> </ol>"},{"location":"Linux/Databases/#sql","title":"SQL","text":""},{"location":"Linux/Databases/#starships","title":"Starships","text":"<pre><code>CREATE TABLE starships (\nname text, registry text, crew integer\n);\n</code></pre> <pre><code>INSERT INTO starships (name, registry, crew) VALUES ('USS Enterprise', 'NCC-1701', 400); -- (1)\n</code></pre> <ol> <li>For some reason, a double-quote \" produces an error, and only single-quotes are accepted.</li> </ol>"},{"location":"Linux/Databases/#cosmos-db","title":"Cosmos DB","text":"..."},{"location":"Linux/Databases/#commands","title":"Commands","text":""},{"location":"Linux/Databases/#psql","title":"psql","text":"<p>Enter an interactive shell to control a PostgreSQL server.</p> Install<pre><code>dnf install postgresql\n</code></pre> <pre><code>psql -d database\n</code></pre> <p>The interactive shell allows SQL queries to be run as well as meta-commands prefixed with a backslash \\.</p> <pre><code>\\dt -- (1)\n</code></pre> <ol> <li>Display tables</li> </ol>"},{"location":"Linux/Databases/#sqlite3","title":"sqlite3","text":"<p>sqlite3 is an interactive frontend to the SQLite library.</p> <p>Meta-commands, prefixed by <code>.</code>, can be used to examine database files or perform administrative operations.</p> <pre><code>.databases  -- (1)\n.tables     -- (2)\n.show       -- (3)\n.exit       </code></pre> <ol> <li>List names and files of attached databases.</li> <li>List names of tables matching a given pattern.</li> <li>Show the current values for various settings.</li> </ol> <p>Files can be provided on invocation from the command-line or they can be provided after the .open meta-command. <pre><code>.open database.db\n</code></pre></p> <p>Without providing an argument on invocation, sqlite3 will open an in-memory database by default, which can also be explicitly specified with a meta-command. <pre><code>.open :memory:\n</code></pre></p>"},{"location":"Linux/Display/","title":"Display","text":""},{"location":"Linux/Display/#tasks","title":"Tasks","text":""},{"location":"Linux/Display/#commands","title":"Commands","text":""},{"location":"Linux/Display/#x11","title":"X11","text":"X Test X11 with the config file automatically generated after <code>Xorg -configure</code> <pre><code>X -config $HOME/xorg.conf.new\n</code></pre> xhost Enable access control to X server <pre><code>xhost -\n</code></pre> Disable access control to X server, allowing clients from any host to connect (not unsafe if you use a firewall that allows only SSH) <pre><code>xhost +\n</code></pre> Add <code>$HOST</code> to list of authorized clients for X server <pre><code>xhost +$HOST\n</code></pre> Remove <code>$HOST</code> from list of authorized clients for X server <pre><code>xhost -$HOST\n</code></pre> Add <code>$USER</code> to ACL <pre><code>xhost si:localuser:$USER\n</code></pre>"},{"location":"Linux/Display/#xmodmap","title":"xmodmap","text":"Replacing Caps Lock with Escape <pre><code>! Swap caps lock and escape\nremove Lock = Caps_Lock\nkeysym Escape = Caps_Lock\nkeysym Caps_Lock = Escape\nadd Lock = Caps_Lock\n</code></pre>"},{"location":"Linux/Display/#xorg","title":"Xorg","text":"Enable automatic configuration of X11 server <pre><code>Xorg -configure\n</code></pre>"},{"location":"Linux/Display/#xrandr","title":"xrandr","text":"Change resolution of DisplayPort1 to 1920x1080 <pre><code>xrandr --output DP1 --mode 1920x1080\n</code></pre> Disable VGA1 output <pre><code>xrandr --output VGA1 --off\n</code></pre> Display current state of the system <pre><code>xrandr -q  --query\n</code></pre>"},{"location":"Linux/Display/#xset","title":"xset","text":"Dynamically add fonts [Haeder: 307][Haeder] <pre><code>xset fp+ /usr/local/fonts\n</code></pre>"},{"location":"Linux/Files/","title":"Files","text":""},{"location":"Linux/Files/#glossary","title":"Glossary","text":""},{"location":"Linux/Files/#squashfs","title":"squashfs","text":"Squashfs is a compressed read-only filesystem for Linux using zlib compression for files, inodes, and directories."},{"location":"Linux/Files/#sgid","title":"SGID","text":"<p>When the set-group-ID bit for a directory is set, all files created therein are assigned to the directory's group and not to the file owner's default group.</p> <p>This is intended to facilitate file sharing. In this scenario, users are assigned to a group, and the group is assigned to shared directories with the SGID bit set.</p>"},{"location":"Linux/Files/#sticky-bit","title":"Sticky bit","text":"When the sticky bit is set on a directory, only root, the directory owner and the owner of a file can remove files in that directory."},{"location":"Linux/Files/#suid","title":"SUID","text":"The set-user-ID bit allows a file to be executed with the privileges of the file's owner."},{"location":"Linux/Files/#commands","title":"Commands","text":""},{"location":"Linux/Files/#chage","title":"chage","text":""},{"location":"Linux/Files/#chage_1","title":"chage","text":"Expire password in 30 days<pre><code>chage -E $(date -d +30days +%Y-%m-%d) $USER\n</code></pre>"},{"location":"Linux/Files/#chgrp","title":"chgrp","text":""},{"location":"Linux/Files/#chgrp_1","title":"chgrp","text":"<p>Change ownership of <code>$FILE</code> to <code>$USER</code> and <code>$GROUP</code></p> <pre><code>chgrp $USER:$GROUP $FILE\n</code></pre>"},{"location":"Linux/Files/#chmod","title":"chmod","text":""},{"location":"Linux/Files/#chmod_1","title":"chmod","text":"Add permissions Remove permissions <pre><code>chmod +t $FILE # Sticky bit\nchmod g+s file # SGID\nchmod u+s file # SUID\n</code></pre> <pre><code>chmod -t $FILE # Sticky bit\nchmod g-s file # SGID\nchmod u-s file # SUID\n</code></pre>"},{"location":"Linux/Files/#chown","title":"chown","text":""},{"location":"Linux/Files/#chown_1","title":"chown","text":"<p>Change a file or directory's ownership. </p> <p>To change the user and group owner of a file to <code>$USER</code> and <code>$GROUP</code>:</p> <pre><code>chown $USER:$GROUP $file\n</code></pre> <p>Recursively grant <code>$USER</code> ownership to <code>$PATH</code> <pre><code>chown -R $USER $PATH\n</code></pre></p> <p>Use a reference file to match the configuration of a particular file <pre><code>chown -vR --reference=. $PATH\n</code></pre></p> <p><code>--preserve-root</code> prevents changes to files in the root directory but only when used together with <code>--recursive</code></p> <pre><code>chown -cfR --preserve-root $USER </code></pre>"},{"location":"Linux/Files/#cp","title":"cp","text":""},{"location":"Linux/Files/#du","title":"du","text":""},{"location":"Linux/Files/#du_1","title":"du","text":"<p>du does not double-count hard-linked files, so it can be used to analyze deduplication in app distribution solutions like Flatpak.</p> <p>Here the second command will display a smaller value for the 21.08 version of the freedesktop Platform runtime, indicating that hard-linked files have not been double-counted. <pre><code>du -sh /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/21.08\ndu -sh /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/21.08 /var/lib/flatpak/runtime/org.freedesktop.Platform/x86_64/20.08\n</code></pre></p>"},{"location":"Linux/Files/#find","title":"find","text":""},{"location":"Linux/Files/#find_1","title":"find","text":"<p>Search for files in a directory hierarchy</p> Find all files owned by user<pre><code>find . -user $USER\n</code></pre> <p>-exec allows a command to be executed for every foudn file, which has to be terminated with an escaped semicolon, i.e. <code>\\;</code>.</p> Remove whitespace from filenames<pre><code>find . -type f -name \"* *\" -exec bash -c 'mv \"$0\" \"${0// /_}\"' {} \\;\n</code></pre> <p>Find recently modified files/folders</p> <p>There are 3 timestamps associated with files in Linux </p> <ul> <li>atime \"access time\": last time file was accessed by a command or application</li> <li>mtime \"modify time\": last time file's contents were modified</li> <li>ctime \"change time\": last time file's attribute was modified </li> </ul> <p>Numerical arguments can be specified in 3 ways:</p> <ul> <li><code>+n</code> greater than {n} days ago</li> <li><code>-n</code> less than {n} days ago</li> <li><code>n</code> exactly n days ago</li> </ul> <pre><code># Find only files that were modified more than 120 days ago\nfind . -type f -mtime +120 -ls\n\n# Modified less than 15 days ago \nfind . -type f -mtime -15 -ls\n\n# Modified exactly 10 days ago \nfind . -type f -mtime 10 -ls # Find files modified over the past day\nfind . -type f -newermt \"1 day ago\" -ls\nfind . -type f -newermt \"-24 hours\" -ls\nfind . -type f -newermt \"yesterday\" -ls\n\n# Find files created today\nfind . -type f -ctime -1 -ls </code></pre>"},{"location":"Linux/Files/#mv","title":"mv","text":""},{"location":"Linux/Files/#rename","title":"rename","text":""},{"location":"Linux/Files/#rename_1","title":"rename","text":"<p>Use regular expressions to rename multiple files</p> <pre><code># Renaming file.old to file.new\nrename 's/old/new/' this.old\n\n# Use globbing to rename all matching files\nrename 's/old/new/' *.old\nrename 's/report/review/' *\n\n# Change all uppercase letters to lowercase\nrename 'y/A-Z/a-z/' *\n</code></pre>"},{"location":"Linux/Files/#rsync","title":"rsync","text":""},{"location":"Linux/Files/#rsync_1","title":"rsync","text":"<p> <code>a</code> <code>b</code> <code> </code> <code> </code> <code>e</code> <code> </code> <code>g</code> <code> </code> <code> </code> <code> </code> <code> </code> <code>l</code> <code> </code> <code> </code> <code>o</code> <code>p</code> <code> </code> <code>r</code> <code> </code> <code>t</code> <code> </code> <code>v</code> <code> </code> <code> </code> <code> </code> <code>z</code> </p> <p>Copy $FILE locally  <pre><code>rsync -zvr $FILE $PATH\n</code></pre></p> <p>Copy $FILE to $PATH on remote $HOST <pre><code>rsync $FILE $HOST:$PATH\n</code></pre></p> <p>Copy $FILE from $HOST to local $PATH <pre><code>rsync $HOST:$FILE $PATH\n</code></pre></p> <p>Copy <code>$DIR</code> recursively <pre><code>rsync -zvr $DIR $PATH\nrsync -avz $DIR $PATH\n</code></pre></p> <p>Copy to remote systems over SSH <pre><code>rsync -zvre ssh $DIR $HOST:$REMOTEPATH\nrsync -avze ssh $DIR $HOST:$REMOTEPATH\n</code></pre></p> <p>Synchronize only specific file type <pre><code>rsync -zvre ssh --include '*.php' --exclude '*' $PATH\n</code></pre></p>"},{"location":"Linux/Files/#facl","title":"facl","text":""},{"location":"Linux/Files/#getfacl","title":"getfacl","text":""},{"location":"Linux/Files/#setfacl","title":"setfacl","text":""},{"location":"Linux/Files/#setfacl_1","title":"setfacl","text":"<p>The effect of ACLs can be illustrated with a web server. This command removes read access from a file which would otherwise be served by the Apache/httpd web server daemon. <pre><code>setfacl -m u:apache:- /var/www/html/index.html\n</code></pre></p> <p>This can be resolved by granting read to the apache service account (or removing the entry altogether) <pre><code>setfacl -m u:apache:r /var/www/html/index.html\nsetfacl -x u:apache /var/www/html/index.html\nsetfacl -b /var/www/html/index.html\n</code></pre></p>"},{"location":"Linux/Files/#attr","title":"attr","text":"<p>A family of commands exists to change file attributes on Linux file systems.</p>"},{"location":"Linux/Files/#lsattr","title":"lsattr","text":""},{"location":"Linux/Files/#chattr","title":"chattr","text":"Make file immutable<pre><code>chattr +i /etc/resolv.conf\n</code></pre>"},{"location":"Linux/Filters/","title":"Filters","text":""},{"location":"Linux/Filters/#awk","title":"awk","text":"<p>Awk programs are equivalent to sed \"instructions\" and can be defined inline or in a program file (also \"source files\").  If no input files are specified awk can accept input from standard input.</p> <pre><code># Inline\nawk $OPTIONS $PROGRAM $INPUTFILES\n\n# Program file\nawk $OPTIONS -f $PROGRAMFILE $INPUTFILES\n</code></pre> <p>awk programs combine patterns and actions</p> <p>Patterns can be:</p> <ul> <li>regular expressions or fixed strings</li> <li>line numbers using builtin variable <code>NR</code></li> <li>predefined patterns <code>BEGIN</code> or <code>END</code>, whose actions are executed before and after processing any lines of the data file, respectively</li> </ul> <p>Convert \":\" to newlines in $PATH environment variable <pre><code>echo $PATH | awk 'BEGIN {RS=\":\"} {print}'\n</code></pre></p> <p>Print the first field of all files in the current directory, taking semicolon <code>;</code> as the field separator, outputting filename, line number, and first field of matches, with colon <code>:</code> between the filename and line number <pre><code>awk 'BEGIN {FS=\";\"} /enable/ {print FILENAME \":\" FNR,$1}' *\n</code></pre> search for string <code>MA</code> in all files, outputting filename, line, and line number for matches <pre><code>awk '/MA/ {OFS=\" \" print FILENAME OFS FNR OFS $0} *\n</code></pre> change field separator (<code>FS</code>) to a colon (<code>:</code>) and run <code>awkscr</code> <pre><code>awk -F: -f awkscr /etc/passwd\n</code></pre> flag also works for awk <pre><code>awk -f script files` `-f\n</code></pre> print the first field of each line in the input file <pre><code>awk '{ print $1 }' list\n</code></pre> equivalent to <code>grep MA *</code> (<code>{print}</code> is implied) <pre><code>awk '/MA/' * | awk '/MA/ {print}' *\n</code></pre> <code>-F</code> flag is followed by field separator <pre><code>awk -F, '/MA/ { print $1 }' list\n</code></pre> pipe output of <code>free</code> to <code>awk</code> to get free memory and total memory <pre><code>free -h | awk '/^Mem|/ {print $3 \"/\" $2}\n</code></pre> pipe output of <code>sensors</code> to <code>awk</code> to get CPU temperature <pre><code>sensors | awk '/^temp1/ {print $2}\n</code></pre> replace initial \"fake.\" with \"real;\" in file <code>fake_isbn</code> <pre><code>awk 'sub(^fake.,\"real;\")' fake_isbn\n</code></pre> print all lines <pre><code>awk '1 { print }' file\n</code></pre> remove file header <pre><code>awk 'NR&gt;1' file\n</code></pre> remove file header <pre><code>awk 'NR&gt;1 { print } file\n</code></pre> print lines in a range <pre><code>awk 'NR&gt;1 &amp;&amp; NR &lt; 4' file\n</code></pre> remove whitespace-only lines <pre><code>awk 'NF' file\n</code></pre> remove all blank lines <pre><code>awk '1' RS='' file\n</code></pre> extract fields <pre><code>awk '{ print $1, $3}' FS=, OFS=, file\n</code></pre> perform column-wise calculations <pre><code>awk '{ SUM=SUM+$1 } END { print SUM }' FS=, OFS=, file\n</code></pre> count the number of nonempty lines <pre><code>awk '/./ { COUNT+=1 } END { print COUNT }' file\n</code></pre> count the number of nonempty lines <pre><code>awk 'NF { COUNT+=1 } END { print COUNT }' file\n</code></pre> count the number of nonempty lines <pre><code>awk '+$1 { COUNT+=1 } END { print COUNT }' file\n</code></pre> Arrays <pre><code>awk '+$1 { CREDITS[$3]+=$1 } END { for (NAME in CREDITS) print NAME, CREDITS[NAME] }' FS=, file\n</code></pre> Identify duplicate lines <pre><code>awk 'a[$0]++' file\n</code></pre> Remove duplicate lines <pre><code>awk '!a[$0]++' file\n</code></pre> Remove multiple spaces <pre><code>awk '$1=$1' file\n</code></pre> Join lines <pre><code>awk '{ print $3 }' FS=, ORS=' ' file; echo\n</code></pre> <pre><code>awk '+$1 { SUM+=$1; NUM+=1 } END { printf(\"AVG=%f\",SUM/NUM); }' FS=, file` | format </code></pre> <pre><code>awk '+$1 { SUM+=$1; NUM+=1 } END { printf(\"AVG=%6.1f\",SUM/NUM); }' FS=, file\n</code></pre> Convert to uppercase  <pre><code>awk '$3 { print toupper($0); }' file\n</code></pre> Change part of a string <pre><code>awk '{ $3 = toupper(substr($3,1,1)) substr($3,2) } $3' FS=, OFS=, file\n</code></pre> Split the second field (\"EXPDATE\") by spaces, storing the result into the array DATE; then print credits ($1) and username ($3) as well as the month (DATE[2]) and year (DATE[3])  <pre><code>awk '+$1 { split($2, DATE, \" \"); print $1,$3, DATE[2], DATE[3] }' FS=, OFS=, file\n</code></pre> <pre><code>awk '+$1 { split($4, GRP, \":\"); print $3, GRP[1], GRP[2] }' FS=, file\n</code></pre> <pre><code>awk '+$1 { split($4, GRP, /:+/); print $3, GRP[1], GRP[2] }' FS=, file\n</code></pre> Search and replace with comma  <pre><code>awk '+$1 { gsub(/ +/, \"-\", $2); print }' FS=, file\n</code></pre> Adding date  <pre><code>awk 'BEGIN { printf(\"UPDATED: \"); system(\"date\") } /^UPDATED:/ { next } 1' file\n</code></pre> Modify a field externally  <pre><code>awk '+$1 { CMD | getline $5; close(CMD); print }' CMD=\"uuid -v4\" FS=, OFS=, file\n</code></pre> Invoke dynamically generated command <pre><code>awk '+$1 { cmd = sprintf(FMT, $2); cmd | getline $2; close(cmd); print }' FMT='date -I -d \"%s\"'  FS=, file\n</code></pre> Join data <pre><code>awk '+$1 { CMD | getline $5; print }' CMD='od -vAn -w4 -t x /dev/urandom' FS=, file\n</code></pre> Add up all first records to {sum}, then print that number out at the end <pre><code>awk '{sum += $1} END {print sum}' file\n</code></pre></p>"},{"location":"Linux/Filters/#cat","title":"cat","text":""},{"location":"Linux/Filters/#cut","title":"cut","text":""},{"location":"Linux/Filters/#grep","title":"grep","text":"<pre><code>grep -R $TEXT $DIRECTORY\n</code></pre>"},{"location":"Linux/Filters/#head","title":"head","text":"Print first 8 characters of <code>$FILE</code> <pre><code>head -c8 $FILE\n</code></pre>"},{"location":"Linux/Filters/#paste","title":"paste","text":"<p>Merge lines of files</p> <p>Make a .csv file from two lists <pre><code>paste -d ',' file1 file2\n</code></pre> Transpose rows <pre><code>paste -s file1 file2\n</code></pre></p>"},{"location":"Linux/Filters/#sed","title":"sed","text":"<p>sed (\"Stream-oriented editor\") is typically used for applying repetitive edits across all lines of multiple files. In particular it is, alongside <code>awk</code> one of the two primary commands which accept regular expressions in Unix systems. </p> <p>sed instructions can be defined inline or in a command file (i.e. script).</p> Inline<pre><code>sed $OPTIONS $INSTRUCTION $FILE\n</code></pre> Command file<pre><code>sed $OPTIONS -f $SCRIPT $FILE\n</code></pre> <p>sed instructions are made of two components: addresses (i.e. patterns) and procedures (i.e. actions).</p> <p>Run sed commands in <code>$SCRIPT</code> on <code>$FILE</code></p> <p><pre><code>sed -f $SCRIPT $FILE\n</code></pre> Suppress automatic printing of pattern space <pre><code>sed -n # --quiet , --silent\n</code></pre></p> <p>Zero, one, or two addresses can precede a procedure. In the absence of an address, the procedure is executed over every line of input. With one address, the procedure will be executed over every line of input that matches.</p> <p>With two addresses, the procedure will be executed over groups of lines whereby:</p> <ul> <li>The first address selects the first line in the first group</li> <li>The second address selects the next subsequent line that it matches, which becomes the last line in the first group</li> <li>If no match for the second address is found, it point to the end of the file</li> <li>After the match, the selection process for the next group begins by searching for a match to the first address</li> </ul> <p>Addressing can be done in one of two ways:</p> <ul> <li>Line addressing, specifying line numbers separated by a comma (e.g. <code>3,7p</code>); <code>$</code> represents the last line of input</li> <li>Context addressing, using a regular expression enclosed by forward slashes (e.g. <code>/From:/p</code>)</li> </ul> <p>Edit the file in-place, but save a backup copy of the original with {suffix} appended to - the filename <pre><code>-i=suffix\n</code></pre></p> <p>In some circles, sed is recommended as a replacement for other filters like head. Here, the first 10 lines of a file are displayed. <pre><code>sed 10q $FILE\n</code></pre></p> <p>Display the top 10 processes by memory or cpu usage. <pre><code>ps axch -o cmd,%mem --sort=-%mem | sed 11q\nps axch -o cmd:15,%cpu --sort=-%cpu | sed 11q\n</code></pre></p> <p>Replace angle brackets with their HTML codes, piped in from a heredoc: <pre><code>sed -e 's/&lt;/\\&amp;lt;/g' -e 's/&gt;/\\&amp;gt;/g' &lt;&lt; EOF\n</code></pre></p> <p>&lt;!--  Display first two lines of file Without <code>-n</code>, each line will be printed twice <pre><code>sed -n '1,2p' emp.lst\n</code></pre></p> <p>Prepending <code>!</code> to the procedure reverses the sense of the command (YUG: 450) <pre><code>sed -n '3,$!p' emp.lst\n</code></pre></p> <p>Display a range of lines <pre><code>sed -n '9,11p' emp.lst\n</code></pre> Use the <code>-e</code> flag to precede multiple instructions <pre><code>sed -n -e '1,2p' -e '7,9p' -e '$p' emp.lst\n</code></pre> Delete lines Delete second line alone <pre><code>sed '2d' myfile\n</code></pre> Delete a range of lines: from the 2nd through the 3rd <pre><code>sed '2,3d' myfile\n</code></pre> Delete a range of lines, from the first occurrence of 'second' to the line with the first occurrence of 'fourth' <pre><code>sed '/second/,/fourth/d' myfile\n</code></pre> Print all of a file except for specific lines Suppress any line with 'test' in it <pre><code>sed '/test/d' myfile\n</code></pre></p> <p>Suppress from the 3rd line to EOF <pre><code>sed '3,$d' myfile\n</code></pre></p> <p>Replace the first instance of the <code>|</code> character with <code>:</code> and display the first two lines [YUG:455] <pre><code>sed 's/|/:/ emp.lst | head -2\n</code></pre> Replace all instances of the <code>|</code> character with <code>:</code>, displaying the first two lines [YUG:455] <pre><code>sed 's/|/:/g' emp.lst | head -2\n</code></pre> Substitute HTML tags: <pre><code>sed 's/&lt;I&gt;/&lt;EM&gt;/g'\n</code></pre> These commands will replace \"director\" with \"executive director\" <pre><code>sed 's/director/executive director/' emp.lst\n</code></pre> <pre><code>sed 's/director/executive &amp;/' emp.lst\n</code></pre> <pre><code>sed '/director/s//executive &amp;/' emp.lst\n</code></pre></p> <p>Searching for text</p> <p>Equivalent to <code>grep MA *</code> <pre><code>sed -n '/MA/p' *\n</code></pre> Stringing sed statements together with pipe Take lines beginning with \"fake\" and remove all instances of \"fake.\", piping them... remove all parentheses with content and count lines of output (results) <pre><code>sed -n '/^fake/s/fake\\.//p' * | sed -nr 's/\\(.*\\)//p' | wc -l\n</code></pre> Take lines of all files in CWD beginning with \"fake\" and remove all instances of string \"fake.\" Then remove all parentheses with any content within them and print only the top 10 lines <pre><code>sed -ne '/^fake/p' * | sed -n 's/fake\\.//p' | sed -nr 's/\\(.*\\)//p' | sed 11q\n</code></pre> Count the number of pipes replaced by piping output to <code>cmp</code>, which will use the <code>-l</code> option to output byte numbers of differing values, then counting the lines of output (YUG:456) <pre><code>sed 's/|/:/g' emp.lst | cmp -l - emp.lst | wc -l\n</code></pre> --&gt;</p>"},{"location":"Linux/Filters/#tail","title":"tail","text":"<p>Output last lines beginning at 30th line from the start</p> Short optionPOSIX <pre><code>tail -n=+30\n</code></pre> <pre><code>tail --lines=+30\n</code></pre>"},{"location":"Linux/Filters/#tr","title":"tr","text":"<p> <code>c</code> <code>d</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code>s</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> </p> <p>Change the case of a string ] <pre><code>tr [:upper:] [:lower:]\n</code></pre> Remove a character or set of characters from a string or line of output <pre><code>tr -d \"text\"\n</code></pre></p>"},{"location":"Linux/Filters/#watch","title":"watch","text":"Execute <code>$CMD</code> at periods of <code>$N</code> seconds, watching its output CLKF <pre><code>watch $CMD -n $N\n</code></pre> Check memory usage in megabytes (<code>-m</code>) every <code>5</code> seconds Enki <pre><code>watch -n 5 free -m\n</code></pre>"},{"location":"Linux/GRUB/","title":"GRUB2","text":"<p>Kernel command line parameters passed in on boot can be queried during runtime: <pre><code>cat /proc/cmdline\n</code></pre></p>"},{"location":"Linux/GRUB/#tasks","title":"Tasks","text":""},{"location":"Linux/GRUB/#resetting-root-password","title":"Resetting root password","text":"Append rd.break to the list of command-line parameters to GRUB. Once the shell is ready, run the following commands <pre><code>mount -o remount,rw /sysroot\nchroot /sysroot\npasswd root\n</code></pre>"},{"location":"Linux/GRUB/#text-mode-installation","title":"Text-mode installation","text":"RHEL can be installed from the console by providing inst.text as a kernel parameter on boot by pressing ++Tab++ on the GRUB splash screen."},{"location":"Linux/GRUB/#grub-rescue-prompt","title":"GRUB rescue prompt","text":"<p>When GRUB2 is unable to find the GRUB folder or its contents are missing or corrupted, it displays the prompt  <pre><code>grub rescue&gt;\n</code></pre> This means it failed to load the <code>normal</code> module. howtoforge.com</p> <p>From GRUB rescue prompt: <pre><code>set prefix=(hd0,1)/boot/grub\nset root=(hd0,1)\ninsmod normal\nnormal\n</code></pre> After booting the system, GRUB should be updated and reinstalled:</p> <p>Update GRUB config file <pre><code>update-grub\n</code></pre> Reinstall GRUB <pre><code>grub-install /dev/sdx\n</code></pre></p>"},{"location":"Linux/GRUB/#commands","title":"Commands","text":""},{"location":"Linux/GRUB/#grub-mkconfig","title":"grub-mkconfig","text":"Generate GRUB configuration <pre><code>grub-mkconfig -o /boot/grub/grub.cfg\n</code></pre>"},{"location":"Linux/GRUB/#grub2-mkconfig","title":"grub2-mkconfig","text":"<p>grub2-mkconfig is used to create a GRUB2 config file from the settings defined in /etc/default/grub</p> <pre><code>grub2-mkconfig -o=/boot/grub2/grub.cfg\n</code></pre>"},{"location":"Linux/GRUB/#grub2-editenv","title":"grub2-editenv","text":"<p>Disable the Nouveau display driver while installing the proprietary Nvidia display driver on Fedora </p> <pre><code>grub2-editenv - set \"$(grub2-editenv - list | grep kernelopts) nouveau.modeset=0\"\n</code></pre>"},{"location":"Linux/GRUB/#update-grub","title":"update-grub","text":"Update GRUB config file <pre><code>update-grub\n</code></pre>"},{"location":"Linux/IAM/","title":"Users","text":""},{"location":"Linux/IAM/#tasks","title":"Tasks","text":""},{"location":"Linux/IAM/#user-management","title":"User management","text":"Lock user<pre><code>usermod -L $USER # --lock\npasswd -l $USER  # --lock\n</code></pre> Unlock user<pre><code>usermod -U $USER # --unlock\npasswd -u $USER  # --unlock\n</code></pre>"},{"location":"Linux/IAM/#groups","title":"Groups","text":"Display groups of effective user<pre><code>id -Gn\ngetent group | grep $(whoami) -\n</code></pre>"},{"location":"Linux/IAM/#commands","title":"Commands","text":""},{"location":"Linux/IAM/#chage","title":"chage","text":"Expire password in 30 days<pre><code>chage -E $(date -d +30days +%Y-%m-%d) $USER\n</code></pre>"},{"location":"Linux/IAM/#getent","title":"getent","text":"<p>Get entries from the passwd file <pre><code>getent passwd bob\n</code></pre></p> <pre><code>getent group dba_admins\n</code></pre>"},{"location":"Linux/IAM/#lastb","title":"lastb","text":"Display failed logins for user<pre><code>lastb $USER\n</code></pre>"},{"location":"Linux/IAM/#sudo","title":"sudo","text":"<p>The /etc/sudoers file (or files placed under /etc/sudoers.d/) contains user specifications that define commands that users may execute.</p> <pre><code>$USER $HOST = ($RUNAS) $CMD\n</code></pre> <ul> <li>$USER: usernames, UIDs, group names when prefixed with % i.e. %wheel, or GIDs when prefixed with %#</li> <li>$HOST: hostnames, IP addresses, or a CIDR range (i.e. 192.0.2.0/24)</li> <li>$RUNAS: optional clause that controls the user or group sudo will run the command as. If a username is specified, sudo will not accept a -g argument when runing sudo. </li> <li>$CMD: full path to an executable, or a comma-delimited list of commands.</li> </ul> <p>Any of these elements can be replaced with the keyword ALL.</p> Ansible service account<pre><code>ansible ALL=(ALL) NOPASSWD: ALL\n</code></pre> Allow user to run only the mkdir command<pre><code>user ALL=/bin/mkdir\n</code></pre> Allow user to run all commands without authenticating<pre><code>user ALL=(ALL) NOPASSWD: ALL\n</code></pre> <p>Change timeout to 10 minutes <pre><code>Defaults timestamp_timeout=10\n</code></pre></p> <p>Change timeout to 10 minutes only for user <code>linuxize</code> <pre><code>Defaults:linuxize timestamp_timeout=10\n</code></pre></p>"},{"location":"Linux/IAM/#gpasswd","title":"gpasswd","text":"<p>Administer /etc/group and /etc/gshadow </p> <p>Add user to group<pre><code>gpasswd -a $USER $GROUP\n</code></pre> Add user as admin of group<pre><code>gpasswd -A $USER $GROUP\n</code></pre> Remove user from group<pre><code>gpasswd -d $USER $GROUP\n</code></pre></p>"},{"location":"Linux/IAM/#groupadd","title":"groupadd","text":""},{"location":"Linux/IAM/#groupdel","title":"groupdel","text":""},{"location":"Linux/IAM/#groupmod","title":"groupmod","text":""},{"location":"Linux/IAM/#useradd","title":"useradd","text":"Add user<pre><code>useradd $USER               \\\n-m                  \\ # Create home directory\n-d $PATH            \\ # Specify home directory\n-s /bin/bash        \\ # Default shell\n-c $FULLNAME        \\ # Note full name in comment\n-G $GROUP1 $GROUP2  \\ # Add groups        \n-u $UID             \\ # Specify user ID\n-e $DATE            \\ # Specify expiration date (YYYY-MM-DD)\n-r                  \\ # System user\n</code></pre> <p>Useradd's config is at /etc/default/useradd but it also inherits settings from /etc/login.defs.</p> Example config<pre><code># useradd defaults file for ArchLinux\n# original changes by TomK\nGROUP=users\nHOME=/home\nINACTIVE=-1\nEXPIRE=\nSHELL=/bin/bash\nSKEL=/etc/skel\nCREATE_MAIL_SPOOL=no\n</code></pre> <p>These settings can be displayed with: <pre><code>useradd -D\n</code></pre></p>"},{"location":"Linux/IAM/#userdel","title":"userdel","text":"Delete an existing user account as well as the user's home directory <pre><code>userdel -r $USER\n</code></pre>"},{"location":"Linux/IAM/#usermod","title":"usermod","text":""},{"location":"Linux/Kernel/","title":"Kernel","text":""},{"location":"Linux/Kernel/#commands","title":"Commands","text":""},{"location":"Linux/Kernel/#sysctl","title":"sysctl","text":"<p>View and configure kernel parameters at runtime. Kernel parameters are tunable values that can be adjusted during runtime.</p> <p>Kernel parameters can be delimited with dots or slashes <pre><code>sysctl kernel.hostname\nsysctl kernel/hostname\n</code></pre></p> <p>```sh title=\"Suppress  sysctl -n kernel.hostname <pre><code>Kernel parameters are set persistently by defining values in **/etc/sysctl.conf** or other .conf files placed in **/etc/sysctl.d/**.\n```ini title=\"/etc/sysctl.conf\"\nnet.ipv4.ip_forward=1\n</code></pre></p> <p>These values are then loaded into memory ad-hoc with: <pre><code>sysctl -p # --load\n</code></pre></p> <p>The runtime can be manipulated directly from the command-line with a different flag\" <pre><code>sysctl -w net.ipv4.ip_forward=1\n</code></pre></p> <p>Alternatively, values can be echoed to the virtual filesystem exposed at /proc/sys <pre><code>echo 1 &gt; /proc/sys/net/ipv4/ip_forward\n</code></pre></p> <p>Disable IPv6 <pre><code>net.ipv6.conf.all.disable_ipv6=1\nnet.ipv6.conf.default.disable_ipv6=1\n</code></pre></p> <p>Alternatively, kernel parameters can be viewed or even edited through the virtual filesystem mounted at /proc/sys</p>"},{"location":"Linux/Kernel/#uname","title":"uname","text":"<pre><code>uname       # Display operating system \"Linux\"\nuname -m    # Kernel architecture\nuname -r    # Kernel release version\nuname -a\n</code></pre>"},{"location":"Linux/Kernel/#modules","title":"Modules","text":"<p>A family of commands exists to manipulate Linux modules, including:</p> <ul> <li>Floppy, which can be used safely as a stand-in for any module while learning the commands</li> <li>KVM</li> <li>Wireguard</li> </ul> <p>Display currently loaded modules. Output in three columns:</p> <ol> <li>Module name</li> <li>Module size (bytes)</li> <li>Processes, filesystems, or other modules using the module</li> </ol>"},{"location":"Linux/Kernel/#rmmod","title":"rmmod","text":"<pre><code>rmmod floppy # (1)\n</code></pre> <ol> <li>Equivalent to <pre><code>modprobe -r floppy\n</code></pre></li> </ol>"},{"location":"Linux/Network/","title":"Networking","text":"<p>The Linux kernel supports several packet-filtering mechanisms.</p> <ul> <li>Netfilter using the venerable iptables utility</li> <li>nftables subsystem, introduced with kernel 3.13 (2014), had been commonly assumed to eventually take the place of iptables. Firewall rules are implemented in an in-kernel VM.</li> <li>bpfilter </li> </ul> <p>Netfilter is a software firewall and packet filtering framework introduced with Linux 2.4.0 (2001) and controlled by the iptables command.</p> <p>Netfilter rules are stored in tables and in chains, and tables are associated with various chains.</p> <p>By convention, table names are specified in lowercase and chain names in uppercase. Every packet starts at the top of a chain and is matched rule by rule. When a match is found the specified action, called the target, is triggered: i.e. \"DROP\" or \"ACCEPT\".</p> Tables INPUT OUTPUT FORWARD PREROUTING POSTROUTING filter \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f nat \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f mangle \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f raw \u2714\ufe0f \u2714\ufe0f <p>There are five builtin netfilter chains, though user-defined chains are also possible:</p> <ul> <li>INPUT used for filtering incoming packets where the host itself is the destination packet.</li> <li>OUTPUT for outgoing packets, where the host is the source of the packet.</li> <li>FORWARD for filtering routed packets, where the host is router.</li> <li>PREROUTING used for DNAT or port forwarding</li> <li>POSTROUTING used for SNAT</li> </ul> <p>Netfilter tables:</p> <ul> <li>filter default</li> <li>nat for SNAT and DNAT</li> <li>mangle for packet alteration</li> <li>raw used only to mark packets that should not be handled by the connection tracking system using the NOTRACK target</li> </ul>"},{"location":"Linux/Network/#networkmanager","title":"NetworkManager","text":"<p>NetworkManager provides a high-level interface for the configuration of network interfaces. It was developed by Red Hat and released in late 2004.</p> <p>The config file format native to NetworkManager is the ini-format keyfile stored in /etc/NetworkManager/system-connections. These files define network interfaces, or connection profiles in NetworkManager's terminology.</p>"},{"location":"Linux/Network/#nmcli","title":"nmcli","text":"<p>Control NetworkManager and report network status</p> <p>Display devices and statuses <pre><code>nmcli device status\n</code></pre></p> <p>Display information on interfaces as well as status Including other network connections not managed by network manager (\"unmanaged\") or not connected (\"unavailable\")  <pre><code>nmcli dev status\n</code></pre></p> <p>Display what connections are enabled  <pre><code>nmcli general status\n</code></pre></p> <p>Display UUIDs associated with network connections  <pre><code>nmcli connection show --active\n</code></pre></p> <p>Display much more information on network devices <pre><code>nmcli device show\n</code></pre></p> <p>Configure settings for network interface {ens01} via interactive shell <pre><code>nmcli connection edit ens01\n</code></pre></p> <p>List all connections NetworkManager has <pre><code>nmcli connection show\n</code></pre></p> <p>Show settings for network interface {ens01} <pre><code>nmcli device show ens01\n</code></pre></p> <p>Show status for all devices <pre><code>nmcli device status\n</code></pre></p> <p>Display currently configured hostname <pre><code>nmcli general hostname\n</code></pre></p> <p>Set hostname to {hostname} <pre><code>nmcli general hostname hostname\n</code></pre></p> <p>Show overall status of NetworkManager <pre><code>nmcli general status\n</code></pre></p> Migrate a connection profile<pre><code>nmcli connection migrate eth0\n</code></pre>"},{"location":"Linux/Network/#nmtui","title":"nmtui","text":"<pre><code>dnf install NetworkManager-tui\n</code></pre> nmtui is a curses-based TUI for control of NetworkManager."},{"location":"Linux/Network/#netplan","title":"Netplan","text":"<p>netplan is a utility for network configuration using YAML files that is the default network management tool used by recent versions of Ubuntu (since Ubuntu 17.10). Netplan is used as the default network management tool (previously ifconfig and its config at /etc/network/interfaces was used).</p> <p>Netplan supports two renderers or backends: NetworkManager and networkd.</p> <p>Netplan configs are YAML format and placed in /etc/netplan. Ubuntu installations usually come with a single config in this location named 01-network-manage-all-yaml, but many configs can be created in subdirectories. These are processed in lexicographical order regardless of subdirectory (unless there are multiple files with the same name). If a boolean or scalar parameter is defined in more than one config, the last value is assumed. Values that are sequences are concatenated.</p> Default config<pre><code># Let NetworkManager manage all devices on this system\nnetwork:\nversion: 2\nrenderer: NetworkManager # (1)\n</code></pre> <ol> <li>This may require the python3-networkmanager package to be installed first.</li> </ol> Static IP configuration<pre><code>network:\nversion: 2\nethernets:\neth0:\naddresses:\n- 192.168.2.100/24\ngateway4: 192.168.2.1\nnameservers:\naddresses:\n- 192.168.1.1\nsearch: []\n</code></pre>"},{"location":"Linux/Network/#netplan_1","title":"netplan","text":"<p>The netplan utility can be used to load the on-disk configuration.</p> Reload configuration temporarily<pre><code>netplan try\n</code></pre>"},{"location":"Linux/Network/#tasks","title":"Tasks","text":""},{"location":"Linux/Network/#bridge","title":"Bridge","text":"<p>A bridge is used to unite two or more network segments, typically used to establish communication channels between VMs, containers, and the host.</p> <p>Unlike the virtual bridge that Windows uses for WSL2 distributions, the bridge in Linux is strictly L2. That is, VMs connecting to the bridge are assigned IPs by the same DHCP server (i.e. the router) in the same subnet as that of the physical hosts. In Windows, the virtual bridge assigns an internal IP in a private range (usually 172.16.0.0/12), and connectivity to the host or the Internet has to be accomplished via NAT.</p> <pre><code>ip link add virbr0 type bridge # (1)\nip link set virbr0 up\n</code></pre> <ol> <li>The link can be deleted thus: <pre><code>ip link delete virbr0\n</code></pre></li> </ol> <p>Adding an interface to the bridge is done by setting its master. <pre><code>ip link set enp2s0f0 master virbr0 # (1)\n</code></pre></p> <ol> <li>This can be undone as follows: <pre><code>ip link set enp2s0f0 nomaster\n</code></pre></li> </ol> <p>The iproute2 bridge utility can be used to verify the command has taken effect: <pre><code>bridge link\n</code></pre></p> <p>This may interrupt network connectivity. In this case, the IP address must be removed from the linked interface and assigned to the bridge <pre><code>ip address delete 192.168.1.3 dev enp2s0f0\nip address add 192.168.1.3 dev virbr0\n</code></pre></p> <p>The default route in the routing table must also be amended. Note this is not the IP address of the interface but rather that of the gateway. Also note that this gateway must already have its own network segment defined. That is, in order for a default route to be defined at least one static route must also be defined, which is the gateway's own local subnet. <pre><code>ip route delete default\nip route add default via 192.168.1.1\n</code></pre></p>"},{"location":"Linux/Network/#downloading-files","title":"Downloading files","text":"<p>Wget defaults to file operations in a way that is more natural for downloading.</p> <pre><code>wget $url\n</code></pre> <p>Curl depends on piping and defaults to STDOUT in a manner similar to cat.</p> <pre><code>curl -O $url </code></pre>"},{"location":"Linux/Network/#wireguard-tunnel","title":"Wireguard tunnel","text":"Red Hat Ubuntu <pre><code>dnf install wireguard-tools\n</code></pre> <pre><code>apt install wireguard\n</code></pre> <p>Successful installation can be confirmed by running the following, which should produce no output (and no error) on success. <pre><code>sudo modprobe wireguard\n</code></pre></p> <p>The first step in creating a Wireguard tunnel is to create a private key on each endpoint of the tunnel. The genkey subcommand creates a 44-character base64 encoded key ending in <code>=</code> which can be redirected to a file. If the file will be world-readable, the utility will ask you to change the umask. <pre><code>wg genkey # \u2593\u2593\u2591\u2591\u2591\u2593\u2591\u2592\u2593\u2592\u2593\u2592\u2591\u2593\u2591\u2592\u2591\u2593\u2591\u2592\u2592\u2591\u2593\u2591\u2593\u2591\u2592\u2591\u2592\u2593\u2592\u2592\u2592\u2591\u2591\u2592\u2592\u2591\u2591\u2591\u2592\u2592\u2593\u2593=\n</code></pre></p> <p>The public key can be generated by piping the private key from STDIN or from the file. <pre><code>wg pubkey private &gt; public\nwg genkey | tee private | wg pubkey &gt; public\n</code></pre></p> <p>Then a Wireguard interface is created, typically named wg0, using network management utilities. <pre><code>ip link add wg0 type wireguard\n</code></pre></p> <p>An IP address is assigned to that interface, to be used within the tunnel: <pre><code>ip addr add 10.0.0.1/24 dev wg0\n</code></pre></p> <p>Now the private key is associated with the interface: <pre><code>wg set wg0 private-key ~/.config/wireguard/private\n</code></pre></p> <p>Finally, the interface is brought up: <pre><code>ip link set wg0 up\n</code></pre></p> <p>The public key of the peer is now associated with the Wireguard interface and the public IP and port of the other endpoint are specified. <pre><code>wg set wg0 peer $PUBKEY allowed-ips 10.0.0.2/32 endpoint $IP\n</code></pre></p> <p>The tunnel is dismantled by removing the interface. <pre><code>ip link delete wg0\n</code></pre></p> <p>Alternatively, many of these steps can be consolidated into creating a config for the Wireguard interface at /etc/wireguard/wg0.conf with the following contents: <pre><code>[Interface]\nPrivateKey = \u2593\u2593\u2591\u2591\u2591\u2593\u2591\u2592\u2593\u2592\u2593\u2592\u2591\u2593\u2591\u2592\u2591\u2593\u2591\u2592\u2592\u2591\u2593\u2591\u2593\u2591\u2592\u2591\u2592\u2593\u2592\u2592\u2592\u2591\u2591\u2592\u2592\u2591\u2591\u2591\u2592\u2592\u2593\u2593=\nAddress = 10.0.0.1/24\nPostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\nPostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE\nListenPort = 51820\n\n[Peer]\nPublicKey = \u2593\u2592\u2593\u2592\u2593\u2593\u2591\u2593\u2592\u2592\u2591\u2591\u2592\u2592\u2592\u2593\u2592\u2591\u2592\u2593\u2592\u2591\u2592\u2592\u2593\u2592\u2591\u2592\u2591\u2591\u2591\u2591\u2592\u2591\u2592\u2592\u2592\u2591\u2591\u2592\u2592\u2593\u2591\u2592=\nAllowedIps = 10.0.0.2/32\nEndpoint = 123.45.67.89:51820\n</code></pre></p> <p>Then to bring it up quickly: <pre><code>wg-quick up wg0\n</code></pre></p> <p>The same utility can be used to teardown the tunnel <pre><code>wg-quick down wg0\n</code></pre></p>"},{"location":"Linux/Network/#static-ip","title":"Static IP","text":"<p>Static IP configuration varies by the network management toolset and backend presenton a system.  Ubuntu systems use Netplan whereas other distributions most commonly use Network Manager.</p> NetplanNetwork Manager <pre><code>network:\nversion: 2\nethernets:\neth0:\naddresses:\n- 192.168.2.100/24\ngateway4: 192.168.2.1\nnameservers:\naddresses:\n- 192.168.1.1\nsearch: []\n</code></pre> <pre><code>[connection]\nid=Ethernet\nuuid=abcdef01-2345-6789-0abc-def012345678\ntype=ethernet\ninterface-name=eth0\n\n[ethernet]\n\n[ipv4]\naddress1=192.168.2.100/24,192.168.2.1\ndns=10.40.7.2\nmethod=manual\n\n[ipv6]\naddr-gen-mode=stable-privacy\nmethod=auto\n</code></pre> <p>Setting a static IP address on Red Hat distributions could involve multiple methods:</p> <ul> <li>nmcli commands</li> <li>NetworkManager keyfiles</li> <li>ifcfg files (prior to distributions downstream to Fedora 36)</li> </ul>"},{"location":"Linux/Network/#commands","title":"Commands","text":""},{"location":"Linux/Network/#curl","title":"curl","text":"<p>Accept a self-signed certificate by skipping verification <pre><code>curl -k https://192.168.1.10\n</code></pre></p> <p>Use the  <code>dict</code> network protocol  to retrieve the definition of a word. ref <pre><code>curl dict://dict.org/d:&lt;word&gt;\n</code></pre> Sending a POST method to a FastAPI app (src) <pre><code>curl -X POST \"http://127.0.0.1:8000/purchase/item/\" -H \"accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"name\\\":\\\"sample item\\\",\\\"info\\\":\\\"This is info for the item\\\",\\\"price\\\":40,\\\"qty\\\":2}\"\n</code></pre></p>"},{"location":"Linux/Network/#firewall-cmd","title":"firewall-cmd","text":"<p>Frontend to Netfilter in Red Hat distributions.</p> <pre><code>firewall-cmd --state # \"running\"\n</code></pre> <p>Firewalld has a runtime configuration and a saved, persistent configuration. Only the runtime configuration will be consulted for any command, unless the persistent configuration is specified with --permanent.</p> <p>The runtime configuration can be saved with this command, which obviates the need to execute every change twice. <pre><code>firewall-cmd --runtime-to-permanent\n</code></pre></p> <p>Alternatively, the persistent configuration can be loaded into memory: <pre><code>firewall-cmd --reload\n</code></pre></p> Display firewall rules<pre><code>firewall-cmd --list-all --permanent\n</code></pre> <p>Firewalld uses zones to define the level of trust for network connections. A connection can only be part of one zone, but a zone can be used for many network connections. Builtin zones have XML-format configs found in /usr/lib/firewalld/zones. <pre><code>firewall-cmd --get-active-zones     # Display active zones along with interfaces\nfirewall-cmd --info-zone=public     # Inspect zone\nfirewall-cmd --new-zone=testlab     # Create new zone\n</code></pre></p> <p>Firewalld rules are generally managed through builtin services. These bundle network settings together for well-known applications like SSH, etc. Builtin services are also XML-format configs found in /usr/lib/firewalld/services.</p> Services<pre><code>firewall-cmd --list-services\nfirewall-cmd --add-service=http\nfirewall-cmd --remove-service=http\n</code></pre> <p>Firewalld's config file is at /etc/firewalld/firewalld.conf /etc/firewalld/firewalld.conf<pre><code>AllowZoneDrifting=no\n</code></pre></p> <p>Since RHEL 8, firewalld's backend has been changed to nftables. /etc/firewalld/firewalld.conf<pre><code>FirewallBackend=nftables\n</code></pre></p>"},{"location":"Linux/Network/#ip","title":"ip","text":"ip address<pre><code>ip address add 192.168.2.2 dev eth0\n</code></pre> ip route<pre><code># Add static route (this is sometimes done automatically by the system after adding an address)\nip route add 192.168.2.0/24 dev eth0\n\n# Add default route\nip route add default via 192.168.2.1 dev eth0\n</code></pre> ip link<pre><code># Create new links\nip link add virbr0 type bridge\nip link add wg0 type wireguard\n\n# Listen for netlink messages\nip monitor # Change the default gateway to 192.168.1.1 on eth0\nip route change default via 192.168.1.1 dev eth0\n\n# Bring interface up\"\nip link set wlp2s0 up\n</code></pre> ip neighbor<pre><code># Display ARP cache\nip neighbor show\n\n# Delete ARP entry\nip neighbor delete $IP_ADDR dev eth0 </code></pre> ip netns<pre><code>ip netns # (1)\n\n# We can create a network namespace then add two virtual Ethernet interfaces.\n# These are **peers**, meaning they are linked together as if connected to the same switch.\nip netns add netns0\nip link add veth0 type veth peer name veth1 netns netns0\n\n# We can then run a command in the **context** of a namespace. Without providing a context, \n# the default namespace is used and we can display veth0 but not veth1. If there are no other\n# links in the namespace (which there shouldn't be) then the **number** of the interface's \n# peer appears in the link's name. By running a command in the context of the new namespace \n# we can display veth1. The interface number of the link it's paired with in the \n# default namespace also appears in this link's name.\nip link show                        # \"veth0@if2\"\nip netns exec netns0 ip link show   # \"veth1@if4\"\n\n# Now we assign an address to the namespaced link and bring it up\nip netns exec netns0 ip addr add 10.0.0.1/24 dev veth1\nip netns exec netns0 ip link set dev veth1 up\n\n# Pinging this IP from outside the namespace will not work because there is no route.\n# Adding an IP in the same subnet to veth0 creates the route.\nip addr add 10.0.0.2/24 dev veth0\n\n# The interface must be brought up, which automatically adds a route to the routing table.\nip link set dev veth0 up\n</code></pre> <ol> <li>Network namespaces are mounted to /var/run/netns</li> </ol>"},{"location":"Linux/Network/#iptables","title":"iptables","text":"<p>A frontend for the kernel-level netfilter service, similar to firewalld. </p> <p>Rules are saved in a rulesfile which once may have been found at /etc/sysconfig/iptables, but this file does not exist on recent Fedora installations.</p> <p>Display rules as written on disk <pre><code>iptables --list-rules\n</code></pre></p> <p>Reload configuration file <pre><code>iptables -F\n</code></pre></p> <p>Accept SSH traffic from a particular IP <pre><code>iptables -A INPUT -p ssh -s 10.0.222.222 -j ACCEPT\n</code></pre></p> <p>Accept incoming TCP traffic to port 80 <pre><code>iptables -A INPUT -p tcp --dport 80 -j ACCEPT\n</code></pre></p> <p>Change FORWARD chain policy <pre><code>iptables -P FORWARD ACCEPT # (1)\n</code></pre></p> <ol> <li>By default, the INPUT chain accepts incoming packets. However, this policy can be changed by specifying a DROP rule specification.</li> </ol> <p>Allow incoming SSH connections only from a single IP address <pre><code>iptables -A INPUT -p tcp --dport 22 -j DROP\niptables -A INPUT -p tcp --dport 22 -s 1.2.3.4 -j ACCEPT\n</code></pre></p> <p>Do not respond to pings <pre><code>iptables -t filter -A INPUT -p icmp -j DROP\n</code></pre></p>"},{"location":"Linux/Network/#netcat","title":"netcat","text":"<p>The netcat utility allows testing of a host's ports, similar to ping, but more versatile because ping only uses the portless ICMP protocol.  GNU and OpenBSD versions available</p> <p>Connect to host on port 80 <pre><code>nc example.com 80\n</code></pre> Scan ports</p> SingleMultipleRange of ports <pre><code>nc -v -w 2 z 192.168.56.1 22\n</code></pre> <pre><code>nc -v -w 2 z 192.168.56.1 22 80\n</code></pre> <pre><code>nc -v -w 2 z 192.168.56.1 22-25\n</code></pre> <p>Transfer files between servers This example uses the <code>pv</code> utility to monitor progress. <pre><code># Run `nc` in listening mode (`-l` option) on port 3000\ntar -zcf - debian-10.0.0-amd64-xfce-CD-1.iso | pv | nc -l -p 3000 -q 5\n\n# On the receiving client, to obtain the file:\nnc 192.168.1.4 3000 | pv | tar -zxf -\n</code></pre> Create a command-line chat server <pre><code># Create chat server listening on port 5000\nnc -l -vv -p 5000\n\n# Launch a chat session on the other system\nnc 192.168.56.1 5000\n</code></pre> Find a service running on port Obtain port banners (<code>-n</code> disables DNS lookup) <pre><code>nc -v -n 192.168.56.110 80\n</code></pre> Create stream sockets Create and listen on a UNIX-domain stream socket <pre><code>nc -lU /var/tmp/mysocket &amp;\nss -lpn | grep \"/var/tmp/\"\n</code></pre> Create a backdoor Netcat needs to listen on a chosen port (here 3001): <code>-d</code> disables reading from stdin; <code>-e</code> specifies the command to run on the target system <pre><code>nc -L -p 3001 -d -e cmd.exe\n</code></pre> Connect to {port} at {host} <pre><code>nc host port\n</code></pre> Netcat command that retrieves a webpage <pre><code>nc host port get\n</code></pre></p>"},{"location":"Linux/Network/#nft","title":"nft","text":"<pre><code>nft list ruleset\nnft list tables\nnft list table ip filter # display just the filter table\nnft flush ruleset\n</code></pre>"},{"location":"Linux/Network/#nmap","title":"nmap","text":"Scan hosts from a text file <pre><code>nmap -iL hosts.txt\n</code></pre> Identify a host's operating system <pre><code>nmap -A localhost.example.com\n</code></pre> Determine whether a host has a firewall enabled <pre><code>nmap -sA localhost.example.com\n</code></pre> Scan a specified range of ports <pre><code>nmap -p 10-300 localhost.example.com\n</code></pre> Perform a SYN TCP scan, stealthier than the TCP connect scan <pre><code>nmap -sT localhost.example.com\n</code></pre> Aggressive scan <pre><code>nmap -A 192.168.1.0/24\n</code></pre> Ping scan home network (not bothering with ports) <pre><code>nmap -sn 192.168.1.0/24\n</code></pre> Fast port scan using SYN packets <pre><code>nmap -sS -F 192.168.1.0/24\n</code></pre> Port scan using SYN (\"synchronize\") packet, first element of TCP handshake <pre><code>nmap -sS 192.168.1.0/24\n</code></pre> Port scan using normal TCP <pre><code>nmap -sT 192.168.1.0/24\n</code></pre> Port scan using UDP <pre><code>nmap -sU 192.168.1.0/24\n</code></pre> Xmas scan <pre><code>nmap -sX\n</code></pre> Scan a range of IPs [ref][Sec+ Lab] <pre><code>nmap 192.168.27.0/24 &gt; hosts.txt\n</code></pre> Identify operating system and scan ports using TCP SYN packets [ref][Sec+ Lab] <pre><code>nmap -O -sS 192.168.27.0/24 &gt; hosts.txt\n</code></pre>"},{"location":"Linux/Network/#tcpdump","title":"tcpdump","text":"<p>Inspect actual IP packets</p> <p>Display all network data <pre><code>tcpdump -i eth0   \n</code></pre> Set snapshot length of capture (default: 65,535B) <pre><code>tcpdump -s\n</code></pre></p>"},{"location":"Linux/Network/#ufw","title":"ufw","text":"<p>Program for managing a Netfilter firewall.</p> <p>Allow traffic associated with various services <pre><code>ufw allow ssh\nufw allow http\nufw allow https\n</code></pre></p>"},{"location":"Linux/Network/#wg","title":"wg","text":"<p>This is the main CLI frontend for Wireguard, the UDP-based tunneling protocol and application that was introduced with kernel 5.6.</p>  Fedora Ubuntu <pre><code>dnf install wireguard-tools\n</code></pre> <pre><code>apt install wireguard\n</code></pre>"},{"location":"Linux/Network/#wget","title":"wget","text":"Accept a self-signed certificate by skipping verification <pre><code>wget --no-check-certificate $URL\n</code></pre>"},{"location":"Linux/Network/#glossary","title":"Glossary","text":""},{"location":"Linux/Network/#ebpf","title":"eBPF","text":"<p>eBPF is an extended version of the Berkeley Packet Filter (BPF).  It is a sandboxed environment that allows code to be inserted into the running kernel.  Kernel functionality must normally be extended by building an entirely new kernel with custom modules or upstream patching of the Linux kernel.</p> <p>eBPF's architecture includes a JIT compiler that compiles the program's generic bytecode, which means eBPF programs run as efficiently as natively compiled kernel code.</p> <p>eBPF programs can be bound to kernel events, such as receipt of a packet from the NIC.</p> <p>bpftool is a core eBPF CLI tool.</p> <pre><code>bpftool prog     # Display running eBPF programs\nbpftool map show # Display maps\n</code></pre>"},{"location":"Linux/Network/#ifcfg","title":"ifcfg","text":"<p>Historically, ifcfg (interface configuration) files were ini-format files found in /etc/sysconfig/network-scripts/ in Red Hat distributions. They were used to control network interfaces on the legacy \"network\" service, now part of the network-scripts package, which included the sysconfig.txt file which documents the ifcfg file format.</p> <p>After the introduction of NetworkManager, this format survived and was expanded with new  directives specific to NetworkManager.</p> <p>By convention, the string value of the DEVICE directive was the suffix of the filename itself. ifcfg-eth0<pre><code>DEVICE=eth0\nBOOTPROTO=dhcp\nONBOOT=yes\nTYPE=Ethernet\n</code></pre></p> <p>The nmcli utility exposes a command that can change the configuration backend from ifcfg to a NetworkManager keyfile. Migrate a connection profile<pre><code>nmcli connection migrate eth0\n</code></pre></p> <p>Ifcfg file support was finally removed in RHEL 9 and Fedora 36. If no ifcfg files are present, the configuration backend that supports them can be removed. <pre><code>dnf remove NetworkManager-initscripts-ifcfg-rh\n</code></pre></p>"},{"location":"Linux/Network/#netfilter","title":"Netfilter","text":"Netfilter is a software firewall and packet filtering framework introduced with Linux 2.4.0 (2001) and controlled by the iptables command."},{"location":"Linux/Package/","title":"Package management","text":""},{"location":"Linux/Package/#commands","title":"Commands","text":""},{"location":"Linux/Package/#add-apt-repository","title":"add-apt-repository","text":"<p>APT repositories (/etc/apt/sources.list) are made of three parts, delimited by whitespace:</p> <ul> <li>Source type: <code>deb</code> for binary packages or <code>deb-src</code> for source packages</li> <li>Base URL of the source: beginning with <code>http://</code>, <code>ftp://</code>, <code>file://</code>, or even <code>cdrom:</code></li> <li>Name of the chosen distribution followed by sections that differentiate packages by license. Kali contains <code>main</code>, <code>non-free</code>, and <code>contrib</code>.</li> </ul> <pre><code>deb http://us-central1.gce.archive.ubuntu.com/ubuntu/ bionic main restricted\ndeb http://us-central1.gce.archive.ubuntu.com/ubuntu/ bionic universe\ndeb http://us-central1.gce.archive.ubuntu.com/ubuntu/ bionic-updates main restricted\ndeb http://us-central1.gce.archive.ubuntu.com/ubuntu/ bionic-updates universe\n</code></pre> <pre><code>add-apt-repository \"deb http://security.ubuntu.com/ubuntu trusty-security main universe\" # Ubuntu\nadd-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" # Docker\nadd-apt-repository \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" # gcloud\nadd-apt-repository \"deb http://security.ubuntu.com/ubuntu trusty-security main universe\" # mailx\nadd-apt-repository \"deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.2 multiverse\" # MongoDB\nadd-apt-repository -y \"ppa:kgilmer/regolith-stable\" # Regolith Linux\n</code></pre>"},{"location":"Linux/Package/#apt-key","title":"apt-key","text":"<p>apt-key is typically used by piping a GPG key from curl. <pre><code># Google Cloud SDK\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - \ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -\n\n# Docker in WSL\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - </code></pre></p> <p>Add key specified by apt in error message <pre><code>apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 68980A0EA10B4DE8\n</code></pre></p> <p>Install key from Mono <pre><code>apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF\n</code></pre></p>"},{"location":"Linux/Package/#apt","title":"apt","text":""},{"location":"Linux/Package/#dnf","title":"dnf","text":"<p>View history of dnf commands <pre><code>dnf history\ndnf history userinstalled # View all packages installed by user\n</code></pre></p> <p>Package groups can be specified using the group command or by prefixing the package group name with <code>@</code></p> <pre><code>dnf info @virtualization # dnf group info virtualization\ndnf install @virtualization # dnf group install virtualization\ndnf install --with-optional @virtualization # Include optional packages\n</code></pre> <p>Remove the configuration backend supporting the use of legacy ifcfg files in NetworkManager. <pre><code>dnf remove NetworkManager-initscripts-ifcfg-rh\n</code></pre></p> <p>Modules are special package groups representing an application, runtime, or a set of tools.  The Node.js module allows you to select several streams corresponding to major versions. <pre><code>dnf module install nodejs:12\n</code></pre></p> <p>Global dnf configuration is stored in either /etc/yum.conf or /etc/dnf.conf.</p> <pre><code>[main]\n; Exclude packages from updates permanently\nexclude=kernel* php*\n; Suppress confirmation\nassumeyes=True\n</code></pre> <p>The configuration can be dumped from the command-line (as root) <pre><code>dnf config-manager --dump\n</code></pre></p>"},{"location":"Linux/Package/#repos","title":"Repos","text":"<p>Repositories are INI files placed in  /etc/yum.repos.d/, but they can also be displayed and manipulated from the command-line.</p> Repositories<pre><code># Display repos\ndnf repolist # -v\n\n# Display enabled repos\ndnf repolist --enabled\n\n# Display a single repo\ndnf repoinfo docker-ce-stable\n\n# Add repo\ndnf config-manager --add-repo $REPO-URL\n\n# Disable repo\ndnf config-manager --set-disabled $REPO-NAME\n</code></pre> Example repos<pre><code>[docker-ce-stable]\nname=Docker CE Stable - $basearch\nbaseurl=https://download.docker.com/linux/fedora/$releasever/$basearch/stable\nenabled=1\ngpgcheck=1\ngpgkey=https://download.docker.com/linux/fedora/gp\n\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\n\n[google-cloud-sdk]\nname=Google Cloud SDK\nbaseurl=https://packages.cloud.google.com/yum/repos/cloud-sdk-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=0\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\n</code></pre> <p>Modules are collections of packages that are installed together. They often also have profiles available, which are variants of the module: i.e. client, server, common, devel, etc. <pre><code>dnf module list php\ndnf module install php:7.4/devel\ndnf module reset php\n</code></pre></p>"},{"location":"Linux/Package/#flatpak","title":"flatpak","text":"<p>Flatpak is one of several recent containerized application distribution solutions for Linux.</p> <p>Flatpak runtimes are compiled reproducibly using BuildStream and they are installed in /var/lib/flatpak/runtime. Like Steam, flatpak uses BubbleWrap to implement sandboxing.</p> <p>Flathub is the de facto Flatpak repo, but it must be added to flatpak installations manually. <pre><code>flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\n\n# Confirming success\nflatpak remotes </code></pre></p> <p>Display installed flatpak applications, including runtime <pre><code>flatpak list --app --runtime\n</code></pre></p> <p>Output columns can also be specified individually after <code>--column</code> (comma-delimited) <pre><code>flatpak list --app --columns=name,application,runtime\n</code></pre></p> <p>Flatpak applications sometimes do not adopt the system theme. The workaround involves first granting some or all applications access to the themes folder. <pre><code>flatpak override --filesystem=$HOME/.themes\n</code></pre></p> <p>Then apply the theme by setting the <code>GTK_THEME</code> environment variable. The value of this variable must be the folder name of a theme installed to the themes folder (typically ~/.themes). <pre><code>flatpak override --env=GTK_THEME=my-theme </code></pre></p> <p>The value of the current theme can be retrieved using gsettings <pre><code>gsettings get org.gnome.desktop.interface gtk-theme\n</code></pre></p>"},{"location":"Linux/Package/#pacman","title":"pacman","text":"<pre><code>pacman -Q # --query\n</code></pre> <p>Display all orphaned dependencies (no longer needed) <pre><code>pacman -Qdt # --query --deps --unrequired\n</code></pre></p> <p>Display only explicitly installed packages and versions <pre><code>pacman -Qe # --query --explicit\n</code></pre></p> <p>Display explicitly installed packages, limiting output to program names <pre><code>pacman -Qeq # pacman --query --explicit --quiet\n</code></pre></p> <p>Display all packages installed from the AUR <pre><code>pacman -Qm # --query --foreign\n</code></pre></p> <p>Display all packages installed from main repos <pre><code>pacman -Qn # --query --native\n</code></pre></p> <p>Find which package owns {file} <pre><code>pacman -Qo file # --query --owns\n</code></pre></p> <p>List all install packages, filtering output to packages that are out-of-date on the local system <pre><code>pacman -Qu # --query --upgrades\n</code></pre></p> <p>Remove <code>$PACKAGE</code> <pre><code>pacman -R $PACKAGE # --remove package\n</code></pre></p> <p>Remove <code>$PACKAGE</code>, dependencies, and config files <pre><code>pacman -Rns $PACKAGE # --remove --recursive --nosave\n</code></pre></p> <p>Remove <code>$PACKAGE</code> as well as its dependencies <pre><code>pacman -Rs # --remove --recursive\n</code></pre></p> <p>Install <code>$PACKAGE</code> from the AUR <pre><code>pacman -S $PACKAGE # --sync\n</code></pre></p> <p>Remove all packages from the cache as well as unused sync databases <pre><code>pacman -Scc # --sync --clean --clean\n</code></pre></p> <p>Display information about {package} <pre><code>pacman -Si $PACKAGE # --sync --info package\n</code></pre></p> <p>Search for <code>$PACKAGE</code> in AUR repos <pre><code>pacman -Ss $PACKAGE # --sync --search package\n</code></pre></p> <p>Search for packages matching <code>$PATTERN</code> <pre><code>pacman -Ss $PATTERN # --sync --search pattern\n</code></pre></p> <p>Update package database <pre><code>pacman -Sy #  --sync --refresh\n</code></pre></p> <p>Update all packages from AUR and official repos <pre><code>pacman -Syu # --sync --refresh --sysupgrade\n</code></pre></p> <p>Force refresh of all package databases, even if they appear to be up-to-date <pre><code>pacman -Syy # --sync --refresh --refresh\n</code></pre></p> <p>Download program updates but don't install them <pre><code>pacman -Syyuw # --sync --refresh --refresh --sysupgrade --downloadonly\n</code></pre></p> <p>Get number of total installed packages <pre><code>pacman -Q | wc -l\n</code></pre></p>"},{"location":"Linux/Package/#rpm","title":"rpm","text":"<p>Query repos for information on a package <pre><code>rpm -qi $PACKAGE # --query --info\n</code></pre></p> <p>Upgrade or install a package, with progress bars <pre><code>rpm -Uvh $PACKAGE # --upgrade --verbose --hash\n</code></pre></p> <p>Display version of Fedora <pre><code>rpm -E %fedora\n</code></pre></p> <p>Import a keyring <pre><code>rpm --import \"https://build.opensuse.org/projects/home:manuelschneid3r/public_key\"\n</code></pre></p>"},{"location":"Linux/Package/#snap","title":"snap","text":"<p>Snap is one of several recent containerized application distribution solutions for Linux.</p> <p>Snap apps are slow to start because data is stored in squashfs images.</p> <p>Installation</p>  Red Hat <pre><code>dnf install -y snapd\nln -s /var/lib/snapd/snap /snap\n</code></pre>"},{"location":"Linux/Process/","title":"Process management","text":""},{"location":"Linux/Process/#commands","title":"Commands","text":""},{"location":"Linux/Process/#chrt","title":"chrt","text":"Lower the priority of tasks relative to others <pre><code>chrt -o\n</code></pre>"},{"location":"Linux/Process/#nice","title":"nice","text":"<p>Priorities range from 0-19 in <code>csh</code> (10 is default): lower values mean a higher priority.</p> <p>View priorities of jobs <pre><code>ps -l\n</code></pre></p> <p>Run <code>cmd</code> at a higher priority <pre><code>nice -5 cmd &amp;\n</code></pre> Run <code>$CMD</code> at a nice value of (positive) 10 <pre><code>nice -10 $CMD\nnice -n 10\nnice $CMD\n</code></pre></p>"},{"location":"Linux/Process/#ps","title":"ps","text":"<p>Display processes in a tree-like display illustrating parent-child relationships <pre><code>ps -f # --forest\n</code></pre></p> <p>Show system processes</p> BSD syntaxPOSIX syntax <pre><code>ps ax\n</code></pre> <pre><code>ps -ef\n</code></pre> <p>Display full listing of processes <pre><code>ps u # -f\n</code></pre></p> <p>Display user processes <pre><code>ps xG # -a\n</code></pre></p> <p>Display SELinux contexts for processes <pre><code>ps auxZ\n</code></pre></p> <p>Display kernel threads <pre><code>ps -ef\n</code></pre></p>"},{"location":"Linux/Process/#taskset","title":"taskset","text":"Send a task to a specific core <pre><code>taskset -c\n</code></pre>"},{"location":"Linux/Random/","title":"Random","text":"<p>There are two random-number devices in the kernel. Historically:</p> <ul> <li>/dev/random  blocked until it had sufficient entropy to return a random value</li> <li>/dev/urandom never blocked but resorted to a pseudorandom number generator (PRNG) in the case of insufficient entropy</li> </ul> <p>However, in 2020 the behavior of /dev/random was changed to make it behave more like the getrandom syscall, in that it blocks only on initialization and provides cryptographic-strength random numbers thereafter without blocking. This has resulted in a blurring of the lines between the two random devices and an effort to remove /dev/urandom for good.</p>"},{"location":"Linux/Red-Hat/","title":"Red Hat","text":""},{"location":"Linux/Red-Hat/#subscriptions","title":"Subscriptions","text":"<p>Subscriptions are managed through the Red Hat entitlement service, integrated with the Customer Portal. Entitlement certificates are stored as X.509 PEM certificate files in /etc/pki/entitlement for Simple Content Access (SCA)-enabled accounts.</p> Inspect X.509 certificate<pre><code>openssl x509 -text -in /etc/pki/entitlement/9012345678901234567.pem\n</code></pre>"},{"location":"Linux/Red-Hat/#subscription-manager","title":"subscription-manager","text":"<pre><code># Display status of subscriptions and products\nsubscription-manager status\n\n# Display installed products\nsubscription-manager list\n</code></pre>"},{"location":"Linux/Red-Hat/#applications","title":"Applications","text":""},{"location":"Linux/Red-Hat/#tuned","title":"TuneD","text":"<p>TuneD is a service that monitors the system and optimizes its performance under certain workloads. TuneD provides predefined profiles for power-saving and performance-boosting use cases.</p> <ul> <li>throughput-performance optimizes for throughput</li> <li>virtual-guest optimizes for performance</li> <li>balanced balances performance and power consumption</li> <li>powersave optimizes for power consumption</li> </ul> <p>These can be listed from the command-line: <pre><code>tuned-adm list profiles\ntuned-adm active\ntuned-adm recommend\ntuned-adm profile powersave                 # Select a profile\ntuned-adm profile virtual-guest powersave   # Select a merged profile\n</code></pre></p> <p>Dynamic tuning monitors system components during uptime and makes system changes dynamically. It is enabled by changing a setting in TuneD's config at /etc/tuned/tuned-main.conf: /etc/tuned/tuned-main.conf<pre><code>dynamic_tuning=1\n</code></pre></p>"},{"location":"Linux/Red-Hat/#cockpit","title":"Cockpit","text":"Cockpit is builtin to Red Hat distributions and, once started as a normal SystemD service, is available at port 9090."},{"location":"Linux/Red-Hat/#storage","title":"Storage","text":""},{"location":"Linux/Red-Hat/#autofs","title":"autofs","text":"<p>Auto File System offers an alternative way of mounting NFS shares that can save some system resources, especially when many shares are mounted. Autofs can mount NFS shares dynamically, only when accessed. <pre><code>dnf install -y autofs\nsystemctl enable --now autofs.service\n</code></pre></p> <p>Mounts are defined in configs called maps. There are three map types:</p> <ul> <li>master map is /etc/auto.master by default</li> <li>direct maps point to other files for mount details. They are notable for beginning with /-</li> <li>indirect maps also point to other files for mount details but provide an umbrella mount point which will contain all other mounts within it. Note that other mountpoints at this parent directory cannot coexist with autofs mounts.</li> </ul> <p>Here is an example indirect map that will mount to /data/sales. /etc/auto.master.d/data.autofs<pre><code>/data /etc/auto.data\n</code></pre> /etc/auto.data<pre><code>sales -rw,soft 192.168.33.101:/data/sales\n</code></pre></p> <p>Map files also support wildcards. <pre><code>* 127.0.0.1:/home/&amp;\n</code></pre></p> <p>AutoFS's config is at /etc/autofs.conf. One important directive is master_map_name which defines the master map file.</p>"},{"location":"Linux/Red-Hat/#stratis","title":"Stratis","text":"<p>Stratis is an open-source managed pooled storage solution in the vein of ZFS or btrfs.</p> <p>Stratis block devices can be disks, partitions, LUKS-encrypted volumes, LVM logical volumes, or DM multipath devices. Stratis pools are mounted under /stratis and, like other pooled storage systems, support multiple filesystems. Stratis file systems are thinly provisioned and formatted with xfs, although vanilla xfs utilities cannot be used on Stratis file systems.</p> <p><pre><code>dnf -y install stratisd stratis-cli\nsystemctl enable --now stratisd\n</code></pre> Create a pool<pre><code>stratis pool create pool /dev/sda /dev/sdb /dev/sdc # (1)\n</code></pre></p> <ol> <li>An error about the devices being \"owned\" can be resolved by wiping it. <pre><code>wipefs -a /dev/sda\n</code></pre></li> </ol> Display block devices managed by Stratis<pre><code>stratis blockdev # (1)\n</code></pre> <ol> <li>This command is equivalent to pvs in LVM.</li> </ol> Create filesystem<pre><code>stratis fs create pool files\n</code></pre> Confirm<pre><code>stratis fs\n</code></pre> /etc/fstab<pre><code>/stratis/pool/files /mnt/stratisfs xfs defaults,x-systemd.requires=stratisd.service 0 0\n</code></pre> Expand pool<pre><code>stratis pool add-data pool /dev/sdb\n</code></pre> Save snapshot<pre><code>stratis fs snapshot pool files files-snapshot\n</code></pre> Restore from snapshot<pre><code>stratis fs rename files files-orig\nstratis fs rename files-snapshot files\numount /mnt/files; mount /mnt/files\n</code></pre>"},{"location":"Linux/Red-Hat/#vdo","title":"VDO","text":"<p>Virtual disk optimizer (VDO) is a kernel module introduced in RHEL 7.5 that provides data deduplication and compression on block devices.</p> <p>The physical storage of a VDO volume is divided into a number of slabs, which are contiguous regions of the physical space.  All slabs for a given volume have the same size, which can be any power of 2 multiple of 128 MB up to 32 GB (2 GB by default). The maximum number of slabs is 8,192. The maximum physical storage of the VDO is provided to the user on creation.</p> <p>Like LVM volumes, VDO volumes appear under /dev/mapper</p> <p>VDO appears not to be installed by default, but it is available in the BaseOS repo. <pre><code>dnf install vdo\nsystemctl enable --now vdo\n</code></pre></p> Create a VDO volume<pre><code>vdo create --name=web_storage --device=/dev/xvdb --vdoLogicalSize=10G\nvdostats --human-readable\nmkfs.xfs -K /dev/mapper/web_storage\nudevadm settle\n</code></pre> <p>The fstab file requires a variety of options <pre><code>/dev/mapper/web_storage /mnt/web_storage xfs _netdev,x-systemd.device-timeout=0,x-systemd.requires=vdo.service 0 0\n</code></pre></p>"},{"location":"Linux/Red-Hat/#labs","title":"Labs","text":""},{"location":"Linux/Red-Hat/#ex200","title":"EX200","text":""},{"location":"Linux/Red-Hat/#iam","title":"IAM","text":"<p>We're going to lay the groundwork here and use these local accounts for all the subsequent tasks. You can write a script to do this, or do it by hand, from the data in the input file for the script. The file contents are:</p> <pre><code>manny:1010:dba_admin,dba_managers,dba_staff \nmoe:1011:dba_admin,dba_staff \njack:1012:dba_intern,dba_staff \nmarcia:1013:it_staff,it_managers \njan:1014:dba_admin,dba_staff \ncindy:1015:dba_intern,dba_staff \n</code></pre> <p>Set all user passwords to dbapass.  Also, change the users' PRIMARY groups' GID to match their UID.  Don't forget to check their home directories to make sure permisisons are correct!</p> <p>Enable the following command aliases:</p> <ul> <li>SOFTWARE</li> <li>SERVICES</li> <li>PROCESSES</li> </ul> <p>Add a new command alias named MESSAGES: <pre><code>/bin/tail -f /var/log/messages\n</code></pre> Enable superuser privilages for the following local groups:</p> <ul> <li>dba_managers: everything</li> <li>dba_admin: Command aliases: SOFTWARE, SERVICES, PROCESSES</li> <li>dba_intern: Command alias: MESSAGES</li> </ul>"},{"location":"Linux/Red-Hat/#repos","title":"Repos","text":"<p>You'll need to configure three repositories and install some software:</p> <ul> <li> <p>RHEL 8 BaseOS:</p> <ul> <li>Repository ID: [rhel-8-baseos-rhui-rpms]</li> <li>The mirrorlist is: https://rhui3.REGION.aws.ce.redhat.com/pulp/mirror/content/dist/rhel8/rhui/$releasever/$basearch/baseos/os</li> <li>The GPG key is located at: /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</li> <li>You will need to add SSL configuration:</li> </ul> <pre><code>sslverify=1 sslclientkey=/etc/pki/rhui/content-rhel8.key sslclientcert=/etc/pki/rhui/product/content-rhel8.crt sslcacert=/etc/pki/rhui/cdn.redhat.com-chain.crt </code></pre> </li> <li> <p>RHEL 8 AppStream:</p> <ul> <li>Repository ID: [rhel-8-appstream-rhui-rpms]</li> <li>The mirrorlist is: https://rhui3.REGION.aws.ce.redhat.com/pulp/mirror/content/dist/rhel8/rhui/$releasever/$basearch/appstream/os</li> <li>The GPG key is located at: /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</li> <li>You will need to add SSL configuration:</li> </ul> <pre><code>sslverify=1\nsslclientkey=/etc/pki/rhui/content-rhel8.key\nsslclientcert=/etc/pki/rhui/product/content-rhel8.crt\nsslcacert=/etc/pki/rhui/cdn.redhat.com-chain.crt\n</code></pre> </li> <li> <p>EPEL:</p> <ul> <li>Repository ID: [epel]</li> <li>The baseurl is: https://download.fedoraproject.org/pub/epel/$releasever/Everything/$basearch</li> </ul> </li> </ul> <p>Configure the repositories on the first server, then make an archive of the files, securely copy them to the second server, then unarchive the repository files on the second server.</p> <ul> <li>Install the default AppStream stream/profile for container-tools</li> <li>Install the youtube-dl package (from EPEL)</li> <li>Check for system updates, but don't install them</li> </ul>"},{"location":"Linux/Red-Hat/#networking","title":"Networking","text":"<p>On the first server, configure the second interface's IPv4/IPv6 addresses using nmtui.</p> <ul> <li>IPv4: 10.0.1.20/24</li> <li>IPv6: 2002:0a00:0114::/64</li> <li>Manual, not Automatic (DHCP) for both interfaces</li> <li>Only IP addresses, no other fields</li> <li>Configure only, do not activate</li> </ul>"},{"location":"Linux/Red-Hat/#logging","title":"Logging","text":"By default, the systemd journal logs to memory in RHEL 8, in the location /run/log/journal. While this works fine, we'd like to make our journals persistent across reboots. Configure the systemd journal logs to be persistent on both servers, logging to /var/log/journal."},{"location":"Linux/Red-Hat/#scheduling","title":"Scheduling","text":"<p>Create one at task and one cron job on the first server:</p> <ul> <li>The at job will create a file containing the string \"The at job ran\" in the file named /web/html/at.html, two minutes from the time you schedule it.</li> <li>The cron job will append to the /web/html/cron.html file every minute, echoing the date to the file.</li> </ul> <p>These files will be available via the web server on the first server after the \"Troubleshoot SELinux issues\" objective is completed.</p>"},{"location":"Linux/Red-Hat/#chrony","title":"Chrony","text":"<p>Time sync is not working on either of our servers. We need to fix that.</p> <p>Configure chrony to use the following server: <pre><code>server 169.254.169.123 iburst \n</code></pre> Make sure your work is persistent and check your work!</p>"},{"location":"Linux/Red-Hat/#grub","title":"GRUB","text":"<p>On server1, make the following changes:</p> <ul> <li>Increase the timeout using <code>GRUB_TIMEOUT=10</code></li> <li>Add the following line: <code>GRUB_TIMEOUT_STYLE=hidden</code></li> <li>Add quiet to the end of the <code>GRUB_CMDLINE_LINUX</code> line</li> </ul> <p>Validate the changes in /boot/grub2/grub.cfg. Do not reboot the server.</p>"},{"location":"Linux/Red-Hat/#storage_1","title":"Storage","text":"<p>On the second server:</p> <ul> <li> <p>Create a VDO device with the first unused 5GB device.</p> <ul> <li>Name: web_storage</li> <li>Logical Size: 10GB</li> </ul> </li> <li> <p>Use the VDO device as an LVM physical volume. Create the following:</p> </li> <li> <p>Volume Group: web_vg</p> <ul> <li> <p>Three 2G Logical Volumes with xfs file systems, mounted persistently at /mnt/web_storage_{dev,qa,prod}q:</p> <ul> <li>web_storage_dev</li> <li>web_storage_qa</li> <li>web_storage_prod</li> </ul> </li> </ul> </li> </ul> <p>We need to increase the swap on the second server. We're going to use half of our first unused 2G disk for this additional swap space. Configure the swap space non-destructively and persistently.</p> <p>On the second server, using the second 2G disk, create the following:</p> <ul> <li>Stratis pool: appteam</li> <li>Stratis file system, mounted persistently at /mnt/app_storage: appfs1</li> </ul>"},{"location":"Linux/Red-Hat/#shares","title":"Shares","text":"<p>Configure autofs on the first server to mount the user home directories on the second server at /export/home.</p> <ul> <li>On the second server, configure a NFS server with the following export:</li> </ul> <pre><code>/home &lt;first_server_private_IP&gt;(rw,sync,no_root_squash)\n</code></pre> <ul> <li>On the first server, configure autofs to mount the exported /home directory on the second server at /export/home. Change the home directories for our six users (manny|moe|jack|marcia|jan|cindy) to be <code>/export/home/&lt;user&gt;</code> and test.</li> </ul> <p>On the second server, create a directory at /home/dba_docs with:</p> <ul> <li>Group ownership: dba_staff</li> <li>Permissions: 770, SGID and sticky bits set</li> </ul> <p>Create a link in each shared user's home directory to this directory, for easy access.</p> <p>Set the following ACLs:</p> <ul> <li>Read-only for jack and cindy</li> <li>Full permissions for marcia</li> </ul>"},{"location":"Linux/Red-Hat/#container-as-service","title":"Container as service","text":"<p>As the cloud_user user on the first server, create a persistent systemd container with the following:</p> <ul> <li>Image: registry.access.redhat.com/rhscl/httpd-24-rhel7</li> <li>Port mappings: 8080 on the container to 8000 on the host</li> <li>Persistent storage at ~/web_data, mounted at /var/www/html in the container</li> <li>Container name: web_server</li> </ul>"},{"location":"Linux/Red-Hat/#selinux","title":"SELinux","text":"The Apache web server on the first server won't start! Investigate this issue, and correct any other SELinux issues related to httpd that you may find."},{"location":"Linux/Red-Hat/#firewall","title":"Firewall","text":"<p>Make sure the firewall is installed, enabled and started on both servers. Configure the following services/ports:</p> <ul> <li> <p>Server 1:</p> <ul> <li>ssh</li> <li>http</li> <li>Port 85 (tcp)</li> <li>Port 8000 (tcp)</li> </ul> </li> <li> <p>Server 2:</p> <ul> <li>ssh</li> <li>nfs</li> <li>nfs3</li> <li>rpc-bind</li> <li>mountd</li> </ul> </li> </ul>"},{"location":"Linux/Red-Hat/#commands","title":"Commands","text":""},{"location":"Linux/Red-Hat/#dnf","title":"dnf","text":"<p>View history of dnf commands <pre><code>dnf history\ndnf history userinstalled # View all packages installed by user\n</code></pre></p> <p>Package groups can be specified using the group command or by prefixing the package group name with <code>@</code></p> <pre><code>dnf info @virtualization # dnf group info virtualization\ndnf install @virtualization # dnf group install virtualization\ndnf install --with-optional @virtualization # Include optional packages\n</code></pre> <p>Remove the configuration backend supporting the use of legacy ifcfg files in NetworkManager. <pre><code>dnf remove NetworkManager-initscripts-ifcfg-rh\n</code></pre></p> <p>Modules are special package groups representing an application, runtime, or a set of tools.  The Node.js module allows you to select several streams corresponding to major versions. <pre><code>dnf module install nodejs:12\n</code></pre></p> <p>Global dnf configuration is stored in either /etc/yum.conf or /etc/dnf.conf.</p> <pre><code>[main]\n; Exclude packages from updates permanently\nexclude=kernel* php*\n; Suppress confirmation\nassumeyes=True\n</code></pre> <p>The configuration can be dumped from the command-line (as root) <pre><code>dnf config-manager --dump\n</code></pre></p>"},{"location":"Linux/Red-Hat/#repos_1","title":"Repos","text":"<p>Repositories are INI files placed in  /etc/yum.repos.d/, but they can also be displayed and manipulated from the command-line.</p> Repositories<pre><code># Display repos\ndnf repolist # -v\n\n# Display enabled repos\ndnf repolist --enabled\n\n# Display a single repo\ndnf repoinfo docker-ce-stable\n\n# Add repo\ndnf config-manager --add-repo $REPO-URL\n\n# Disable repo\ndnf config-manager --set-disabled $REPO-NAME\n</code></pre> Example repos<pre><code>[docker-ce-stable]\nname=Docker CE Stable - $basearch\nbaseurl=https://download.docker.com/linux/fedora/$releasever/$basearch/stable\nenabled=1\ngpgcheck=1\ngpgkey=https://download.docker.com/linux/fedora/gp\n\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\n\n[google-cloud-sdk]\nname=Google Cloud SDK\nbaseurl=https://packages.cloud.google.com/yum/repos/cloud-sdk-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=0\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\n</code></pre> <p>Modules are collections of packages that are installed together. They often also have profiles available, which are variants of the module: i.e. client, server, common, devel, etc. <pre><code>dnf module list php\ndnf module install php:7.4/devel\ndnf module reset php\n</code></pre></p>"},{"location":"Linux/Red-Hat/#firewall-cmd","title":"firewall-cmd","text":"<p>Frontend to Netfilter in Red Hat distributions.</p> <pre><code>firewall-cmd --state # \"running\"\n</code></pre> <p>Firewalld has a runtime configuration and a saved, persistent configuration. Only the runtime configuration will be consulted for any command, unless the persistent configuration is specified with --permanent.</p> <p>The runtime configuration can be saved with this command, which obviates the need to execute every change twice. <pre><code>firewall-cmd --runtime-to-permanent\n</code></pre></p> <p>Alternatively, the persistent configuration can be loaded into memory: <pre><code>firewall-cmd --reload\n</code></pre></p> Display firewall rules<pre><code>firewall-cmd --list-all --permanent\n</code></pre> <p>Firewalld uses zones to define the level of trust for network connections. A connection can only be part of one zone, but a zone can be used for many network connections. Builtin zones have XML-format configs found in /usr/lib/firewalld/zones. <pre><code>firewall-cmd --get-active-zones     # Display active zones along with interfaces\nfirewall-cmd --info-zone=public     # Inspect zone\nfirewall-cmd --new-zone=testlab     # Create new zone\n</code></pre></p> <p>Firewalld rules are generally managed through builtin services. These bundle network settings together for well-known applications like SSH, etc. Builtin services are also XML-format configs found in /usr/lib/firewalld/services.</p> Services<pre><code>firewall-cmd --list-services\nfirewall-cmd --add-service=http\nfirewall-cmd --remove-service=http\n</code></pre> <p>Firewalld's config file is at /etc/firewalld/firewalld.conf /etc/firewalld/firewalld.conf<pre><code>AllowZoneDrifting=no\n</code></pre></p> <p>Since RHEL 8, firewalld's backend has been changed to nftables. /etc/firewalld/firewalld.conf<pre><code>FirewallBackend=nftables\n</code></pre></p>"},{"location":"Linux/Red-Hat/#httpd","title":"httpd","text":"<p>The Apache web server daemon is named httpd in RHEL and other RPM-based distributions. HTML content is served from /var/www/html by default, but this can be changed by modifying the DocumentRoot directive in the Apache config located at /etc/httpd/conf/httpd.conf.</p> /etc/httpd/conf/httpd.conf<pre><code>DocumentRoot \"/web\"\n# ...\n&lt;Directory \"/web\"&gt;\n</code></pre> <p>Containers must mount content to /usr/local/apache2/htdocs.</p> <p>Users can also serve files from their home directories, by default from a directory named public_html.</p>"},{"location":"Linux/Red-Hat/#podman","title":"podman","text":"<p>On RHEL, podman can be installed as a package or as part of a module <pre><code>dnf module install container-tools\n</code></pre></p> <p>With few exceptions, podman exposes a command-line API that closely imitates that of Docker.</p> Arch Linux <p>On Arch, /etc/subuid and /etc/subgid have to be set. These are colon-delimited files that define the ranges for namespaced UIDs and GIDs to be used by each user.  Conventionally, these ranges begin at 100,000 (for the first, primary user) and contain 65,536 possible values. <pre><code>terry:100000:65536\nalice:165536:65536\n</code></pre></p> <p>Then podman has to be migrated <pre><code>podman system migrate\n</code></pre></p> <p>Podman supports pulling from various repos using aliases that are defined in /etc/containers/registries.conf.d. RHEL and derivative distributions support additional aliases, some of which reference images that require a login.</p> <p>For example, Red Hat offers a Python 2.7 runtime from the RHSCL (Red Hat Software Collections) repository on registry.access.redhat.com, which does not require authentication. However, Python 3.8 is only available from registry.redhat.io, which does. Interestingly, other Python runtimes are available from the ubi7 and ubi8 repos from unauthenticated registries.</p> <p>Container images are stored in ~/.local/share/containers/storage. <pre><code>podman pull rhscl/httpd-24-rhel7 # (1)\n</code></pre></p> <ol> <li>Alias to registry.access.redhat.com/rhscl/httpd-24-rhel7</li> </ol> <p>The Z option is necessary on SELinux systems (like RHEL and derivatives) and tells Podman to label the content with a private unshared label. On systems running SELinux, rootless containers must be explicitly allowed to access bind mounts. Containerized processes are not allowed to access files without a SELinux label. <pre><code>podman run -d -v=/home/jasper/notes/site:/usr/share/nginx/html:Z -p=8080:80 --name=notes nginx\npodman run -d -v=/home/jasper/notes/site:/usr/local/apache2/htdocs:Z -p=8080:80 --name=notes httpd-24\n</code></pre></p> <p>Mapped ports can be displayed <pre><code>podman port -a\n</code></pre></p> <p>Output a SystemD service file from a container to STDOUT (this must be redirected to a file) <pre><code>podman generate systemd notes \\\n--restart-policy=always   \\\n--name                    \\ # (3)\n--files                   \\ # (2)\n--new                     \\ # (1)\n</code></pre></p> <ol> <li>Yield unit files that do not expect containers and pods to exist but rather create them based on their configuration files.</li> <li>Generate a file with a name beginning with the prefix (which can be set with --container-prefix or --pod-prefix) and followed by the ID or name (if --name is also specified)</li> <li>In conjunction with --files, name the service file after the container and not the ID number.</li> </ol>"},{"location":"Linux/Red-Hat/#rpm","title":"rpm","text":"<p>Query repos for information on a package <pre><code>rpm -qi $PACKAGE # --query --info\n</code></pre></p> <p>Upgrade or install a package, with progress bars <pre><code>rpm -Uvh $PACKAGE # --upgrade --verbose --hash\n</code></pre></p> <p>Display version of Fedora <pre><code>rpm -E %fedora\n</code></pre></p> <p>Import a keyring <pre><code>rpm --import \"https://build.opensuse.org/projects/home:manuelschneid3r/public_key\"\n</code></pre></p>"},{"location":"Linux/Red-Hat/#rpmkeys","title":"rpmkeys","text":"<p>Manage RPM keyrings</p> <p>Import a keyring <pre><code>rpmkeys --import $PUBKEY\n</code></pre></p>"},{"location":"Linux/Red-Hat/#vdo_1","title":"vdo","text":"<p>Manage kernel VDO devices and related configuration information.</p> <pre><code>vdo create --name=storage --device=/dev/xvdb --vdoLogicalSize=10G\n</code></pre>"},{"location":"Linux/Red-Hat/#vdostats","title":"vdostats","text":"<p>Display configuration and statistics of VDO volumes</p> <pre><code>vdostats --human-readable\n</code></pre>"},{"location":"Linux/Red-Hat/#glossary","title":"Glossary","text":""},{"location":"Linux/Red-Hat/#centos","title":"CentOS","text":"<p>A community distribution of Linux that was created by Gregory Kurtzer in 2004 and acquired by Red Hat in 2014. </p> <p>It has traditionally been considered downstream to RHEL, incorporating changes to RHEL after a delay of several months.  In fact, it is a rebuild of the publicly available source RPMs (SRPMs) of RHEL packages, which historically allowed CentOS maintainers to simply package and ship them rebranded.</p> <p>For years, CentOS was the distribution of choice for experienced Linux administrators who did not feel the need to pay for Red Hat's support. In December 2020, Red Hat announced that CentOS 8 support will end at the end of 2021 (rather than 2029), while CentOS 7 will continue to be supported until 2024.  This represented a shift in focus from CentOS Linux to CentOS Stream and a change from a fixed-release (or \"stable point release\") to a rolling-release distribution model.</p> <p>CentOS Stream was announced in September 2019 as a distribution of CentOS maintained on a model previously misidentified as rolling-release but now described as \"continuously delivered\", organized into Streams.  CentOS Stream originated  in an effort to get more community participation in development of RHEL, rather than merely passive consumption.</p>"},{"location":"Linux/Red-Hat/#fedora","title":"Fedora","text":"<p>Fedora is a community distribution supported by Red Hat launched as \"Fedora Core\" in 2003.  It has traditionally been considered upstream to RHEL, serving as a testing ground for new features and improvements.</p> <p>Fedora CoreOS is a Fedora edition built specifically for running containerized workloads securely and at scale.  Because containers can be deployed across many nodes for redundancy, the system can be updated and rebooted automatically without affecting uptime. CoreOS systems are meant to be immutable infrastructure, meaning they are only configured through the provisioning process and not modified in-place.  All systems start with a generic OS image, but on first boot it uses a system called Ignition to read an Ignition config (which is converted from a Fedora CoreOS Config file) from the cloud or a remote URL, by which it provisions itself, creating disk partitions, file systems, users, etc.</p>"},{"location":"Linux/Ricing/","title":"Tiling window managers","text":"<ul> <li>i3 is perhaps the most popular tiling window manager, typically used with polybar.</li> <li>awesome is written and configured in Lua. It originated as a fork of dwm, it offers creature comforts that make it the easiest for neophytes to tiling window managers.</li> <li>bspwm (\"Binary Space Partitioning Window Manager\") uses tree partitioning as the logic for organizing tiles, with the default being the \"dwindle\" pattern.  Notably, it uses two config files: <ul> <li>.bspwmrc which determines what programs to autoload but doesn't contain any key bindings</li> <li>.sxhkdrc which uses a syntax similar to i3 or herbstluft.</li> </ul> </li> <li>dwm: One of the oldest and lightest tiling window managers.  Because Suckless wants the source code not to exceed 2,000 lines of code, a lot of functionality is incorporated by means of patches, which modify the source code using diff files. </li> <li>herbstluft has a single pool of workspaces that is shared across all monitors.</li> <li>xmonad is written and configured in Haskell, making it challenging to configure.</li> </ul> <p>All window managers place an INI-format .desktop file in /usr/share/xsessions/. xmonad.desktop<pre><code>[Desktop Entry]\nName=xmonad\nComment=Tiling window manager\nExec=xmonad-start\nTerminal=false\n\n[Window Manager]\nSessionManaged=true\n</code></pre></p>"},{"location":"Linux/Ricing/#xmonad","title":"Xmonad","text":"Install<pre><code>dnf install xmonad \\\nxterm dmenu # (1)\n</code></pre> <ol> <li>At the recommendation of DistroTube.</li> </ol> <p>Default keybindings which must be known by the neophyte:</p> Default keybinding Description ++Alt+Shift+Enter++ Terminal ++Alt+Shift+C++ Close pane <p>The config is typically placed in $XDG_CONFIG_HOME/xmonad/ (resolving to ~/.config/xmonad/), although other locations are possible. A good default config is available here.</p> <p>Change Mod key to Super <pre><code>myModMask = mod4Mask\n</code></pre></p>"},{"location":"Linux/Security/","title":"Security","text":""},{"location":"Linux/Security/#gpg","title":"GPG","text":"<p>GPG keys are used to sign packages and repos. For example, yum repos and apt incorporate APIs and handle GPG keys.</p> <p>The KWallet Manager and GNOME Keyring (Seahorse) applications can also be used to manage GPG keys.</p>"},{"location":"Linux/Security/#pam","title":"PAM","text":"<p>Pluggable authentication modules form an authentication framework that can be used by \"PAM-aware applications\". These applications have config files that are found in /etc/pam.d The various pam modules have man pages prefixed with pam_, i.e. \"pam_wheel\" etc.</p>"},{"location":"Linux/Security/#commands","title":"Commands","text":""},{"location":"Linux/Security/#gpg_1","title":"gpg","text":"<p>Generate a public and private (\"secret\") key pair (\"keyring\") after displaying interactive prompts to the user, who must enter real name and email address and specify variables like key length, encryption algorithm etc. <pre><code>gpg --full-generate-key\ngpg --generate-key # (1)\n</code></pre></p> <ol> <li>Generate a new keyring using current default parameters.</li> </ol> <p>The rngd daemon found in the rng-tools package can be enabled for additional entropy if needed by the system. <pre><code>pacman -S community/rng-tools\n</code></pre></p> <p>The generates a public and private key in ~/.gnupg. The public key, which can be distributed publicly so that people can encrypt messages to the user, is named pubring.kbx More than one master keypair can be generated in this manner, even for the same email address.</p> <p>Decrypt file <pre><code>gpg file.txt\n</code></pre></p> <p>Export GPG public key <pre><code>gpg --export --output ~/jdoe.pub\n</code></pre></p> <p>Import another person's public key <pre><code>gpg --import jdoe.pub\n</code></pre></p> <p>List available GPG keys <pre><code>gpg --list-key\n</code></pre></p> <p>Encrypt a file <pre><code>gpg --encrypt -r jdoe@dplaptop.lab.itpro.tv $FILE\n</code></pre></p> <p>Sign $FILE without encrypting it (produces file.asc) <pre><code>gpg --clearsign $FILE\n</code></pre></p> <p>Import another person's public key <pre><code>gpg --import ~/jdoe.pub\n</code></pre></p> <p>Send keys to $SERVER <pre><code>gpg --send-keys keyIDs --keyserver $SERVER\n</code></pre></p>"},{"location":"Linux/Security/#pass","title":"pass","text":"<p>The standard unix password manager, backed by GPG, is a command-line password manager and MFA program.</p> <p>The first step in using pass is generating a new key pair. </p> <p>Generate a public and private (\"secret\") key pair (\"keyring\") after displaying interactive prompts to the user, who must enter real name and email address and specify variables like key length, encryption algorithm etc. <pre><code>gpg --full-generate-key\ngpg --generate-key # (1)\n</code></pre></p> <ol> <li>Generate a new keyring using current default parameters.</li> </ol> <p>The rngd daemon found in the rng-tools package can be enabled for additional entropy if needed by the system. <pre><code>pacman -S community/rng-tools\n</code></pre></p> <p>The generates a public and private key in ~/.gnupg. The public key, which can be distributed publicly so that people can encrypt messages to the user, is named pubring.kbx More than one master keypair can be generated in this manner, even for the same email address.</p> Display public keys<pre><code>gpg -k # --list-keys\n</code></pre> <p>Unwanted keys can be deleted by specifying the public key: <pre><code>gpg --delete-secret-and-public-keys \u2592\u2592\u2593\u2591\u2591\u2592\u2593\u2591\u2593\u2591\u2593\u2591\u2593\u2592\u2591\u2591\u2592\u2592\u2591\u2591\u2591\u2592\u2593\u2591\u2592\u2591\u2592\u2591\u2593\u2591\u2592\u2592\u2592\u2593\u2592\u2592\u2593\u2591\u2593\u2592\u2591\n</code></pre></p> <p>Now a password store can be initialized by providing that same email address. This email is stored at ~/.password-store/.gpg-id <pre><code>pass init email@example.com\n</code></pre></p> Add password<pre><code>pass add email\n</code></pre> <p>This produces a binary, encrypted file at ~/.password-store/email.gpg. The password can be retrieved, after authenticating with the master password, with the following: <pre><code>pass email # (1)\n</code></pre></p> <ol> <li>In fact, because this is simply a GPG encrypted file, GPG could be used equivalently. In fact, this appears to be the command executed by the pass shell script. <pre><code>gpg -dq ~/.password-store/email.gpg\n</code></pre></li> </ol> Display names of passwords<pre><code>pass ls # (1)\n</code></pre> <ol> <li>This command is equivalent to using tree on the password store directory. <pre><code>tree ~/.password-store\n</code></pre></li> </ol> <p>Pass can also handle OTP generation for MFA, as long as you can retrieve the OTP URI (beginning with otpauth://).  QR code images can be deciphered with zbarimg to retrieve these URIs. <pre><code>pass otp add mimecast # (1)\n</code></pre></p> <ol> <li>Note that otpauth URLs usually contain an embedded email address, which must match that of the intialized password store. If this identity does not match, an error that read \"There is no assurance this key belongs to the named user\" is produced .</li> </ol> Resources <p>Luke Smith video</p>"},{"location":"Linux/Shell/","title":"Shells","text":""},{"location":"Linux/Shell/#fish","title":"fish","text":"<p>Fish switch statements look completely different from bash case statements, with an incompatible syntax.</p> Conditionally setting $PATH:<pre><code>switch \"$PATH\" # (1)\ncase \"*$HOME/.cargo/bin*\" # (2)\necho '$PATH already contains $HOME/.cargo/bin' # (3)\ncase '*'\nset --global PATH $HOME/.cargo/bin $PATH # (4)\nend # (5)\n</code></pre> <ol> <li>Because the $PATH is rendered as a list delimited by whitespace, without quotes this statement will be expanded to many arguments and will produce an error.</li> <li>Double quotes must be used, because with single quotes fish will not expand the $HOME variable.</li> <li>I have not found an empty placeholder similar to <code>pass</code> in Python which could simply occupy space here.  Without a statement, fish appears to execute the following block by default.</li> <li>Environment variables use the set keyword. The --universal option, which would otherwise make sense here, does not work because $PATH is a global variable. Note that there is no equal sign, only a space separating the variable identifier and value.</li> <li>Bash equivalent<pre><code>case \":${PATH}:\" in\n*:\"$HOME/.cargo/bin\":*)\n;;\n*)\nexport PATH=\"$HOME/.cargo/bin:$PATH\"\n;;\nesac\n</code></pre></li> </ol> Setting environment variables<pre><code>set -x EDITOR /usr/bin/vim # (1)\n</code></pre> <ol> <li>Without -x this variable will not be visible to applications. Bash equivalent<pre><code>export EDITOR=/usr/bin/vim\n</code></pre></li> </ol> <p>Fish for-in loops are concluded with end. Set metadata in a loop<pre><code>for i in $(exa Godfrey*)\necho Processing $i\nset title $(string replace -r \"\\(.*mp3$\" \"\" $i) # (1)\nffmpeg -i $i -metadata title=\"$title\" -metadata album=\"Godfrey\" -metadata artist=\"Vlad TV\" -codec copy output/$i\nend\n</code></pre></p> <ol> <li>string replace is used here to remove the ending of a filename, including extension.</li> </ol>"},{"location":"Linux/Shell/#bash","title":"bash","text":"<p>The systemwide config for bash is at /etc/profile.</p> <p>Command-line arguments are available as the positional arguments <code>$1</code>, <code>$2</code>, etc. with the script itself being <code>$0</code>. Handling command-line arguments is conventionally done with the shift command in a <code>while</code> loop.</p> Conditionally setting $PATH<pre><code>case \":${PATH}:\" in\n*:\"$HOME/.cargo/bin\":*)\n;;\n*)\nexport PATH=\"$HOME/.cargo/bin:$PATH\"\n;;\nesac\n</code></pre> <p>The shopt internal command is used to set (-s) or unset (-u) various shell settings.</p> Disable case sensitivity<pre><code>shopt -s nocasematch\n</code></pre> Tag audio with metadata<pre><code>#!/bin/bash\ntag () {\nTAG=$1 ; shift # First arg has to be a valid tag name.\nshopt -s nocasematch\n    case $TAG in\n\"amapiano\")\nwhile [ $# -gt 0 ]\ndo\nINPUTFILE=\"$1\"\nffmpeg -i \"$INPUTFILE\" -metadata genre=Amapiano -c copy \"${INPUTFILE/./_tagged.}\"\nshift\ndone\n;;\n*)\necho \"Invalid tag!\"\n;;\nesac\nshopt -u nocasematch\n}\n</code></pre> <p>A more useful and less brittle version of this script may be possible using the getopts function to define a named parameter, rather than forcing the first positional argument to be one of a number of set values.</p>"},{"location":"Linux/Storage/","title":"Storage","text":"Resources <p>Unlike ZFS which has a lot of material in written and video form for potential users to learn from, BtrFS appears not to have much available. BtrFS does have an official wiki, but written articles on FOSS blogs focus on operation from the command-line but don't do a good job of describing the taxonomy of concepts, aside from the glossary.</p> <p>Users of ZFS, in contrast, have taken the trouble to create introductory material, including Ars Technica's ZFS 101 article, and many talks by enthusiasts like Philip Paeps.</p> <p>This might be because btrfs's concepts seem less well thought-out, or at least more poorly described. For example, the term subvolume is used in btrfs but the container for subvolumes is not \"volume\" but rather \"top-level subvolume\".</p> <p>Jim Salter from Ars Technica (who wrote the ZFS 101 article above) appears to have devoted some effort to fleshing out the topic:</p> <ul> <li> <p>Examining btrfs, Linux's perpetually half-finished filesystem</p> </li> <li> <p>Install and configure Samba server</p> </li> <li>Install Samba4 on RHEL 8 for File Sharing on Windows</li> <li>FreeNAS 11.3 - How to Set Up Windows SMB Shares</li> <li>BtrFS</li> <li>Creating and Destroying ZFS Storage Pools</li> <li>Managing devices in ZFS storage pools</li> <li>Getting started with btrfs for Linux</li> <li>Understanding Linux filesystems: ext4 and beyond</li> </ul>"},{"location":"Linux/Storage/#tasks","title":"Tasks","text":""},{"location":"Linux/Storage/#create-virtual-disks","title":"Create virtual disks","text":"<pre><code>fallocate -l 100M /tmp/disk0    # Create sparse file\nlosetup -f /tmp/disk0           # Create loopback device\n</code></pre>"},{"location":"Linux/Storage/#formatting-filesystems","title":"Formatting filesystems","text":"<pre><code>mkfs.ext4 /dev/sda1\nmkfs.xfs /dev/sda2\n</code></pre> <p>Check filesystems <pre><code>fsck.ext4 /dev/sda1\nxfs_repair /dev/sda2\n</code></pre></p>"},{"location":"Linux/Storage/#hdd-serial-numbers","title":"HDD serial numbers","text":"Produce a CSV of hard disk identifiers and their serial numbers using hdparm, grep, cut, and output redirection. <pre><code>for l in {a..w} do echo -n \"/dev/sd$l,\" &gt;&gt; drives\n    hdparm -I /dev/sd$l | grep 'Serial Number' - |\ncut -d : -f 2 | tr -d '[:space:]' &gt;&gt; drives\n    echo '' &gt;&gt; drives;\ndone\n</code></pre>"},{"location":"Linux/Storage/#samba_1","title":"Samba","text":"<p>Configure Samba  <pre><code>mkdir /samba                   # Create a directory for the share\nchmod -R 0777 /samba\nchown -R nobody:nobody /samba  # Remove ownership, not necessary\n</code></pre></p> <p>Open firewall rule (not strictly necessary) <pre><code>firewall-cmd --permanent --add-service=samba\nfirewall-cmd --reload\nfirewall-cmd --list-services # verify\n</code></pre></p> <p>Configure the main Samba config file at /etc/samba/smb.conf. The name in brackets becomes the name of the share. <pre><code>[samba]\ncomment = Samba on Ubuntu\npath = /samba\nread only = no\nbrowsable = yes\n</code></pre></p> <p>Verify configuration <pre><code>testparm\n</code></pre></p> <p>Set SELinux context of share directory <pre><code>semanage fcontext -a -t samba_share_t '/samba(/.*)?'\nrestorecon -vvFR /samba\n</code></pre></p> <p>&lt;!-- Allow SELinux to work with Samba <pre><code>setsebool -P samba_export_all_ro on\n</code></pre></p> <p>Set up a Samba account for <code>$USER</code> <pre><code>smbpasswd -a $USER\n</code></pre></p> <p>Restart Samba service <pre><code>systemctl restart smbd\n</code></pre> --&gt;</p> <p>Browse all available shares <pre><code>smbclient -L $HOST\n</code></pre></p> <p>Access samba share at <code>$SHARE</code> at server <code>$HOST</code> using user credential <code>$USER</code> <pre><code>smbclient //$HOST/$USER -U $USER # (1)\n</code></pre></p> <ol> <li>This will display the Samba CLI <pre><code>smb: \\&gt;\n</code></pre></li> </ol> <p>On TrueNAS, the option to \"Allow Guest Access\" should be turned on, unless password-based authentication for specific users is desired. Also, the directory must have write permissions enabled to allow uploading. <pre><code>chmod o+w\n</code></pre> Bizarrely, the ability to navigate into subdirectories appears to depend on the owner execute bit. This may have something to do with anonymous guest access. <pre><code>chmod u+x\n</code></pre></p> <p>Permanently mounting a Samba share in /etc/fstab <pre><code>//nas/Videos /home/jasper/Videos cifs guest,uid=1000,iocharset=utf8 0 0\n</code></pre> Then mount the fstab file <pre><code>mount -a\n</code></pre></p>"},{"location":"Linux/Storage/#nfs","title":"NFS","text":"<p>NFS is a distributed filesystem based on the RPC protocol that provides transparent access to remote disks.</p> <p>Modern NFS deployments in the wild are usually versions 3 or 4:</p> <ul> <li>V4 has superior performance, requires only the additional rpc.mountd service, and TCP port 2049 to be open</li> <li>V3 requires additional services (rpcbind, lockd, rpc.statd) and many firewall ports</li> </ul> <p>NFS shares are enabled using the /etc/exports file. /etc/exports<pre><code>/export/web_data1 *(ro,sync)\n/export/web_data2 127.0.0.1(rw,sync,no_root_squash)\n</code></pre></p> <p>Once exports are defined, the NFS server can be started <pre><code>systemctl enable --now nfs-server.service\n</code></pre></p> <p>Exports on localhost can be displayed using showmount <pre><code>showmount -e\n</code></pre></p> <p>Shares can be mounted in /etc/fstab using the following syntax: <pre><code>127.0.0.1:/export/web_data1 /mnt/nfs_web_data1 nfs defaults,_netdev 0 0\n127.0.0.1:/export/web_data2 /mnt/nfs_web_data2 nfs defaults,_netdev 0 0\n</code></pre></p> <p>Better still is using autofs.</p> Resources <ul> <li> How to Share Files Using NFS: Linux Server Training 101</li> </ul>"},{"location":"Linux/Storage/#autofs","title":"autofs","text":"<p>Auto File System offers an alternative way of mounting NFS shares that can save some system resources, especially when many shares are mounted. Autofs can mount NFS shares dynamically, only when accessed. <pre><code>dnf install -y autofs\nsystemctl enable --now autofs.service\n</code></pre></p> <p>Mounts are defined in configs called maps. There are three map types:</p> <ul> <li>master map is /etc/auto.master by default</li> <li>direct maps point to other files for mount details. They are notable for beginning with /-</li> <li>indirect maps also point to other files for mount details but provide an umbrella mount point which will contain all other mounts within it. Note that other mountpoints at this parent directory cannot coexist with autofs mounts.</li> </ul> <p>Here is an example indirect map that will mount to /data/sales. /etc/auto.master.d/data.autofs<pre><code>/data /etc/auto.data\n</code></pre> /etc/auto.data<pre><code>sales -rw,soft 192.168.33.101:/data/sales\n</code></pre></p> <p>Map files also support wildcards. <pre><code>* 127.0.0.1:/home/&amp;\n</code></pre></p> <p>AutoFS's config is at /etc/autofs.conf. One important directive is master_map_name which defines the master map file.</p>"},{"location":"Linux/Storage/#lvm-volume","title":"LVM volume","text":"<pre><code>pvcreate /dev/vd{b,c,d}\nvgcreate group /dev/vd{b,c,d}\nlvcreate -l 100%FREE -n volume group\n</code></pre>"},{"location":"Linux/Storage/#vdo","title":"VDO","text":"<p>Virtual disk optimizer (VDO) is a kernel module introduced in RHEL 7.5 that provides data deduplication and compression on block devices.</p> <p>The physical storage of a VDO volume is divided into a number of slabs, which are contiguous regions of the physical space.  All slabs for a given volume have the same size, which can be any power of 2 multiple of 128 MB up to 32 GB (2 GB by default). The maximum number of slabs is 8,192. The maximum physical storage of the VDO is provided to the user on creation.</p> <p>Like LVM volumes, VDO volumes appear under /dev/mapper</p> <p>VDO appears not to be installed by default, but it is available in the BaseOS repo. <pre><code>dnf install vdo\nsystemctl enable --now vdo\n</code></pre></p> Create a VDO volume<pre><code>vdo create --name=web_storage --device=/dev/xvdb --vdoLogicalSize=10G\nvdostats --human-readable\nmkfs.xfs -K /dev/mapper/web_storage\nudevadm settle\n</code></pre> <p>The fstab file requires a variety of options <pre><code>/dev/mapper/web_storage /mnt/web_storage xfs _netdev,x-systemd.device-timeout=0,x-systemd.requires=vdo.service 0 0\n</code></pre></p>"},{"location":"Linux/Storage/#stratis","title":"Stratis","text":"<p>Stratis is an open-source managed pooled storage solution in the vein of ZFS or btrfs.</p> <p>Stratis block devices can be disks, partitions, LUKS-encrypted volumes, LVM logical volumes, or DM multipath devices. Stratis pools are mounted under /stratis and, like other pooled storage systems, support multiple filesystems. Stratis file systems are thinly provisioned and formatted with xfs, although vanilla xfs utilities cannot be used on Stratis file systems.</p> <p><pre><code>dnf -y install stratisd stratis-cli\nsystemctl enable --now stratisd\n</code></pre> Create a pool<pre><code>stratis pool create pool /dev/sda /dev/sdb /dev/sdc # (1)\n</code></pre></p> <ol> <li>An error about the devices being \"owned\" can be resolved by wiping it. <pre><code>wipefs -a /dev/sda\n</code></pre></li> </ol> Display block devices managed by Stratis<pre><code>stratis blockdev # (1)\n</code></pre> <ol> <li>This command is equivalent to pvs in LVM.</li> </ol> Create filesystem<pre><code>stratis fs create pool files\n</code></pre> Confirm<pre><code>stratis fs\n</code></pre> /etc/fstab<pre><code>/stratis/pool/files /mnt/stratisfs xfs defaults,x-systemd.requires=stratisd.service 0 0\n</code></pre> Expand pool<pre><code>stratis pool add-data pool /dev/sdb\n</code></pre> Save snapshot<pre><code>stratis fs snapshot pool files files-snapshot\n</code></pre> Restore from snapshot<pre><code>stratis fs rename files files-orig\nstratis fs rename files-snapshot files\numount /mnt/files; mount /mnt/files\n</code></pre>"},{"location":"Linux/Storage/#zfs-management","title":"ZFS management","text":"<pre><code># Create a storage pool, conventionally named \"tank\" in documentation\nzpool create tank raidz /dev/sd{a,b,c}\n\n# By default, disks are identified by UUID\nzpool status tank\nzpool list\n\n# Display real paths (i.e. block device names)\nzpool status tank -L \nzpool list -v\n\n# Destroy pool\nzpool destroy tank\n</code></pre> Mirrored arrays<pre><code>zpool add tank mirror sde sdf\nzpool detach sdb\n</code></pre> Hot spares<pre><code>zpool add tank spare sdg\nzpool remove tank sdg # (1)\n</code></pre> <ol> <li>The zpool remove command is used to remove hot spares, as well as cache and log devices.</li> </ol> <p>Replacing a used disk with one that is unused uses zpool replace, initiating the resilvering process.</p> <pre><code>zpool replace tank sdb sdc\n</code></pre> <p>Ongoing resilvers can be cancelled using zpool detach: <pre><code>zpool detach tank sdc\n</code></pre></p> <p>If a disk has gone bad, it must first be taken offline (apparently requiring its UUID) before physically replacing it.</p> Replace disk<pre><code>zpool clear tank\nzpool offline $UUID\nzpool replace tank sdb sdc\nwatch zpool status tank\n</code></pre> <p>A dataset in ZFS is equivalent to the btrfs subvolume, defined as an independently mountable POSIX filetree.</p> Create dataset<pre><code>zfs create tank/dataset\nzfs list\nzfs rename tank zpool\nzfs remove zpool/dataset\n</code></pre> Configure dataset<pre><code>zfs set compression=on tank/dataset # Enable compression\nzfs set sync=disabled tank/dataset  # Disable sync\nzfs set acme:disksource=vendorname  # Set tag\n</code></pre> Snapshot management<pre><code>zfs snapshot tank@snapshot1\nzfs rollback tank@snapshot1\nzfs destroy tank@snapshot1\n</code></pre> <p>ZFS datasets are automatically mounted when created, but this behavior can be managed and changed.</p> <pre><code>zfs get mountpoint tank\nzfs set mountpoint=/tank tank\n</code></pre>"},{"location":"Linux/Storage/#glossary","title":"Glossary","text":"ARC ARC serves as ZFS's read cache mechanism and avoids the thrashing possible with standard OS page caches by using a more efficient algorithm."},{"location":"Linux/Storage/#btrfs","title":"btrfs","text":"<p>B-Tree Filesystem \"butter fs\" is an open-source CoW filesystem that offers many of the same features as ZFS. </p> <p>It was founded by Chris Mason in 2007. By 2009, btrfs 1.0 was accepted into the mainline Linux kernel. Btrfs was adopted by SUSE Enterprise Linux, but support was dropped by Red Hat in 2017.</p> <p>A B-tree is a self-balancing tree data structure used by btrfs to organize and store metadata. The superblock holds pointers to the tree roots of the tree of tree roots and the chunk tree.</p> block group In btrfs the fundamental unit of storage allocation consisting of one or more chunks, depending on RAID level, each stored on a different device. boot environment Allow changes to OS installations to be reverted copy-on-write In a CoW filesystem like ZFS and btrfs, when data on the filesystem is modified, that data is copied first before being modified and then written back to a different free location.  The main advantage of this method is that the original data extent is not modified, so the risk of data corruption or partial update due to power failure is eliminated. This ensures that writes are atomic and the filesystem will always be in a consistent state."},{"location":"Linux/Storage/#dataset","title":"dataset","text":"In ZFS, datasets represent mountable filesystems. Improves on the use of traditional use of partitions in, say, Linux installations where mount points are typically separate partitions. Datasets allow quotas and other rules to be enforced. extent In btrfs, an extent is the fundamental storage unit corresponding to a contiguous sequence of bytes on disk that holds file data.  Files can be fragmented into multiple extents, and this fragmentation can be measured using the <code>filefrag</code> CLI utility. Extended File System <p>Ext was first implemented in 1992 by Remy Card to address limitations in the MINIX filesystem, which was used to develop the first Linux kernel.  It could address up to 2GB of storage and handle 255-character filenames and had only one timestap per file.</p> <ul> <li>Ext2 was developed by Remy Card only a year after ext's release as a commercial-grade filesystem, influenced by BSD's Berkeley Fast File System. It was prone to corruption if the system crashed or lost power while data was being written and performance losses due to fragmentation. Nevertheless, it was quickly and widely adopted, and still used as a format for USB drives.</li> <li>Ext3 was adopted by mainline Linux in 2001 and uses journaling, whereby disk writes are stored as transactions in a special allocation, which allows a rebooted system to roll back incomplete transactions.</li> <li>Ext4 was added to mainline Linux in 2008, developed by Theodore Ts'o, and improves upon ext3 but is still reliant on old technology.</li> </ul>"},{"location":"Linux/Storage/#inode","title":"inode","text":"An inode (index node) is a data structure that stores all the metadata about a file but not its name or data. subvolume A tree of files and directories inside a btrfs that can be mounted as if it were an independent filesystem. Each btrfs filesystem has at least one subvolume that contains everything else in the filesystem, called the top-level subvolume. thrashing All OSes implement the page cache using the LRU algorithm, which maintains a queue of the most recently read blocks. As more recent blocks are read, older blocks are evicted from the bottom of the queue even if they are more frequently accessed. This process is referred to as thrashing. RAID hole Condition in which a stripe is only partially written before the system crashes, making the array inconsistent and corrupt after a restart RAIDz RAIDz1, RAIDz2, and RAIDz3 are special varieties of parity RAID in ZFS: the number indicates how many parity blocks are allocated to each data stripe. Resilvering Process of rebuilding redundant groups after disk replacement SMB <p>Server Message Block (SMB) is a client/server protocol developed in the early 1980s by Intel, Microsoft, and IBM that has become the native protocol for file and printer sharing on Windows. It is implemented in the Samba application suite.</p> <p>CIFS (Common Internet File System, pronounced \"sifs\") is a dialect and implementation of SMB whose acronym has survived despite the fact the protocol itself has fallen into disuse.</p>"},{"location":"Linux/Storage/#vdev","title":"vdev","text":"<p>In ZFS a vdev (\"virtual device\") is an abstraction of one or more storage devices and therefore equivalent to a volume group in LVM. A collection of vdevs constitutes a zpool.</p> <p>Vdevs support one of five topologies:</p> <ul> <li>Single-device vdevs cannot survive any failure</li> <li>Mirror vdevs duplicate every block on each of their devices</li> <li>RAIDz1</li> <li>RAIDz2</li> <li>RAIDz3</li> </ul> <p>Special support classes of vdev:</p> <ul> <li><code>CACHE</code></li> <li>LOG (also SLOG), because it usually has faster write performance, provides the pool with a separate vdev to store the ZIL in.</li> <li><code>SPECIAL</code></li> </ul>"},{"location":"Linux/Storage/#volume","title":"volume","text":"A ZFS volume is a dataset that represents a block device. They are created with the -V option and can be found under /dev/zvol. <pre><code>zfs create -V 5gb tank/vol\n</code></pre> A volume can also be shared as an iSCSI target by setting the shareiscsi property on the volume. ZED Daemon that will listen to kernel events related to ZFS, conducting action defined in zedlets. zfs-fuse ZFS filesystem daemon"},{"location":"Linux/Storage/#zfs","title":"ZFS","text":"<p>ZFS is a technology that combines the functions of a 128-bit CoW filesystem, a volume manager, and software RAID.</p> <p>Like RAID, ZFS attempts to achieve data reliability by abstracting volumes over physical devices.  But ZFS improves on RAID with error handling: it can use checksum information to correct corrupted files. This is unlike hardware RAID mirrors, where failures occur silently and are typically only detected upon reading a corrupt file.</p> <p>ZFS writes use CoW meaning they are atomic and aren't affected by issues like RAID holes.</p> <p>ZFS can also transparently compress data written to datasets.</p> <p>ZFS on Linux (ZOL) is considered the ugly stepchild of the ZFS community despite the fact that the Linux implementation has the most features and the most community support. ZFS is too tightly bound to the operation of the kernel to operate in true userspace, and that is why each implementation is different for operating systems.</p> ZIL <p>The ZIL is a special storage area used for synchronous writes.</p> <p>Most writes are asynchronous, where the filesystem is allowed to aggregate and commit them in batches to reduce fragmentation and increase throughput.</p> <p>Synchronous writes in ZFS are committed to the ZIL while also kept in memory. Writes saved to the ZIL are committed to main storage in normal TXGs moments later.</p> <p>Normally, the ZIL is written to and never read from again. Writes saved to ZIL are committed to main storage from RAM in normal TXGs after a few moments and unlinked from the ZIL.</p> <p>The ZIL is only read during pool imports that occur after a crash and restart.</p> <p>The ZIL can be placed on the LOG vdev to take advantage of higher write performance during sync writes.</p> <p>The ZIL is typically mirrored because that is where data can be lost.</p>"},{"location":"Linux/Storage/#zpool","title":"zpool","text":"<p>A zpool is the largest structure in the ZFS taxonomy, representing an independent collection of one or more vdevs. Essentially, a zpool is a JBOD with special characteristics.</p> <p>Writes are distributed across available vdevs in accordance with their available free space, such that they fill more or less evenly.</p> <p>A utilization awareness mechanism built into ZFS also accounts for if one vdev is significantly more busy than another, i.e. reading. In such a case, writes to that busy vdev will be deferred in favor of less busy ones.</p> <p>Zpools are automatically mounted at root upon creation (without the need to edit fstab).</p>"},{"location":"Linux/Storage/#commands","title":"Commands","text":""},{"location":"Linux/Storage/#btrfs_1","title":"btrfs","text":"<p>Show storage consumed, including how much is shared by all snapshots <pre><code>btrfs fi du /home -s\n</code></pre></p> <pre><code>btrfs fi df /home\n</code></pre>"},{"location":"Linux/Storage/#fallocate","title":"fallocate","text":"<p>Create a file of a given size with the <code>--length</code>/<code>-l</code> option</p> 1 gigabyte1 gibibyte <pre><code>fallocate -l 1GB $FILENAME # gigabyte\n</code></pre> <pre><code>fallocate -l 1G $FILENAME  # gibibyte\n</code></pre>"},{"location":"Linux/Storage/#hdparm","title":"hdparm","text":"<pre><code>hdparm -I /dev/sda\n</code></pre>"},{"location":"Linux/Storage/#losetup","title":"losetup","text":"Create a loopback device (i.e. a virtual block device) <pre><code>losetup -f /tmp/file1\n</code></pre>"},{"location":"Linux/Storage/#lsblk","title":"lsblk","text":"Display filesystems<pre><code>lsblk -f # --fs\n</code></pre>"},{"location":"Linux/Storage/#sfdisk","title":"sfdisk","text":"<p>Script-based partition table editor, similar to <code>fdisk</code> and <code>gdisk</code>, which can be run interactively. It does not interface with GPT format, neither is it designed for large partitions. [ref][11]</p> <p>List partitions on all devices</p> <p>Display size of {partition} or {device} This command produces the size of {partition} (i.e. <code>/dev/sda1</code>) or even {device} (<code>/dev/sda</code>) in blocks <pre><code>sfdisk -s partition\nsfdisk -s device\n</code></pre> Apply consistency checks to {partition} or {device} <pre><code>sfdisk -V partition\nsfdisk --verify device\n</code></pre> Create a partition <pre><code>sfdisk device\n</code></pre> Save sectors changed This command will allow recovery using the following command <pre><code>sfdisk /dev/hdd -O hdd-partition-sectors.save\n</code></pre> Recovery Man page indicates this flag is no longer supported, and recommends use of <code>dd</code> instead. <pre><code>sfdisk /dev/hdd -I hdd-partition-sectors.save\n</code></pre></p>"},{"location":"Linux/Storage/#shred","title":"shred","text":"Write random data to an unmounted disk for {n} passes <pre><code>shred --iterations=n\n</code></pre>"},{"location":"Linux/Storage/#lvm","title":"LVM","text":""},{"location":"Linux/Storage/#lvm_1","title":"lvm","text":"<pre><code>lvm version\n</code></pre>"},{"location":"Linux/Storage/#lvresize","title":"lvresize","text":"Resize existent logical volume Marketing in volume group vg1 to have an additional 10 gigabytes of space <pre><code>lvresize -L +10G /dev/vg1/Marketing\n</code></pre>"},{"location":"Linux/Storage/#pvcreate","title":"pvcreate","text":"<pre><code>pvcreate /dev/sd{a,b,c}\n</code></pre>"},{"location":"Linux/Storage/#lvresize_1","title":"lvresize","text":"<p>Resize existent logical volume Marketing in volume group vg1 to have an additional 10 gigabytes of space <pre><code>lvresize -L +10G /dev/vg1/Marketing\n</code></pre></p> <p>It is possible to use LVM to format the storage media when installing CentOS or RHEL on a virtual machine, even if there is only a single disk. This will result in a swap partition being created as a small logical volume. This can be removed: <pre><code>swapoff cs/swap\nlvremove cs/swap\n</code></pre> Then the remaining logical volume mounted to root can be expanded: <pre><code>lvresize -l 100%VG cs/root\n</code></pre></p>"},{"location":"Linux/Storage/#pvcreate_1","title":"pvcreate","text":"<pre><code>pvcreate /dev/loop0\n</code></pre>"},{"location":"Linux/SystemD/","title":"SystemD","text":"<p>SystemD is the de facto Linux init system since replacing Sysvinit and Upstart in all major distributions.  SystemD organizes resources into units, which can be managed by daemons and manipulated by SystemD utilities.</p> <p>It was designed by a pair of Red Hat developers in 2010 to be a general purpose system manager. It offers parallel execution, explicit dependencies between services, an escape from slow shell scripts, and per-daemon resource control and watchdogs.</p>"},{"location":"Linux/SystemD/#tasks","title":"Tasks","text":""},{"location":"Linux/SystemD/#scheduling-services","title":"Scheduling services","text":"<p>Services can be scheduled to start with timers. sshd.timer<pre><code>[Unit]\nDescription=Starts sshd service at beginning of workday, and shuts it down at the end.\n\n[Timer]\nUnit=sshd.service\nOnCalendar=Mon..Fri *-*-* 09:00:00\n\n[Install]\nWantedBy=timers.target\n</code></pre></p> <p>Now, when stopping sshd manually the following output is printed. <pre><code>Warning: Stopping sshd.service, but it can still be activated by:\n  sshd.timer\n</code></pre></p> <p>The service can be scheduled to shutdown within the service file itself using the RuntimeMaxSec directive. sshd.service<pre><code>RuntimeMaxSec=36000 # i.e. 10 hours\n</code></pre></p> <p>This unfortunately will result in the service being reported as failed. This failure can be cleared with this command: <pre><code>systemctl reset-failed\n</code></pre></p>"},{"location":"Linux/SystemD/#masking","title":"Masking","text":"On TrueNAS, the libvirtd socket is masked by default.  This means that virsh is not able to connect to the hypervisor until it is unmasked and the service restarted. <pre><code>systemctl unmask libvirtd.socket\nsystemctl restart libvirtd.service\nvirsh connect qemu:///system\n</code></pre>"},{"location":"Linux/SystemD/#glossary","title":"Glossary","text":""},{"location":"Linux/SystemD/#service-files","title":"Service files","text":"<p>Service files are a type of unit file which have replaced earlier init scripts and describe how to manage a service or application on the server. Active services are placed in /etc/systemd/system, whereas inactive service files distributed with installed packages are placed in /usr/lib/systemd/system.</p> <p>Docker container as a service: <pre><code>[Unit]\nDescription=Notes Container (Docker)\n\n[Service]\nExecStart=/usr/bin/docker start notes\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></p>"},{"location":"Linux/SystemD/#slice","title":"Slice","text":"<p>A slice unit is a unit configuration file ending in \".slice\" which manages resources of a group of processes. SystemD slices implement and build on Linux cgroups.</p> <p>Slices exist in a hierarchy below the root slice (-.slice) and are used to group scopes and services</p> <ul> <li>Scopes contain unrelated processes but not necessarily hierarchically</li> <li>Services are from unit files or Transient Runtime Services and contain processes</li> </ul> <p>Root slices themselves only contain scopes and other slices.</p> <ul> <li> <p>user.slice contains all user-related slices and scopes, named after the pattern user-UID.slice</p> <ul> <li>session.slice is created for every login session</li> </ul> </li> <li> <p>system.slice contain slices, scopes, and services</p> </li> <li> <p>machine.slice contains all container-related slices, scopes, and services.</p> </li> </ul> <p>Services can be assigned to specific slices explicitly by editing the value of the Slice key in the service file. Keys like CPUWeight can assign cgroup resource controls. Other such controls can be viewed in the systemd.resource-control(5) man page. <pre><code>[Unit]\nSlice=user.slice\nCPUWeight=50\n</code></pre></p>"},{"location":"Linux/SystemD/#sysvinit","title":"SysVinit","text":"<p>SysVInit is the oldest init system used in Linux.</p> <p>In SysVinit, which used bash scripts to run and manage servicesj, processes were started serially and synchronously, wasting time and system resources. For years, a common mitigation was to run services in the background, simulating concurrency.</p>"},{"location":"Linux/SystemD/#target-files","title":"Target files","text":"<p>Target files are equivalent to SysVInit runlevels.</p> SystemD target SysVInit runlevel poweroff.target 0 rescue.target 1 multi-user.target 3 graphical.target 5 reboot.target 6 emergency.target emergency"},{"location":"Linux/SystemD/#timers","title":"Timers","text":"<p>Timer files are systemd unit files with names ending in .timer that control service files. For each timer file, a matching unit file must exist describing the unit to activate when the timer elapses. By default, systemd will search for a service file with a filename matching that of the timer, but failing that a specific unit can be specified with the Unit key within the timer file itself.</p> Display timers<pre><code>systemctl list-timers\nsystemctl status *timer\n</code></pre> <p>Like other unit files, timer files may include Unit and Install sections, but must include the Timer section.</p> <p>Specifying time is done using timestamps which can be monotonic or realtime.</p> <ul> <li>Monotonic timers are defined relative to various system hooks using the following directives: OnActiveSec, OnBootSec, OnStartupSec, OnUnitActiveSec, and OnUnitInactiveSec.</li> <li>Realtime timers define timers according to calendar event expressions, denoting real-world dates and times as humans understand them. </li> </ul> <p>Validate timestamps: <pre><code>systemd-analyze calendar '*-*-* 00:00:00' --iterations\n</code></pre></p> <p>systemd-run can be used for one-off events as a substitute for anacron. <pre><code>systemd-run --on-active=-30sec /bin/touch /home/user/file\n</code></pre> This command creates a transient unit file, whose name is provided in the output. <pre><code>systemctl cat run-u97.service\n</code></pre></p>"},{"location":"Linux/SystemD/#unit-files","title":"Unit files","text":"<p>Unit files are case-sensitive .ini files organized into sections. Unit files can be found in several directories:</p> <ul> <li>/lib/systemd/system where the system's copy of unit files are placed by default</li> <li>/etc/systemd/system where unit files override the system default</li> <li>/run/systemd/system where run-time unit definitions are found and given a higher priority than the system default in /lib but lower than that in /etc. These unit files are created dynamically and lost on reboot.</li> </ul> <p>Unit files come in many different types which can be identified by their filename extension (i.e. .service, target, etc.).</p>"},{"location":"Linux/SystemD/#upstart","title":"Upstart","text":"Upstart was an init system developed by Canonical for Ubuntu meant to replace SysVinit, but it was abandoned in 2014."},{"location":"Linux/SystemD/#commands","title":"Commands","text":""},{"location":"Linux/SystemD/#hostnamectl","title":"hostnamectl","text":"Permanently change hostname <pre><code>hostnamectl set-hostname $HOSTNAME\n</code></pre>"},{"location":"Linux/SystemD/#journalctl","title":"journalctl","text":"<p>Clean up old logs</p> <pre><code>journalctl --disk-usage # (3)\njournalctl --rotate # (1)\njournalctl --vacuum-time=1d # (2)\n</code></pre> <ol> <li>Ask journal daemon to rotate journal files, immediately archiving and renaming currently active journal files.</li> <li>--vacuum-size, --vacuum-time, and --vacuum-files can be used singly or in combination to enforce limits on archived journal files.</li> <li>Show current disk usage of all journal files</li> </ol> <p>Display logs</p> <pre><code>journalctl -r # --reverse (1)\njournalctl -f # --follow (2)\n</code></pre> <ol> <li>Display output in reverse (newest entries first)</li> <li>Continuously update the display as new log entries are created</li> </ol> <p>By default, SystemD logs to memory. This can be changed by adjusting /etc/systemd/journald.conf.  This requires the directory /var/log/journal to exist.</p> Persistent logging<pre><code>[Journal]\nStorage=persistent\n</code></pre>"},{"location":"Linux/SystemD/#localectl","title":"localectl","text":"Change locale to French <pre><code>localectl set-locale LANG=fr_FR.utf8\n</code></pre>"},{"location":"Linux/SystemD/#loginctl","title":"loginctl","text":"Enable user lingering, which allows users that are not logged in to run long-running services. <pre><code>loginctl enable-linger\nloginctl show-user | grep Linger - # Confirm\n</code></pre>"},{"location":"Linux/SystemD/#systemctl","title":"systemctl","text":"Services<pre><code>systemctl list-unit-files --type=service    # Display all services\nsystemctl enable --now $SERVICE             # Configure service to start on boot and start it immediately\nsystemctl status $SERVICE\nsystemctl is-active $SERVICE \nsystemctl disable $SERVICE\nsystemctl mask $SERVICE                     # Prevent service from being started inadvertently by another process\nsystemctl restart $SERVICE\n</code></pre> Boot targets<pre><code>systemctl get-default\nsystemctl set-default graphical.target\nsystemctl isolate emergency.target          # Change target\nsystemctl suspend                           # Suspend system\n</code></pre> <p>--user specifies the service manager of the calling user. <pre><code>systemctl --user enable --now container-notes.service # (1)\nsystemctl --user status container-notes.service\n</code></pre></p> <ol> <li>Here, container-notes.service has been created at ~/.config/systemd/user</li> </ol>"},{"location":"Linux/SystemD/#systemd-analyze","title":"systemd-analyze","text":"Check security of a service<pre><code>systemd-analyze security sshd.service\n</code></pre>"},{"location":"Linux/SystemD/#systemd-cgls","title":"systemd-cgls","text":"systemd-cgls recursively shows the contents of the selected cgroup hierarchy in a tree."},{"location":"Linux/SystemD/#systemd-delta","title":"systemd-delta","text":"<p>Show files that are overridden with systemd.</p> <p>Display differences among files when they are overridden <pre><code>systemd-delta --diff\n</code></pre></p>"},{"location":"Linux/Virtualization/","title":"Virtualization","text":"<p>The typical virtualization stack on Linux is referred to as QEMU/KVM; both of these are separate technologies.</p>"},{"location":"Linux/Virtualization/#tasks","title":"Tasks","text":""},{"location":"Linux/Virtualization/#check-cpu-for-virtualization-support","title":"Check CPU for virtualization support","text":"<pre><code>grep -E 'svm|vmx' /proc/cpuinfo # (1)\n</code></pre> <ol> <li>AMD CPUs will have svm in the flags section, whereas Intel CPUs will have vmx.</li> </ol>"},{"location":"Linux/Virtualization/#virtual-machine","title":"Virtual machine","text":"<p>The easiest way to create a VM is with the Boxes GNOME Desktop Environment application or virt-manager.</p> <pre><code>virt-install \\\n--cdrom=/tmp/debian-9.0.0-amd64-netinst.iso \\\n--vcpus=1 --memory=1024 --disk size=5 \\\n--os-variant=debian8\n    --name=linuxconfig-vm \\\n</code></pre>"},{"location":"Linux/Virtualization/#virtual-networking","title":"Virtual networking","text":"Using Boxes, a new interface will be created (apparently named tap0, etc) and slaved to a bridge, or a bridge will be created if none exist."},{"location":"Linux/Virtualization/#console-access","title":"Console access","text":"<p>In order to enable console access to a domain, the serial-gettty@.service service must be started. <pre><code>systemctl enable --now serial-getty@ttyS0.service\n</code></pre> Now console access is available from the host <pre><code>virsh console $DOMAIN\n</code></pre></p> <p>Note that the console will remain at 24 lines by 80 columns no matter if the terminal window is resized.</p>"},{"location":"Linux/Virtualization/#virtual-disk","title":"Virtual disk","text":"CoW filesystems <p>If the disk image is created on a filesystem that does not support O_DIRECT (ref. <code>man 5 open</code>), i.e. COW filesystem like btrfs and ZFS, the cache must be disabled.  This appears to be impossible on btrfs, so disk images must be created on partitions with non-CoW alternatives, like ext4 and xfs.</p> <p>A virtual disk can be created in various ways and in various formats (the sparse QCOW2 disk image format, associated with QEMU, is preferred).</p> <p>One way is to create the image using a utility like qemu-img. Create qcow2 disk image<pre><code>qemu-img create -f qcow2 disk0.qcow2 5G # (1)\n</code></pre></p> <ol> <li>By omitting -f, qemu-img will create a RAW format file.</li> </ol> <p>Alternatively, and more circuitously, a volume can be created within a storage pool. <pre><code>virsh pool-define-as --name Disks --type dir --target /disk/Disks # (1)\nvirsh pool-start Disks # (2)\nvirsh vol-create-as Disks disk0.qcow2 10G --format qcow2\n</code></pre></p> <ol> <li>A pool is deleted by first making sure its contents are deleted (but not the containing folder, in the case of a directory-based storage pool) <pre><code>virsh pool-destroy Disks  # Destroy the contents\nvirsh pool-delete Disks   # Delete directory\nvirsh pool-undefine Disks # Delete resource\n</code></pre></li> <li>Alternatively, activate pool on boot <pre><code>virsh pool-autostart Disks\n</code></pre></li> </ol> <p>Regardless of the method, the disk image is then attached to the domain, whether or not it is running.</p> <pre><code>virsh attach-disk rhel \\\n--source /tmp/Disks/disk0.qcow2 \\\n--target vdb --cache none \\\n--driver qemu --subdriver qcow2 \\\n--persistent # (1)\n</code></pre> <ol> <li>--persistent is necessary for the disk to remain attached after a shutdown. If the domain is not running, --config is necessary. <pre><code>virsh attach-disk rhel \\\n--source /tmp/Disks/disk0.qcow2 \\\n--target vdb --cache none \\\n--driver qemu --subdriver qcow2 \\\n--config\n</code></pre> This can be reversed with the following command. <pre><code>virsh detach-disk rhel /tmp/Disks/disk0.qcow2\nvirhs detach-disk rhel vdb # Specifying target instead\n</code></pre></li> </ol>"},{"location":"Linux/Virtualization/#snapshots","title":"Snapshots","text":"<p>Snapshots of VMs can be taken from within Boxes or via the command-line: <pre><code>virsh snapshot-create-as rhel --name \"Disks added\"\n</code></pre></p> <p>These produce XML records that can then be viewed: note that the field that Boxes uses to identify each snapshot is actually \"description\". <pre><code>virsh snapshot-dumpxml rhel \"Disks added\"\n</code></pre></p> <p>Snapshots can be renamed by changing the value of the name element in a text editor. <pre><code>virsh snapshot-edit rhel --snapshotname \"Disks added\" --rename\n</code></pre></p> <p>Revert to a snapshot <pre><code>virsh snapshot-revert rhel --snapshotname </code></pre></p>"},{"location":"Linux/Virtualization/#custom-resolution","title":"Custom resolution","text":"<p>Specify a custom resolution in a VM using KVM <pre><code>cvt 2560 1440\nxrandr --newmode \"2560x1440_60.00\" 312.25 2560 2752 3024 3488  1440 1443 1448 1493 -hsync +vsync\nxrandr --addmode Virtual-1 2560x1440_60.00\nxrandr --output Virtual-1 --mode 2560x1440_60.0\n</code></pre></p> <p>On a Hyper-V VM, this method will not work, but a simple change to a line in /etc/default/grub will do the trick after running update-grub and restarting</p> <pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash video=hyperv_fb:1920x1080\"\n</code></pre>"},{"location":"Linux/Virtualization/#commands","title":"Commands","text":""},{"location":"Linux/Virtualization/#virt-install","title":"virt-install","text":""},{"location":"Linux/Virtualization/#virsh","title":"virsh","text":"<p>virsh is the main interface for managing libvirt guest domains. In virsh terminology, the word domain refers to a VM.</p> <p>virsh commands can be entered from the virsh shell or from the command-line.</p> <pre><code>virsh list --all\nvirsh start rhel\nvirsh shutdown rhel\nvirsh destroy rhel  # Forcefully\nvirsh undefine rhel\nvirsh autostart rhel # (1)\n</code></pre> <ol> <li>Start domain at boot</li> </ol> <p>Inspect a running domain <pre><code>virsh dominfo $DOMAIN\nvirsh domiflist $DOMAIN\nvirsh domblklist $DOMAIN\nvirsh domrename $DOMAIN $NEWNAME`\n</code></pre></p> <p>Virsh uses XML documents to define domain resources. <pre><code>virsh dumpxml $DOMAIN\nvirsh edit $DOMAIN\n</code></pre></p> <p>Several virsh commands come in two varieties, one to handle XML documents that define resources and another to define them inline from the command-line.</p> XML CLI Description pool-define pool-define-as Define a persistent storage pool vol-create vol-create-as Create a volume <p>The commands ending in -as also support use of the --print-xml option, which will output the equivalent XML document to stdout.</p>"},{"location":"Linux/Virtualization/#glossary","title":"Glossary","text":""},{"location":"Linux/Virtualization/#boxes","title":"Boxes","text":"Boxes is a GNOME Desktop Environment application intended as a more user-friendly alternative to virt-manager to make virtualization easier for end-users."},{"location":"Linux/Virtualization/#domain","title":"domain","text":"In libvirt, a domain is a guest VM."},{"location":"Linux/Virtualization/#kvm","title":"KVM","text":"<p>KVM is a FreeBSD and Linux kernel module that allows the kernel to function as a hypervisor.</p> <p>KVM was first merged into kernel 2.6.20.</p>"},{"location":"Linux/Virtualization/#libvirt","title":"libvirt","text":"libvirt is an open-source API, daemon, and management tool for managing virtualization. It is a C toolkit to interact with the virtualization capabilities of the Linux KVM module, but it can also be used with KVM along with other virtualization technologies like QEMU."},{"location":"Linux/Virtualization/#qemu","title":"QEMU","text":"QEMU is an open-source emulator that interoperates with KVM to run VMs at near-native speed when the guest architecture is the same as that of the host."},{"location":"Linux/Virtualization/#storage-pool","title":"storage pool","text":"In libvirt, a storage pool is a file, directory, or storage device managed by libvirt to provide storage for domains."},{"location":"Linux/Applications/bind/","title":"BIND","text":"<pre><code>apt install bind9 bind9-utils bind9-dnsutils -y\n</code></pre> <p>Set BIND to IPv4 mode in the service parameters file:</p> /etc/default/bind9<pre><code>OPTIONS=\"-4 -u bind\"\n</code></pre> <p>BIND configs have a unique syntax that make heavy use of the semicolon. The main config is at /etc/named.conf on Arch and RHEL systems and at /etc/bind/named.conf on Ubuntu.</p> <p>A DNS zone is a database with resource records for a specific sub-tree in the domain space.</p> <p>A DNS zone requires a start of authority (SOA) record. For readability, admins typically break the record apart into lines with comments describing each field following a semicolon.</p> Representative SOA record<pre><code>@ IN SOA ns1.example.com. hostmaster.example.com. (\n                          2022070601 ; serial number\n                          1d         ; refresh period\n                          3h         ; retry period\n                          3d         ; expire time\n                          3h )       ; minimum TTL\n</code></pre> <p>Allow recursive queries from trusted clients</p> /etc/bind/named.conf.options<pre><code>acl \"trusted\" {\n    10.128.10.11;    # ns1 - can be set to localhost\n    10.128.20.12;    # ns2\n    10.128.100.101;  # host1\n    10.128.200.102;  # host2\n};\n</code></pre> <p>Allow recursion</p> /etc/bind/named.conf.options<pre><code>options {\n    directory \"/var/cache/bind\";\n\n    recursion yes;\n    allow-recursion {trusted; };\n    listen-on { 0.0.0.0; };\n    allow-transfer { none; };\n    forwarders { 192.168.1.1; };\n};\n</code></pre> <p>Now zone files can be specified in named.conf.local. An additional zone and zone file must be specified for every private subnet.</p> /etc/bind/named.conf.local<pre><code>zone \"mydns\" {\n        type master;\n        file \"/etc/bind/zones/db.mydns\";\n}\n</code></pre> <p>The actual zone files can be copied from /etc/bind/db.local and edited manually.</p> /etc/bind/zones/db.mydns<pre><code>\n</code></pre>"},{"location":"Linux/Applications/ffmpeg/","title":"ffmpeg","text":""},{"location":"Linux/Applications/ffmpeg/#convert-format","title":"Convert format","text":"ffmpeg is most often used to convert file formats for media from the command-line Convert mp3 to m4a<pre><code>ffmpeg -i media.{mp3,m4a}\n</code></pre>"},{"location":"Linux/Applications/ffmpeg/#display-metadata","title":"Display metadata","text":"<pre><code>ffmpeg -hide_banner -i $INPUT\n</code></pre>"},{"location":"Linux/Applications/ffmpeg/#specify-metadata","title":"Specify metadata","text":"<p>Metadata is defined as key/value pairs, although not all formats support all metadata. This example adds metadata but does not reencode the input file. <pre><code>ffmpeg -i $INPUTFILE -metadata title=$TITLE -metadata year=$YEAR -codec copy $OUTPUTFILE\n</code></pre></p> Tag all audio in a directory<pre><code>for INPUT in $(ls *.mp3);\ndo\nffmpeg -i \"$INPUT\" -c copy -metadata genre=Amapiano \"${INPUT/.mp3/_tagged.mp3}\"\ndone\n</code></pre>"},{"location":"Linux/Applications/ffmpeg/#concatenating-multiple-files","title":"Concatenating multiple files","text":"<p>It is possible to combine many files into one. The canonical way of doing this is by first assembling a list of filenames. These must appear in a specific format: <pre><code>file 'file1.mp3'\nfile 'file2.mp3'\n# etc...\n</code></pre></p> <p>This can be done quickly by piping the output of ls to a file, then editing it manually. <pre><code>echo $(ls -1 *.mp3) &gt; files\n</code></pre></p> <p>Then this file can be used by ffmpeg, specifying the concat demuxer as the argument to -f <pre><code>ffmpeg -f concat -i files -c copy compilation.mp3\n</code></pre></p> <p>Chapters will be accepted with the right container (apparently not mp3). Note that mp3 files cannot be placed into a m4a container without re-encoding. Also note that the -map_metadata option must be specified after the second infile, because its argument refers to the second infile as if it were zero-indexed. <pre><code>ffmpeg -f concat -i files -i chapters -map_metadata 1 -c copy compilation.m4a\n</code></pre></p>"},{"location":"Linux/Applications/git/","title":"Git","text":""},{"location":"Linux/Applications/git/#git_1","title":"Git","text":"<p>Git is a very complex utility with multiple commands and subcommands and a strong dependency on version control system concepts.</p> <p>The most basic useful command may be clone which simply downloads a repository. <pre><code>git clone https://gitlab.gnome.org/GNOME/gtk.git\n\n# The depth of the tree can be specified, and various configuration parameters can be passed with -c\ngit clone https://gitlab.gnome.org/GNOME/gtk.git --depth 1 -c http.sslVerify=false\n</code></pre></p> <p>Add file, located in <code>$HOME</code> to the git repo at <code>$PATH</code></p> <pre><code>git --git-dir=$PATH.git --work-tree=$HOME add file\n</code></pre> <pre><code># Update index to include all files in the working tree, including removals\ngit add -A # --no-ignore-removal\n\n# Stage all modifications in work-tree, including deletions\ngit add -u\n</code></pre> <p>See a list of branches.  A \"*\" indicates that branch is checked out. <pre><code>git branch\n</code></pre></p> <pre><code># Display the last commit for each branch\ngit branch -v\n\n# Display branches that have not been merged\ngit branch --no-merged\n</code></pre> <pre><code># Discard unstaged uncommitted changes to file\ngit checkout -- file\n\n# Switch to branch\ngit checkout branch\n</code></pre> <p>Apply a single, specific commit from another branch <pre><code>git cherry-pick commit\n</code></pre></p> <p>Provides a frontend to the INI formatted config files typically found within <code>.git/config</code> (or <code>~/.gitconfig</code> when using <code>--global</code>)</p> <pre><code># Set up alias \"br\" for `branch`\ngit config --global alias.br branch # (1)\n\n# Store authentication details in a cache\ngit config --global credential.helper cache # (2)\n</code></pre> <ol> <li>Equivalent to: <pre><code>[alias]\nbr = branch\n</code></pre></li> <li>Equivalent to  <pre><code>[credential]\nhelper = cache\n</code></pre></li> </ol> <p>Show commits between January 1 and January 5, 2016 <pre><code>git log --after=\"2016-01-01\" --before=\"2016-01-05\"\n</code></pre></p> <p>See commits that are on {branch} but not on {master} <pre><code>git log master..branch\n</code></pre></p> <p>Show tracked files <pre><code>git ls-files\n</code></pre></p> <p>Show tracked files, each line is terminated by a null byte <pre><code>git ls-files -z\n</code></pre></p> <p>Show tracked files that have been deleted <pre><code>git ls-files --deleted\n</code></pre></p> <p>Move or rename a tracked file <pre><code>git mv file\n</code></pre></p> <p>Transfer data from local branch {master} to remote {origin} <pre><code>git push -u origin master\n</code></pre></p> <p>To add changes to a commit that is not the most recent, a rebase is necessary.  First stash the changes to be added, then initiate a rebase and mark the commit to be edited with <code>edit</code> or <code>e</code>.  Leave the other commits alone, save, and drop back to the stash.  Pop the stash (<code>git stash pop</code>), which will apply the changes stored in the most recent stash.  Now you can stage the changes and commit: <pre><code>git commit --amend --no-edit\n</code></pre></p> <p>Finally, continue the rebase, rewriting the rest of the commits against the new one. <pre><code>git rebase --continue\n</code></pre></p> <p>Combine branches by replaying the changes made on one branch to another <pre><code>git rebase\n</code></pre></p> <p>Add remote repo <pre><code>git remote add $REPO $URL\n</code></pre></p> <pre><code># Display URL of remote repo\ngit remote get-url $REPO\n\n# Set url for existing repo\ngit remote set-url $URL $REPO\n</code></pre> <p>Undo unstaged changes since last commit <pre><code>git reset --hard\n</code></pre></p> <p>Reset master to state before last commit <pre><code>git reset --hard HEAD~\n</code></pre></p> <p>Remove (committed) changes in {commit} <pre><code>git revert commit\n</code></pre></p> <p>Remove tracked file from repo <pre><code>git rm file\n</code></pre></p> <p>Stash changes to work-tree <pre><code>git stash\n</code></pre> View stashes in stash stack <pre><code>git stash list\n</code></pre> Apply changes in most recent stash <pre><code>git stash apply\n</code></pre> Apply changes in stash <code>$STASH</code> <pre><code>git stash apply stash@$STASH\n</code></pre></p>"},{"location":"Linux/Applications/git/#tasks","title":"Tasks","text":""},{"location":"Linux/Applications/git/#existing-codebase","title":"Existing codebase","text":"<p>An existing directory can be turned into a repo.</p> <pre><code>git init\n\n# Define an upstream repo\ngit remote add origin $REPO\n\n# Before a first commit, the global email and user name must be set.\ngit config --global user.name $NAME\ngit config --global user.email $EMAIL\n\n# Add and commit as normal\ngit add .\ngit commit -m $MESSAGE\n\n# The first push must have the upstream repo set\ngit push --set-upstream origin master\n</code></pre>"},{"location":"Linux/Applications/git/#rebasing","title":"Rebasing","text":"<p>Rebase changes committed to branch onto MASTER</p> <pre><code>git checkout $BRANCH\ngit rebase $MASTER\n</code></pre> <p>This will rewind $BRANCH to the commit shared by the two branches, then applying all changes made subsequently to $MASTER. </p> <p><pre><code>git checkout &lt;master&gt;\ngit merge &lt;branch&gt;\n</code></pre> Now the history will appear as though all changes were made in series, when they were actually made in parallel on separate branches. Move the last commit to a new branch <pre><code>git branch test         # create a new branch with current HEAD\ngit reset --hard HEAD~  # reset master to before last commit \ngit checkout test       # continue on new branch\n</code></pre> Line endings Git will automatically append CRLF endings on Windows. This setting can be displayed with the following command: <pre><code>git config core.autocrlf\n</code></pre> In order to disable this, adjust the setting <pre><code>git config core.autocrlf false\n</code></pre></p>"},{"location":"Linux/Applications/git/#squashing","title":"Squashing","text":"Sometimes many commits are made to resolve a single issue. These should be \"squashed\". To squash the last 4 commits: <pre><code>git rebase -i HEAD~4\n</code></pre> This will open a text editor where you will have to select what to do with each of the 4 commits. Most recent commits are at the bottom, and at least the top (oldest) commit has to remain \"pick\" in order to squash the others. The repo will have to be force-pushed once these changes have been made.  <pre><code>git push --force\n</code></pre> To add changes to the most recent commit, stage changes as normal (including removals), but when committing use the <code>--amend</code> option. This will present an editor, allowing you to edit the commit message, if necessary. [6] <pre><code>git add README.md\ngit commit --amend \n</code></pre> To split up <code>$COMMIT</code> <pre><code>git rebase -i \"$COMMIT\"^ # Start a rebase at the commit you want to split\n</code></pre> Mark the commit to be split with <code>edit</code>. Now reset state to the previous commit <pre><code>git reset HEAD^\n</code></pre> The files are presented unstaged, and can be added to new commits as needed. Finally, finish the rebase <pre><code>git rebase --continue\n</code></pre>"},{"location":"Linux/Applications/git/#tig","title":"tig","text":"<p>Provides a curses-based browser that allows you to navigate the commits in the current branch.  It is essentially a wrapper around <code>git log</code>, and therefore accepts the same arguments that can be passed to it. Tig's config is at ~/.tigrc.</p> <pre><code># Browse the commit history for a single file\ntig $FILE\n\n# Filter commits to a date range\ntig --after=\"2017-01-01\" --before=\"2018-05-16\" -- $FILE\n\n# Find who made a change to a file and why\ntig blame $FILE\n\n# Browse stash\ntig stash\n\n# Browse refs\ntig refs\n\n# Navigate the output of git grep\ntig grep -i foo lib/Bar\n\n# Pipe a list of commit IDs to tig\ngit rev-list --author=olaf HEAD | tig show --stdin\n</code></pre>"},{"location":"Linux/Applications/gnome/","title":"GNOME","text":"<p>GTK3 attempted to get away from strong dependency on theming engines by introducing CSS stylesheets. This was supposed to make application theming simple and portable.</p> <p>In GTK4 you can choose either a theming engine or CSS stylesheets.</p>"},{"location":"Linux/Applications/gnome/#keyring","title":"Keyring","text":"<p>GNOME Keyring is a collection of components that store and manage application access to secrets, passwords, keys, and certificates.</p> <p>GNOME Keyring can be managed:</p> <ul> <li>Seahorse via GUI</li> <li>secret-tool which uses (and is included in) libsecret</li> <li>gnome-keyring-query which uses the archived libgnome-keyring</li> </ul>"},{"location":"Linux/Applications/gnome/#extensions","title":"Extensions","text":"<p>GNOME Extensions provide a variety of popular hacks and changes to the Shell. They are managed by gnome-extensions-app but they are typically added from the GNOME Extensions website using a browser plugin.</p> <p>These extensions are added to ~/.local/share/gnome-shell/extensions, but many of them can also be made available to all users by installing them using a package manager, in which case they are placed in /usr/share/gnome-shell/extensions.</p> <p>Extensions appear to be mostly JavaScript applications, so they can probably simply be git cloned into the respective directories as well.</p>"},{"location":"Linux/Applications/gnome/#configuration","title":"Configuration","text":"<p>dconf is a key-based blob database for storing GNOME configurations and application settings. These settings are stored as keys grouped under paths in a way analogous to the Windows Registry. </p> <ul> <li>dconf is also a CLI utility for reading and writing individual values or entire directories to and from a dconf database.  Direct manipulation of dconf is discouraged, rather users and developers are encouraged to use dconf-editor or gsettings.</li> <li>GSettings is a high-level API for application settings that serves as the frontend for dconf as well as a CLI utility for changing user settings.</li> </ul> <p>A dconf profile is a list of binary dconf databases, typically stored at /etc/dconf/profile/user</p> <p>Here is a representative dconf profile. user is the name of the user database, typically found at ~/.config/dconf/ or /etc/dconf/profile/user and local and site refer to binary databases named as such in /etc/dconf/db/. <pre><code>service-db:keyfile/user # (1)\nuser-db:user\nsystem-db:local\nsystem-db:site\n</code></pre></p> <ol> <li>This line sets the dconf keyfile backend, required when home directories are mounted over NFS</li> </ol> <p>Keyfiles are INI-format configs placed in directories like local.d/ that allow dconf settings to be specified declaratively. <pre><code>[org/gnome/desktop/input-sources]\nxkb-options=['terminate:ctrl_alt_bksp', 'compose:ralt'] # (1)\n</code></pre></p> <ol> <li>Equivalent to: <pre><code>gsettings set org.gnome.desktop.input-sources xkb-options=['terminate:ctrl_alt_bksp', 'compose:ralt']\n</code></pre></li> </ol>"},{"location":"Linux/Applications/gnome/#tasks","title":"Tasks","text":""},{"location":"Linux/Applications/gnome/#desktop-background","title":"Desktop background","text":"Create a keyfile for the local database in /etc/dconf/db/local.d/01-background <pre><code>[org/gnome/desktop/background]\n\npicture-uri='file:///usr/local/share/backgrounds/wallpaper.jpg'\npicture-options='scaled'\nprimary-color='000000'\nsecondary-color='FFFFFF'\n</code></pre>"},{"location":"Linux/Applications/gnome/#custom-application-shortcut","title":"Custom application shortcut","text":"<p>Custom shortcuts are stored in dconf using a \"relocatable schema\" which has three keys: name, command, and binding.</p> <pre><code>gsettings set org.gnome.setting-daemon.plugins.media-keys.custom-keybinding:/org/gnome/settings-daemon/plugins/media-keys/custom-keybindings/custom0 name 'Terminal'\ngsettings set org.gnome.setting-daemon.plugins.media-keys.custom-keybinding:/org/gnome/settings-daemon/plugins/media-keys/custom-keybindings/custom0 binding '&lt;Super&gt;Enter'\ngsettings set org.gnome.setting-daemon.plugins.media-keys.custom-keybinding:/org/gnome/settings-daemon/plugins/media-keys/custom-keybindings/custom0 command '/usr/bin/gnome-terminal'\n</code></pre> <p>Note that this doesn't seem to work...</p>"},{"location":"Linux/Applications/gnome/#file-associations","title":"File associations","text":"<p>File associations are stored in .desktop files stored in /usr/share/applications/.  These INI-format files store all kinds of metadata on installed applications, including names and keywords in all supported languages. Filetypes are stored under the MimeType key as semicolon-delimited MIME Types.</p> <pre><code>[Desktop Entry]\nType=Application\nMimeType=application/x-newtype\nName=My Application 1\nExec=myapplication1\n</code></pre> <p>MIME Type descriptors as stored as XML files stored in /usr/share/mime/packages/:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;mime-info xmlns=\"http://www.freedesktop.org/standards/shared-mime-info\"&gt;\n&lt;mime-type type=\"application/x-newtype\"&gt;\n&lt;comment&gt;new mime type&lt;/comment&gt;\n&lt;glob pattern=\"*.xyz\"/&gt;\n&lt;/mime-type&gt;\n&lt;/mime-info&gt;\n</code></pre>"},{"location":"Linux/Applications/gnome/#applications","title":"Applications","text":""},{"location":"Linux/Applications/gnome/#gio","title":"gio","text":"<p>GIO (Gnome Input/Output) is a library that facilitates interaction with virtual file systems. Applications built with the GIO library can access GVFS mounts, which can have many backends.</p> <p>GIO commands appear to substitute for common POSIX commands and GNU utilities (e.g. <code>gio cat</code>, <code>gio mkdir</code>, <code>gio rename</code>, etc).</p> <p>Set custom GIO metadata</p> <pre><code># Read (empty) attribute of new file\ngio info -a 'metadata::*' /tmp/myfile\n\n# Create attribute\ngio set -t string /tmp/myfile 'metadata::mynote' 'Please remember to delete this file!'\n\n# Rename file\ngio move /tmp/myfile /tmp/newfile\n\n# Confirm that attribute still exists\ngio info -a 'metadata::*' /tmp/newfile # (1)\n</code></pre> <ol> <li>gio info appears to have replaced the earlier gvfs-info and gvfs-mime utilities used to inspect registered MIME types.</li> </ol>"},{"location":"Linux/Applications/gnome/#gsettings","title":"gsettings","text":"<p>gsettings is the CLI frontend intended to support changes to GNOME application settings, stored in dconf databases.</p> Examples<pre><code># Change function of Caps Lock\ngsettings set org.gnome.desktop.input-sources xkb-options \"['caps:ctrl_modifier']\"\n\n# Change mouse cursor size to various sizes. This can also be done in GNOME as Settings &gt; Accessibility\ngsettings set org.gnome.desktop.interface cursor-size 24 # (1)\n\n# Enable GTK Inspector\ngsettings set org.gtk.Settings.Debug enable-inspector-keybinding true # (2)\n</code></pre> <ol> <li>Valid sizes include 24, 32, 48, 64, and 96</li> <li>Can be run with Ctrl+Shift+D</li> </ol>"},{"location":"Linux/Applications/gnome/#notify-send","title":"notify-send","text":"Used for displaying desktop notifications on GNOME Desktop Environment <pre><code>notify-send -i face-smile Hello \"Hello, World!\"\n</code></pre>"},{"location":"Linux/Applications/nginx/","title":"Nginx","text":"<p>Nginx (\"engine-x\") is described as an event-based reverse proxy server. This refers to the fact that it has an asynchronous architecture, unlike its competitors Apache and IIS which create a new blocking thread per connection. Nginx is much newer than Apache which started in 1995, although it has seen widespread adoption since 2008, growing mostly at Apache's expense. A typical and favored deployment is to place Nginx in the front-end and Apache in the back-end to combine the advantages of both platforms.</p> <p>Nginx follows the convention of even version numbers being stable and odd numbers being mainline or development.</p>  Red Hat Ubuntu <p><pre><code># /etc/yum.repos.d/nginx.repo\n\n[nginx]\nname=nginx repo\nbaseurl=http://nginx.org/packages/centos/7/$basearch/\ngpgcheck=0\nenabled=1\n</code></pre> <pre><code>dnf install nginx\n</code></pre></p> <p><pre><code># /etc/apt/sources.list\n\ndeb http://nginx.org/packages/ubuntu/ trusty nginx\ndeb-src http://nginx.org/packages/ubuntu/ trusty nginx\n</code></pre> <pre><code>curl -fsSL http://nginx.org/keys/nginx_signing.key\napt-key add nginx_signing.key\napt install nginx\n</code></pre></p> <p>Depending on installation method and distribution, configurations can exist in various directories. A config can be explicitly specified at runtime with <code>--conf-path</code>/<code>-c</code>.</p> <p>This option also appears in the output of <code>ps</code> for the Nginx master process, which is one way of interrogating which config is being used for the current Nginx instance. Nginx can also be interrogated for its default config with <code>-t</code></p> <p>Nginx config files contain directives: </p> <ul> <li>Simple directives like <code>listen *:80;</code> contain a name, multiple optional parameters, and a closing semicolon.  Parameters themselves can pass a value after an equal sign, i.e. <code>backlog=511</code>.</li> <li>Context directives (or simply \"contexts\", also \"block directives\") like <code>events</code>, <code>http</code>, and <code>server</code> wrap a group of other directives in a pair of braces and can be nested. Most simple directives can only be declared in specific contexts.</li> <li>There is also an implied main context which wraps all the contents of the file, and putting a simple directive into the main context means making it a top-level statemtn.</li> <li>Comments can be written using <code>#</code></li> </ul>"},{"location":"Linux/Applications/nginx/#examples","title":"Examples","text":"<p>A very simple representative config that creates an HTTP server listening on port 80 of every network interface, with no HTTP Host specified, from the specified root path:</p> Default<pre><code>events {\n}\n\nhttp {\nserver {\n}\n}\n</code></pre> Expanded with explicit values<pre><code>user nobody nogroup;\nworker_processes 1;\n\nevents {\nworker_connections 512;\n}\n\nhttp {\nserver {\nlisten *:80;\nserver_name \"\";\nroot /usr/share/nginx/html;\n}\n}\n</code></pre> <pre><code>http {\nserver {\nlisten 8080;\nroot /www;\n\nlocation /images {\nroot /;\n}\n}\n}\nevents { }\n</code></pre> <pre><code>nginx -s stop\nnginx -s start\nnginx restart\n</code></pre>"},{"location":"Linux/Applications/nginx/#reverse-proxy","title":"Reverse proxy","text":"<p>Each Nginx virtual server should be described by a file in the /etc/nginx/sites-available directory.  These are linked to by symlinks placed in /etc/nginx/sites-enabled. Configuring a reverse proxy involves associating routes to proxied servers in these virtual server configs. </p> <pre><code>server {\nlisten 80;\nlocation / {\nproxy_pass \"http://127.0.0.1:8000\";\n}\n}\n</code></pre> <p>The configuration to serve static files placed in the local directory /path/to/staticfiles from the URL /static is: <pre><code>location /static/ {\nroot /path/to/staticfiles/\n}\n</code></pre></p>"},{"location":"Linux/Applications/nginx/#load-balancer","title":"Load balancer","text":"<p>A load balancer is similar to a reverse proxy, with the following differences.</p> <ul> <li>Load balancers perform reverse proxy across many backends, rather than a single one</li> <li>Load balancers operate at either Layer 7 or Layer 4, whereas a reverse proxy operates only at Level 7</li> <li>Load balancers are expected to handle much higher scale.</li> </ul> <p>Load balancers themselves tend to be load balanced by DNS servers, which can serve multiple A records to clients which are supposed to choose one of the IP addresses at random. Some DNS providers like AWS Route 53 randomize the order of these records per query.</p> <pre><code>http {\nupstream backend {\nserver 192.0.2.10;\nserver 192.0.2.11;\n}\n\nserver {\nlisten 80;\n\nlocation / {\nproxy_pass http://backend;\n}\n}\n}\n</code></pre>"},{"location":"Linux/Applications/nginx/#glossary","title":"\ud83d\udcd8 Glossary","text":"default server block First server block defined in the config events Context that governs connection processing configuration. Events can only be declared in the main context and there can only be a single events defined within the configuration. http Context that allows configuration of HTTP servers and typically serves as a container for the server context. Directives that are intended to apply to multiple server contexts are typically placed within the http context. listen Simple directive in the server context that configures the network interfaces and ports to listen on for requests. <pre><code>server {\nlisten *:80;\nlisten *:81;\n}\n</code></pre> location <p>Context directive used when there is not a 1:1 mapping between path of the HTTP request and the filesystem. Prefix location blocks, the most basic implementation, allow various root directories to be specified depending on the request path.</p> <p>Various modifiers can be used to modify how the request path is matched. When resolving paths, the most specific match is used.</p> <p>Location blocks in order of precedence:</p> <ul> <li>Exact match modifier (<code>=</code>) </li> <li>Order matters with regex blocks because the first match will be used.<ul> <li>Non-regex prefix (<code>^~</code>) overrides any regex match</li> <li>Case-sensitive regex (<code>~</code>) </li> <li>Case-insensitive regex (<code>~*</code>)</li> </ul> </li> <li>Prefix (no modifier)</li> </ul> <pre><code>location /images/ {\nroot /var/www/images;\n}\n\nlocation = /images/business_cat.gif {\n# ...\n}\n\nlocation ~ \\.(gif|jpg)$ {\n# ...\n}\n\nlocation ~* \\.(GIF|JPG)$ {\n# ...\n}\n\nlocation ^~ /foobar/images {\nroot /var/www/foobar;\n}\n</code></pre> server (context directive) http-context context directive. server (simple directive) upstream-context directive that specifies a backend node. Additional parameters can specify load-balancing behavior.<pre><code>- **weight** controls weighting of backend nodes (default value is 1)\n- **max_fails** controls the number of times that the server can be marked as unhealthy before it is removed from the pool\n- **fail_timeout** controls the time a server is removed from the pool when it is marked unhealthy, and for how long `max_fails` is good for\n</code></pre> server_name Server context simple directive that enables virtual hosting. Values of this directive are matched to the HTTP GET request header's <code>Host</code>. If no matches are found, nginx uses the default server block. upstream http-context simple directive that can, using the <code>server</code> simple directive, specify a pool of backend server. <pre><code>upstream backend {\nserver 192.0.2.10:443 weight=3;\nserver app1.example.com;\nserver unix:/u/apps/my_app/current/tmp/unicorn.sock;\n}\n</code></pre> Each server directive can additionally  user Main context simple directive that sets the Unix user and group that nginx worker processes will run as; by default <code>nobody</code> and the group is <code>nogroup</code>. worker process The non-root nginx process that serves incoming HTTP requests. Each worker process is single-threaded and runs a non-blocking event loop to process requests efficiently. worker_connections Main context simple directive that sets the maximum number of simultaneous connections that can be opened by each worker process. worker_processes Main context simple directive that sets the number of worker processes to serve HTTP requests (1 by default)."},{"location":"Linux/Applications/rhythmbox/","title":"Rhythmbox","text":""},{"location":"Linux/Applications/rhythmbox/#rhythmbox","title":"Rhythmbox","text":"<p>Rhythmbox's database is an XML file located at $HOME/.local/share/rhythmbox/rhythmdb.xml</p> <pre><code>&lt;?xml version=\"1.0\" standalone=\"yes\"?&gt;\n&lt;rhythmdb version=\"2.0\"&gt;\n&lt;entry type=\"song\"&gt;\n&lt;title/&gt;\n&lt;genre/&gt;\n&lt;artist/&gt;\n&lt;album/&gt;\n&lt;location&gt;file:///Music/...&lt;/location&gt;\n&lt;!-- snip --&gt;\n&lt;/entry&gt;\n&lt;/rhythmdb&gt;\n</code></pre>"},{"location":"Linux/Applications/screen/","title":"screen","text":""},{"location":"Linux/Applications/selinux/","title":"SELinux","text":"<p>Info</p> <ul> <li>SELinux (Arch Linux Wiki)</li> </ul> <p>SELinux implements Mandatory Access Control (MAC) in Linux, which is distinguished from traditional Linux access controls (file permission octets, the use of sudo, etc) which constitute Discretionary Access Control (DAC).</p> <p>SELinux's config is at /etc/selinux/config Example config<pre><code># This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX=enforcing\n# SELINUXTYPE= can take one of these three values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy. Only selected processes are protected.\n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted\n</code></pre></p>"},{"location":"Linux/Applications/selinux/#contexts","title":"Contexts","text":"<p>SELinux security contexts define access controls and are also referred to as \"labels\". All system objects have such contexts associated with them, stored in the extended attributes of the filesystem.</p> <p>Contexts are compared to subject, verb, and object in English sentences and have the following structure: <pre><code>user_u:role_r:type_t:level\n</code></pre></p> <p>The user or user identity can be associated with one or more roles. User identities are suffixed with _u, and there a eight such identities builtin. </p> <ul> <li>By default, all non-root users are mapped to unconfined_u as is root itself, which means they operate with unlimited privileges. </li> <li>Users labeled with user_u cannot run su or sudo or programs in their home directories.</li> </ul> <p>The role is an attribute of the RBAC security model that classifies who is allowed to access what (domains, types). It can be associated to one or more types and is suffixed with _r.</p> <p>The type (for file contexts) or domain (for process contexts) defines what processes or domains the user can access. Types are suffixed with _t.</p> <ul> <li>Certain files have their own types, like passwd_file_t which is associated with /etc/passwd.</li> <li>Builtin and user-created file contexts are stored in the file_contexts and file_contexts.local files under /etc/selinux/targeted/contexts/files/.</li> </ul> <p>A level is an attribute of Multi-Level Security and Multi-Category Security.</p> <p>SELinux extends existing utilities to handle contexts with the -Z flag: <pre><code>ps auxZ\nls -Z\nid -Z\n</code></pre></p>"},{"location":"Linux/Applications/selinux/#booleans_1","title":"Booleans","text":"In SELinux, booleans refers to optional settings that can be turned on and off."},{"location":"Linux/Applications/selinux/#tasks","title":"Tasks","text":""},{"location":"Linux/Applications/selinux/#samba-share","title":"Samba share","text":"<p>Enabling a Samba file share requires setting a specific SELinux context using semanage <pre><code>semanage fcontext -a -t samba_share_t '/samba(/.*)?'\n</code></pre></p> <p>The context must then be restored <pre><code>restorecon -vvFR /samba\n</code></pre></p>"},{"location":"Linux/Applications/selinux/#troubleshooting-apache","title":"Troubleshooting Apache","text":"<p>In this scenario, an Apache httpd daemon fails to start due to SELinux.</p> <p>SELinux provides recommended commands to resolve the issue in the audit log at /var/log/messages: <pre><code>grep httpd /var/log/messages | less\n</code></pre></p> <p>Generate and install a new policy module from the logs <pre><code>ausearch -c httpd --raw | audit2allow -M my-httpd\nsemodule -i my-httpd\n</code></pre></p>"},{"location":"Linux/Applications/selinux/#apache-home-directories","title":"Apache home directories","text":"<p>A feature of Apache is that users can host personal websites from the directory named public_html in their home directories. When Apache policies are in effect, this directory is automatically given the http_user_content_t tag, which will allow the httpd daemon to host the website at the path /~user where \"user\" is the name of the user. <pre><code>curl localhost/~user/index.html\n</code></pre></p> <p>However, without a specific boolean enabled, the files will not be accessible: <pre><code>setsebool -P httpd_enable_homedirs 1\n</code></pre></p>"},{"location":"Linux/Applications/selinux/#apache-port","title":"Apache port","text":"<p>Default Apache settings appear in the main config file located at /etc/httpd/conf/httpd.conf.</p> <p>For example, the default directory served by Apache can be changed by setting a new value for the DocumentRoot directive. /etc/httpd/conf/httpd.conf<pre><code>DocumentRoot \"/web\"\n# ...\n&lt;Directory \"/web\"&gt;\n</code></pre></p> <p>Create example content <pre><code>echo \"Hello, World!\" &gt; /web/index.html\n</code></pre> The context for the content must be set. <pre><code># Set context manually\nchcon -R /web -t http_content_t\n\n# Alternatively, set policy and restore the contexts\nsemanage -a -t httpd_sys_content_t '/web(/.*)?'\nrestorecon -R /web\n</code></pre></p> <p>The default port can also be changed with the Listen directive. /etc/httpd/conf/httpd.conf<pre><code>Listen 1000\n</code></pre></p> <p>Now Apache will attempt to serve /web from port 1000, however while SELinux is enforcing policy this port will not be accessible to the daemon, and in fact Apache will exit with an error code.</p> <p>These errors can be inspected in a variety of ways. <pre><code>journalctl -xe\nausearch -m AVC -ts recent\n\n# Find SELinux message IDs, which provide remediation tips:\ngrep sealert /var/log/messages\nsealert -l $MESSAGE_ID\n</code></pre></p> Add port context<pre><code>semanage port -a -t http_port_t -p tcp 1000\n</code></pre> <p>Now starting httpd succeeds, and we can confirm that port 1000 is open: <pre><code>ss -nlt\n</code></pre></p>"},{"location":"Linux/Applications/selinux/#commands","title":"Commands","text":"<p>SELinux commands are separated into get/set varieties similar to PowerShell cmdlets:</p> get set object getenforce setenforce Operating mode getsebool setsebool Booleans <p>Similarly,</p> restore change object restorecon chcon Contexts"},{"location":"Linux/Applications/selinux/#audit2allow","title":"audit2allow","text":"Generate policy module from logs of denied operations<pre><code>ausearch -c httpd --raw | audit2allow -M my-httpd\n</code></pre>"},{"location":"Linux/Applications/selinux/#ausearch","title":"ausearch","text":"<p>Display events in a date range <pre><code>ausearch --start $STARTDATE --end $ENDDATE\n</code></pre></p> <p>Search events for today for logins of UID 500 <pre><code>ausearch --start today --loginuid 500\n</code></pre></p> <p>Search for events associated with an executable. <pre><code>ausearch -c httpd --raw\n</code></pre></p> Display recent (10 minutes) events<pre><code>ausearch -m AVC -ts recent\n</code></pre>"},{"location":"Linux/Applications/selinux/#chcon","title":"chcon","text":"<p>Change context of a file to be hosted via httpd <pre><code>chcon system_u:object_r:httpd_sys_content_t:s0 index.html\nchcon -t httpd_sys_content_t index.html # (1)\n</code></pre></p> <ol> <li>Change only the type portion of the context.</li> </ol>"},{"location":"Linux/Applications/selinux/#getenforce","title":"getenforce","text":"<p>getenforce displays the operating mode of SELinux, which can be one of three values:</p> <ul> <li>enforcing</li> <li>permissive</li> <li>disabled</li> </ul>"},{"location":"Linux/Applications/selinux/#getsebool","title":"getsebool","text":"Display all booleans<pre><code>getsebool -a # (1)\n</code></pre> <ol> <li>A more descriptive listing of the booleans can be displayed with semanage <pre><code>semanage bool -l\n</code></pre></li> </ol>"},{"location":"Linux/Applications/selinux/#restorecon","title":"restorecon","text":"Restore security context policy <pre><code>restorecon -R /web\n</code></pre>"},{"location":"Linux/Applications/selinux/#seinfo","title":"seinfo","text":"List users<pre><code>seinfo -u\n</code></pre>"},{"location":"Linux/Applications/selinux/#semanage","title":"semanage","text":"<p>semanage is used to configure certain elements of SELinux policy without requiring modification to or recompilation from policy sources.</p> File contexts<pre><code>semanage fcontext -l\nsemanage fcontext -a -t httpd_sys_content_t /web </code></pre> Port contexts<pre><code>semanage port -l\nsemanage port -a -t http_port_t -p tcp 1000\n</code></pre> Booleans<pre><code>semanage bool -l\n</code></pre> <p>Examine the mapping between Linux login names and SELinux users. <pre><code>semanage login -l\n</code></pre></p>"},{"location":"Linux/Applications/selinux/#semodule","title":"semodule","text":"Install a policy module<pre><code>semodule -i my-httpd.pp\n</code></pre>"},{"location":"Linux/Applications/selinux/#sestatus","title":"sestatus","text":"<pre><code>sestatus\n</code></pre>"},{"location":"Linux/Applications/selinux/#setenforce","title":"setenforce","text":"<pre><code>setenforce 0 # Permissive\nsetenforce 1 # Enforcing\n</code></pre>"},{"location":"Linux/Applications/selinux/#setsebool","title":"setsebool","text":"<pre><code># Allow SELinux to work with Samba (-P makes the change persistent)\nsetsebool -P samba_export_all_ro 1\n\n# Allow httpd to serve HTML from home directories\nsetsebool -P httpd_enable_homedirs 1\n\n# Prevent runtime changes to SELinux mode\nsetsebool -P secure_mode_policyload 1\n</code></pre>"},{"location":"Linux/Applications/ssh/","title":"SSH","text":"<p>SSH is a secure protocol and the most common way of remotely administering Linux servers and other equipment. SSH uses symmetrical encryption, which means a single key encrypts outbound messages to and inbound messages from the other participant.</p> <p>The SSH session is established in two stages:</p> <ol> <li>Negotiate session key</li> <li>Authenticate the user</li> </ol> <p>The symmetrical key used for the session, called the session key, is negotiated through the asymmetrical Diffie-Hellman key exchange protocol. This algorithm combines private data with public data from the other participant to produce the identical, session key, and the encryption used for the rest of the connection is called binary packet protocol.</p> <p>The simplest and least secure method of authentication is password-based. Although the password is sent through the encryption, it is still considered vulnerable to brute-force attacks.</p> <p>SSH key pairs, which are asymmetric, are recommended. These are what is generated by ssh-keygen, and stored in $HOME/.ssh with names that reflect the encryption algorithm, i.e. \"id_rsa\" and \"id_rsa.pub\", etc. The public key, used to encrypt data for the private key, can be freely shared. In fact, this is the purpose of ssh-copy-id, to share the public key. However the private key, which is used for decryption, must be kept secret.</p> <p>The client sends an ID for the key pair it wants to authenticate with to the server. The server then checks the authorized_keys file of the requested account for the ID. A random number is generated by the server, encrypted with the public key, and sent to the client. The client then decrypts the random number and combines it with the shared session key and calculates the MD5 hash. This hash is then sent back to the server, which checks the calculation.</p> <p>Note that the SSH server is named openssh-server in Ubuntu repos and the service is named ssh, as opposed to sshd on Red Hat systems.</p>"},{"location":"Linux/Applications/ssh/#tasks","title":"Tasks","text":""},{"location":"Linux/Applications/ssh/#port-forwarding","title":"Port forwarding","text":"<p>Port forwarding is accomplished in one of two ways, local or remote with respect to the server not the client.</p> <ul> <li>Local (<code>-L</code>): connections to the client are forwarded through the SSH tunnel to the SSH server. This technique is used to provide functionality similar to a VPN, where remote access is made possible to content on a private network, such as file shares or web applications that are not exposed publicly.</li> <li>Remote (<code>-R</code>)...</li> <li>Dynamic</li> </ul> <p>Here, a private web application served locally on ssh-server will be served on the client at the same port. The first \"localhost\" can actually be omitted, since the connection will be exposed on localhost host by default and is almost universally.</p> <p>The confusing part is the second \"localhost\", because that is actually in reference to the ssh server itself. <pre><code>ssh -L localhost:80:localhost:80 ssh-server\n</code></pre> It is actually possible to forward a request to another host on ssh-server's network, creating a jump box. Here a connection on the client's localhost:81 is forwarded to ssh-server, which then sends it to 192.168.1.1:80. <pre><code>ssh -L 81:192.168.1.1:80 ssh-server\n</code></pre></p>"},{"location":"Linux/Applications/ssh/#x-forwarding","title":"X forwarding","text":"<pre><code>ssh -Y user@host\n</code></pre> Have remote system use local computer {me.luna.edu}'s X display <pre><code>export DISPLAY=me.luna.edu:0\n</code></pre>"},{"location":"Linux/Applications/ssh/#fail2ban","title":"fail2ban","text":"<p>&lt;!-- On the first ban, f2b creates a new chain named f2b-name where \"name\" is the name of the jail, as defined in the config.</p> /etc/fail2ban/action.d/iptables.conf<pre><code>actionstart = &lt;iptables&gt; -N f2b-&lt;name&gt;\n</code></pre> <p>This chain becomes the target of banned IPs, which are somehow added (although I don't know how). --&gt;</p> <p>Fail2ban is an intrusion prevention framework written in Python and that runs as a service. It can be installed from most distributions' repos.</p> <p>The jail is a key concept in f2b that couples filters and actions definitions.</p> <p>Fail2ban is configured through .ini-format configs found in /etc/fail2ban. It is recommended not to edit the default configs ending in .config but rather to create a custom config called jail.local which will be automatically loaded by the service.</p> Example jail<pre><code>[sshd]\nenabled=true\nport=ssh\nfilter=sshd\nlogpath=/var/log/auth.log\nmaxretry=0\nfindtime=300\nbantime=3600\n</code></pre> <p>Failed logins can be checked by running lastb, and connections are also logged to SystemD. <pre><code>journalctl -ru sshd\n</code></pre></p> <pre><code># Display banned IPs\nfail2ban-client banned\n\n# Manually ban an IP\nfail2ban-client set sshd banip $IPADDRESS\n\n# Manually unban an IP\nfail2ban-client unban $IPADDRESS\n</code></pre>"},{"location":"Linux/Applications/ssh/#configuration","title":"Configuration","text":"<p>Server and client configuration both use the same set of keywords that can be defined inline on invocation or in config files.</p>"},{"location":"Linux/Applications/ssh/#client-configuration","title":"Client configuration","text":"<pre><code>Host home\nHostName 192.168.1.1\nUser root\nPort 50022\nSetEnv BAT_THEME=OneHalfLight # (1)\nLocalForward 8080 localhost:8080 # (2)\n</code></pre> <ol> <li>SetEnv allows environment variables to be set in a remote session.  However, these same environment variables must be explicitly specified in AcceptEnv key of the server configuration. This entry will set a specific syntax highlighting theme for use on the bat CLI utility. <pre><code>AcceptEnv BAT_THEME\n</code></pre></li> <li>The use of LocalForward here is equivalent to the use of the -L option at the command-line: <pre><code>ssh -L 8080:localhost:8080 $SERVER\n</code></pre></li> </ol>"},{"location":"Linux/Applications/ssh/#ssh-to-a-transient-server","title":"SSH to a transient server","text":"<p>To prevent recording a transient server to the client's known hosts file, for example when SSHing to many hosts from a single client, say while managing a corporate environment. <pre><code>UserKnownHostsFile /dev/null # (1)\nStrictHostKeyChecking no # (2)\n</code></pre></p> <ol> <li>UserKnownHostsFile</li> <li>StrictHostKeyChecking</li> </ol>"},{"location":"Linux/Applications/ssh/#canonical-hostname","title":"Canonical hostname","text":"<p>In corporate environments with verbose domain names, canonical hostnames can be configured to automatically append repetitive domain names (\"canonicalize\") to destination hosts.</p> <p>In this example, any connection made to a hostname beginning with \"server\" will append \"example.com\". <pre><code>Host server*\n    CanonicalDomains example.com # (1)\n    CanonicalizeHostname always # (2)\n</code></pre></p> <ol> <li>CanonicalDomains</li> <li>CanonicalizeHostname</li> </ol>"},{"location":"Linux/Applications/ssh/#server-configuration","title":"Server configuration","text":"<p>/etc/ssh/sshd_config is the configuration for the SSH server daemon.</p> <p>Disable cleartext passwords <pre><code>PasswordAuthentication no\n</code></pre></p> <p>Disable root login <pre><code>PermitRootLogin no\n</code></pre></p>"},{"location":"Linux/Applications/ssh/#commands","title":"Commands","text":""},{"location":"Linux/Applications/ssh/#endlessh","title":"endlessh","text":"Log verbosity<pre><code># Silent\nendlessh\n\n# Normal\nendlessh -v\n\n# Debug\nendlessh -vv\n</code></pre> Log verbosity<pre><code>LogLevel 0 # silent\nLogLevel 1 # normal\nLogLevel 2 # debug\n</code></pre>"},{"location":"Linux/Applications/ssh/#ssh-add","title":"ssh-add","text":"<p>ssh-add adds private key identities to the OpenSSH authentication agent, ssh-agent. Notably, ssh-add requires the SSH_AUTH_SOCK environment variable set by ssh-agent.</p> <p>When run without arguments, it adds the private keys found in ~/.ssh, i.e.</p> <ul> <li>id_rsa</li> <li>id_dsa</li> <li>id_ecdsa</li> <li>id_ecdsa_sk</li> <li>id_ed25519</li> <li>id_ed25519_sk</li> </ul> <pre><code>eval $(ssh-agent); ssh-add &lt;(cat \"$(keyFile.secureFilePath)\")\n</code></pre>"},{"location":"Linux/Applications/ssh/#ssh-agent","title":"ssh-agent","text":"<p>ssh-agent is a helper program that keeps track of identity keys and passphrases, allowing them to be used without further interaction, similar to SSO. Running it produces output that is meant to be used with the eval command in order to set the environment variables SSH_AGENT_PID and SSH_AUTH_SOCK, which are needed by ssh-add.</p> <pre><code>eval $(ssh-agent); ssh-add &lt;(cat \"$(keyFile.secureFilePath)\")\n</code></pre> <p>If only a single process is running, the -k option will kill it (although it is possible to fork multiple ssh-agent processes). <pre><code>ssh-agent -k # (1)\n</code></pre></p> <ol> <li>Equivalent to <pre><code>kill $SSH_AGENT_PID\n</code></pre></li> </ol>"},{"location":"Linux/Applications/ssh/#ssh-copy-id","title":"ssh-copy-id","text":"<p>This command copies the SSH public key to a specified account's ~/.ssh/authorized_keys file.</p> <p>In Windows, this command is not available, so a workaround is to simply pipe the public key over SSH itself.</p> <pre><code>type $env:USERPROFILE\\.ssh\\id_rsa.pub | ssh {IP-ADDRESS-OR-FQDN} \"cat &gt;&gt; .ssh/authorized_keys\"\n</code></pre>"},{"location":"Linux/Applications/ssh/#ssh-keygen","title":"ssh-keygen","text":"Generate host keys<pre><code>sudo ssh-keygen -A\n</code></pre>"},{"location":"Linux/Applications/syncthing/","title":"Syncthing","text":""},{"location":"Linux/Applications/syncthing/#syncthing","title":"SyncThing","text":""},{"location":"Linux/Applications/vim/","title":"vim","text":"<p>Unlike WYSIWYG editors which optimize input for writing text, vim optimizes for editing it. Vim offers a composable language for expressing these editing changes whose syntax can be composed into two elements, operations and text objects, which are analogous to verbs and nouns in language. YouTube</p> <p>The framework of understanding vim's syntax as a language appears to date back to an influential 2011 Stack Overflow post.</p> <p>On Unix-derived operating systems the main config file for Vim is placed at $HOME/.vimrc. On Windows it is placed at $HOME/_vimrc.</p>"},{"location":"Linux/Applications/vim/#syntax","title":"Syntax","text":""},{"location":"Linux/Applications/vim/#normal","title":"normal","text":"<p>Use <code>:normal</code> to define a series of normal-mode commands</p> Select all lines of a buffer<pre><code>:normal ggVG\n</code></pre>"},{"location":"Linux/Applications/vim/#keybindings","title":"Keybindings","text":"<p>There are two kinds of keybindings in Vim</p> <ul> <li>Recursive using command words <code>map</code>, <code>nmap</code>, <code>vmap</code>, etc. In these keybindings, the mapping itself is interpreted.</li> <li>Nonrecursive </li> </ul> <p>There are two types of keycodes:</p> <ul> <li>Vim keycodes which are identifiable as being in angle brackets: <code>&lt;Space&gt;</code>, <code>&lt;Return&gt;</code>, etc</li> <li>Terminal keycodes that appear similar to <code>^[[1;2A</code>. These may or may not be identifiable with the keycodes which the Linux kernel maps to raw keyboard scancodes. [ref][archwiki:Keyboard_input]</li> </ul> <p>The leader key is used to create more complicated keybindings using any arbitrary keypress, for example using <code>,</code> or <code>&lt;Space&gt;</code>.</p> <pre><code>let mapleader = ' '\n</code></pre>"},{"location":"Linux/Applications/vim/#autocommands","title":"Autocommands","text":"Autocommands expose an API that allows handling editor events like <code>BufNewFile</code>, <code>BufReadPost</code>, <code>BufWritePost</code>, <code>BufWinLeave</code>, and especially to implement functionality specific to filetypes. <p>Highlight added lines in green and removed lines in red in .diff files  <pre><code>filetype on\n\naugroup PatchDiffHighlight\n  autocmd!\n  autocmd FileType diff syntax enable\naugroup END\n</code></pre></p> <p>Turn syntax highlighting on only for certain filetypes  <pre><code>augroup PatchDiffHighlight\n  autocmd!\n  autocmd BufEnter *.patch,*.rej,*.diff syntax enable\naugroup END\n</code></pre></p>"},{"location":"Linux/Applications/vim/#color","title":"Color","text":"<pre><code>; Change the color of ELEMENT\nhighlight ELEMENT ctermfg=COLOR ctermbg=COLOR guifg=#abc123 guibg=#abc123\n\n; Select alternative colorschemes\n:colo[rscheme] &lt;tab&gt;\n\n; Display all available colorschemes\n:colo &lt;C-d&gt;\n</code></pre> <p>Clear custom color commands <pre><code>:highlight clear\n:hi clear\n</code></pre> Set file format to Unix/DOS <pre><code>:set fileformat=unix\n:set fileformat=dos\n</code></pre></p>"},{"location":"Linux/Applications/vim/#completion","title":"Completion","text":"<ul> <li>Context-aware completion</li> <li>Ctrl+X Ctrl+L</li> <li>Omni completion Ctrl+X Ctrl+O</li> </ul>"},{"location":"Linux/Applications/vim/#tasks","title":"Tasks","text":""},{"location":"Linux/Applications/vim/#invoking-to-a-specific-line-number","title":"Invoking to a specific line number","text":"<pre><code># Open with cursor at line 13\nvim .bashrc +13\n</code></pre>"},{"location":"Linux/Applications/vim/#configuration","title":"Configuration","text":"Configuration<pre><code>\" Prevent vim from creating backups files\nset nobackup\n\n\" Set relative line numbers\nset rnu\n</code></pre>"},{"location":"Linux/Applications/vim/#search-and-replace","title":"Search and replace","text":"<pre><code>\" Replace foo with bar across all lines, wherever they occur\n%s/foo/bar/g\n</code></pre>"},{"location":"Linux/Applications/vim/#mapping-keys","title":"Mapping keys","text":"Map Alt+J and Alt+K to move lines of text up or down <pre><code>nnoremap &lt;A-j&gt; :m .+1&lt;CR&gt;==\nnnoremap &lt;A-k&gt; :m .-2&lt;CR&gt;==\ninoremap &lt;A-j&gt; &lt;Esc&gt;:m .+1&lt;CR&gt;==gi\ninoremap &lt;A-k&gt; &lt;Esc&gt;:m .-2&lt;CR&gt;==gi\nvnoremap &lt;A-j&gt; :m '&gt;+1&lt;CR&gt;gv=gv\nvnoremap &lt;A-k&gt; :m '&lt;-2&lt;CR&gt;gv=gv\n</code></pre>"},{"location":"Linux/Applications/vim/#yanking-stdout","title":"Yanking STDOUT","text":"<p>To run a shell command from the normal mode command line, you simply run the <code>!</code> (\"bang\") command in normal mode. <pre><code>:!env\n</code></pre></p> <p>However to store the output of that command into a register, you must run a command like the following, which stores the output of the shell command into the a register. <pre><code>:let @a = system('env')\n</code></pre> The register signified by <code>@\"</code> will be placed into the buffer by the put command (<code>p</code>). <pre><code>:let @\" = system('env')\n</code></pre></p> <p>Alternatively <pre><code>:put =system('env')\n</code></pre></p>"},{"location":"Linux/Applications/vim/#filetype-associated-settings","title":"Filetype-associated settings","text":"Set indentation behavior specific to YAML<pre><code>autocmd FileType yaml setlocal ai ts=2 sw=2 et\n</code></pre>"},{"location":"Linux/Applications/vim/#plugins","title":"Plugins","text":"<p>Vim 8 supports native loading of plugins (put in $HOME/.vim/pack/start/</p> <p>vim-plug is a popular plugin manager.</p> <p>Install a plugin to provide Rust language support <pre><code>Plug 'rust-lang/rust.vim'\n</code></pre></p>"},{"location":"Linux/Applications/vim/#mouse-support","title":"Mouse support","text":"From here <pre><code>set mouse=a\n</code></pre>"},{"location":"Linux/Applications/vim/#language-definition","title":"Language definition","text":"<p>Syntax highlighting for various languages are stored in syntax files, stored in /usr/share/vim/vim82/syntax.</p> <p>Defining highlighting for pymdownx snippets</p> <pre><code>syn match markdownPymdownxSnippet '^-\\{2,}8&lt;-\\{2,} .*' \" (1)\nhi def link markdownPymdownxSnippet Error\n</code></pre> <ol> <li>Note that the quantifier specifying at least two instances of the preceding hyphen requires the initial brace to be escaped. However, the open angle bracket does not.</li> </ol>"},{"location":"Linux/Applications/youtube-dl/","title":"Youtube dl","text":""},{"location":"Linux/Applications/youtube-dl/#yt-dlp","title":"yt-dlp","text":"<pre><code># Download the highest quality stream in mp4 format\nyt-dlp -f 'bestvideo[ext=mp4]+bestaudio' $URL\n\n# Re-encode a video into mp4 and provide a filename\nyt-dlp --recode-video mp4 -o '%(upload_date&gt;%Y%m%d)s.mp4' $URL\n</code></pre>"},{"location":"Misc/","title":"Index","text":""},{"location":"Misc/#processing-cookbooks","title":"Processing cookbooks","text":"<p>Cookbooks are collections of tasks with representative implementations (e.g. Azure commands and procedures for the AZ-103.)</p> <ol> <li>Number tasks for easy reference, indexing, and linking in markdown</li> <li>Catalog tasks and desciptions in a spreadsheet</li> <li>Copy catalog with task and description to markdown. This will serve as both an index of tasks as well as the skeleton for the content. Use multiple cursors to introduce <code>####</code> heading syntax before the task identifier, followed by a carriage return before the one-line description of the task. This will ensure that the task is easily found by identifier. These should be collected in a single-cell table, producing a \"cloud\" of tasks.\"</li> <li>Fill markdown with syntax, producing a true reference of the source's syntax</li> <li>Map each form-based feature (e.g. commands) to tasks in a spreadsheet (Command | Task). Once organized by command, the resulting associations can form another table of content which associates form features to tasks. These should be placed in another single-cell cloud where each token is followed by links to the tasks in which it appears. The tokens should be organized, either by command group or roughly by domain.</li> <li>Index form-based features at the top of the markdown as a concordance.</li> </ol>"},{"location":"Misc/#bootloaders","title":"Bootloaders","text":"<p>bootloader: software located in the first sector (Master Boot Record) of a HDD, which is read by the BIOS - implementing interruptions requires knowledge of Assembler - expertise in low-level programming in C - Java and C# produce intermediate code, which must be executed by a special virtual machine - mixed-code technique requires at least two compilers (one for Assembler and C, another as a linker to join the *.obj files to create a single executable file)</p>"},{"location":"Misc/#bots","title":"Bots","text":""},{"location":"Misc/#discord","title":"Discord","text":"<ol> <li>Create the bot user on Discord and register it with a guild.</li> <li>Write code that uses Discord\u2019s APIs and implements your bot\u2019s behaviors.</li> </ol> <p>Create a Discord connection ^ A <code>Client</code> is an object that represents a connection to Discord, handling events, tracking state, and interacting with Discord APIs. <pre><code># bot.py\nimport os, discord\nfrom dotenv import load_dotenv # Install via `pip install -U python-dotenv`\n\nload_dotenv()\ntoken = os.getenv('DISCORD_TOKEN')\n\nclient = discord.Client()\n\n@client.event\nasync def on_ready():\n  print(f'{client.user} has connected to Discord!')\n\nclient.run(token)\n</code></pre> Store token in <code>.env</code> file <code>.env</code> should be placed in the same directory as <code>bot.py</code> <pre><code># .env\nDISCORD_TOKEN={your-bot-token}\n</code></pre></p>"},{"location":"Misc/#twitch","title":"Twitch","text":"<ul> <li>Nightbot</li> <li>Mee6</li> </ul>"},{"location":"Misc/#ruby-bot-programming","title":"Ruby bot programming","text":"<p>Ruby library \"socket\" allows integration with Twitch's IRC API, which provides an oauth token which can be stored as password. Command <code>write_to_system</code> appears to be  what is needed to concatenate IRC commands <code>PASS #{@password</code>, <code>NICK #{@nickname}</code>, <code>USER #{@nickname} 0 * #{@nickname}</code>, and <code>JOIN #@{channel}</code>\\ From the REPL, you instantiate an instance of the class after running the script, which will allow passing messages to the chat room by using an instance method ^ <pre><code>bot = TwitchBot.new\nbot.write_to_chat \"Hello world\"\n</code></pre></p>"},{"location":"Misc/#vmware","title":"VMware","text":"<p>Hypervisor, similar to Hyper-V, but provided at a cost, with a robust command-line interface via PowerShell. ^</p>"},{"location":"Misc/Akro-Mils/","title":"Akro-Mils","text":"<p>*: already own</p> <p>Giant bins for cube storage</p> Bin Length divider H L W $ ea. 30260* 40260 10.000 18.000 11.000 25.67 30280 6.000 20.000 12.375 17.53 <p>Cabinets </p> <p>&lt;21\" of horizontal room</p> Bin Length divider H L W $ ea. 30230* 40230 5.000 10.875 5.000 5.27 30235* 40230 5.000 10.875 11.000 9.18 30255 40230 5.000 10.875 16.500 11.00 <p>Pantry closet</p> <p>&lt;25\" of horizontal room</p> Bin Length divider H L W $ ea. 30120 n/a 4.000 11.625 4.125 2.77 30150 n/a 4.000 11.625 8.375 3.47 30040 n/a 6.000 11.625 4.125 4.18 30080 n/a 6.000 11.625 8.375 5.71 S-13396 n/a 4.000 12.000 4.000 1.45 S-13398 n/a 4.000 12.000 8.500 2.65 S-16257* n/a 6.000 12.000 4.000 2.60 S-16277* n/a 6.000 12.000 8.500 4.50"},{"location":"Misc/CI-CD/","title":"CI/CD","text":""},{"location":"Misc/CI-CD/#github-actions","title":"Github Actions","text":"<p>All that's needed is a yaml file in .github/workflows with the following keys: YouTube - <code>name</code> - <code>on</code> - <code>jobs</code></p> <p>In order to use the  Python projects need to have a .spec file </p> <p>GitHub actions can be either Docker or JavaScript</p> <pre><code>name: Build and publish presentation with reveal-md\non: push\njobs:\nrelease:\nname: Build &amp; Publish\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v1\n- name: Install dependencies and build presentation\nrun: | sudo npm install -g reveal-md --unsafe-perm\nsudo reveal-md Presentation.md --static _site --highlight-...\n</code></pre>"},{"location":"Misc/CI-CD/#on","title":"on","text":"<p>src <pre><code>on:\npush:\nbranches:\n- main\n</code></pre></p>"},{"location":"Misc/CI-CD/#jobs","title":"jobs","text":"<p>src</p> <pre><code>jobs:\nrelease:\nif: github.actor == 'JackMcKew' &amp;&amp; startsWith(github.event.head_commit.message, 'Update README')\nname: Build\nruns-on: ubuntu-latest\nsteps:\n\n- uses: actions/checkout@v1\n- name: Set up Python 3.7\nuses: actions/setup-python@v1\nwith:\npython-version: 3.7\n\n- name: Install dependencies &amp; Convert README.ipynb\nrun: |\npython -m pip install --upgrade pip\npip install -r requirements.txt\njupyter nbconvert --template \"pythoncodeblocks.tpl\" --ClearMetadataPreprocessor.enabled=True --ClearOutput.enabled=True  --to markdown README.ipynb\n- name: Commit files\nrun: |\ngit config --local user.email \"action@github.com\"\ngit config --local user.name \"GitHub Action\"\ngit add README.md\ngit commit -m \"Convert README.ipynb to README.md\" -a\n- name: Push changes\nif: success()\nuses: ad-m/github-push-action@master\nwith:\nbranch: main\ngithub_token: ${{ secrets.ACCESS_TOKEN }}\n</code></pre>"},{"location":"Misc/Cars/","title":"Cars","text":"<p>Commute to work is 24.3 miles one direction</p> <p>The compact sedan segment has been dominated recently by the Mazda3, with competition among the Honda Civic, Toyota Corolla, Kia Forte, and VW Jetta.</p> Brand Crossover CUV Honda CR-V HR-V Hyundai Tucson Kona Kia Sportage Seltos, Soul Mazda CX-5 CX-30 Nissan Murano Toyota RAV4 C-HR"},{"location":"Misc/Cars/#hyundai","title":"Hyundai","text":"Dealership Cars Brandon Hyundai Tucson, Tucson Hybrid Courtesy Hyundai of Tampa Tucson, Tucson Hybrid"},{"location":"Misc/Cars/#hyundai-kona","title":"Hyundai Kona","text":""},{"location":"Misc/Cars/#hyundai-tucson","title":"Hyundai Tucson","text":"Year, Model Mileage (k mi) Cost (k USD) 2018 Hyundai Tucson Limited 51.4 20.7+ Care Package 2.0+ Dealer Fee 1.0 2018 Hyundai Tucson Value 14 25.0 2023 Hyundai Tucson Hybrid Blue New 33.6 2022 Hyundai Tucson Hybrid SEL Convenience 29 33 2022 Hyundai Tucson Hybrid Blue 16 35 2023 Hyundai Tucson Hybrid Blue New 33.6 2023 Hyundai Tucson Hybrid Blue New 33.3 <p>The Tucson had a refresh for the 2022 model that introduced a lot of new technology and made the Tucson one of the roomiest options in the segment.</p> <p>The Tucson Hybrid, which uses a 1.6L turbo GDI I-4, is not much more expensive than the gas, but offers much more torque and 30% better fuel economy in a stepped automatic transmission. This gives it segment-leading acceleration. Non-hybrid Tucson trims all use the same 2.5L engine, which was described as lethargic. It is a well-rounded car that feels like it's well put-together.</p> <p>Used models of the latest generation of the Tucson Hybrid are available in the 30s. Courtesy Hyundai offers 0% APR for 48 months on the Tucson (excluding the Hybrid).</p> <p>The third generation (2005-2021) was notable for being much smaller than competitors, almost the size of a hatchback.</p> <p>The most common engine for this generation was a 2.0L four-cylinder (164 hp/151 lb. ft.) paired with a 6-speed automatic transmission. But a powerful 1.6L turbocharged four-cyclinder engine (175 hp/195 lb. ft.) had been available to Value and Limited trims before being discontinued in 2019 along with the 7-speed dual-clutch which was paired with it. This turbocharged engine was replaced by a 2.4L naturally aspirated four-cylinder (184 hp/ 175 lb. ft.), the same as that available in the Kia Sportage. Performance with this naturally aspirated engine was noted for being anemic with poor gas mileage.</p> <p>Android Auto became available in 2017.</p> <p>Of the various trims, the Value has a panoramic sunroof and parking sensors, which are lacking in the Sport.</p>"},{"location":"Misc/Cars/#infiniti","title":"Infiniti","text":""},{"location":"Misc/Cars/#infiniti-qx30","title":"Infiniti QX30","text":"<p>The Infiniti Q30 was sold between 2016 and 2019 as a premium hatchback. The QX30, with higher ground clearance, is described as a subcompact luxury crossover that was designed to straddle the border between hatchback, wagon, and crossover segments. The QX30 targets premium city-dwelling customers or first-time luxury buyers who couldn't otherwise afford the Q50, which had been Infiniti's previous entry-level model.</p> <p>The QX30 is based on the third-generation Mercedes-Benz A-class chassis, and so uses many Mercedes-Benz parts. It is built in the QX30 factory in Tennessee.</p>"},{"location":"Misc/Cars/#jaguar","title":"Jaguar","text":""},{"location":"Misc/Cars/#jaguar-f-pace","title":"Jaguar F-PACE","text":"<p>Introduced in 2017...</p>"},{"location":"Misc/Cars/#kia","title":"Kia","text":"<p>Two dealerships in the Tampa area:</p> <ul> <li>Century Kia</li> <li>Courtesy Kia of Brandon</li> </ul>"},{"location":"Misc/Cars/#kia-sportage","title":"Kia Sportage","text":"Year, Model Mileage (k mi) Cost (k USD) 2019 Kia Sportage SX 60.3 21.2+ Dealer Fee 1.022.2 2020 Kia Sportage SX 56.0 22.5+ Dealer fee 1.2+ Reconditioning 1.0+ Paint 1.526.2 2023 Kia Sportage EX New 29.8 2023 Kia Sportage EX New 30.2 2020 Kia Sportage EX 39 28.0 2018 Kia Sportage LX 25 21.0 2019 Kia Sportage LX 23 22.0 2020 Kia Sportage S 24 26.0 <p>The fifth-generation refresh is built on the N3 platform. It offers a hybrid 1.6L turbo 4-cylinder with 38 mpg city and highway. Unlike the Tucson, Kia offers FWD.</p> <p>EX trims and up have a 12.3 inch display, whereas lower trims have only an 8 inch.</p> <p>SX trims since 2011 have offered a turbocharged 2.0L four-cylinder engine (237 hp/260 lb. ft.).</p>"},{"location":"Misc/Cars/#kia-forte","title":"Kia Forte","text":"Year, Model Mileage (k mi) Cost (k USD) 2019 Kia LXS 48 19.0 2019 Kia LXS 45 19.0 2021 Kia LXS 39 21.0 <ul> <li>EX has cooled seats</li> <li>good stereo</li> <li>better option than the sister Hyundai Elantra</li> <li>FWD</li> </ul>"},{"location":"Misc/Cars/#kia-optima","title":"Kia Optima","text":"<p>The previous generation Kia Optima offers an impressive 2.0L turbo four-cylinder paired with a dual-clutch transmission.</p>"},{"location":"Misc/Cars/#kia-seltos","title":"Kia Seltos","text":"<p>A new subcompact SUV offering introduced in 2021, designed to imitate the Land-Roveresque cues of the hot-selling Telluride. It comes with a Bose sound system for higher trims, although there is very poor noise insulation.</p> <p>LX, S, and EX trims use the same 2.0L i4 found in the Forte, paired with a CVT, starting around $24,900.</p> <p>S and SX trims have a torquey 1.6L turbo i4 paired with a 7-speed dual-clutch transmission and AWD standard.</p> <p>No ventilated seats.</p>"},{"location":"Misc/Cars/#kia-soul","title":"Kia Soul","text":"<p>The Kia Soul is the last survivor of the box car segment and has even been Kia's most successful model. In 2017 the top of the-line Exclaim model was introduced with a 1.6L turbo four-cylinder.</p> <p>The Soul was introduced in 2010 and each model year introduced iterative changes.</p> <p>After 2020, the Base, Plus (+) and Exclaim (!) trims were renamed LX, S, and EX, although the 1.6L turbocharger that was previously available to the Exclaim was exclusively relegated to the new Turbo trim. In the 2020 year only, this Turbo trim was confusingly called the GT-Line Turbo. The non-turbo GT-Line trim, despite its name, did not feature an engine or performance different from that of the other trims.</p> <p>In 2023 the turbo option was dropped entirely.</p> <p>The Kia Soul LX is available new from $22,000.</p> Year, Model Mileage (k mi) Cost (k USD) 2018 Kia Soul ! 48.5 17.0 2022 Kia Soul Turbo 27.6 24.0 2023 Kia Soul LX New 21.7 2023 Kia Soul LX New 21.9"},{"location":"Misc/Cars/#mazda","title":"Mazda","text":"<p>| Dealership                                                       | Cars                                                                                                                                | Fees                                       | | ---------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- | | Ferman Mazda of Brandon | CX-30, CX-5 | | Westshore Mazda                | CX-5                                                                           | | Mazda of Wesley Chapel   | CX-5                                              | $1199 dealer fee plus \"reconditioning fee\" |</p>"},{"location":"Misc/Cars/#mazda-cx-5","title":"Mazda CX-5","text":"Year, Model Mileage (k mi) Cost (k USD) 2019 Mazda CX-5 Signature 62.6 23.5- Financing 1.0+ Dealer fee 0.9+ Electronic filing fee 0.2+ OPC Connect 0.524.1 2023 Mazda CX-5 2.5 S New 28.1 2020 Mazda CX-5 Signature 13.0 32.0 2020 Mazda CX-5 Signature 23.5 28.9 2020 Mazda CX-5 Signature 33.2 29.6 <p>The sportiest and best trim of the compact crossover segment (competing with the Honda CR-V and the Toyota RAV-4).</p> <p>These models predominantly used a 2.5L turbo I-4 engine  (as of the 2019 year and later) which always came paired with AWD.  Naturally aspirated engines are much more common and, in used cars, much less expensive. But the 6-speed transmission is a weakness that shortchanges the engine, especially in comparison with competitors with have moved to a CVT in the case of Honda or an 8-speed tranmission in the case of Toyota.</p> <p>The 2019 refresh introduced Android Auto and Apple CarPlay as a standard feature, although older models can be retrofitted at additional cost.</p> <p>The 2021 refresh introduced a 10 inch screen and upgraded backup camera which are highly recommended over the 2020 model.</p> <p>The 2022 refresh introduced a new, larger key fob as well as reshuffled trim tiers: the new Signature trim is fully-loaded.</p> <p>New CX-5s start from $28,000 and up. Turbo-equipped CX-5s run from $35,000 and up.</p>"},{"location":"Misc/Cars/#mazda-cx-30","title":"Mazda CX-30","text":"Year, Model Mileage (k mi) Cost (k USD) 2020 Mazda CX-30 Preferred 41 24.0 <p>The CX-30 is a subcompact crossover launched in 2020, competing with the smaller vehicles like the Honda HR-V and Toyota CH-R.</p> <p>Like the Mazda3 on which it is based, it incorporates many improvements to the interior and user experience. It uses the same naturally aspirated 2.5L I-4 found in the Mazda3 and CX-5, although turbocharged trims appear to be available at considerable markup.</p> <p>The Preferred Trim has a Bose sound system. And as with other vehicles, Mazda prefers the driver not to have the added distraction of a touchscreen and insists that the infotainment system be controlled using the control knob.</p> <p>New CX-30s run in the mid- to high 20s.</p>"},{"location":"Misc/Cars/#mazda3","title":"Mazda3","text":"<p>Too small</p> <p>The latest and current generation was introduced in 2019. Three main trim levels are Select, Preferred, and Premium, with all trims available in FWD and AWD.</p> <p>Mazda put a lot of effort into redesigning and improving the interior, from physical controls to the center console to the improved 8.8 inch screen and command knob. Changes to the driving experience are a marked improvement from the previous generation.</p> <p>The naturally aspirated engine (2.5L i4, 186 hp and 186 lb-ft.) has anemic performance, but the turbocharged version (2.5L turbo i4, 227 hp, 310 lb-ft) are class-leading, aside from performance-focused specialty models like the Civi Type R.</p>"},{"location":"Misc/Cars/#nissan","title":"Nissan","text":""},{"location":"Misc/Cars/#rogue","title":"Rogue","text":"Year, Model Mileage (k mi) Cost (k USD) 2018 Nissan Rogue SV 18 25.0 <p>The Rogue was refreshed in 2021. Used previous generation Rogues appear to offer Android Auto, adaptive cruise, and similar features at reasonable prices The driving experience is unremarkable and inoffensive. The 2.5L 4-cylinder dates from 2002 and feels sluggish paired with a CVT.</p>"},{"location":"Misc/Cars/#toyota","title":"Toyota","text":""},{"location":"Misc/Computers/","title":"Computers","text":"Item Cost (USD) Rosewill chassis (15 bays) 225 Chassis railkit 72 Asus ROG Strix X570-F 200 Radeon RX 6600 XT 360 Ryzen 7 5700 G 300 Power Supply 120 32 GB DDR4 RAM 130 SATA Expansion card 61 GPU VRAM (GB) PassMark Cost (USD) Asus Radeon RX 6600 XT 8 15862 480 XFX Radeon RX 6600 XT 8 15862 360 ASRock Radeon RX 6600 XT 8 360 CPU Cores (threads) Cost Ryzen 7 5700G (APU) 8 (16) 299 Ryzen 7 5700X 8 (16) 287 Ryzen 5 5600 6 (12) 200 Ryzen 7 5800X 8 (16) 315 Ryzen 7 4700G 8 (16) 240"},{"location":"Misc/Computers/#stan-nas","title":"Stan NAS","text":""},{"location":"Misc/Computers/#cases","title":"Cases","text":"Picture Form factor 3.5\" bays Cost (USD) Mini-ITX 024 7088106 Mini-ITX 1 170 Mini-ITX 4 85 Mini-ITX 5 145"},{"location":"Misc/Computers/#motherboards","title":"Motherboards","text":"Model Form Factor SATA ports M.2 slots Price ASRock A520M Mini ITX 4 1 105 ASRock B550 Phantom Mini-ITX 4 2 170 ASUS ROG STRIX B450-I Mini-ITX 4 2 178 ASUS ROG Strix X570-I Mini-ITX 4 2 265"},{"location":"Misc/Diaz/","title":"Joey Diaz","text":"<ul> <li> Chinese restaurants in Boulder, CO </li> <li> Puerto Rican Nelson </li> <li> Ralphie May falling on a dollhouse </li> </ul>"},{"location":"Misc/Intelligence/","title":"\ud83d\udd0e Intelligence","text":"<ul> <li>Inside the military's secret undercover army  </li> </ul>"},{"location":"Misc/Intelligence/#china","title":"China","text":"<p>Chinese writers often wrote on intelligence matters in contrast with Western writers[^1]</p> <ul> <li>Historical writings on intelligence continue to be used by military institutions of PRC</li> <li>Fragments of earlier works \u201cprotobooks\u201d survive in later works.</li> </ul> <p>Sunzi wrote that warfare must be undertaken only after a comprehensive analysis of relative strengths and weaknesses of combatants, the world\u2019s first net assessment procedure. He also advocated deception on the battlefield. Later writers responded to </p> <p>Sunzi, updating and interpreting his precepts: Guan Zhong Li Quan, Li Jing.</p> <p>Sunzi condemned generals who failed to gather necessary intelligence and disparaged divination and consulting ancestors in favor of hard intelligence. Later writers like Shi Zimei also upbraided rulers who ignored these rules. Works advocating covert action - Toubi Fuban - Warring States period works on statecraft, e.g. Han Feizi</p> <p>Sunzi\u2019s Five Types of Spy</p> <ol> <li>Local Spy: Knowledgeable spies living outside their native habitat, including emigrants, travelers and exiles (e.g. defectors)</li> <li>Internal spy: Officials</li> <li>Turned spy: Double agent</li> <li>Living spy: Talented people dispatched abroad to observe and then report back</li> <li>Dead spy: Spies deliberately sent on suicide missions without their knowledge. \u00a0Enemy agents could also be deceived and provided with false information, causing them to be executed when they report false information to their masters.</li> </ol>"},{"location":"Misc/Intelligence/#subversion","title":"Subversion","text":"<p>By end of Spring and Autumn Period, subversion was an accepted goal of espionage. Assassination used most often in periods of fragmentation.  Six Secret Teachings compiled two chapters on systematic programs of subversion. \u00a0These two chapters, with Sunzi\u2019s \u201cEmploying Spies\u201d in Art of War formed the basis of espionage as late as the Ming Dynasty. Later military writers also devoted at least a few paragraphs to subversion: Le Quan\u2019s Techniques for Secret Plots, Huqian Jing, Bingfa Baiyan. These took historical and semihistorical episodes as examples (Wu Yue Chunqua). Covert action and subversion used by Qin in the western hinterland. </p>"},{"location":"Misc/Intelligence/#debauching-kings","title":"\u201cDebauching\u201d kings","text":"<p>Sunzi: \u201cYou must first know the names of the defensive commander, his assistants, staff, door guards, and attendants for any armies that you want to strike, cities you want to attack, and men you want to assassinate.\u201d</p>"},{"location":"Misc/Intelligence/#egypt","title":"Egypt","text":"<p>Egyptian intelligence had its origins in the urban policing organizations established during the British Khedive and occupation.</p> <p>Mamur Zapts were the de facto chiefs of secret police in Cairo and Alexandria, operating networks of mukbireen informants, by the time of British occupation in 1882.</p> <p>The Central Special Office (CSO) was established in 1911 after the Coptic Prime Minister was assassinated by a young nationalist.  When discontent exploded in 1919, and CSO couldn\u2019t respond effectively, the Interior Ministry formed the Special Section (SS) to centralize intelligence collection.  CSO was closed and files transferred to SS in 1925.</p> <p>Egyptian Military Intelligence was being indigenized in the late 1930s.  MI officers were complicit in the army coup of 23 July 1952.  Once the Free Officers were in power, they set about creating a new intelligence community.  The Military Intelligence Directorate (MID) as it was then called, became active in covert action and subversion across the Middle East and Africa.</p> <p>Fear of communist subversion fueled the creation of the General Intelligence Directorate (GID), subordinate to the Interior Minister, which was led at first by Zakaria Muhi al-Din and stood up within months of the coup. GID inherited and took the place of the old political police organs.  GID was renamed the State Security Investigations Service (SSIS) in 1971.</p> <p>As part of Gamal Abd al-Nasser\u2019s emphasis on covert action, the Egyptian General Intelligence Service (EGIS) was established by March 1954, also headed by Zakaria Muhi al-Din.  EGIS was the capstone of the new Egyptian government\u2019s emphasis on projecting influence through covert action, and it was modeled after the CIA. During the heyday of Egyptian subversion abroad, Salah Nasr was EGIS Director.</p> <p>Egyptian covert action grew out of the effort to end the British occupation, remove British influence from government organs, and eject the British from the Canal Zone. In 1952, MID created a Special Resistance Office to form a guerrilla army against British military units based along the Suez Canal. The campaign became the template for Egyptian subversion abroad for the next decade and half. MID also sent officers to Sudan to recruit sources and build influence for possible unity with Sudan.  While Egypt occupied the Gaza Strip, Palestinian infiltrators were a source of irritation for MID. However, MID sponsored infiltrations using Bedouins, Palestinians, and even its own scouts for intelligence-gathering. These infiltrations eventually were made from southern Lebanon as well. The death of an Israeli settler during one such raid sparked a cycle of reprisals that led to war. The four years after the British withdrawal from the Suez in 1956 marked Egypt at the height of its regional power. Nasser was the hero of the Arab world, and Cairo was the wellspring of a vigorous new Pan-Arab nationalism. However, Egyptian subversion against conservative Arab states and British protectorates was checked in many places by the United States. After Egypt and Syria joined the United Arab Republic (UAR), Nasser began covert action campaigns in Jordan and Lebanon, combining subversion with radio propaganda. In Lebanon, UAR meddling triggered a larger crisis that drew the attention of the US and ended Egyptian arming of Lebanese insurgents. A 1958 coup in Iraq initially drew feelersfrom the Egyptians, who hoped to draw Iraq into their circle of influence. However, old animosities arose again, and by 1959 Egypt was broadcasting radio propaganda, and senior UAR spymasters backed a short-lived army revolt in Mosul. Alienated by Nasser, Saudi Arabia fended off feeble Egypt\u2019s attempts to use its military presence and attache corps there for subversion. Nasser created African Affairs Branch, led by Mohamed Fa\u2019iq, to pursue Egyptian interests clandestinely across Africa. Key targets were Ethiopia and Congo. Egypt promoted Eritrean Liberation Front (ELF) after Suez Crisis and assisted Eritrean declaration of independence by 1960. Close relations with Somalia, which also had territorial disputes with Ethiopia. Egypt provided money, arms to friendly regime in Congo, flew Ghanaian and Egyptian troops to prop up regime.  Also provided arms to resistance movements in Angola, Cameroon, Nigeria, and Portuguese Guiana, and training to Congo Brazzaville and Tanzania. MID broke down under pressure of war. Israelis had strong SIGINT and intercepted an insecure phone call between Nasser and King Hussein. Israel also captured a valuable cache of Egyptian intelligence documents in Gaza on MID\u2019s Palestinian infiltrators.</p> <p>Voice of the Arabs (VOA) served as a propaganda arm buttressing Egypt\u2019s foreign subversion policies. Daily radio programming was handled by Egyptian State Broadcasting (ESB) and used transmitters supplied by CIA. ESB turned to former Nazi propagandists, who must have felt at home with anti-Jewish programming. ESB grew out of EGIS promotion of VOA. EGIS had a representative on ESB\u2019s board of directors.  EGIS was also responsible for running clandestine radio stations, reliant usually reliant on mobile transmitters. Voice of the Arab Nation targeted Iraq during the 1956 war when the British and French knocked out overt ESB transmitters. Egypt also operated a clandestine radio station called Voice of Free Iran in the early 1960s and gave support to anti-shah clerics. </p> <p>Egyptian intelligence had been preparing Yemen for subversion since 1950s. VOA broadcasted propaganda, and the signal to begin the coup in September 1962 was delivered by VOA.  Egyptian army was overwhelmed by Yemeni rural insurgency, because Cairo didn\u2019t plan for a long war. No good cultural intelligence on Yemeni tribes. Intervention antagonized Great Britain and Saudi Arabia. MID provided training to National Liberation Front (NLF) which was set up by Egypt as an anti-British umbrella organization. NLF systematically kidnapped, tortured, and executed Aden SB officers and informants. Egypt still relied on broken Enigma-based encryption. GCHQ and NSA had access to military COMINT. Despite successful Egyptian-backed coup and energetic covert action campaign against British Protectorate in South Yemen, Egypt could not maintain political leverage over Yemen. South Yemen turned to GDR for intelligence training.</p> <p>The British were Egypt\u2019s first instructors in counterintelligence, and also some of its first victims. MI and Cairo SB busted a German spy ring in cooperation with British intelligence (The Key to Rebecca). Operation Susannah was an Israeli terror plot meant to undermine international faith in Cairo\u2019s ability to secure the Suez Canal. In 1954, an Israeli case officer activated sabotage cells among the remaining Egyptian Jewry. Egyptians doubled the Israeli case officer and rolled up the ring. Huge success for nascent Egyptian CI and was an impetus in formation of EGIS. GID rolled up a spy network led by the British expat James Swinburn in 1956. Unfortunately, this had the knock-on effect of forcing the British to rely on their formidable SIGINT collection. GCHQ had broken Egypt\u2019s diplomatic cipher and routinely intercepted Egyptian military communications. Egyptian CI penetrated several Israeli spy rings after the Suez War. The Goudswaard Ring of European and Egyptian nationals was recruited by Mossad. Eventually the GID turned them and were using them to pass disinformation. The Thomas Ring gathered military documents and passed them to Israel in microfilm hidden in furniture which was then exported. In 1961, GID rolled up this network. In the run-up to the Yom Kippur War, Egyptian denial and deception extended to their erstwhile allies the Soviet Union. Soviet photoreconnaissance satellites monitored the war. After the Yom Kippur War, CIA resumed its relationship with Egypt, and along with providing training and equipment, CIA began to aggressively recruit from throughout Egyptian society. Egypt joined the Safari Club (a coalition of intelligence agencies from France, Saudi Arabia, Iran, and Morocco), which provided aid to Zaire, Somalia, Djibouti and anti-Qadhafi groups in Libya and Egypt as well as the Afghan resistance. After Camp David, Egyptian intelligence had to contend with Libyan subversion and radio propaganda, mimicking Egyptian tactics of yore. Covert action escalated to a short border war in 1977. Libyan subversion continued, and in 1978 SSIS uncovered a clandestine organization for the \u201cliberation\u201d of Egypt through sabotage and assassination. Egypt also stopped an Iranian who planned to undermine the peace process by conducting and bomb attacks in Egypt. In 1979, Egyptian CI began a covert war with Soviet and East European services. SSIS claimed to have uncovered a Bulgarian intelligence network that year. In 1981, Soviet and Hungarian diplomats were expelled after Egyptian security discovered a spy ring allegedly inciting sectarian unrest.</p> <p>Israel attempted to subvert Egypt early on by using the Jewish population in Cairo and Alexandria as a base. IDF created sabotage cells which were activated in 1954 when Egypt and UK were negotiating a British withdrawal from the Canal Zone. Operation Susannah was rolled up, and the operatives brutally tortured in a MID prison. The case had political  ripple effects within Israel that reached into the 1960s.</p> <p>Several Israeli spy rings were rolled up in the late 1950s and 1960s. The Goudswaard Ring, run by Mossad in a false-flag operation that posed it as a NATO service, was doubled and began passing disinformation. The Thomas Ring, which gathered military documents and passed them to Israel in microfilm hidden in exported furniture, was rolled up by GID in 1961.</p> <p>EGIS claimed to have run a \u201csuper-spy\u201d named Jack Bitton before and during the Six-Day War (1967). Bitton opened a travel agency in Tel Aviv in in 1954 or 1955. Some claim he was doubled by the Israelis, but Egypt claims he provided warning of Israel\u2019s attack through his contacts with senior Israelis. For Egyptians, Bitton is Egypt\u2019s master spy and the subject of a highly popular television serial in the 1980s.</p> <p>Israeli spy Wolfgang Lotz mapped out Egypt\u2019s SAM facilities and other important military infrastructure. Israel also operated an agent \u201cSulayman\u201d who reported the movements of individual Egyptian units during the war. Sulayman may have provided encryption material, because Israeli MI (Aman) broke Egypt\u2019s military cipher before the war.</p> <p>Israeli deception measures went undetected by the Egyptians. IDF created an entire fake military unit in Eilat, complete with encrypted and unencrypted radio traffic, which succeeded in tricking the Egyptians.</p> <p>In the run-up to the Yom Kippur War, Egypt suffered from COMSEC shortfalls which were aggravated by excellent Israeli SIGINT. After the 1967 war, Israeli SIGINT stations on the banks of the Suez could reach deeper into Egypt. Israel even planted listening devices on communications lines used by an Egyptian headquarters complex. Egyptian CI also discovered bugs in hollowed-out telephone poles which Israel was using to tap military communications between Red Sea bases and Cairo. Israel\u2019s \u201cTop Source\u201d, Ashraf Marwan, was turned by the Egyptians before the onset of war and gave false warnings of Egyptian attack that cost Israel money and lulled it into a state of complacency.</p> <p>Anwar Sadat and MID formulated a plan of strategic deception to accomplish diplomatic victory in a limited war (British deception before Battle of el-Alamein). EGIS planted deceptive media stories on military unpreparedness. Military coordinated movements to avoid US imagery satellites. Brinksmanship produced calm-alarm-calm cycle that bred complacency in Israelis. Egyptians improved intelligence collection by recruiting Bedouins and obtaining valuable intelligence on Israeli plans and codenames. Also leveraged OSINT. Ashraf Marwan, Sadat\u2019s new presidential gatekeeper, was recruited by Israel but doubled by Egyptians, gave false warnings of imminent attacks. After early success in the war, Israelis exploited weaknesses and were ready to pounce when ceasefire was declared. Egypt and Israel made peace and began sharing intelligence on Palestinians.</p> <p>Sources:</p> <ul> <li>Sirrs, Owen L. The Egyptian Intelligence Service: A History of the Mukhabarat, 1910-2009 (Studies in Intelligence).</li> </ul>"},{"location":"Misc/Intelligence/#finland","title":"Finland","text":"<p>Finnish economy\u2019s reliance on technology is growing and so is economic espionage. \u00a0National innovation system is considered protected.</p> <p>Finland\u2019s intelligence community - Finnish Security Intelligence Service (Suojehpolisi, Supo) has been performing counterespionage, counterterrorism, and security since 1949. \u00a0 - Finnish Military Intelligence Command (FINMIC) is under Defense Command\u2019s Intelligence Division. \u00a0 - Finnish Intelligence Research Establishment (Viestikoelaitos) is Finnish Defense Force\u2019s (FDF) SIGINT unit, under Finnish Air Force (FAF).</p> <p>Predecessors to Supo - Detective Central Police (Etsiva keskuspoliisi) 1919-1937 - State Police (Vattriollinen poliisi, Valpo) 1937-1949 - Red Valpo, when dominated by Communists, 1945-1949 - Finnish Security Police est. 1949, name changed to Supo 2010.</p>"},{"location":"Misc/Intelligence/#organizational-structure","title":"Organizational structure","text":"<p>Supo is subordinate to the Ministry of Interior, while other Nordic services are subordinate to the Ministry of Justice. \u00a0Supo handles no foreign HUMINT sources. Four organizational reforms over past 20 years - In 1992, Supo had three directorates: Counterespionage, Security, and Development and Support - In 1998, operational and development matters were divided more clearly - In 2004, Supo was reorganized to develop research and analysis functions. \u00a0Line organization was introduced. - In 2009, Supo was divided into Operational and Strategic Branches.      - Operational Branch: Counterespionage Unit, Counterintelligence Unit, Security and Regional Unit, Field Surveillance Unit     - Strategic Branch: Situational Awareness Unit, International Relations Unit, Internal Surveillance Unit     - Communications Office directly subordinate to C/Supo</p>"},{"location":"Misc/Intelligence/#personnel","title":"Personnel","text":"<p>Supo employs 220 people and has a 17 million euro budget. - 55% are police personnel (30% command, 40% senior, 30% officers) - 1/3 of employees have a degree - Average age of 44 years</p>"},{"location":"Misc/Intelligence/#iran","title":"Iran","text":"<p>In 1978-1979 (1357 H.S.) some former SAVAK officers revealed what they knew in a televised news conference.</p> <p>SAVAK had 9 or 10 chief directorates:</p> <ol> <li>First Chief Directorate: administration</li> <li>Second Chief Directorate: foreign intelligence</li> <li>Third Chief Directorate: internal security</li> <li>Fourth Chief Directorate: counterintelligence</li> <li>Fifth Chief Directorate: technical espionage, including telephone intercept and clandestine audio recordings, censorship, photography, and flaps and seals</li> <li>Sixth Chief Directorate: budgeting</li> <li>Seventh Chief Directorate: analysis, including compilation of daily \"bulletins\"</li> <li>Eighth Chief Directorate: counterespionage</li> <li>Ninth Chief Directorate: individual biographies and passport affairs</li> <li></li> <li> <p>Iraj Faridi, former chief of operations of the first section of the Third Chief Directorate, mentioned the Trident intelligence agreement but seemed to think the relationship with Turkey, not Israel, was sensitive. He claimed to have 17 years of service in SAVAK during the press conference.</p> </li> <li>Mohsen Toluei</li> </ol>"},{"location":"Misc/Intelligence/#trident","title":"Trident","text":"<p>A three-way intelligence sharing agreement between Iran, Israel, and Turkey. This was prominently covered by the press when former Mossad officer Yossi Alpher published his book Periphery: Israel's Search for Allies in the Middle East.</p>"},{"location":"Misc/Intelligence/#russia","title":"Russia","text":"<p>Kouzminov, Alexander. Biological espionage: Special Operations\u00a0. Directorate S, Department 12 Responsible for obtaining intelligence to aid the Soviet BW program, as well as new strains of pathogens. Requirements included Western governments, state commissions, civil defense and laboratories.  Vladimir Kuzichkin worked as Illegals support officer in S/12 for 10 years Laboratory X founded in 1920s, transferred to NKVD in 1937. Soviet biological espionage - Morris and Leontina Cohen, controlled by Gordon Lonsdale, obtained information on British BW program. - Marcus Klinberg was director of Israeli BW program, spied for USSR.</p>"},{"location":"Misc/Intelligence/#communications-intelligence-and-tsarist-russia-by-thomas-r-hammant","title":"Communications Intelligence and Tsarist Russia by Thomas R. Hammant","text":""},{"location":"Misc/Intelligence/#ministry-of-foreign-affairs","title":"Ministry of Foreign Affairs","text":"<p>Since Peter the Great, COMINT involving foreign governments and their representatives was the responsibility of the Ministry of Foreign Affairs (MID). \u00a0Methods used included opening diplomatic letters (perlustration) and decrypting the contents, if encrypted, by cryptanalysis or purchasing codebooks.</p> <p>MID was aided by the \u201cBlack Cabinets\u201d of the Imperial Russian Postal Service. \u00a0Post offices in major cities of the Russian Empire had Black Cabinets, which photographed contents of suspect correspondence and disseminating the information to the appropriate ministry. \u00a0When the contents of a letter were encrypted, it was worked on not by a Black Cabinet but by a \u201csimilar establishment attached to the Ministry of Foreign Affairs.\u201d</p> <p>Little is known about MID\u2019s cryptographic organization, but it may have been brought under the control of the Minister of Foreign Affairs himself in the 1900s.</p> <p>Codebooks could be easily acquired on the open market.</p>"},{"location":"Misc/Intelligence/#russian-comint-in-world-war-i","title":"Russian COMINT in World War I","text":"<p>Army and Navy operated independent COMINT elements.</p> <p>At each Army HQ, radio intelligence operations were controlled by Chief of Army Communications through his assistant for technical matters. Each army\u2019s radio battalion had a radio intelligence squad or section which operated two stations: one monitored enemy communications, and the other station then recorded them once detected. Intercepts of encrypted German Army radiograms were sent to a \u201cspecial bureau\u201d of Chief Directorate of the General Staff in St. Petersburg for cryptanalysis. Generally, COMINT was poorly organized under the Russian Army.</p> <p>Black Sea and Baltic Sea Fleets established independent COMINT services in autumn 1914 after German naval codebooks were recovered from a sunken German cruiser. \u00a0Copies of the codebook were shared with the British and French, and there was continued COMINT collaboration between the Allies throughout the war.</p> <p>The Baltic Sea Fleet\u2019s first radio intercept station was established close to Tallin. \u00a0Intelligence was sent by underground cable to the Communications Service of the Southern Region. \u00a0Each region (North, East, and South) had a Central Radio Station (CRS) that produced all-source intelligence and supported fleet communications. By 1916, Northern Region had 5 DF and 5 intercept stations, and Southern Region had 5 DF and 4 intercept stations. \u00a0Southern Region also established a Radio Intelligence Center, probably to administer COMINT from these stations, which was subordinate to the CRS, and other Regions may have had similar units.</p> <p>The Baltic Sea Fleet\u2019s greatest debt to COMINT was accrued on 31 July 1915, when the Russians learned the German Navy planned to seize the city of Riga. \u00a0Cryptanalysis of the messages, aerial reconnaissance, and shore-based observation posts allowed Russian ships to be ready for the attack when it came, and the Russians prevailed. The Black Sea Fleet\u2019s first radio intercept station was at Sevastopol, and although its Communications Service had two regions to administer, there are fewer details available about Black Sea Fleet COMINT. Black Sea Fleet was greatly helped by Turkey\u2019s use of German codes during the war. \u00a0In December 1916, Black Sea Fleet decrypted information that indicated a German submarine was to return to Constantinople and included the location of the mine-swept channel by which it was to pass. Russian minelayers went to work, and within 48 hours the Russians learned the submarine had been sunk.</p>"},{"location":"Misc/Intelligence/#from-the-okhrana-to-the-kgb-by-christopher-andrew","title":"From the Okhrana to the KGB, by Christopher Andrew","text":"<p>Okhrana est. 1881 Soviet intelligence MO and methods rooted in Tsarist secret service</p> <ul> <li>Okhrana active measures campaign to persuade French investors to invest in Russia. \u00a0By 1914, a quarter of France\u2019s FDI was in Russia, three times as much as in its own empire, 80% of it in government loans.</li> <li>Peter Rachkowsky, head of Okhrana\u2019s Paris-based Foreign Agency from 1884 to 1982 may have been responsible for producing the Protocols of the Elders of Zion.</li> </ul>"},{"location":"Misc/Intelligence/#humint","title":"HUMINT","text":"<ul> <li>Colonel Alfred Redl, senior Austrian MI officer. \u00a0In winter 1901-2, Colonel Batyushin, head of Russian MI in Warsaw, discovered Redl was a homosexual. \u00a0Redl sold Austria\u2019s mobilization plans against Russia and Serbia until his suicide in 1913.</li> <li>Roman Malinovsky, worker who became one of the most trusted Bolsheviks. One of 6 Bolshevik deputies to Duma (1912), then chair of Bolshevik faction when Mensheviks broke off. When Lenin smelled a rat and set up a committee to investigate the possibility of penetration, Malinovsky was a member of the committee. Okhrana sent him out of the country with a 6000 ruble payoff, and when Okhrana files were opened in 1917 Lenin couldn\u2019t believe Malinovsky had been a traitor.</li> </ul>"},{"location":"Misc/Intelligence/#sigint","title":"SIGINT","text":"<ul> <li>Okhrana began stealing cipher material to assist SIGINT at the beginning of the 20th century, decades before anyone but the French. \u00a0Okhrana bribed embassy to services to make impressions of keys and smuggle them out, as well as papers to be photographed. \u00a0SIGINT was used in diplomatic negotiations with Germany over the Bosphorus Canal.</li> <li>Bolshevik Revolution damaged SIGINT, dispersed codebreakers and cryptologists to other countries, where they sometimes joined those SIGINT services. \u00a0For a decade after the Revolution, Soviet diplomatic traffic was easily decrypted. \u00a0Soviets adopted the one-time pad in 1927.</li> <li>GB adopted the tactic of stealing cryptographic material. \u00a0KGB and GRU operated a joint unit headed by Gleb Boki.</li> <li>SIGINT was responsible for a panic regarding a possible Japanese surprise attack 1931-1932. \u00a0Intercepted attache cables were published in the Moscow press. \u00a0Soviets provided edited excerpts of diplomatic intercepts to Germany to influence Germans into signing Molotov-Ribbentrop Pact.</li> <li>Maskirovka on Eastern Front achieved comparable results to British and Western denial and deception (XX system)</li> <li>Capture of hundreds of German signals personnel among tens of thousands of German POWs resulted in a windfall for Soviet SIGINT, 1943.</li> <li>Multiple penetrations of NSA, 1959-1963.</li> </ul>"},{"location":"Misc/Intelligence/#sword-and-the-shield-the-by-christopher-andrew","title":"Sword and the Shield, the by Christopher Andrew","text":""},{"location":"Misc/Intelligence/#chapter-2-from-lenins-cheka-to-stalins-ogpu","title":"Chapter 2: From Lenin\u2019s Cheka to Stalin\u2019s OGPU","text":"<p>The paranoid instincts and shadowy methods of the Cheka and its successors were motivated by persecution of Bolshevik revolutionaries during the Tsarist period and provoked by agents provocateurs planted by the Tsarist Okhrana and foreign powers. - Cheka founded on 19171220 only weeks after Bolshevik Revolution: Feliks Dzerzhinsky     - Foreign Intelligence Department (INO) established 19201220: Made use chiefly of Illegals because Soviet state had no legal residencies abroad - Foiled plots encouraged paranoia of young Cheka     - Envoys\u2019 plot by naive young diplomats, caught in the net laid by the Cheka     - Agents provocateurs Eduard Berzin and Yan Buikis: Berzin received Order of the Red Star, became Cheka officer, but then fell victim to Stalin\u2019s Terror and was shot in 1937; Buikis survived by changing his identity     - Okhrana agents provocateurs - Bolshevik experience as an underground movement: Use of pseudonyms (\u2019Lenin\u2019, \u2018Stalin\u2019)</p>"},{"location":"Misc/Intelligence/#chapter-3-the-great-illegals","title":"Chapter 3: The Great Illegals","text":"<p>The Great Illegals of the interwar period leveraged their personal flair and charisma to achieve remarkable successes against target countries with very weak security posture. Some of their earliest successes were in obtaining diplomatic cipher material, which was passed to a large SIGINT agency where diplomatic traffic was deciphered. Stalin didn\u2019t trust anyone to analyze the intelligence for him and acted as his own intelligence analyst. This reinforced his warped worldview as the secret services produced reports that catered to his paranoid suspicions. - Great Illegals were unique and remarkable spies: multilingual Central Europeans with great faith in Communist future; freer from bureaucracy, in comparison to \u00a0post-war period     - Target countries had very lax security - First successes were in obtaining diplomatic ciphers     - Dmitri Aleksandrovich Bystroletov (HANS, ANDREI): very handsome, extroverted: portrait hangs in secret memory room of SVR Center in Yasenovo         - Seduced female staff in foreign embassies: Prague, 1927: seduced 29 y.o. secretary in French embassy (LAROCHE) who provided British and Italian diplomatic ciphers and classified communiques for 2 years         - Agents introduced ANDREI to other sources of information             - Oldham, who provided British ciphers, provided introduction to Raymond Oake (SHELLEY)             - De Ry provided Italian ciphers, provided introduction to Rodolphe Lemoine - Rodolphe Lemoine (JOSEPH)     - Passion for espionage: began work for French Deuxi\u00e8me Bureau (DB) in 1918     - Recruited German cipher clerk in 1931 who was DB\u2019s most important source for a decade     - Some intel fed into Enigma code breaking machines     - Eventually passed to Ignace Reiss (RAYMOND), who defected in 1937 - Henri Christian Piecke (COOPER)     - Flamboyant Dutch artist     - John H. King (MAG)     - Irish, hated English     - Classified Foreign Office communications coroborated by DUNCAN (below)     - Moisei Markovich Akselrod (OST, OSTO)     - Jewish family, born 1898     - hired by INO in 1922     - Multilingual: Arabic, French, German, English, Italian     - Francesco Constantini (DUNCAN)     - Classified documents, ciphers from British Embassy in Rome     - Also sold documents to Italian intelligence     - Continued to provide intelligence after dismissal through brother Secondo Constantini (DUDLEY), also employed at embassy     - Executed during Great Terror     - Joint OGPU/Fourth Department SIGINT agency decrypted diplomatic traffic     - largest SIGINT agency in the world at the time     - No analysis of intelligence     - Stalin considered analysis to be \u201cguesswork\u201d     - Conspiracy theories of Stalin\u2019s continue to survive to this day</p>"},{"location":"Misc/Intelligence/#chapter-4-the-magnificent-five","title":"Chapter 4: The Magnificent Five","text":"<p>Arnold Deutsch established the recruiting strategy for the Magnificent Five, young talents in Oxford and Cambridge Universities with Communist sympathies who became the most successful Soviet penetrations of Western governments during WW2. Arnold Deutsch (STEFAN, OTTO): True believer in Communism, chemistry PhD from Vienna University, five years after entering as undergraduate; began work for INO in 1932. Recruited 20 agents, including C5, over 4 years as controller</p> <ol> <li>Kim Philby (SOHNCHEN, SYNOK): heterosexual athlete; was not productive before 1937, when he was sent to Spain as war correspondent, wounded, and ultimately awarded medal by Franco, whom he was supposed to assassinate</li> <li>Donald MacLean (WAISE, SIROTA): bisexual, approached by Philby in 1934; Foreign Office</li> <li>Guy Burgess (MADCHEN): flamboyant homosexual and social butterfly     Joined SIS in 1938, in newly founded Section D (covert action and influence)</li> <li>Anthony Blunt: homosexual, introduction by Burgess     Talent spotter</li> <li>John Cairncross (MOLI\u00c8RE, LISZT): polygamist, spotted by Blunt, approached by Burgess, recruited by Klugmann; Foreign Office</li> <li>Norman Klugmann (MER): prominent Communist activist who acted as talent spotter for NKVD, recr. 1936. Given away by Ignace Poretsky in 1937 Teodor Maly (MANN)</li> <li>Hungarian POW during WW1, joined Bolsheviks during Revolution</li> <li>Head of London residency in 1936, where he completed recruitment of C5 with Deutsch</li> <li>Recalled to Moscow during Great Terror, shot in 1937 (Ch. 5)</li> <li>Internal turmoil in Soviet Union affected espionage</li> <li>Hunt for Trotskyites became priority by end of 1937</li> <li>Great Terror: all 3 of Deutsch\u2019s residents during residency in London were executed</li> </ol>"},{"location":"Misc/Intelligence/#chapter-5-terror","title":"Chapter 5: Terror","text":"<p>The fantasy of a Trotskyite conspiracy increasingly obsessed Stalin during the 1930s, who directed the NKVD and OGPU to penetrate Trotsky\u2019s organization. Trotskyites became targets of a cell of assassins called the Administration for Special Tasks, based out of the Paris residency. The Great Terror resulted in the liquidation of so many NKVD officers that tradecraft suffered. The Cambridge Five themselves, despite the quality of intelligence they provided, were suspected of being plants. \u00a0 \u2022   Mark Zborowski (MAKS, MAK, TULIP, KANT): Russian-born Polish Communist who deeply penetrated Trotsky\u2019s entourage \u25e6   Confidant of Lev Sedov, elder son of Trotsky \u25aa   Entrusted with key to Sedov\u2019s letterbox and Trotsky\u2019s most confidential files and archives \u25aa   Convinced Sedov to go to a Russian clinic for appendicitis while assassination was being planned \u25e6   After Sedov\u2019s death, encouraged internecine warfare between Trotskyites \u25e6   Orlov knew his first name and attempted to warn Trotsky after defection in 1938 \u2022   NKVD Administration for Special Tasks specialized in assassination and abduction, especially in France, headed by Yasha Serebryansky, resident in Paris \u25e6   Largest section of Soviet foreign intelligence by 1938, claiming to have 212 illegals in 16 countries \u25e6   Trained members of International Brigades in sabotage \u25e6   Main task was surveillance and destabilization of French Trotskyites \u25aa   theft of Trotsky\u2019s papers from a Paris flat coordinated by Zborowski, who escaped suspicion \u25e6   Abduction of General Yevgeni Karlovich Miller \u25aa   Entourage penetrated: Miller\u2019s deputy was NKVD agent \u25aa   Another illegal was used to surveil Miller \u25aa   Miller disappeared in broad daylight on a Paris street, drugged, packed in a heavy trunk, and sent to Moscow by Soviet freighter where he was interrogated and shot \u25e6   Assassination of Lev Sedov \u25aa   Op was aborted after furor re. NKVD involvement in Miller\u2019s disappearance \u25aa   Sedov developed appendicitis, died mysteriously a few days after a successful operation in Russian clinic (at Zborowski\u2019s insistence) \u25aa   NKVD had a sophisticated medical section called the Kamera, experimented with lethal drugs \u25e6   Assassination of Rudolf Klement: secretary of Trotsky\u2019s Fourth International \u25e6   Assassination of Ignace Poretsky (Reiss, RAYMOND) using machine gun and chocolates laced with strychnine \u25e6   Assassination of Leon Trotsky: operation UTKA \u201cduck\u201d became chief Soviet foreign policy objective, to be effected by three groups \u25aa   Penetration by illegal Ram\u00f3n Mercader (RAYMOND, alias Frank Jacson sic), who seduced a Trotskyite secretary \u25aa   Succeeded in killing Trotsky with icepick, caught and sentenced to 20 years imprisonment \u25aa   Hero\u2019s welcome in Moscow 1960 \u25aa   Assault on villa led by David Alfaro Siqueiros (KONE), Communist painter \u25aa   Iosif Romualdovich Grigulevich (MAKS, FELIPE), member of Serebryanksy\u2019s cell, real leader of assault \u25aa   Escaped to Argentina where he planted hundreds of mines in cargo ships bound for Germany \u2022   Spanish Civil War was training ground for saboteurs and battlefield against Franco\u2019s fascists as well as Trotskyites \u25e6   Orlov coordinated two-front war in Spain, ultimate goal was to build a secret police force under Soviet control \u25aa   NKVD assassins murdered Andreu Nin, head of a Trotskyist workers\u2019 organization, as well as dozens of other Trotskyites in Spain \u25aa   Orlov eventually defected to the US \u25e6   Stanislav Alekseyevich Vaupshasov: top assassin - Led raids on Polish and Lithuanian border villages dressed in Polish and Lithuanian army uniforms in the 1920s - Murdered a colleague in 1929 - Constructed and guarded secret crematorium which disposed of NKVD victims (SVR still considers this topic sensitive, gave hush money to female relative of the NKVD agent in charge of guarding this crematorium) - Great Terror sprung from Stalin\u2019s obsession with counterrevolutionaries - Leadership of NKVD liquidated and re-liquidated - Nikolai Ivanovich Yezhov, head of NKVD 1936-1938: author of \u00a0Great Terror, replaced Yagoda who soon made absurd confessions - Replaced by Lavrenti Beria in December 1938 before accused of conspiracy - Abram Slutsky, chief of INO, poisoned by cyanide in 1938 - Slutsky\u2019s successors also shot before the end of the same year - NKVD officers were liquidated - Had to be careful even of body language or sighing - Officers most quick to denounce peers of imaginary crimes were most likely to survive Most of the Great Illegals were liquidated by 1938, except for: - Deutsch who was betrayed in 1937 by Ignace Poretsky (Reiss, RAYMOND) - Bystroletov brutally tortured before confession, imprisonment; wife sent to gulag where she cut her own throat with a kitchen knife; mother poisoned herself - Serebryansky himself recalled to Moscow and condemned in 1938 - Show trials depicted a vast, absurd conspiracy authored by Stalin, who proofread transcripts before publication - Great Terror and British operations - C5 transferred to legal residency, where controllers were much less experienced - MacLean seduced his new Soviet controller (NORMA, ADA) - Condemnation of C5\u2019s controllers and recruiters as enemies of the people placed their intelligence and reliability under question - Beria eventually disbanded the residency in 1940, Centre ordered all contact with Philby and Burgess to be broken off - Ideological commitment of C5 remained strong even after the Molotov-Ribbentropp pact - British agents were motivated out of revilement for fascism - Some agents ended their espionage - Histories of Stalin era still whitewash the emphasis on assassination of political opposition in Western Europe</p>"},{"location":"Misc/Intelligence/#south-africa","title":"South Africa","text":"<p>Intelligence's role in supporting counter-revolutionary operations of the apartheid state, as well as in the AND and SACP's efforts to overthrow the state. Five key uses of intelligence in counter-revolutionary struggle:[^4]</p> <ol> <li>Targeting enemies of the state, internal \u00a0(including South West Africa) and external (including in Europe)</li> <li>ZA relationships with other states (Angola, Botswana, Mozambique, Tanzania, Zambia, and Zimbabwe) as anti colonial movement spread, isolating ZA</li> <li>Anti-Communist paradigm of Cold War, alliance with US, UK, West Germany, and Israel</li> <li>Overcoming anti-apartheid sanctions from the 1970s and 80s</li> <li>Developing a nuclear weapon</li> </ol> <p>Relationship with British services strained because of Afrikaner resentment, British concern of infiltration by Afrikaner nationalists. In the nineteenth century, the Boer republics (Transvaal Republic and Orange Free State) maintained limited intelligence organizations led by Cornelius Smidt and Willem Leyds (Transvaaler Secret Service).[^5]</p> <ul> <li>South African Police Detective Branch (SAP/DB) conducted counter-subversion and counterintelligence after 1899-1902 Anglo-Boer War and the establishment of the Union of South Africa in 1910. SAP/DB concentrated mostly on Nazi sympathizers in South West Africa until 1948, when the National Party (NP) was elected.[^6]</li> <li>MI5 conducted foreign intelligence but also watched radical Afrikaner groups such as Ossewa-Brandwag (OB), a paramilitary organization in competition with NP and with many sympathizers in SAP. Union Defense Forces, considered an anglophile institution, cooperated with MI5 on internal threats (Afrikaner nationalists and Republicans) and British Special Operations Executive (SOE), operating out of Durban. MI5 Director General Sir Percy Sillitoe served in South Africa and Rhodesia and was a key influence in shaping the South African intelligence structure.</li> <li>SAP Special Branch (SB) founded as Special Staff to hunt Nazis in 1939 before being redirected to investigating political crimes. Increasingly into the 1950s, became known as Security Branch.</li> <li>Union Defense Forces Department of Military Intelligence (DMI) created Feb 1940 but neglected after 1948. After independence from Britain in 1961, UDF became South African Defense Forces (SADF) and established a new Directorate of Military Intelligence (DMI) July 1962. </li> <li>Rivalry between SB and DMI survived administrative efforts to coordinate intelligence functions: State Security Committee (est. 1963) and State Security Advisory Board (est. 1966). SB\u2019s criminal emphasis hampered intelligence work, and a central intelligence agency was needed, sought first in Republican Intelligence (RI) spun off from SB 1963, then found in BOSS.</li> <li>Bureau for State Security (BOSS) founded 19690513 as a central intelligence apparatus to mitigate the rivalry between DMI and SAP. Reorganized as National Intelligence Service (NIS) in 1980. Grew from 500 personnel in 1969 to more than 1,000 by 1978. Six departments: Subversion, Counter-espionage, Political and Economic Intelligence, Military Intelligence, Administration, and National Evaluation, Research and Special Studies. Forged a relationship with Portuguese and Rhodesian intelligence services. Brought down by government\u2019s increased reliance on COIN strategies (vice counterintelligence and counter-espionage) and by the Information Scandal.</li> <li>African National Congress (ANC), Umkhonto weSizwe (MK), and South African Communist Party (SACP) established intelligence structures separate but parallel to that of the government during their armed struggle against the apartheid state. ANC established Department of Intelligence and Security (DIS).</li> </ul> <p>DMI gained control of \u201cTotal National Strategy\u201d and achieved dominance over BOSS. \u00a0DMI strategists implemented various counter-insurgency (COIN) strategies they learned from abroad in ZA and SWA. Botha appointed Minister of Defence in 1966 and began a campaign to reinvigorate the SADF. \u00a0By the beginning of Project SAVANNAH (South African intervention in Angola[^7] in 1975, Botha had begun a process of streamlining the SADF that would culminate years later in the incorporation of COIN principles in the South African Army.</p> <ul> <li>Area Defence Policy, later known as National Security Management System, was fully incorporated into the counter-insurgency forces of SADF. \u00a0COIN forces were made up of part-time SADF personnel from the Citizen Force and Commandos and were divided into ten regional commands covering the countryside.</li> <li>SADF doubled in size between 1975 and 1990, reaching almost 100,000 with another 325,000 in the Citizen Force and Reserves ZA security confronted radical new challenges from 1975 to 1978. </li> <li>Key governments on ZA's periphery had turned hostile. Marxist MPLA took over Angola and hosted SWAPO bases on the border of South West Africa. Mozambique's new government was Marxist.</li> <li>Mozambique became a shelter for Rhodesian guerrillas, threatening ZA's last counter-revolutionary ally.</li> <li>Radicalization of blacks after 1976 uprising in Soweto overwhelmed internal security, which responded by introducing COIN concepts and reacting more harshly to protests.</li> </ul> <p>SADF COIN expertise was gained in collaboration with Rhodesian ISS and SOF during the 1960s and 1970s. ZA intelligence establishment absorbed members of Rhodesian Security Forces in the transition to majority rule in 1980 (Operation Winter).[^8] COIN Strategy Adopted Wholesale, New Units Established Opposition to apartheid state grew more radical while the state\u2019s response to opponents hardened. A sustained domestic protest movement called United Democratic Front ultimately gave ANC-MK their long sought-after internal subversion capability within ZA. Pretoria adopted COIN strategies in response to failing effort against MPLA in AO and SWAPO in SWA and deteriorating domestic security as MK stepped up attacks. </p> <p>K-Unit \u201cKoevoet\u201d founded by SAP/SB in January 1979, building on their decades of cooperation with Rhodesians in COIN operations. Formed after the Selous Scouts and Portuguese Flechas for the purpose of turning captured ANC, SWAPO, and PAC guerrillas called askaris. Turned SWAPO fighters who collaborated with Koevoet were known as makakunyanas \"blood-suckers\", and Koevoet collaborators were targeted for assassination by SWAPO. \u00a0They were paid for each guerrilla killed. SAP/C1 \u201cVlakplaas\u201d named after the police farm outside Pretoria. \u00a0Originally established 1979 when BG Johan Coetzee, C/SB, decided to use COIN activities for counter-revolutionary purposes within ZA. \u00a0Revealed by Coetzee in the press in 1989 and disbanded in 1993.</p> <ul> <li>Koevoet elements including de Kock were withdrawn from SWA to form C1 in May 1983.</li> <li>Identification, tracking, and \"rehabilitation\" (turning) of ANC and PAC guerrillas. C1 also assassinated up to 65 people from 1980 to 1991.</li> <li>C1\u2019s operations in Swaziland were to disrupt the ANC/MK structures there. \u00a022 ANC members were assassinated in Swaziland in the 1980s.</li> <li>C2 established concurrently to track activists leaving ZA and to interrogate arrested guerrillas</li> </ul> <p>SAP/G section, responsible for the penetration of ANC abroad, was resurrected after the reorganization of BOSS in 1980. G section attempted to assassinate ANC/MK strategist Joe Slovo, killing his wife instead. \u00a0G section also blew up ANC\u2019s London office Directorate Covert Collection (Direktoraat von Koverte Insameling) established at an unclear date, but possible predecessor was Directorate of Covert Information, active in SWA by 1982. Established multiple front companies with the goal of duplicating successful COIN operations of AO and SWA within South Africa.</p> <p>Spread of liberation movements across Southern Africa removed governments traditionally friendly to Pretoria, which saw all black liberation movements as Communist-backed threats to regime. South African government resorted to policy of destabilizing neighbors and conducting covert action to remove safe havens for ANC/MK. Eventually South Africa\u2019s hand in regional politics became transparent. DMI integrated intelligence collection with covert action by taking control of South African Special Forces (SASF) in 1979. Rhodesian special forces integrated into SADF in 1980, further buttressing COIN capabilities. Directorate of Special Tasks (DST) formed in mid-1970s from a corps of DMI operators named Spesmagte, similar to Recces. DST was responsible for overseeing contra-mobilization and counter-revolutionary activities of DMI throughout southern Africa as part of a strategy to deny ANC-SACP safe havens in Frontline States. DST began operations in an office in Rundu, Namibia in 1976 in the wake of South African withdrawal from AO. First chief was COL Cornelius van Niekerk. DST terminated operations in the early 1990s. Two sections: - DST-1 (external operations) covered UNITA, RENAMO, and Zimbabwe - DST-2 (internal operations) covered Lesotho Liberation Army (LLA), and Operations MARION and KATZEN</p> <p>DST maintained logistical infrastructure throughout Southern Africa and conducted several operations, providing support to anti-Marxist proxies in neighboring countries: - DISA/SILWER: support to UNITA in Angola - DRAMA: support to Zimbabwean dissidents - PIKI/PUNDU MILIA/ALTAR: support to RENAMO and operations against FRELIMO in Mozambique. 5 Recce was principally responsible because many 5 Recce personnel had trained with the Selous Scouts. When RENAMO\u2019s headquarters moved from Phalaborwa, Transvaal (!) to Gorongosa, Mozambique, South African officers followed offering intelligence training. - PLATHOND: support to surrogate force in Zambia - CAPSIZE/LATSA: support to Lesotho proxy grou 5 Recce based out of Phalaborwa, Transvaal. Supported Op PIKI/PUNDU MILIA. Also used pseudo-operations against SWAPO in Namibia, sometimes cooperating with Koevoet. DCC mobilized contras in Namibia. Various operations: - ETANGO: DCC and other DMI units attempted to establish a conservative contra based in Ovambo tribalism to counter SWAPO. - EZUVA: Similar project to establish a contra among the Kavango.</p> <p>Many experienced contra-mobilizers from DCC moved into domestic contra-mobilization 1985-1986, setting up groups to foment black-on-black violence and undermine support of ANC and UDF: 23 such projects by 1986. Operations included: - Operation MARION provided security training and weapons to more than 200 Inkatha cadres 1986-1990. These units later conducted targeted killings. Inkatha had been supported by BOSS as an alternative to ANC from 1975, including funds and stage-managing internal political rivals to Chief Buthulezi.  - Operation KATZEN was an attempt to organize a contra group among the Xhosa known as the Xhosa Resistance Movement (XWB, known as Iliso Lomzi). Cooperated with Army Intelligence Hammer units, which conducted special operations. Civil Cooperation Bureau (CCB), also known as Burgerlike Samewerkingsburo (BSB), was formed in 1986 out of Operation BARNACLE. Formed by SASF to fulfill the requirement of domestic intelligence collection, which was used primarily for external operations. CCB was imagined to be fully functional only in the mid-nineties, possibly to conduct counter-revolutionary warfare after the transfer to black rule had been completed. CCB was organized as a corporation into Regions that coordinated covert activities in concert with other state bodies. CCB numbered up to 250-300 individuals. By the late 1980s, CCB had established numerous front-companies and businesses and was involved in lucrative criminal activities. Operations: - CCB conducted internal assassinations in line with the state\u2019s emphasis on counter-revolutionary warfare. As such, CCB was DMI\u2019s equivalent to SAP\u2019s C1. - CCB supported SASF in operations in the Frontline States by undertaking reconnaissance of ANC targets. 3 Recce (active 1980-1981) absorbed the remnants of Rhodesian special forces which fled Zimbabwe in 1980 as well as DMI\u2019s D-40 assassination unit (active 1979-1980) led by the Rhodesian Garth Barrett. 3 Recce operated against Zimbabwe, exploding very destructive bombs and assassinating ANC\u2019s representative in Harare.[^9] Operation BARNACLE, conducted by a group 30-40 mostly black ex-Rhodesians, was a project to use CBW to assassinate guerrillas, SWAPO prisoners of war, and members of South African security forces suspected of disloyalty with poison. BARNACLE was to be a completely independent resource at the disposal of the country\u2019s leaders, to serve as a hedge against the prospect of the government granting too much power to blacks. BARNACLE actors were not accountable to official security organs or to SADF commanders: they reported directly to General Office Commanding Special Forces (GOC-SF). Later reorganized into the Civil Cooperation Bureau.</p>"},{"location":"Misc/Intelligence/#notable-people","title":"Notable People","text":"<ul> <li>BG J.P. Tolletjie Botha ran Directorate Covert Collection. </li> <li>COL Jan Breytenbach founded the Reconnaissance Commandos, 32 Battalion, and the Directorate Special Tasks.</li> <li>Chief Buthulezi was leader of Inkatha and a BOSS stooge.</li> <li>COL Eugene de Kock was one of the most ruthless and effective of Koevoet's commanders. \u00a0Eleven tours of duty between 1968 and 1973 in Rhodesia with Rhodesian SAS and Rhodesian African Rifles. \u00a0Commanded Koevoet for four years before he requested a transfer to SAP/C1, where he assumed command in 1985. De Kock emphasized the assassination program and introduced paramilitary training for police members. During this time, De Kock became known as Prime Evil for his mercilessness.</li> <li>MAJ Craig Williamson was a counterintelligence operative in SAP/G Section from... to... Williamson infiltrated ANC by using the International University Exchange Fund (IUEF), but was exposed in 1980. Williamson served in SAP/G until December 1985. \u00a0Williamson also established Longreach Pty Ltd in April 1986, which served as a front company for SAP/SB operations and also coordinated DMI and SASF operations.</li> </ul>"},{"location":"Misc/Intelligence/#sweden","title":"Sweden","text":"<p>There was no specific institution in Sweden for intelligence before the 1930s. Navy intercepted communications and diplomats gather intelligence.[^10]</p>"},{"location":"Misc/Intelligence/#military-intelligence-before-ww2","title":"Military Intelligence Before WW2","text":"<ul> <li>General Staff gathered intelligence against Norway during the war of secession</li> <li>Swedish Defense Staff established in 1937. Intelligence branch formed with 20 officers. Mostly OSINT collection and attache reporting from 15 attaches and SIGINT.</li> </ul>"},{"location":"Misc/Intelligence/#intelligence-organizations-formed-in-ww2","title":"Intelligence Organizations Formed in WW2","text":"<ul> <li>C-Bureau (central byr\u00e5a) under Defense Staff, but separate from Intelligence Division, established large intelligence network that was not fully documented.</li> <li>Cryptographic Department (CD) of Defense Staff took over SIGINT from Navy using civilians to succesfully break Soviet crypto and comms. Results were shared with Finnish.</li> <li>Decrypted machine crypto used over landlines. 150,000 cables over two years, until Germans changed codes. Swedish were unable to fully exploit this windfall of intelligence. \u00a0CD reformed as F\u00e5ssvarets Radioanstalt (FRA), directly under Ministry of Defense.</li> <li>General Security Service (Allm\u00e4nna S\u00e4kerhetaj\u00e4nsten, GSS) formed out of a secret, extralegal government decision, established massive program of unlimited authority to monitor telephone, telegraph, and mail communications. Dissolved after scandal in 1946.</li> </ul>"},{"location":"Misc/Intelligence/#postwar-developments","title":"Postwar Developments","text":"<p>2 of the 3 wartime intelligence agencies would be resurrected after dissolution 1947-1948.</p>"},{"location":"Misc/Intelligence/#india","title":"India","text":"<p>Kautilya\u2019s Arthashastra[^11] - Constitutes a doctrine of statecraft using espionage as a basic means of governance. - Comprehensive textbook on statecraft, foreign diplomacy, and war emphasizing the collection of domestic and foreign intelligence.  - Rediscovered and translated by Orientalist Rudrapatnam Shamasasty in 1909-1915. \u00a0Written by Kautilya, trusted advisor to Chadragupta Maurya, founder of Mauryan Empire 321-185 BCE.</p>"},{"location":"Misc/Intelligence/#eight-institutes-of-espionage","title":"Eight Institutes of Espionage","text":"<ul> <li>Four were forms of religious cover (fraudulent disciple, recluse, ascetic, and mendicant woman), which were to take advantage of the intensely religious population of India. \u00a0Religious class had access to other castes. \u00a0Wandering female spies were to take religious cover, poor widows of Brahman caste were to target upper castes while Sudra-caste women willing to shave their head were to target lower caste communities.</li> <li>Classmate spies referred to recruitment pool, and the preferred choice for courier.</li> <li>Firebrands were to be used for covert action as assassins, agent provocateurs, and saboteurs.</li> <li>Result was a pervasive surveillance network covering the whole country. Treasury was also to have intelligence function</li> <li>Householder spies were to ascertain validity of assets</li> <li>Merchant spies were to monitor price changes and foreign goods</li> <li>Networks of spies under cover of bands of thieves would monitor the criminal underworld Provocation and entrapment are standard tactics in Arthashastra.</li> </ul>"},{"location":"Misc/Intelligence/#islamic-caliphate","title":"Islamic Caliphate","text":"<p>Pre-Islamic Arab tradition of intelligence predated a more developed intelligence culture in the Islamic age.[^12] Various words referring to spy or scout: - jasus: foreign spy - tajassasah: discouraged in the Qur\u2019an - \u2018ain: \u201ceye\u201d - suhhar: night sentinels who kept watch for strangers at approaches to market town or crossroads - rabi\u2019ah: lookout - other words</p>"},{"location":"Misc/Intelligence/#espionage-in-early-arab-states","title":"Espionage in Early Arab States","text":"<p>Lakhmid and Ghassanid buffer states between Sasanian Persia and Byzantium: - Story in 10th c. Kitab al-Aghani relates Lakhmid spies catching a would-be assassin and killing him in the 6th century - Scouts in Arabian peninsula</p>"},{"location":"Misc/Intelligence/#brigandage-among-bedouin","title":"Brigandage among Bedouin","text":"<p>Skirmishes and raids (suluk) involved use of scouts - al-Basus War was remembered as the days of rabi\u2019ah - Abu Faraj al-Asbahani\u2019s anthology of Arabic verse - Muhammad b. al-Tabari on agents using disguises</p>"},{"location":"Misc/Intelligence/#muhammad-and-intelligence","title":"Muhammad and Intelligence","text":"<p>Qur\u2019anic regulations on espionage reflect importance of clandestine activites in early Islam. \u00a0The Prophet Muhammad\u2019s involvement in intelligence and espionage: - Muhammad gathered information on early converts, seeking candidates with honesty, trustworthiness, and the ability to keep a secret - Muhammad possessed detailed knowledge of clan loyalties and politics, and used this knowledge in negotiations with Bedouin - Abdullah b. Abu Bakr mingled with Quraishis of Mecca and report back to him at night in his cave. \u00a0Abu Bakr\u2019s sister Asma also spied for the Prophet: first spies for Islam. - Abu al-Fadhl al-Abbas ran spy network in Mecca - Many \u2018ains from various corners of Arabia, from every town and tribe - Muhammad deliberately retreated during the Battle of Uhud to allow his lookouts to determine the size of the army, whether it had mounted camels (to retreat) or horses (to attack) - Muhammad debriefed two boys who were caught drawing water from a well before the Battle of Badr. They divulged key intelligence on the closing Quraishi army.</p>"},{"location":"Misc/Intelligence/#deception","title":"Deception","text":"<ul> <li>After the indecisive Battle of Uhud, Muhammad sent one of his \u2018ains to deceive the Quraishis into thinking a large host was approaching, causing them to retreat.</li> </ul>"},{"location":"Misc/Intelligence/#assassination-of-poets","title":"Assassination of poets","text":"<p>Poets had a complex role in Arab society and were highly influential - Asma of Marwan was stabbed in her sleep, but w\u2019o Prophet\u2019s prior approval - Abu Afak killed by fellow tribesmen - False prophet al-Aswad al-Ansi became influential and killed the governor of Yemen. Muhammad ordered Wabrak b. Yahmus to organize a plot. Wabrak recruited a circle of Persian Muslim converts and the governor\u2019s wife, who facilitated the operatives\u2019 infiltration into the castle where al-Ansi was murdered</p>"},{"location":"Misc/Intelligence/#intelligence-by-islams-enemies","title":"Intelligence by Islam\u2019s enemies","text":"<ul> <li>Abu Sufyan determined Muslim spies were present by finding date seeds in camel dung, indicating the animals had Medinan fodder</li> <li>Multiple assassination attempts on Muhammad\u2019s life</li> <li>Umar b. al-Khattab in charge of counterintelligence and security</li> <li>Byzantines sent a monk who claimed to be a convert to Islam and established a mosque in Medina. \u00a0Muslim agents surveilled the mosque after suspicious comings and goings and ultimately demolished the mosque.</li> </ul>"},{"location":"Misc/Intelligence/#us","title":"US","text":""},{"location":"Misc/Intelligence/#corporate-espionage","title":"Corporate espionage","text":"<p>Vice reported that McDonald's had established an intelligence unit to monitor workers who supported increasing the minimum wage. </p> <p>The unit had targeted the Fight for $15 movement for increasing the wage to $15 an hour in particular. One intelligence report titled \"Ongoing FF$15 Activity Against McDonald's During the COVID-19 Crisis\" contained an analysis of the activities of labor activists.</p> <p>McDonald's had been using two different data collection software suites to collect open-source intelligence on the social networks of workers involved in the labor movement.</p>"},{"location":"Misc/Intelligence/#comint","title":"COMINT","text":"<p>War Department set up first organized cryptanalytic office in June 1917, numbering 3 people. \u00a0By war\u2019s end, it would grow to 150.</p>"},{"location":"Misc/Intelligence/#navy","title":"Navy","text":"<p>In 1917 and 1918, Navy set up medium frequency DF stations along Atlantic coast to track U-boats. HFDF stations were researched and deployed by 1938. \u00a0Strategic HFDF stations were established at Manila, Guam, Midway, Oahu, Dutch Harbor, Samoa, Canal Zone in Panama, San Juan Puerto Rico, and Greenland. \u00a0US began tracking Japanese warships and merchant vessels in 1939, five years after the Japanese had begun tracking US vessels. Navy had established the Code and Signal Section of Naval Communications for producing codes and ciphers for use by Navy. Registered Publication Section, responsible for distribution of secret and confidential documents, was spun off in 1923. \u00a0Navy funded development of Electric Cipher Machine from 1922.  Communications Intelligence Organization (CIO) was established 1924. \u00a0Intercept stations were established in the Pacific Area (Shanghai, Oahu, Peking, Guam, Manila, Bar Harbor, Astoria), and Washington DC. \u00a0Cryptanalytic Units established in Manila and Pearl Harbor. \u00a0Training was done with technical manuals, using the codes to send messages. Minor intercept activities were performed in strategic HFDF stations. In 1938, CIO became the Communications Security Group (CSG) and took over all Navy DF stations. \u00a0By 1941, CSG had 730 total personnel.</p>"},{"location":"Misc/Intelligence/#arm","title":"Arm","text":"<p>Army Signal Corps founded 1860 by Albert James Myer, inventor of wig-wag flag signaling method. Signal Intelligence Service (SIS) founded 1930 as a secret part of Signal Corps for cryptanalysis. \u00a0By 1939, SIS made use of 7 intercept sites from the Philippines and Hawaii in the West to the East Coast of the US. \u00a0These were the sources of SIS intercepts until after Pearl Harbor. At SIS HQ in Arlington Hall, traffic was split between four analytic sections: - J: Japanese - G: German - I: Italian - M: Mexican and Latin American Although SIS intercepted tens of thousands of IJA messages from its station in Manila, these messages could not be fully exploited because IJA ciphers were not broken. \u00a0However, SIS broke several diplomatic ciphers including Purple. After the war, SIS changed its name to the Army Security Agency (ASA) in 1945. \u00a0In 1947, ASA and the Army Intelligence Agency were merged into the newly formed Intelligence and Security Command (INSCOM).</p>"},{"location":"Misc/Intelligence/#radio-free-europe","title":"Radio Free Europe","text":"<p>Established 1949 by the National Committee for a Free Europe (NCFE), an anticommunist organization with Allen Dulles and Dwight D. Eisenhower as board members. Funded by CIA until 1972. \u00a0Targeted Eastern European countries (as opposed to Radio Liberty).</p>"},{"location":"Misc/Intelligence/#radio-liberty","title":"Radio Liberty","text":"<p>Established by American Committee for the Liberation of the Peoples of Russia (Amcomlib) 1951. \u00a0By 1954 was broadcasting in several other Central Asian languages. Foreign Broadcast Information Service Foreign Broadcast Monitoring Service, or FBMS, established 1941 under FCC to monitor Axis shortwave broadcasts to the US. \u00a0Name changed to FBIS 1947 when it was made part of the new CIA.</p>"},{"location":"Misc/Intelligence/#france-andrew-orr","title":"France (Andrew Orr)","text":"<p>France took over Syria and Turkey\u2019s SE (Cilicia) after WW1 and perceived Turkish War of Independence as threat to its new imperial interests. Military intelligence services of Army and Navy monitored Kemalist movements and always saw the hand of German and Russian commies behind Turkey\u2019s developments. \u00a03 reasons</p> <ol> <li>German closely involved in Ottoman military affairs from 1883 and German general Otto Liman von Sanders commanded the Ottoman Army</li> <li>Germans had also promoted pan-Islamic movement during the War</li> <li>Germans possibly still controlled Russia, according to the French, reasoning that they had sent Lenin to Russia inside of a sealed train car</li> </ol> <p>Colonial intelligence services lacked some of the checks on extreme predictions when reporting on events outside of Europe</p>"},{"location":"Misc/Intelligence/#military-intelligence","title":"Military Intelligence","text":"<p>French Army\u2019s Service de renseignments guerre (SR Guerre), which was part of a unified French intelligence organization during the War, but then reverted to the Army\u2019s II Bureau after its end.</p> <p>During the Turkish War of Independence, SRG deployed a small number of officers to the Middle East, stations opened in Constantinople in 1919, Algiers 1925, Rabat and Tangiers 1929.</p> <p>French Navy service (SR Marine) was similarly structured to Army, but with more familiarity with Mediterranean Sea and the Middle East</p> <p>SRM opened Constantinople station in 1919</p> <p>SR sources included Europeans and Americans fleeing Turkey, human informants, and newspaper articles, as well as intercepted radio messages sometimes by way of the Brits</p> <p>Coincidence of treaty signings between USSR, Turkey, and Afghanistan and Persia led SR personnel to believe there was a plot brewing</p>"},{"location":"Misc/Intelligence/#poland","title":"Poland","text":"<p>From Anglo-Polish HUMINT, by PRJ Winter</p> <p>Histories of WW2 intelligence exalt COMINT successes of GCCS to the detriment of MI6 Historiography of British WW2 intelligence Agents - Paul Thummel (codename A-54), senior officer of German MI (Abwehr), recruited by Czechs 1936. \u00a0SIS and Czechs ran him jointly from 1939 until he was arrested by the Gestapo and died in prison 1942. - Warlock, on staff of German High Command (Oberkommando der Wehrmacht, OKW), turned by 1941. - Knopf, reported on OKW intentions to take Malta, but records show that Germans were noncommital to the plan (Op Herkules) which would only support Italia High Command. \u00a0Knopf may have been turned by this time. \u00a0MI14\u2019s evaluation gave Knopf a mixed, but generally positive score. Polish government-in-exile settled in London and cooperated with British intelligence (II Bureau of Polish General Staff) SIS cooperation with Poles was driven out of desperation because aside from Warlock they had no useful penetrations of Nazi Germany CX reports were SIS, JX reports were from Poles. \u00a0Some JX reports found in British National archives, including one report on Malta which was passed to Churchill himself. Poles ran sources reporting from the heart of OKW and OKH (Oberkommando des Heeres, Supreme High Command of the German Army) British interception of Polish communications confirmed Knopf\u2019s bona fides (as agent number 594) and the Poles\u2019 as well</p> <p>[^1]:   Sawyer, Ralph D. \u201cSubversive Information: The Historical Thrust of Chinese Intelligence.\u201d Intelligence Elsewhere: Spies and Espionage Outside the Anglosphere. Ed. Philip H. J. Davies, Ed. Kristian C. Gustafson [^2]:  [^3]:   Homstr\u00f6m, Lauri. \u201cFinnish Security and Intelligence Service.\u201d Intelligence Elsewhere: Spies and Espionage Outside the Anglosphere.Ed. Philip H. J. Davies, Ed. Kristian C. Gustafson [^4]:   O\u2019Brien, Kevin A. The South African Intelligence Services: From apartheid to democracy, 1948-2005. Routledge: New York, NY 2011. [^5]:   Blackburn, Douglas and Caddel, W. Waithman. Secret Service in South Africa. Honolulu: University Press of the Pacific, 2001. Swanepoel, P.C. Really Inside BOSS: A Tale of South Africa\u2019s Late Intelligence Service (And Something about the CIA). Pretoria, 2008. [^6]:   Ref. Kent Fedorowich, \u201cGerman espionage and British counter-intelligence in ZA and Mozambique, 1939-1944\u201d, The Historical Journal 48:1 [^7]:   Robin Hallett, \u201cThe ZA Intervention in Angola,\u201d African Affairs 77:312 (July 1978) [^8]:   Ngwabi Bhebe, Terence Ranger, Soldiers in Zimbabwe's Liberation War, 1995. [^9]:   D-40 in turn was the reconstitution of the supposedly disbanded Z-squads used by BOSS for assassinations until its reorganization in 1979. [^10]:  Agrell, Wilhelm. \u201cSweden: Intelligence the Middle Way.\u201d Intelligence Elsewhere: Spies and Espionage Outside the Anglosphere. Ed. Philip H. J. Davies, Ed. Kristian C. Gustafson [^11]:  Davies, Philip H. J. \u201cThe Original Surveillance State: Kautilya\u2019s Arthashastra and Government by Espionage in Classical India. Intelligence Elsewhere: Spies and Espionage Outside the Anglosphere. Ed. Philip H. J. Davies, Ed. Kristian C. Gustafson [^12]:  Al-Asmari, Abdulaziz A. \u201cOrigins of an Arab and Islamic Intelligence Culture.\u201d Intelligence Elsewhere: Spies and Espionage Outside the Anglosphere. Ed. Philip H. J. Davies, Ed. Kristian C. Gustafson</p>"},{"location":"Misc/Intelligence/#united-states","title":"United States","text":"<p>Linda Zall established a program to analyze classified historical statellite imagery to analyze not foreign militaries but changes in the environment, in particular the extent of ice retreat in the polar regions of the Earth. The effort was sparked by then-Senator Al Gore whose letter to the CIA led to the establishment of the MEDEA program which declassified satellite imagery and oceanographic data.</p> <p>John Walker was a notorious spy who volunteered to the Soviet embassy in Washington in 1967. Especially after the North Koreans captured the USS Pueblo, Walker's information on the key list of the KL-47 cryptographic machine meant the Soviets were able to read US Navy communications until the entire system was replaced. John Walker was managed by former KGB general Oleg Kalugin.</p> <p>The acoustic characteristics of the Victor III submarine were made substantially less detectable as a result of Walker's revelation that the Soviet submarine fleet was easily tracked.</p> <p>The stealthy Akula-class submarines, launched in 1985, also benefited from the import of a Toshiba CNC milling machine, which in combination with Norwegian CNC machines, allowed propellors to be designed that were much quieter than before.</p>"},{"location":"Misc/Lab/","title":"Home lab","text":""},{"location":"Misc/Lab/#media-server","title":"Media server","text":"<ul> <li>tubearchivist, which describes itself as a self-hosted YouTube media server, can be used to store, index, and play YouTube videos. It uses yt-dlp to download from YouTube. It can be deployed using a docker-compose file.</li> <li>tubesync is not a complete media server, but a web application frontend that also allows channels and playlists to be added and downloaded to a file server. It supports Plex as a media server, but it has to be added separately. It is not meant to be used to download individual videos, but rather to scan specified channels or playlists for new content and to download them in the background.</li> </ul>"},{"location":"Misc/Nutanix/","title":"Nutanix","text":"<p>Nutanix AOS is an offering that creates a storage fabric distributed across all nodes of an HCI cluster, intended for data center. Nutanix was the first to offer an HCI solution in 2011, and since then the market has exploded.</p> <p>AOS supports multiple hypervisors, including Nutanix's native AHV, as well as ESXi and Hyper-V.</p> <p>AOS nodes are able to run all the core services of the cluster.</p> <p>Nutanix has a CLI, known as NCLI. Prism is the name of the graphical management console.</p>"},{"location":"Misc/Nutanix/#architecture","title":"Architecture","text":"<p>UVMs are controlled by the CVM or Controller VM which runs the Nutanix software. The CVM is a hardened Linux appliance and a \"User Mode VM\" which exists in only a single instance per node. AOS has a \"shared-nothing\" architecture, so in the event of one node's CVM failing, the cluster's other nodes take over management of that node's UVMs until the CVM has recovered. The CVM runs several services, including:</p> <ul> <li>Stargate the data I/O manager</li> <li>Cassandra metadata store</li> <li>Prism user interface</li> <li>Cerebro replication and \"DR\"</li> <li>Zookeeper distributed configuration store</li> <li>Curator MapReduce cluster manager and cleanup</li> <li>Acropolis AHV </li> </ul> <p>A block refers to a chassis that supports 1-4 nodes, providing power, cooling, and a shared backplane to all hosted nodes. However unlike a blade chassis it does not have shared networking.</p>"},{"location":"Misc/Nutanix/#storage","title":"Storage","text":"<p>Several blocks connected to a third-party switch form a Distributed Storage Fabric, which combines every block's storage into a single storage pool.</p> <p>Containers are logical storage policies and do not correspond with physical disks, and all are thinly provisioned. In ESXi a container is presented as a datastore.</p>"},{"location":"Misc/Russia/","title":"Russia","text":""},{"location":"Misc/Russia/#aircraft","title":"Aircraft","text":"<pre><code>graph LR\n    A{&lt;em&gt;Su-27&lt;/em&gt;}\n    B[Su-30]\n    C[Su-30SM]\n    D[Su-33]\n    E[Su-34]\n\n    A --- B\n    B --- C\n    A --- D\n    A --- E\n\n    click A href \"#su-27\"\n    click B href \"#su-30\"\n    click C href \"#su-30sm\"\n    click D href \"#su-33\"\n    click E href \"#su-34\"</code></pre>"},{"location":"Misc/Russia/#mig-35","title":"Mig-35","text":"<p>Export variant of the MiG-29M2 with:</p> <ul> <li>New MFD displays instead of analog instruments</li> <li>RD-33MKB engines that implement thrust-vectoring</li> <li>AESA radar</li> <li>The ability to be armed with ground-attack weapons like bombs</li> </ul>"},{"location":"Misc/Russia/#su-27","title":"Su-27","text":""},{"location":"Misc/Russia/#su-30","title":"Su-30","text":"<p>The Su-30 was originally called the Su-27PU and intended to be a long-range interceptor. The airframe of the Su-27PU, in turn, was based on that of the Su-27UB, another variant intended to be a two-seat trainer.</p> <p>It entered service in the 1990s as an all-weather multirole two-seat fighter.</p> <p>It achieved success in the export market:</p> <ul> <li>Su-30MKI, jointly produced with Hindustan Aeronautics Limited, featured thrust vectoring.</li> <li>Su-30MKM, designed for the Royal Malaysian Air Force, inherited the Su-30MKI's thrust vetoring and added avionics upgrades.</li> <li>Su-30MKK, intended for China, spawned derivatives of its own that were purchased by Vietnam and Venezuela.</li> </ul>"},{"location":"Misc/Russia/#su-30sm","title":"Su-30SM","text":"<p>Like the Su-35, a modernized variant of the Su-27 that adds jamming pods and improved communications for the Russian Air Force.</p> <p>The Su-30SM2 will use the same engine as the Su-35: the AL-41F-1S.</p>"},{"location":"Misc/Russia/#su-33","title":"Su-33","text":"<p>The Su-33 is a carrier-based variant of the Su-27 with reinforced undercarriage, rugged landing gear, canards, larger folding wings, and slightly more powerful engines.</p> <p>Although the concept dates from the late 1970s, when it was initially called the Su-27K, it was only introduced in 1998. It was developed to populate the fighter wings of \"heavy aviation cruisers\", a hybrid between an aircraft carrier and battleship that was developed by the Soviet Union late in the Cold War. These wings were originally intended to be filled by the Yak-38, which was a disappointment and quickly retired.</p> <p>Despite the changes made to accomodate carrier-based aviation, it still proved too big and did not have all the payload delivery features necessary.</p> <p>Efforts to export the Su-33 to China and India fell through, however China did reverse-engineer it to create the J-11B. India elected to purchase the more advanced MiG-29K. Russian Naval Aviation has been the Su-33's only operator. In 2009, the several dozen Su-33s in service began to be replaced by [MiG-29K][#mig-29k]s.</p>"},{"location":"Misc/Russia/#su-34","title":"Su-34","text":"Fighter-bomber variant of the Su-27, designed by Rolan Martirosov."},{"location":"Misc/Russia/#ground-forces","title":"Ground Forces","text":"<p>Battalions can be subordinate to brigades or regiments, depending on context. Brigades are more self-contained, whereas regiments are themselves subordinate to divisions.</p>"},{"location":"Misc/Russia/#vdv","title":"VDV","text":"<p>Modern VDV units can be divided by mode of entry into airborne and air assault units.</p> <p>Historically, airborne troops were controlled by the Soviet General Staff for strategic objectives: capturing command and control nodes, political targets, etc deep in enemy territory. Air assault forces, in contrast, generally operated heavier ground equipment and had operational objectives to support ground forces. Some air assault forces had been under the control of military districts but since 2013 have been consolidated into the VDV.</p> <p>Both air assault and airborne platoons consist of 3 squads in their own IFVs, either the BMD-2 or the BMD-4M. Each IFV can only mount 7 personnel, of which two are the driver-mechanic and gunner-operator who remain with the vehicle after infantry dismount. Apparently the deputy platoon commander stays in the vehicle as well, providing a total of 14 dismounts per platoon.</p> <p>Airborne and air assault companies combine three such platoons with a Headquarters Section made of two additional IFVs. Air assault companies add a Grenade-Machine Gun Section in its own APC.</p> <p>Three such companies in combination with reconnaissance and support platoons and a medical section, form the core of a battalion. Air assault battalions add a mortar battery with six tubes.</p>"},{"location":"Misc/Russia/#bmd-2","title":"BMD-2","text":"Introduced in 1985, an IFV with a 30 mm cannon."},{"location":"Misc/Russia/#bmd-4","title":"BMD-4","text":"Introduced in 2016, an IFV with a 100 mm cannon."},{"location":"Misc/Space/","title":"\ud83d\ude80 Space","text":"<p>Missions to look forward to </p> <ul> <li>James Webb Space Telescope (JWST) to be launched ca. October 31, 2021</li> <li>Artemis-1 to be launched in late 2021, with first scientific observations after 6 months of testing</li> <li>Jupiter Icy Moon Explorer (JUICE) to be launched 2022 and arrive 2029</li> <li>E-ELT first light expected November 2026</li> <li>Dragonfly mission to Titan scheduled to launch in 2027 and to arrive in 2036 </li> </ul>"},{"location":"Misc/Storage/","title":"Storage","text":""},{"location":"Misc/Storage/#nas","title":"NAS","text":"<ul> <li>The Dell PowerEdge R720 and R720XD use the H710 PERC RAID controller with 512 MB cache</li> <li>Helios64 is billed as the ultimate ARM-powered NAS. It comes with its own UPS which can power the unit for 15 minutes. It was reviewed by Alex from the Self-Hosted podcast, who took issue with poor build quality and value. Consumer-friendly products from Synology and QNap may perhaps be a better solution.</li> <li>Synology 1621+ was reviewed in Self-Hosted 43. Synology offers DSM for easy management.</li> <li>Brian Moses has an annual blog series on making your own DIY NAS.</li> </ul>"},{"location":"Misc/Storage/#flash-memory","title":"Flash memory","text":"<p>3D NAND flash chips can be defined by how much data is stored in memory cells which are stacked vertically. SLC, MLC, TLC, and QLC represent progressively more memory-dense NAND technologies. They also represent progressively less long-lived devices in terms of P/E cycles.</p>"},{"location":"Misc/TrueNAS/","title":"TrueNAS","text":"<p>TrueNAS supports additional applications through catalogs, such as TrueCharts.</p> <p>z</p>"},{"location":"Misc/TrueNAS/#glossary","title":"Glossary","text":""},{"location":"Misc/TrueNAS/#midclt","title":"midclt","text":"middleware client"},{"location":"Misc/TrueNAS/#truecharts-material-discord","title":"TrueCharts  :material-discord:","text":"<p>A catalog of applications made available by veteran TrueNAS forum users.</p> <p>Applications are collected in several trains: stable, core, and incubator</p> <p>Applications are packaged as Helm packages.</p>"},{"location":"Misc/bittorrent/","title":"BitTorrent","text":"<p>Bram Cohen invented BitTorrent protocol in 2001 and wrote the first client in Python. It is a peer-to-peer file sharing protocol where those who share a file are called seeders and those who download are called peers. All seeders and peers related to a particular torrent comprise the swarm. The tracker server or tracker serves as a repository for information about peers associated with the same file. Files are downloaded in hashed pieces from multiple seeders to distribute the burden of seeding a file. ^</p> <p>A Torrent Descriptor file is a hashmap file</p> Torrent Descriptor property Description Announce URL of the tracker Info dictionary whose keys depend on whether one or more files are being shared, including:Files: list of dictionaries, only exists when multiple files are being shared, each dictionary has two keys and corresponds to a fileLength: size of the file in bytesPath: list of strings corresponding to subdirectory names, the last of which is the actual filename length size of the file in bytes (when one file is being shared name suggested file or directory name Pieces length number of bytes per piece; must be a power of 2 and at least 16KiB Pieces list of SHA-1 160-bit hashes calculated on various parts of data <pre><code>{\n\"Announce\": \"url of tracker\",\n\"Info\": {\n\"Files\": [{ \"Length\": 16, \"path\": \"/folder/to/path\" }, { \"length\": 193, \"path\": \"/another/folder\" }] },\n\"length\": 192, \"name\":\" Ubuntu.iso\", \"Pieces length\": 262144, \"Pieces\": [AAF4C61DDCC5E8A2DABEDE0F3B482CD9AEA9434D, CFEA2496442C091FDDD1BA215D62A69EC34E94D0]\n}\n</code></pre>"},{"location":"Misc/bittorrent/#bittorrent-clients","title":"BitTorrent clients","text":"<ul> <li>Deluge ^ ^</li> <li>command-line functionality</li> <li>open-source with expandable functionalities</li> <li>chosen as the best torrent client by Lifehacker</li> <li>qBittorrent open-source, ad-free alternative to uTorrent</li> <li>Tixati closed-source</li> <li>Transmission installed by default on Ubuntu (ca. 2017)</li> <li>Tribler</li> <li>Vuze has ads and is closed-source</li> <li>Frostwire: multiplatform, including Android</li> <li>WebTorrent Desktop</li> </ul>"},{"location":"Misc/cryptocurrency/","title":"\ud83e\ude99 Cryptocurrency","text":"<p>The establishment of the ERC-20 protocol allows new tokens to launch on Ethereum's blockchain using Ethereum smart contracts. This resulted in an explosion of new cryptocurrencies in 2017. Since then, investors have switched focus to tokens that are exchanged on creditable exchanges. Initial Exchange Offerings (IEO) have become popular. ref</p> <p>Crypto tokens form one of the two categories of cryptocurrency and represent  a tradable asset or utility that is found on a blockchain. Cryptocurrency is a standard currency used for the sole purpose of making or receivng payments on the blockchain. Crypto tokens represent an underlying asset, customer loyalty points for example. ref</p>"},{"location":"Misc/cryptocurrency/#blockchain","title":"Blockchain","text":"<p>Blockchain is a distributed digital ledger consisting of interlinked blocks, each of which stores information that cannot be retroactively tampered with or deleted. ref</p> <p>Blockchain is a database technology that uses hashes to ensure reliability and security of data stored across a network of computers, popularized by BitCoin. Records, containing information, are validated and then added to Blocks, or hashed containers, which are then concatenated in a chain by associating each block with the hash of both of its neighbors. ref</p> <p>There can only be a a maximum of 21 million BTC, and the reward for mining a new bitcoin halves every 210,000 blocks. This has already occurred twice in the 10-year history of Bitcoin until late 2019, and another blockhalving is expected to occur in May 2020. ref</p>"},{"location":"Misc/languages/","title":"Languages","text":"Introductions English Spanish Portuguese Swahili How tall are you? Cuanto mides en altura? Qu\u00e3o alta eres? SpanishPortuguese <ul> <li> <p>Cuanto mides en altura?</p> </li> </ul> <ul> <li>Qu\u00e3o alto eres?</li> </ul> Politeness SwahiliSpanish <ul> <li>Habari ya asubuhi, umeamkaje?<ul> <li>Nimeamka poa.</li> </ul> </li> <li>Umeshindaje?<ul> <li>Nimeshinda poa.</li> </ul> </li> <li>Habari za mchana?</li> <li>Usiku mwema.</li> </ul> <ul> <li>Gracias por el cumplido. \"Thanks for the compliment\"</li> <li>Que tan la est\u00e1 pasando?</li> </ul> <p>Information</p> SwahiliSpanish <ul> <li>Wewe ni mkabila gani?</li> </ul> <ul> <li>Tuve que quedarme despierto hasta tarde.</li> <li>Tom\u00e9 una siesta.</li> </ul> <p>Hair</p> SpanishPortuguese <ul> <li>Cabello rizado</li> <li>Alisas tu cabello?</li> <li>Corte rapado te quedar\u00e1 bien.</li> <li>Peluca </li> </ul> <ul> <li>Peruca</li> </ul> Reconnecting PortugueseSpanish <p>Te lembras de mim?</p> <p>Me recuerdas?</p> Biography PortugueseSpanish <p>Eu quis lan\u00e7ar a discuss\u00e3o falando pouco de mim. Tenho 39 anos e trabalho na tecnologia de informa\u00e7\u00e3o como engenheiro de servidores.  Eu tenho uma filha de nove anos de um casamanto anterior. Gosto de document\u00e1rios e hist\u00f3ria. Especialmente tenho interesse na hist\u00f3ria do sul da \u00c1frica, especialmente as guerras que a \u00c1frica do Sul travava com os pa\u00edses vizinhos. Tu deves saber muito sobre esse assunto.</p> <p>Se puderes, fala de se. Eu gostar\u00eda de saber quantos irm\u00e3os tens, teus interesses, e tua hist\u00f3ria de relacionamentos. Gostas de estrangeiros, de Angolanos, outros Africanos..</p> <p>Bueno amor, como te dije quiero intercambiar \u00e1udios contigo. Quise empezar con unos hechos de mi vida e podemos partir de ah\u00ed. Tengo 39 a\u00f1os, y trabajo en inform\u00e1tica como ingeniero de servidores. Tengo una ni\u00f1a de 9 a\u00f1os de un matrimonio anterior. Me gustan documentales y hist\u00f3ria. Y mucho me gusta aprender idiomas extranjeros. Lo que te pueda interesar es que trabajaba como traductor para el gobierno estadounidense.</p> <p>Nosotros nos casamos en 2011. Nosotros nos divorciamos en 2019.</p> <p>Tengo un hermano que es tr\u00e9s a\u00f1os menor que yo. Crec\u00ed en Texas.</p> Sex French <ul> <li>Faire la cave</li> </ul>"},{"location":"Misc/languages/#angolan-dialect","title":"Angolan dialect","text":"<ul> <li>O portugu\u00eas angolano soa diferente e n\u00e3o me acostumei.</li> <li>Est\u00e1s falando por enigmas. \"you're speaking in riddles\"</li> </ul>"},{"location":"Misc/languages/#politeness","title":"Politeness","text":"<ul> <li>Asante \"Thank you\"</li> <li>Karibu \"You're welcome\"</li> </ul>"},{"location":"Misc/languages/#location","title":"Location","text":"<ul> <li>Unaishi wapi? \"Where do you live?\"</li> <li>Ninaishi Marekani \"I live in America\"</li> <li>Ninaishi Ukunda.<ul> <li>Ukunda wapi?</li> <li>Ukunda karibu na Mombasa. \"Ukunda is close to Mombasa\"</li> </ul> </li> </ul>"},{"location":"Misc/languages/#travel","title":"Travel","text":"<ul> <li>Naja Mombasa hivi karibuni \"I am coming to Mombasa very soon\"</li> <li>Nipo kunondon. \"I am here\"</li> </ul> Sex SwahiliSpanish <ul> <li>Nataka kujibamba \"I want to have fun\"</li> <li>Sawa jibambe \"Enjoy\"</li> <li>Unataka kujibamba vipi \"How do you want to have fun?\"<ul> <li>Ngono \"sex\"</li> <li>Hakuna ngono ya bure \"There is no free sex\"</li> </ul> </li> <li>Tunaweza kulala wote? \"Can we sleep together?\"</li> <li>Ninataka kulamba uko wake</li> <li>Matako \"butt\"</li> </ul> <ul> <li>en cuatro \"doggystyle\"</li> <li>chocartelo to have sex forcefully</li> </ul> <p>On prostitution</p> Spanish <p>No tiene que andar en el calle para ser una prostituta. En estos d\u00edas con aplicaciones de citas, prostitutas ya no necesitan hacer eso y facilmente encontran clientes en l\u00ednea. Yo se sobre eso personalmente porque ya encontr\u00e9 muchas muchas chicas hiciendo eso especialmente en tu pa\u00eds.</p> <p>Y pienso k tuve un malentendido sobre lo que yo busco.  Yo realmente quiero conocer a una chica y k estemos juntos, \u00edntimos, no una vez pero muchas vezes. Y quiero k salgamos juntos y nos divertamos y estemos juntos, con intimidad.</p> <p>Eso k deciste sobre tu relaci\u00f3n antiga, me parece k ese hombre no fue tu pareja pero un papi dulce.</p>"},{"location":"Misc/learn/","title":"Learning","text":""},{"location":"Misc/learn/#retrieval","title":"Retrieval","text":"<p>Retrieval-based learning refers to the coupling of two ideas:</p> <ul> <li>Retrieval processes, those involved in using available cues to actively reconstruct knowledge, are most important in learning</li> <li>Active retrieval is most important for producing learning.</li> </ul> <p>Retrieval-based learning characterizes knowledge as something that is reconstructed at the time of recall.  Knowledge reconstruction is affected by the presence or absence of retrieval cues. This is contrasted with the traditional analogy of knowledge as static storage.</p> <p>Retrieval-based learning is an outgrowth of recent cognitive science research that shows that the act of measuring knowledge - by recall, answering questions, or solving novel problems - actually aids learning.  The testing effect refers to the observation that the act of taking a test, by itself and without any feedback or further study, results in improved learning. (src)</p> <p>Retrieval effort is a key concept in retrieval-based learning, which refers to the observation that activities that are difficult and require effort can be good for learning. In other words, the effort involved in retrieval is the key to learning.</p> <p>Learning activites that engage retrieval processes include group discussions, reciprocal teaching, and questioning techniques. (src)</p> <p>Free recall refers to a specific task provided to subjects whereby the experimenter presents a list of items to be remembered and the subject is free to recall them in any order.</p>"},{"location":"Misc/learn/#paying-forward","title":"Paying forward","text":"<p>What's the best way to organize information for newcomers?</p> <p>That is to say, what is the best way to organize notes on the sources of information that I stumble across, rather than merely the information itself? The information itself is practical, but the context of what type of material assisted me in learning it should also be preserved, somehow.</p> <p>For example, for someone new to vim, Chris Toomey's talk on YouTube might be a very good tool for learners who prefer to see lectures by impassioned and articulate people. Someone who is more mechanically inclined might benefit more from <code>pacvim</code>, or other hands-on activities. Maybe a combination of both?</p> <p>Some segments of PluralSight videos on esoteric technical topics appear to cover basic material concisely and effectively, in a way that made me wish I had access to those segments when I was learning it before. Gathering this type of information could be useful, not to me, but to others.</p> <p>How do I organize my thoughts and observations on the value of sources without doubling my effort?</p> <p>Solution</p> <p>Wikipedia-style links in a static site!</p>"},{"location":"Misc/learn/#command-line-syntax","title":"Command-line syntax","text":"<p>After several weeks of refining my note-taking technique with regard to syntax, I believe I have settled on an improved workflow.</p> <p>For all command-line syntax: 1. Note the command itself within \"Commands\" spreadsheet (separate from \"Terms\", which is for vocabulary) 2. If any options are encountered, document them in <code>Options</code> 3. If commands form command groups (like <code>apt</code>, <code>docker</code>, <code>git</code>, <code>netsh</code>, etc), those command groups need to be broken out separately (\"Group-style commands\") 4. If a command launches its own REPL (<code>bluetoothctl</code>, <code>diskpart</code>, <code>fdisk</code>...) those are broken out as well</p> <p>This turned out to be far too cumbersome. Better is the approach of learning syntax in the context of actual tasks.</p>"},{"location":"Misc/learn/#finding-magic-numbers","title":"Finding magic numbers","text":"<p>Before understanding the \"lay of the land\", or rather the best epistemology for a unit of information, you are first confronted with a list of information without context. This happened while studying for the Network+. On the topic of authentication, I learned a list of material, basically concepts associated with AAA. </p> <ul> <li>Authentication process of determining...</li> <li>Authorization identifying the resources...</li> <li>Accounting tracking methods used ...</li> <li>Authentication, Authorization, Accounting, and Auditing (AAAA) conceptual model...</li> <li>Remote Authentication Dial-In User Service (RADIUS) protocol that enables ...</li> <li>Terminal Access Control Access Control System (TACACS) security protocol designed ...</li> <li>Kerberos security system ...</li> <li>ticket security tokens issued to clients ...</li> <li>Local authentication subsystem (LASS) authenticates users ...</li> </ul> <p>But after further research, I found that once you understand the role of authentication, then really there are only three main systems that implement it (according to the material): Kerberos, TACACS, and RADIUS.</p> <p>Reducing a confusing mass of knowledge into a magic number (2, 3, 4, etc) helps in identifying interrelationships between concepts and entities</p>"},{"location":"Misc/learn/#anki","title":"Anki","text":"<p>Made good progress incorporating task-based learning by simplifying procedures into command sequences with no parameters or (at most) one or two.</p> <p>Cloze notes with input comprise a low-level way of practicing the skill. The best strategy to pursue is to identify common patterns, and make the most common elements of those patterns into cloze cards.</p> <p>Basic templates:</p> DSCC# <pre><code>Configuration DnsClient\n{\n    Import-DscResource -ModuleName \"xNetworking\"\n    Node (\"ServerA\",\"ServerB\")\n    {\n        xDnsServerAddress DnsServer\n        {\n            Address=10.0.0.1\n            AddressFamily=\"Ipv4\"\n            InterfaceAlias=\"Ethernet\"\n        }\n    }\n}\n</code></pre> <pre><code>namespace HelloWorld\n{\nclass Program\n{\nstatic void Main(string[] args)\n{\nConsole.WriteLine(\"Hello world!\");\n}\n}\n}\n</code></pre> <p>Two tasks with related forms</p> <pre><code># Get connection string of account\nconstring=$(az storage account show-connection-string)\n\n# Create file share with connection string\naz storage share create --connection-string $constring\n</code></pre> <p>Single task with different implementations (see tasks associated with cloud providers)</p> <p>Creating an availability set</p> Azure PowershellAzure CLI <pre><code>New-AzAvailabilitySet\n    -PlatformUpdateDomainCount\n    -PlatformFaultDomainCount\n    -Sku \"{{c8::Aligned}}\"\n</code></pre> <pre><code>az vm availability-set create\n    --platform-update-domain-count\n    --platform-fault-domain-count\n</code></pre> <p><code>Get</code>-<code>Set</code> pattern in PowerShell</p> Capture a managed VM imageCreate a subnetCreate DNS record setChange VM sizeAdd a route to a routing table <pre><code>$vm = Get-AzVM\n$image = New-AzImageConfig -SourceVirtualMachineId $vm.Id\nNew-AzImage -Image $image\n</code></pre> <pre><code>$vnet2 = Get-AzVirtualNetwork -Name VNet2 -ResourceGroupName ExamRefRG\n$vnet2.Subnets += New-AzVirtualNetworkSubnetConfig -Name GatewaySubnet -AddressPrefix 10.2.1.0/27\n$vnet2 = Set-AzVirtualNetwork -VirtualNetwork $vnet2\n</code></pre> <pre><code>$records = @()\n$records += New-AzDnsRecordConfig -IPv4Address \"1.2.3.4\"\n$records += New-AzDnsRecordConfig -IPv4Address \"5.6.7.8\"\nNew-AzDnsRecordSet -Name \"@\" -RecordType A -ZoneName examref.com -ResourceGroupName ExamRefRG -Ttl 3600 -DnsRecords $records\n</code></pre> <pre><code>$vm = Get-AzVM\n$vm.HardwareProfile.VMSize = Standard_DS3_v2\nUpdate-AzVM -VM $vm\n</code></pre> <pre><code>$rt = New-AzRouteTable\nAdd-AzRouteConfig -RouteTable $rt\nSet-AzRouteTable -RouteTable $rt\n</code></pre>"},{"location":"Misc/learn/#structure","title":"Structure","text":"<p>Playing around with reference-style links and tooltips has me thinking that there really should be a more structured, flexible way of generating text reports from object-style hierarchical information. For example, whether a definition appears beside a word dictionary style or in a tooltip on hover is really an implementation detail. There should be an easy way of storing that data and specifying that presentation dynamically.</p> <p>What I have settled on is a multilayered note-taking strategy. Every lexeme is defined first in a slug or one-line description that establishes its epistemological context as well as its semantic significance. A stub further elaborates the lexeme, especially insofar as it encapsulates further lexemes or can be analyzed into components.</p> <p>These slugs and stubs can be presented in various ways. Most recently I have gotten into the habit of putting slugs into tooltips that appear when I hover over lexemes in my markdown notes. This is an especially elegant solution in tables, where I can provide a highly condensed and legible index of commands, each of which can be understood at a high level by hovering the mouse while still providing full details when clicked on. This is also an elegant solution in tables of contents, where I can use a tooltip to contain a synopsis of a chapter which still links to the full notes. It provides a way of rendering information of intermediary fidelity, between the mere title and fully developed notes.</p> <p>Actually, on second thought, notes themselves are not particularly useful once a topic has actually been learned...</p>"},{"location":"Misc/mkdocs-material/","title":"Mkdocs Material","text":""},{"location":"Misc/mkdocs-material/#mkdocsyml","title":"mkdocs.yml","text":"<pre><code>site_name: Notes\ntheme:\n    name: material\n    features:\n        - content.code.annotate # (1)\n    palette:\n        scheme: default\n        primary: white\nmarkdown_extensions:\n    - admonition\n    - attr_list # (5)\n    - md_in_html\n    - pymdownx.snippets # (2)\n    - pymdownx.details\n    - pymdownx.tabbed: # (4)\n        alternate_style: true\n    - pymdownx.superfences: # (3)\n        custom_fences:\n            - name: mermaid\n              class: mermaid\n              format: !!python/name:pymdownx.superfences.fence_code_format\n</code></pre> <ol> <li>This is a code annotation</li> <li>Snippets allow inclusions to be made from other files.</li> <li>Superfences allow code blocks to be palced inside tabs and admonitions.</li> <li>Tabbed allows tabs. Note that the alternate_style configuration is the only supported style and is required.</li> <li>Attribute lists are necessary for image alignment.</li> </ol>"},{"location":"Misc/mkdocs-material/#audio","title":"Audio","text":"<p>Audio clips require the md_in_html extension. Keep in mind that the filename of the audio will be appended to the route of the current page.</p> <pre><code>&lt;audio controls=\"controls\"&gt;&lt;source type=\"audio/mp4\" src=\"gabriela.m4a\"&gt;&lt;/source&gt;&lt;/audio&gt;\n</code></pre>"},{"location":"Misc/pins/","title":"Lapel pin ideas","text":"<ul> <li>Zeon </li> <li>Weyland-Yutani Corp</li> <li>Tyrell Corporation</li> <li>OCP</li> <li>Homeworld</li> <li>Mass Effect</li> <li>Renegade/Paragon</li> <li>N7</li> <li>Mirror Universe</li> </ul>"},{"location":"Misc/Text-editors/code/","title":"VS Code","text":"<p>Code can be folded by placing markers in comments</p> MarkdownC#Python <pre><code>&lt;!-- #region --&gt;\n...\n&lt;!-- #endregion --&gt;\n</code></pre> <pre><code>#region \n...\n#endregion\n</code></pre> <pre><code>#region\n...\n#endregion\n</code></pre> <p>Snippets</p> <p>\"Editor group\" refers to window panes.</p> Keyboard shortcut Setting Description ++Ctrl+\\++ <code>workbench.action.splitEditor</code> Split Editor ++Ctrl+k+Ctrl+UpArrow++ <code>workbench.action.focusAboveGroup</code> View: Focus Above Editor Group ++Ctrl+k+Ctrl+RightArrow++ <code>workbench.action.focusRightGroup</code> View: Focus Right Editor Group ++Ctrl+k+Ctrl+DownArrow++ <code>workbench.action.focusBelowGroup</code> View: Focus Below Editor Group ++Ctrl+k+Ctrl+LeftArrow++ <code>workbench.action.focusLeftGroup</code> View: Focus Left Editor Group ++Ctrl+k+UpArrow++ <code>workbench.action.moveActiveEditorGroupUp</code> View: Move Editor Group Up ++Ctrl+k+RightArrow++ <code>workbench.action.moveActiveEditorGroupRight</code> View: Move Editor Group Right ++Ctrl+k+DownArrow++ <code>workbench.action.moveActiveEditorGroupDown</code> View: Move Editor Group Down ++Ctrl+k+LeftArrow++ <code>workbench.action.moveActiveEditorGroupLeft</code> View: Move Editor Group Left ++Alt+UpArrow++ <code>editor.action.moveLinesUpAction</code> Move line up ++Alt+DownArrow++ <code>editor.action.moveLinesDownAction</code> Move line down ++Option+Command+DownArrow++ Add a cursor down ++Option+Command+UpArrow++ Add a cursor up ++Option+Shift+Left Click++ Click and drag to add cursors ++Ctrl+Shift+5++ Terminal: Split terminal ++Ctrl+h++ Replace ++Ctrl+l++ Expand line selection ++Ctrl+j++ <code>workbench.action.togglePanel</code> View: Toggle Panel ++Ctrl+b++ View: Toggle Side Bar Visibility"},{"location":"Misc/Text-editors/code/#terminal","title":"Terminal","text":"<p>The shells available in the integrated terminal for any OS can be adjusted using terminal.integrated.profiles</p> Developer PowerShell for VS 2022<pre><code>\"terminal.integrated.profiles.windows\": {\n\"Developer PowerShell for VS 2022\": {\n\"source\": \"PowerShell\",\n\"args\": [\"-NoExit\", \"-Command\",\"&amp;{Import-Module \\\"C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\Common7\\\\Tools\\\\Microsoft.VisualStudio.DevShell.dll\\\"; Enter-VsDevShell 1916cd63}\"],\n\"icon\": \"terminal-powershell\",\n}\n</code></pre>"},{"location":"Misc/Web/","title":"\ud83c\udf0e Web","text":""},{"location":"Misc/Web/#emoji","title":"Emoji","text":"<p>The codepoint U+FE0F (\"variation select 16\") is placed immediately after an emoji to indicate it should indeed be rendered as an emoji. This is used for some ambiguous codepoints that can be rendered either as emoji or as older-style glyphs, such as the heart, arrows, etc.</p> <pre><code>\u2665&amp;#xFE0F;\n</code></pre>"},{"location":"Misc/Web/#firefox","title":"Firefox","text":""},{"location":"Misc/Web/#aboutconfig","title":"about:config","text":"<ul> <li><code>font.name-list.emoji</code> Font used for emoji</li> </ul>"},{"location":"Misc/Web/CSS/","title":"CSS","text":""},{"location":"Misc/Web/CSS/#css","title":"CSS","text":""},{"location":"Misc/Web/CSS/#browser-compatibility","title":"Browser compatibility","text":"<p>User agent stylesheets are bundled with the browser and contain default CSS rules in the absence of an external stylesheet. Their styles may be removed using a reset stylesheet.</p>"},{"location":"Misc/Web/CSS/#attribute-selectors","title":"Attribute selectors","text":"<p>Selectors enclosed in square brackets \u201c[\u201d are called attribute selectors, and define selectors by the presence of an attribute - <code>a[href]</code> selects <code>anchor</code> tags with an <code>href</code> attribute - <code>a[href=\"#\"]</code> selects <code>anchor</code> tags with an <code>href</code> attribute defined as \u201c#\u201d - <code>a[href^=\"http\"]</code> all <code>anchors</code> with <code>href</code> attribute that starts with \u201chttp\u201d - <code>a[href$=\".com\"]</code> all <code>anchors</code> with <code>href</code> attribute that ends with \u201c.com\u201d. - <code>a[href*=\"volusion\"]</code> all <code>anchors</code> with <code>href</code> attribute that contains the word volusion.</p>"},{"location":"Misc/Web/CSS/#miscellaneous-properties","title":"Miscellaneous properties","text":"<p><code>overflow</code> controls how content overflows its container. Three possible values: - <code>visible</code> by default - <code>hidden</code> from view - <code>scroll</code> producing a scroll bar within the container</p> <p><code>visibility</code>  allows the content of elements to be hidden. The space reserved for the element will still be there. - <code>visible</code> by default - <code>hidden</code></p> <p><code>display</code> an element to be completely removed from the rendered webpage, unlike Visibility. - <code>none</code> - <code>unset</code> will reset the value, for example in responsive web design</p> <p><code>box-sizing</code> defines how width and height of elements are calculated  - <code>content-box</code>     by default, width and height properties includes only content - <code>border-box</code>     includes content, padding, and border</p>"},{"location":"Misc/Web/CSS/#bem-naming-convention","title":"BEM naming convention","text":"<p>In the BEM (\u201cblock, element, modifier\u201d) naming convention a double hyphen \"--\" separates an element from its modifier while a double underscore \u201c__\u201d separates an element from its subelement. For example: - .person  - .person__hand  - .person--female  - .person--female__hand  - .person__hand--left </p>"},{"location":"Misc/Web/CSS/#pseudo-classes","title":"Pseudo classes","text":""},{"location":"Misc/Web/CSS/#dynamic-selectors","title":"Dynamic selectors","text":"<ul> <li><code>:link</code> unvisited link</li> <li><code>:visited</code> visited link</li> <li><code>:hover</code> mouse hover</li> <li><code>:active</code> when a user activates an element (between click and release of mouse button)</li> </ul>"},{"location":"Misc/Web/CSS/#structural-selectors","title":"Structural selectors","text":"<ul> <li><code>:first-child</code> first child of the parent element</li> <li><code>:last-child</code> last child</li> <li><code>:nth-child(an+b)</code> where <code>a</code> represents every second, third element if a was 2 or 3 and <code>b</code> represents the first element to start the subset</li> </ul>"},{"location":"Misc/Web/CSS/#media-queries","title":"Media Queries","text":"<p><code>@media only screen and (max-width: 480px) \\{ ... \\}</code> - <code>@media</code> begins a media query - <code>only screen</code> instructs the CSS compiler to apply the rules only to display devices (other options are <code>print</code> and <code>handheld</code>) - <code>and (max-width: 480px)</code> called a media feature, CSS compiler is instructed to apply the rules to screens of less than 480 pixels - CSS rules follow in between curly braces, which will be applied if the media query is satisfied</p> <p><code>@media only screen and (max-width: 480px) and (min-resolution: 300dpi) \\{ ...\\}</code> - <code>and</code> can be used to chain multiple conditions together</p> <p><code>@media only screen and (min-width: 480px), (orientation: landscape) \\{ ... \\}</code> - <code>comma (,)</code> separates criteria either of which may be satisfied for the rules to take effect</p>"},{"location":"Misc/Web/CSS/#positioning","title":"Positioning","text":"<p>Adjusting the position of HTML elements with the following 5 properties: 1. <code>position</code> which changes the default position of an element - <code>static</code> by default - <code>relative</code> which places the element relative to its default static position by means of the 4 offset properties: <code>top</code>, <code>bottom</code>, <code>left</code>, and <code>right</code> - <code>absolute</code> all other elements will ignore the element, and the element will be positioned to its closest parent element, and will scroll with the rest of the page - <code>fixed</code> ignores user scrolling and places the element at a fixed location on the page (useful for navbars, for example). max-width:100% must be specified 2. <code>display</code> with 3 values: -  <code>inline</code> - <code>block</code> - <code>inline-block</code> Some elements, such as a, strong, em, and a are inline by default, and their height and width are defined by their content. And some elements, such as p and h1 are block by default. But these values can be manipulated in CSS. Inline-block combines features of both inline and block. They appear next to each other but their width and height can be manipulated, such as images. 3. <code>z-index</code> accepts integer values to control the depth of elements: a higher value will bring the element to the front 4. <code>float</code> which will move elements as far <code>left</code> or <code>right</code> as possible. Width must be specified. 5. <code>clear</code> specifies how elements behave when they bump into each other on the <code>left</code>, <code>right</code>, <code>both</code>, or <code>none</code> sides</p>"},{"location":"Misc/Web/CSS/#flexbox","title":"Flexbox","text":"<p>A new tool developed for CSS3 that simplifies the layout and positioning of some elements. the <code>display</code> property of the container must be set to : <code>flex</code> or <code>inline-flex</code></p> <p>There are then 10 properties that specify how its children can behave. 1.  <code>justify-content</code> (parent) with 5 values: <code>flex-start</code>, <code>flex-end</code>, <code>center</code> , <code>space-around</code>, <code>space-between</code> 2.  <code>align-items</code> (parent) vertical alignment, similar to vertical justification: - <code>stretch</code> by default, child elements will stretch from top to bottom of parent, unless height is defined. <code>min-height</code> is permissible - <code>flex-start</code>, <code>flex-end</code>, <code>center</code>, <code>baseline</code> 3.  <code>flex-grow</code> (child) allows items to grow. This property takes an integer value: higher values allow the element to grow larger. <code>max-width</code> takes precedence 0 by default 4.  <code>flex-shrink</code> (child) allows items to shrink, similar to flex-grow. <code>min-width</code> takes precedence - 1 by default 5.  <code>flex-basis</code> (child) allows the parent to be sized  6.  <code>flex</code> (child) allows flex-grow, flex-shrink, and flex-basis to be defined in a single line, in that order 7.  <code>flex-wrap</code> (parent) similar to text-wrapping, causing child elements to overflow to another line. 3 values: <code>nowrap</code> by default, <code>wrap</code>, <code>wrap-reverse</code> 8.  <code>align-content</code> (parent) affects the behavior of child elements while wrapping similar to align-items: <code>flex-start</code>, <code>flex-end</code>, <code>center</code>, <code>space-between</code>, <code>space-around</code>, <code>stretch</code> 9.  <code>flex-direction</code> (parent) allows flex containers to define how children are populated and which directions are assigned to the major and cross axes: <code>row</code>, <code>row-reverse</code>, <code>column</code>, <code>column-reverse</code> 10. <code>flex-flow</code> (parent) allows both flex-wrap and flex-direction properties to be declared on a single line</p>"},{"location":"Misc/Web/CSS/#animation","title":"Animation","text":"<p>Simple transitions - <code>transition-property</code> specifies the property which is to be animated - <code>transition-duration</code> specifies animation length, in seconds (<code>s</code>) or milliseconds (<code>ms</code>) - <code>transition-delay</code></p> <p>Timing function Default value is <code>ease</code> - <code>ease-in</code> starts slow, accelerates quickly, stops abruptly - <code>ease-out</code> begins abruptly, slows down, and ends slowly - <code>ease-in-out</code> starts slow, gets fast, ends slow - <code>linear</code> constant speed</p> <p><code>Transition</code> declaration combines multiple declarations for brevity <code>transition: transition-property transition-duration transition-timing-function (optional: transition-delay)</code></p>"},{"location":"Misc/Web/CSS/#accessibility","title":"Accessibility","text":"<p>Accessible Rich Internet Applications (ARIA) describe guidelines to make webpages accessible to a broad audience. - Use semantic elements: <code>article</code>, <code>aside</code>, <code>details</code>, <code>figcaption</code>, <code>figure</code>, <code>footer</code>, <code>header</code>, <code>main</code>, <code>mark</code>, <code>nav</code>, <code>section</code>, <code>summary</code>, <code>time</code>. - <code>role=\"complementary\"</code> attribute and value help a screen reader to understand that the element contains information supporting other text - <code>role=\"presentation\"</code> suppresses a screen reader\u2019s reading of the name of the element when unnecessary (for ordered lists, for example) - ARIA properties such as <code>aria-label=\"...\"</code> identify the significance of ambiguous elements  - <code>alt</code> attributes of some elements is built in (i.e. img). It can be empty but should always be present. Limit of 150 characters.</p>"},{"location":"Misc/Web/CSS/#bootstrap","title":"Bootstrap","text":"<p>Most popular front-end framework. CSS library used by developers to quickly build responsive websites - <code>.navbar</code> applied to top-level <code>nav</code> element - themes: <code>.navbar-default</code>, <code>.navbar-inverse</code> (dark), <code>.navbar-brand</code> applied to <code>anchor</code> element</p> <p>Positioning: <code>.navbar-fixed-top</code>, <code>.navbar-fixed-bottom</code>, <code>.navbar-left</code>, <code>.navbar-right</code></p> <p>Jumbotron: showcase area directly beneath header, drawing attention to important site content - <code>.jumbotron</code>, <code>.jumbotron-fluid</code></p>"},{"location":"Misc/Web/CSS/#grid-system","title":"Grid system","text":"<p>All grid content must be wrapped in a <code>.container</code> or <code>.container-fluid</code> div - <code>.row</code> direct children of the <code>.container</code> have 12 columns - <code>.col-md-\\#</code> direct children of <code>.row</code>, spans # columns; <code>.col-md-4</code> 4 columns, <code>.col-md-6</code> 6 columns, etc - <code>.col-xs-\\#</code> applied to <code>img</code>, spans # columns</p>"},{"location":"Misc/Web/CSS/#responsive-design","title":"Responsive design","text":"<ul> <li><code>.col-xs-x</code> when viewport is less than 768px</li> <li><code>.col-sm-x</code> 768-991px</li> <li><code>.col-md-x</code> 992-1199px</li> <li><code>.col-lg-x</code> greater than 1199px</li> </ul>"},{"location":"Misc/Web/CSS/#buttons","title":"Buttons","text":"<p><code>.btn</code></p> <p>Color schemes: <code>.btn-primary</code>, <code>.btn-secondary</code>, <code>.btn-success</code>, <code>.btn-info</code>, <code>.btn-warning</code>, <code>.btn-danger</code>, <code>.btn-link</code></p>"},{"location":"Misc/Web/CSS/#low-quality-image-placeholders-lqip-in-react","title":"Low-Quality Image Placeholders (LQIP) in React","text":"<p>devtips (a-74Zy9EfMQ)</p> <ul> <li>Wrap the image in a div</li> </ul> <pre><code>&lt;div className=\"imageWrapper\"&gt;\n</code></pre> <ul> <li>Use <code>padding-bottom</code> to define height in terms of <code>width</code></li> </ul> <pre><code>padding-bottom: 150%;\n</code></pre> <ul> <li>Create logic to replace the placeholder image with the high-quality image upon load</li> </ul> <pre><code>const image = {\n    original: './path/original.jpg',\n    optimized: './path/optimized.jpg',\n    svg: './path/svg.svg'\n}\n</code></pre> <pre><code>componentDidMount() {\n    const img\n    img.src = image.original\n    img.onload = function() {\n\n        // Query the DOM\n        document\n            .querySelector('imageWrapper')\n            .style['background-image']\n            = `url('${img.src}')`\n    }\n}\n</code></pre> <ul> <li>Ensure proper scaling</li> </ul> <pre><code>background-size: 100%;\n</code></pre>"},{"location":"Misc/Web/mkdocs/","title":"Mkdocs","text":"<p>Supporting emoji (src)</p> mkdocs.yml<pre><code>markdown_extensions:\n    - pymdownx.emoji: # from https://squidfunk.github.io/mkdocs-material/reference/icons-emojis/#emoji\n        emoji_index: !!python/name:materialx.emoji.twemoji\n        emoji_generator: !!python/name:materialx.emoji.to_svg\n</code></pre>"},{"location":"Misc/Web/JavaScript/","title":"Axios","text":"<p>Accessing RESTful web services and HTTP APIs in JavaScript. Inspired by the <code>$http</code> service in Angular, and development of Axios was an effort to provide a similar standalone service for use outside of Angular.</p> <pre><code>axios\n  .get(url)\n  .then(response =&gt; console.log(response))\n  .catch(error =&gt; console.log(error))\n</code></pre>"},{"location":"Misc/Web/JavaScript/#installation","title":"Installation","text":"<ul> <li>$ <code>npm install axios</code></li> <li>cdn link: https://unpkg.com/axios/dist/axios.min.js</li> </ul>"},{"location":"Misc/Web/JavaScript/#tutorial","title":"Tutorial","text":"<p>GET request for a given user ID: <pre><code>const axios = require('axios')\naxios.get('/user?ID=12345')   // Request user with given ID\n.then(function (res) {\nconsole.log(res)          // Handle success\n})\n.catch(function (err)\n{\nconsole.log(err)          // Handle error\n}\n)\n.then(function () {})       // Always executed\n</code></pre> Alternatively <pre><code>axios.get('user', {\nparams: { ID: 12345 }\n}\n)\n.then(function (response) { console.log(response) })\n.catch(function (error) { console.log(error) })\n.then(function () {})\n</code></pre></p>"},{"location":"Misc/Web/JavaScript/#blade","title":"Blade","text":"<p>Templating engine used in Laravel</p>"},{"location":"Misc/Web/JavaScript/#directives","title":"Directives","text":"<ul> <li><code>@section('component')</code> Used to define a section of content</li> <li><code>@yield('variable')</code> Used to display the contents of a given section</li> <li><code>@endsection</code></li> <li><code>@parent</code> append content, rather than overwrite</li> </ul>"},{"location":"Misc/Web/JavaScript/#gulp","title":"Gulp","text":"<p>Toolkit for automating time-consuming tasks in development workflow - <code>const gulp = require('gulp');</code> - gulp-uglify <code>const uglify = require('gulp-uglify');</code></p> <pre><code>gulp.task('scripts', function() {\ngulp.src('src/*.js')\n.pipe(uglify())\n.pipe(gulp.dest('dist'));\n}\n);\n</code></pre>"},{"location":"Misc/Web/JavaScript/#laravel","title":"Laravel","text":"<p>PHP framework for the development of web applications following the model-view-controller architectural pattern. Developed as a more advanced alternative to the CodeIgniter framework.</p> <p>Installation</p> <ul> <li>XAMPP, MAMP (Mac), or WAMP (Windows) to ensure the Apache server environment</li> <li>Composer dependency manager for PHP, similar to npm. It will want to know where the <code>PHP.exe</code> file is, which will be in the directory installed of the server environment installed above.</li> <li>VS Code, Git Bash, Git</li> </ul> <p>Initialization <pre><code>composer create-project laravel/laravel lsapp\ncd lsapp\n</code></pre></p> <p>This project will be accessible at <code>localhost/lsapp/</code>. This is a security issue and must be fixed:</p> <ul> <li>Edit <code>C:/xampp/apache/conf/extra/httpd-vhosts.conf</code> (if using XAMPP)</li> <li>Uncomment the opening and closing tags for the <code>VirtualHost</code> tag</li> <li>Uncomment the <code>DocumentRoot</code> line, changing the path to the <code>public</code> directory</li> <li>Uncomment the <code>ServerName</code> line, which can be named arbitrarily, e.g. <code>lsapp.dev</code></li> <li> <p>Add another <code>VirtualHost</code> pointing to the htdocs directory (within which lsapp was created) and set <code>ServerName</code> to localhost</p> </li> <li> <p>Open Notepad as an administrator   Navigate to <code>C:/Windows/System32/drivers/etc</code>, view All files, and open <code>hosts</code>   Add <code>127.0.0.1 localhost</code>   Add <code>127.0.0.1 lsapp.dev</code></p> </li> </ul> <p>Stop and then start the Apache server</p>"},{"location":"Misc/Web/JavaScript/#folder-structure","title":"Folder structure","text":"<ul> <li><code>public/</code> frontend of the application</li> <li><code>app/</code> all models go in this folder, including User.php</li> <li><code>Http/Controllers/</code> contains all controllers</li> <li><code>resources/views/</code> all Laravel views use the Blade template engine </li> <li><code>routes</code> routing middleware can be installed here</li> <li><code>config/database.php</code> contains settings</li> </ul>"},{"location":"Misc/Web/JavaScript/#syntax","title":"Syntax","text":"<ul> <li><code>namespace</code> keyword assigns an identifier</li> <li><code>Illuminate</code> refers to Laravel core</li> </ul>"},{"location":"Misc/Web/JavaScript/#typescript","title":"TypeScript","text":"<p>Programming language developed and maintained by Microsoft, a strict syntactical superset of JavaScript which supports generic programming</p> <ul> <li>static typing using annotations, including <code>number</code>, <code>boolean</code>, <code>string</code>, and <code>any</code>. These declarations can be exported to a declarations file.</li> </ul> <pre><code>function add(left: number, right: number): number {\nreturn left + right;\n}\n</code></pre>"},{"location":"Misc/Web/JavaScript/#promises","title":"Promises","text":"<p>A promise is the eventual result of an asynchronous operation.</p> <p>Stages: </p> <ul> <li>Wrapping</li> <li><code>then</code>-ing</li> <li>Catching</li> <li>Chaining</li> </ul> <p>Promises can be in one of 4 states:</p> <ul> <li><code>fulfilled</code>: action relating to the promise succeeded</li> <li><code>reject</code>: action relating to the promise failed</li> <li><code>pending</code>: has not fulfilled or rejected yet</li> <li><code>settled</code>: has fulfilled or rejected</li> </ul> <p>Promises vs. events</p> <ul> <li>an event listener registered after an event has occurred will never fire</li> <li>an action set for resolution can fire after a promise has already resolved</li> <li>an event can fire many times, but promises can only settle once</li> </ul> <p>Promise is a try/catch wrapper around code that will finish at an unpredictable time</p> <p>A <code>Promise</code> takes a function as argument. That function takes two arguments: <code>resolve</code> and <code>reject</code>. They are both callbacks that will execute when the promise has succeeded or failed</p> <p>any argument passed to <code>resolve</code> or <code>reject</code>, will then be received by <code>then</code> or <code>catch</code> methods, respectively</p> <p><code>resolve</code> leads to the next <code>then</code> in the chain, and <code>reject</code> leads to the next <code>catch</code></p>"},{"location":"Misc/Web/JavaScript/#glossary","title":"Glossary","text":""},{"location":"Misc/Web/JavaScript/#babel","title":"Babel","text":"<p>JavaScript preprocessor</p>"},{"location":"Misc/Web/JavaScript/Express/","title":"Express","text":"<pre><code>const express = require('express')\nconst app = express()\n\napp.get('/', (req,res) =&gt; res.send('Hello world!'))\napp.listen(3000, () =&gt; console.log('Server ready'))\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/","title":"React","text":"<p>Most popular JavaScript library for building user interfaces, built by Facebook in 2011, competing with Angular and Vue.  Every React application is a tree of components: independent, isolated, and reusable pieces of UI.  React Elements map to DOM elements maintained in memory (Virtual DOM).  React state changes are then updated to the real DOM.</p> <ul> <li>React is a library</li> <li>Angular is a framework</li> </ul> <p><pre><code>sudo npm i -g create-react-app@1.5.2\n\n# Create ./src/App.js\ncreate-react-app $APPNAME\n\n# Launch development server at http://localhost:3000/\nnpm start\n</code></pre> <pre><code>// index.js\nimport React from 'react';\nimport ReactDOM from 'react-dom';\n\nconst element = &lt;h1&gt;Hello World&lt;/h1&gt;;\nconsole.log(element);\n</code></pre></p>"},{"location":"Misc/Web/JavaScript/React/#counter-app","title":"Counter app","text":"<ul> <li><code>create-react-app counter-app</code>         Create counter-app</li> <li>Ctrl+` to open terminal within Code</li> <li><code>npm i bootstrap@4.1.1</code>     Install Bootstrap into the app</li> <li>Cmd+P to open file explorer     Find index.js</li> <li>Append <code>import 'bootstrap/dist/css/bootstrap.css'</code> to import statements at top</li> </ul>"},{"location":"Misc/Web/JavaScript/React/#creating-a-component","title":"Creating a component","text":"<p>By convention, components are added to the components directory</p> <p>Using the Simple React Snippets extension for Code allows convenient expansion: - <code>imrc</code>: Import React/Component - <code>cc</code>: Class Component</p> <p>React is being imported because the JSX expression will be compiled into a React object.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx","title":"counter.jsx","text":"<pre><code>import React, { Component } from 'react';\n\nclass Counter extends Component {\n render() { \n  return ( &lt;h1&gt;Hello World&lt;/h1&gt; );\n}}\n\nexport default Counter;\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#indexjs","title":"index.js","text":"<pre><code>...\nimport Counter from './components/counter';\n\nReactDOM.render(&lt;Counter /&gt;, document.getElementById('root'));\n...\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#embedding-expressions","title":"Embedding expressions","text":"<p>A button is added into the HTML within counter.jsx</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_1","title":"counter.jsx","text":"<pre><code>import React, { Component } from 'react';\n\nclass Counter extends Component {\n render() { \n  return ( &lt;div&gt;&lt;h1&gt;Hello World&lt;/h1&gt;&lt;button&gt;Increment&lt;/button&gt;&lt;/div&gt; );\n }\n}\n\nexport default Counter;\n</code></pre> <p>Upon compile, the JSX expression within render() is converted to a statement using the <code>React.createElement()</code> method, which takes two arguments.</p> <p>Replacing <code>&lt;div&gt;</code> with <code>&lt;React.Fragment&gt;</code> - Cmd+D to select all instances - Shift+Option+F to format document</p> <p>Instead of hard-coding \u201cHello World\u201d, we can display a dynamic value. We do this at the component level using the <code>state</code> property, which is an object.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_2","title":"counter.jsx","text":"<pre><code>import React, { Component } from \"react\";\n\nclass Counter extends Component {\n state = {\n  count: 0\n };\n\n render() {\n  return (\n   &lt;React.Fragment&gt;\n    &lt;span&gt;{this.state.count}&lt;/span&gt;\n    &lt;button&gt;Increment&lt;/button&gt;\n   &lt;/React.Fragment&gt;\n  );\n}}\n\nexport default Counter;\n</code></pre> <p>In between those curly braces, we can write any valid JavaScript expression, even arithmetic.</p> <p>Adding a formatCount() method which will return the string \u2018Zero\u2019 if count is zero. </p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_3","title":"counter.jsx","text":"<pre><code>import React, { Component } from \"react\";\n\nclass Counter extends Component {\n state = {\n  count: 0\n };\n\n render() {\n  return (\n   &lt;React.Fragment&gt;\n    &lt;span&gt;{this.formatCount()}&lt;/span&gt;\n    &lt;button&gt;Increment&lt;/button&gt;\n   &lt;/React.Fragment&gt;\n  );\n }\n\n formatCount() {\n  const { count } = this.state;\n   return count === 0 ? 'Zero' : count;\n}}\n\nexport default Counter;\n</code></pre> <p>Alternatively, instead of returning plaintext, we can return a JSX expression with h1: <code>return count === 0 ? &lt;h1&gt;Zero&lt;/h1&gt; : count;</code></p>"},{"location":"Misc/Web/JavaScript/React/#setting-attributes","title":"Setting attributes","text":"<p>HTML attributes can also render dynamically imported data:</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_4","title":"counter.jsx","text":"<pre><code>import React, { Component } from \"react\";\n\nclass Counter extends Component {\n  state = {\n    count: 0,\n    imageUrl: 'https://picsum.photos/200'\n  };\n\n  render() {\n    return (\n      &lt;React.Fragment&gt;\n        &lt;img src={ this.state.imageUrl } alt=\"\"/&gt;\n        &lt;span&gt;{this.formatCount()}&lt;/span&gt;\n        &lt;button&gt;Increment&lt;/button&gt;\n      &lt;/React.Fragment&gt;\n    );\n  }\n\n  formatCount() {\n    const { count } = this.state;\n    return count === 0 ? 'Zero' : count;\n  }\n}\n\nexport default Counter;\n</code></pre> <p>Specifying HTML class requires <code>className</code> because <code>Class</code> is a reserved word in JavaScript.</p> <pre><code>...\nrender() {\n return (\n  &lt;React.Fragment&gt;\n   &lt;span className=\"badge badge-primary m-2\"&gt;{this.formatCount()}&lt;/span&gt;\n   &lt;button className=\"btn btn-secondary btn-sm\"&gt;Increment&lt;/button&gt;\n  &lt;/React.Fragment&gt;\n );\n}\n</code></pre> <p>CSS styling can be specified in the same way, passing an object in as an HTML attribute     ...     styles = {      fontSize: 50,      fontWeight: 'bold'     }</p> <pre><code>render() {\n return (\n  &lt;React.Fragment&gt;\n   &lt;span style = {this.styles} className=\"badge badge-primary m-2\"&gt;{this.formatCount()}&lt;/span&gt;\n   &lt;button className=\"btn btn-secondary btn-sm\"&gt;Increment&lt;/button&gt;\n  &lt;/React.Fragment&gt;\n );\n}\n...\n</code></pre> <p>Alternatively, CSS can be defined inline by using double curly braces: <code>...&lt;span style={{fontSize: 30}}&gt;...</code></p>"},{"location":"Misc/Web/JavaScript/React/#rendering-classes-dynamically","title":"Rendering classes dynamically","text":"<p>CSS classes can be edited using simple string concatenation techniques that key off of conditional statements</p> <pre><code>...\n render() {\n  let classes = \"badge m-2 badge-\";\n  classes += this.state.count === 0 ? \"warning\" : \"primary\";\n\n  return (\n   &lt;React.Fragment&gt;\n    &lt;span className={classes}&gt;{this.formatCount()}&lt;/span&gt;\n...\n</code></pre> <p>The lines associated with <code>classes</code> cause the <code>render()</code> method to become bloated. We can refactor within Code using Ctrl+Shift+R, which extracts the two lines to a new method.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_5","title":"counter.jsx","text":"<pre><code>...\n getBadgeClasses() {\n  let classes = \"badge m-2 badge-\";\n  classes += this.state.count === 0 ? \"warning\" : \"primary\";\n  return classes;\n }\n...\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#rendering-lists","title":"Rendering lists","text":"<p>Let\u2019s see how to render a list of tags. Loops do not exist as a concept within JSX, but we can use the <code>.map()</code> method with arrays.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_6","title":"counter.jsx","text":"<pre><code>...\n state = {\n  count: 0,\n  tags: ['tag1','tag2','tag3']\n };\n...\n    &lt;ul&gt;\n     { this.state.tags.map(tag =&gt; &lt;li&gt;{tag}&lt;/li&gt;)}\n    &lt;/ul&gt;\n...\n</code></pre> <p>This produces an error in the console, because React wants each DOM element to have a distinct key value. For now, we can use the same tag as a key.</p> <pre><code>&lt;ul&gt;\n { this.state.tags.map(tag =&gt; &lt;li key ={tag}&gt;{ tag}&lt;/li&gt;)}\n&lt;/ul&gt;\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#conditional-rendering","title":"Conditional rendering","text":"<p>Unlike Angular, JSX is not a templating engine, so there are no conditionals. We can use JavaScript outside of the JSX expression and pass that into the expression.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_7","title":"counter.jsx","text":"<p>Another technique is to take advantage of truthy expressions and how JavaScript evaluates the logical AND operator.</p>"},{"location":"Misc/Web/JavaScript/React/#handling-events","title":"Handling events","text":"<p>Properties based on standard DOM events placed within JSX expressions (note camelcase): - <code>onClick()</code> - <code>onDoubleClick</code> - <code>onKeyDown</code> - <code>onKeyUp</code> - <code>onKeyPress</code></p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_8","title":"counter.jsx","text":"<pre><code>...\n handleIncrement() {\n  console.log('Increment clicked')\n }\n...\n&lt;button onClick={this.handleIncrement} ...\n</code></pre> <p>Attempting to log <code>this.state.count</code> produces an error, revealing that count is not available to the method.</p>"},{"location":"Misc/Web/JavaScript/React/#binding-event-handlers","title":"Binding event handlers","text":"<p>JavaScript will return undefined if <code>this</code> is used in strict mode in a standalone function without an object reference. To solve this, we use the bind method.</p> <p>We have to add a constructor for every event handler</p> <pre><code>constructor() {\n super();\n this.handleIncrement = this.handleIncrement.bind(this);\n }\n</code></pre> <p>Alternatively, an arrow function can be used because they inherit the <code>this</code> object.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_9","title":"counter.jsx","text":"<pre><code>handleIncrement = () =&gt; {\n console.log(\"Increment Clicked\", this\")\n};\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#updating-state","title":"Updating state","text":"<p>State cannot be updated directly, e.g. <code>this.state.count++;</code> is ineffective. React must be told explicitly what part of the DOM has been changed, unlike Angular.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_10","title":"counter.jsx","text":"<p>handleIncrement = () =&gt; {     this.state.count++;     this.setState({ count: this.state.count + 1 });      }</p> <p>To solve this problem we use of the <code>setstate()</code> method available in the <code>Component</code> class (from which <code>Counter</code> inherits).</p> <pre><code>handleIncrement = () =&gt; {\n this.setState( { count: this.state.count + 1 });\n};\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#what-happens-when-state-changes","title":"What happens when state changes","text":"<p>When state changes, an asynchronous call is made to the <code>render</code> method. React compares the updated virtual DOM with the old, real DOM and updates only the DOM nodes which need updating.</p>"},{"location":"Misc/Web/JavaScript/React/#pass-arguments-using-arrow-functions","title":"Pass arguments using arrow functions","text":"<p>Earlier, we saw that the <code>onClick()</code> method only takes a function reference, not a full function call with parameters.</p> <p>We can declare a new method named <code>.doHandleIncrement()</code> which acts as a wrapper for <code>.handleIncrement()</code>, passing an argument.</p>"},{"location":"Misc/Web/JavaScript/React/#counterjsx_11","title":"counter.jsx","text":"<pre><code>doHandleIncrement = () =&gt; {\n this.handleIncrement({ id: 1})\n}\n</code></pre> <p>But this is wasteful. Better is defining an inline function.</p> <pre><code>...\n&lt;button\n onClick={ () =&gt; this.handleIncrement(product)}\n className=\"btn btn-secondary btn-sm\"\n&gt;\n...\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#summary","title":"Summary","text":"<ul> <li>JSX (JavaScript XML)</li> <li>Rendering lists</li> <li>Conditional rendering</li> <li>Handling events</li> <li>Updating state</li> </ul>"},{"location":"Misc/Web/JavaScript/React/#composing-components","title":"Composing components","text":"<p>Changing <code>Counter</code> component to <code>Counters</code></p> <p>Every React component has a property called <code>props</code></p>"},{"location":"Misc/Web/JavaScript/React/#index-of-react-commands-and-methods","title":"Index of React commands and methods","text":"<ul> <li><code>.setstate()</code></li> </ul>"},{"location":"Misc/Web/JavaScript/React/#javascript-for-react-developers","title":"JavaScript for React Developers","text":""},{"location":"Misc/Web/JavaScript/React/#let-vs-var-vs-const","title":"<code>let</code> vs <code>var</code> vs <code>const</code>","text":"<p>Variables declared with <code>let</code> are block-scoped.</p>"},{"location":"Misc/Web/JavaScript/React/#example","title":"example","text":"<pre><code>function sayHello() {\n for (let i = 0; i &lt; 5; i++) {\n  console.log(i);\n }&gt;)\nconsole.log(i) // undefined\n}\n\nsayHello();\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#objects","title":"Objects","text":""},{"location":"Misc/Web/JavaScript/React/#example_1","title":"example","text":"<pre><code>const person = {\n name: 'Mosh',\n walk: function() {},\n talk() {} // Alternative way of declaring a method\n}\n\nperson.talk();\nconst targetMember = 'name';\nperson[targetMember.value] = 'John'\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#this-keyword","title":"<code>this</code> keyword","text":"<p><code>this</code> can be made explicit by using the <code>bind</code> method, which will avoid complications of using <code>this</code> in top-level function calls.</p> <p>Functions are objects in JavaScript.</p>"},{"location":"Misc/Web/JavaScript/React/#example_2","title":"example","text":"<pre><code>const person = {\n name: 'Mosh',\n walk() {\n  console.log(this);\n },\n}\n\nperson.walk(); // person {}\n const walk = person.walk.bind(person)\n</code></pre> <p>In React, strict mode is enabled by default, so the <code>this</code> keyword returns <code>undefined</code>.</p>"},{"location":"Misc/Web/JavaScript/React/#example_3","title":"example","text":"<pre><code>const person = {\n name: 'Mosh',\n walk() {\n  console.log(this);\n },\n}\n\nperson.walk(); // person {}\n\nconst walk = person.walk();\nwalk();        // undefined\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#arrow-functions","title":"Arrow functions","text":"<p>Arrow functions allow a good way to clean up code for the simplest functions.     const square = function(number) {         return number * number     }</p> <pre><code>const square = number =&gt; number * number;\n</code></pre> <p>But they do not rebind the <code>this</code> object for callback functions.</p>"},{"location":"Misc/Web/JavaScript/React/#arraymap","title":"Array.map()","text":"<p>One of the new array methods defined in ECMAScript 6, <code>.map()</code> is very useful in rendering lists.     const colors = ['red','green','blue']     const items = colors.map(color =&gt; <code>&lt;li&gt;${color}&lt;/li&gt;</code>)     })</p>"},{"location":"Misc/Web/JavaScript/React/#object-destructuring","title":"Object destructuring","text":"<pre><code>const address = {\n    street: '',\n    city: '',\n    country: ''\n}\n\nconst street = address.street;\nconst city = address.city;\nconst country = address.country;\n</code></pre> <p>The repetitive use of the object name <code>address</code> is a good object to use destructuring syntax.</p> <pre><code>const {street, city, country } = address;\nconst {street: st } = address;\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#classes","title":"Classes","text":"<p>When we have an object with at least one method, we use classes to ensure that child objects do not reduplicate code unnecessarily.</p> <pre><code>const person = {\n name: 'Mosh',\n walk() {\n  constole.log('walk') // console is mispelled\n}}\n\nconst person2 = {\n name: 'Mosh',\n walk() {\n  constole.log('walk') // copying reduplicates the error\n}}\n\nclass Person {\n constructor(name) {\n  this.name = name;\n }\n walk() {\n  console.log('walk');\n}}\n\nconst person = new Person('Mosh');\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#inheritance","title":"Inheritance","text":"<pre><code>class Person {\n constructor(name) {\n  this.name = name;\n }\n walk() {\n  console.log('walk');\n }\n}\n\nclass Teacher {           // Teacher should also be able to walk, \n teach() {                // but we don't want to reduplicate code...\n  console.log('teach');\n }\n}\n\nclass Teacher extends Person {\n constructor(name, degree) {\n  super(name)                 // references parent class\n  this.degree = degree\n }\n\n teach() {\n  console.log('teach')\n }\n}\n\nconst teacher = new Teacher ('Mosh', 'MSc')\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#modules","title":"Modules","text":"<p>Splitting code across multiple files, each of which is called a module. Class keyword must be prefixed by <code>export</code></p> <p>person.js     export class Person {      constructor(name) {       this.name = name;      }      walk() {       console.log('walk');      }     }</p> <p>teacher.js     import { Person } from './person'      // extension is not added</p> <pre><code>export class Teacher extends Person {\n constructor(name, degree) {\n  super(name)\n  this.degree = degree\n }\n\n teach() {\n  console.log('teach')\n }\n}\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#indexjs_1","title":"index.js","text":"<pre><code>import Teacher from './teacher'\n\nconst teacher = new Teacher ('Mosh', 'MSc')\n</code></pre>"},{"location":"Misc/Web/JavaScript/React/#named-and-default-exports","title":"Named and default exports","text":"<ul> <li><code>default</code> keyword to export an entire object, after <code>export</code> and before <code>class</code></li> <li>named exports to export functions using the <code>export</code> keyword</li> <li>named exports must be individually named and placed within braces</li> </ul>"},{"location":"Misc/Web/JavaScript/React/#react-native","title":"React Native","text":"<p>React Native is like react, but it uses native components instead of web components as building blocks, allowing true mobile apps to be programmed.</p> <pre><code>import React, { Component } from 'react';\nimport { Text, View } from 'react-native';\n\nexport default class HelloWorldApp extends Component {\nrender() {\nreturn (\n&lt;View&gt;\n&lt;Text&gt;Hello world!&lt;/Text&gt;\n&lt;/View&gt;\n);\n}\n}\n</code></pre> <p>Parameters associated with customizing components are called props that appear similar to HTML attributes: <pre><code>&lt;Greeting name='Jaina'/&gt;\n&lt;Greeting name='Sanjay'/&gt;`\n</code></pre></p> <p>Two types of data control a component:  1. <code>props</code> set by the parent are fixed throughout the lifetime of a component 2. <code>state</code> data that changes</p>"},{"location":"Misc/Web/JavaScript/Web%20Components/","title":"Web Components","text":"<p>Web Components is a suite of technologies allowing you to create reusable custom elements</p>"},{"location":"Misc/Web/JavaScript/Web%20Components/#3-main-technologies","title":"3 main technologies:","text":"<ol> <li>Custom elements set of APIs that allow you to define custom elements and their behavior</li> <li>Shadow DOM set of APIs for attaching an encapsulated shadow DOM tree to an element, rendered separately from the main document DOM, to keep an element's features private.</li> <li>HTML templates write markup templates using <code>template</code> and <code>slot</code> elements that are not rendered in the rendered page.</li> </ol>"},{"location":"Misc/Web/JavaScript/Web%20Components/#basic-approach","title":"Basic approach:","text":"<ol> <li>Create a <code>class</code> or function in which you specify web component functionality</li> <li>must use <code>super()</code> command at the top</li> <li> <p>must contain a <code>constructor()</code> function that defines structure of Shadow DOM using <code>appendChild()</code> methods</p> </li> <li> <p>Use <code>CustomElementRegistry.define()</code> to link the component <code>class</code> and the custom element</p> </li> <li>Attach a Shadow DOM to custom element using <code>Element.attachShadow()</code> and add children, event listeners, using regular DOM methods: <code>const shadow = this.attachShadow({mode: 'open'})</code></li> <li>Define an HTML template using <code>template</code> and <code>slot</code></li> <li>Use custom element at will on page.</li> </ol>"},{"location":"Misc/Web/JavaScript/Web%20Components/#2-types-of-custom-elements","title":"2 types of custom elements:","text":"<ol> <li>Autonomous custom elements are standalone and don't inherit from standard HTML elements, e.g. <code>&lt;popup-info&gt;</code> or <code>document.createElement('popup-info')</code>. They almost always extend <code>HTMLElement</code></li> <li>Customized built-in elements inherit from basic HTML elements, e.g. <code>&lt;p is=\"word-count\"&gt;</code> or <code>document.createElement(\"p\",{ is: \"word-count\"})</code></li> </ol>"},{"location":"Misc/Web/JavaScript/Web%20Components/#lifecycle-callbacks","title":"Lifecycle callbacks","text":"<p><code>adoptedCallback</code> invoked each time the custom element is moved to a new document <code>attributeChangedCallback</code> invoked when one of the custom element's attributed is added, removed, or changed <code>connectedCallback</code> invoked every time the custom element is appended into a document-connected element <code>disconnectedCallback</code> invoked each time the custom element is disconnected from the document's DOM</p>"},{"location":"Misc/Windows/","title":"Windows","text":"<p>Like other multiuser OSes, Windows architecture draws a distinction between kernel mode and user mode. When user-mode threads call a system service, a special instruction is executed that switches the calling thread to kernel mode. When the call completes, the thread context is switched back to user mode.</p> executive The Windows executive contains base OS services like memory management, process and thread management, security, I/O, networking, and IPC heterogeneous multi-processing A type of SMP-based design where some processor cores have less capability but higher efficiency than others. This allows power consumption to be reduced by allocating appropriate work to slower cores while power managing the faster ones. kernel The Windows kernel consists of low-level OS functions, like thread scheduling, interrupt, and exception dispatching, and multiprocessor synchronization. It also provides a set of routines and basic objects that the rest of the executive uses to implement higher-level constructs. kernel mode privileged processor mode with access to system data and hardware user mode non-privileged processor mode with limited access to system data and no direct access to hardware"},{"location":"Misc/Windows/#windows-core-files","title":"Windows core files","text":"condrv.sys Console driver, which spawns conhost.exe dwm.exe Desktop Window Manager ntdll.dll Special system support library primarily for the use of subsystem DLLs and native applications (meaning images that are not tied to any particular subsystem) ntoskrnl.exe contains the Windows executive and kernel ssmss.exe Session Manager"},{"location":"Misc/Windows/Active%20Directory/","title":"Active Directory","text":""},{"location":"Misc/Windows/Active%20Directory/#table-of-contents","title":"Table of Contents","text":"<p><code>01</code> <code>02</code> <code>03</code> <code>04</code> <code>05</code> <code>06</code> <code>07</code> <code>08</code> <code>09</code> <code>10</code> <code>11</code> <code>12</code> <code>13</code> <code>14</code> <code>15</code> <code>16</code> <code>17</code> <code>18</code> <code>19</code> <code>20 </code>\\ <code>21</code> <code>22</code> <code>23</code> <code>24</code> <code>25</code> <code>26</code> <code>27</code> <code>28</code> <code>29</code> <code>30 </code> <code>31</code> <code>32</code> <code>33</code> </p>"},{"location":"Misc/Windows/Active%20Directory/#terms","title":"Terms","text":"<ul> <li>Active Directory components</li> <li>Active Directory Lightweight Directory Services (AD LDS)) <ul> <li>Instance</li> <li>Configuration set</li> <li>Replica</li> <li>Partition/naming context</li> <li>Application partition</li> <li>Configuration partition</li> <li>Schema partition</li> <li>Bindable object</li> <li>Bindable proxy object</li> </ul> </li> <li>Active Directory Federated Services (ADFS) </li> <li>Directory Information Tree (DIT) <ul> <li>Key tables:</li> <li>Data table</li> <li>Link table</li> <li>Hidden table</li> <li>Security descriptor table</li> </ul> </li> <li>Extensible Storage Engine (ESE) </li> <li>Identity Management for Unix (IMU) </li> <li>Security Accounts Manager (SAM)</li> <li>Global Catalog</li> <li>Schema<ul> <li>attribute</li> <li>syntax</li> </ul> </li> <li>Active Directory concepts</li> <li>Domain Controller (DC)<ul> <li>FSMO roles:</li> <li>Schema Master</li> <li>Domain Naming Master</li> <li>PDC Emulator</li> <li>RID Master</li> <li>Infrastructure Master</li> </ul> </li> <li>Distinguished Name (DN)</li> <li>domain tree</li> <li>forest</li> <li>organizational unit</li> <li>Trust<ul> <li>forest trust</li> <li>simple trust </li> <li>transitive trust</li> </ul> </li> <li>Domain models: <ul> <li>Multimaster</li> <li>Single-domain </li> <li>Single-master </li> <li>Complete trust</li> </ul> </li> <li>Groups:<ul> <li>Scopes</li> <li>[Domain local][domain local group]</li> <li>[Domain global][domain global group]</li> <li>[Universal][universal group]</li> <li>Types:</li> <li>Distribution</li> <li>Security</li> </ul> </li> <li>Site topology</li> <li>site </li> <li>subnet </li> <li>site link </li> <li>connection object </li> <li>Windows Management Interface (WMI)</li> <li>CIM infrastructure<ul> <li>CIM Repository</li> <li>CIMOM</li> </ul> </li> <li>WMI providers</li> </ul>"},{"location":"Misc/Windows/Active%20Directory/#fundamentals","title":"Fundamentals","text":""},{"location":"Misc/Windows/Active%20Directory/#history","title":"History","text":"<p>Active Directory has its origins in 1990 when Microsoft released Windows NT 3.0, its first Network Operating System (NOS). Limitations of NT led Microsoft to rearchitect their solution based on LDAP, a directory service that originated in 1993 as a lighter-weight alternative to X.500.</p> Feature NT AD Database SAM ESE Trust Simple Transitive Domain models Multimaster Single-domain Single-master Complete trust Complete trust Name resolution WINS DNS Schemas Not extensible Extensible"},{"location":"Misc/Windows/Active%20Directory/#major-components","title":"Major components","text":"<p>AD objects, which can be containers or non-containers (leaf nodes), are stored in a DIT file.  Each object is identified by a GUID but also commonly referred to by distinguished name (i.e. <code>dc=mycorp,dc=com</code>)</p> <p>Active Directory's structure is based on the concept of a domain, based on the following components: - Hierarchical structure of containers and objects based on X.500 - DNS domain name - Security service to provide AAA - Policies to restrict functionality for users or machines</p> <p>Domains can be organized into domain trees, and domain trees can be organized into forests.</p> <p>The most common container type is the OU. Global Catalog can be used to search for AD objects.</p> <p>Because Kerberos, which underlies AD, is sensitive to time differences all computers on a domain must have clocks synchronized to within 5 minutes. NTP can be useful for this.</p>"},{"location":"Misc/Windows/Active%20Directory/#naming-contexts","title":"Naming contexts","text":"<p>Predefined NCs within AD: - Domain Naming Context  - Schema Naming Context  - Configuration Naming Context </p>"},{"location":"Misc/Windows/Active%20Directory/#schema","title":"Schema","text":"<p>Each object in AD is an instance of a class defined in the schema. The schema version can be queried from the command-line with [<code>adfind</code>][adfind] OID</p>"},{"location":"Misc/Windows/Active%20Directory/#sid","title":"SID","text":"<p>A Windows SID is generally composed of 2 fixed fields and up to 15 additional fields, all separated by dashes:</p> <p><code> S-v-id-s1-s2-s3-s4-s5-s6-s7-s8-s9-s10-s11-s12-s13-s14-s15 </code></p>"},{"location":"Misc/Windows/Active%20Directory/#ad-lds","title":"AD LDS","text":"<p>AD LDS offers a pared-down version of AD that is easy to set up and tear down. It was first released in November 2003 as Active Directory Application Mode (ADAM) V1.0 and offers security benefits because it doesn't enable so many services by default. It was renamed AD LDS with the release of Windows Server 2008.</p> <p>Differences between AD and AD LDS - AD LDS is a standalone application run from a <code>dsamain.exe</code> process (rather than <code>lsass.exe</code>), which means it can be started or stopped on demand without rebooting and multiple instances can be run. - AD LDS lacks the global catalog functionality (removing NSPI and AB as well)</p>"},{"location":"Misc/Windows/Active%20Directory/#site-topology","title":"Site topology","text":"<p>A site topology is a map of the sites, subnets, site links, site link bridges, and connection objects as it relates to a forest.</p>"},{"location":"Misc/Windows/Active%20Directory/#wmi","title":"WMI","text":"<p>An industry effort to develop a model for managing systems and devices for vendor use arose in the 1990s which resulted in CIM, which provides the basis for WMI. The WMI architecture is composed of two main layers: the CIM infrastructure (CIMOM and CIM Repository) and the WMI providers Each provider is associated with a namespace, which is similar in concept to a filesystem.</p>"},{"location":"Misc/Windows/Active%20Directory/#net","title":".NET","text":"<p>The .NET Framework was developed with the intention of replacing the old Win32 and COM APIs. It has two major components: - Common Language Runtime (CLR) - .NET Framework class library</p>"},{"location":"Misc/Windows/Active%20Directory/#searching-active-directory","title":"Searching Active Directory","text":""},{"location":"Misc/Windows/DNS-labs/","title":"DNS labs","text":""},{"location":"Misc/Windows/DNS-labs/#configuring-dns-servers","title":"Configuring DNS servers","text":"Hostname IP Address PLABDC01 192.168.0.1 PLABDM01 192.168.0.2 PLABSA01 192.168.0.4 <ol> <li>Create a Domain Forest</li> <li>Create a new domain and forest on PLABSA01 named \"PRACTICEIT.CO.UK\".</li> <li>Configure PLABDC01 to forward for the new domain, and PLABSA01 to forward for the old one.</li> <li>Create a new DNS zone</li> <li>Set up alternate DNS server</li> <li>Configure DNS forwarders</li> </ol>"},{"location":"Misc/Windows/DNS-labs/#new-ad-forest","title":"New AD forest","text":"<p>Create a new domain and forest on PLABSA01 named \"PRACTICEIT.CO.UK\" <pre><code># PLABSA01\nAdd-WindowsFeature dns, ad-domain-services -IncludeManagementTools\n$pw = ConvertTo-SecureString -Force -AsPlainText 'Passw0rd'\nInstall-ADDSForest -DomainName PRACTICEIT.CO.UK -SafeModeAdministratorPassword $pw\n</code></pre></p>"},{"location":"Misc/Windows/DNS-labs/#forwarding","title":"Forwarding","text":"<p>Forward DNS queries for the new domain to PLABSA01 <pre><code># PLABDC01\n# Equivalent to `netsh interface ipv4 add dns Ethernet 192.168.0.4 index=2`\nSet-DNSClientServerAddress -InterfaceAlias Ethernet -ServerAddresses ('192.168.0.1','192.168.0.4') \nAdd-DnsServerConditionalForwarderZone -Name 'practiceit.co.uk' -MasterServers '192.168.0.4'\nAdd-DnsServerForwarder -IpAddress '192.168.0.4'\nTest-NetConnection plabsa01.practiceit.co.uk\n</code></pre> Forward DNS queries for the old domain to PLABDC01 <pre><code># PLABSA01\n# Equivalent to `netsh interface ipv4 add dns Ethernet 192.168.0.1 index=2`\nSet-DnsClientServerAddress -InterfaceIndex 13 -ServerAddresses ('127.0.0.1','192.168.0.1') \nAdd-DnsServerConditionalForwarderZone -Name 'practicelabs.com' -MasterServers '192.168.0.1'\nTest-NetConnection plabdc01.practicelabs.com\n</code></pre></p>"},{"location":"Misc/Windows/DNS-labs/#create-new-zone","title":"Create new zone","text":"<p><pre><code># PLABDM01\nAdd-WindowsFeature dns -IncludeManagementTools\nAdd-DnsServerPrimaryZone -ZoneFile 'apac.practicelabs.com.dns' -ZoneName 'apac.practicelabs.com' -DynamicUpdate NonsecureAndSecure\n</code></pre> Delegate to the new zone <pre><code># PLABDC01\nAdd-DnsServerZoneDelegation -Name 'practicelabs.com' -ChildZoneName 'apac' -NameServer 'plabdm01.practicelabs.com' -IPAddress '192.168.0.2'\nAdd-DnsServerPrimaryZone -ZoneName PLTEST.com -ReplicationScope Domain\nAdd-DnsServerResourceRecordA -Name www -ZoneName pltest.com -IPv4Address 192.168.0.1\n\n# Copying PowerShell commands from a script\nAdd-DnsServerClientSubnet -Name EMEA -IPv4Subnet '192.168.0.0/24'\nAdd-DnsServerClientSubnet -Name APAC -IPv4Subnet '192.168.1.0/24'\nAdd-DnsServerZoneScope -ZoneName \"PLTEST.com\" -Name \"EMEAZoneScope\"\nAdd-DnsServerZoneScope -ZoneName \"PLTEST.com\" -Name \"APACZoneScope\"\nAdd-DnsServerResourceRecord -A -Name www -ZoneName 'PLTEST.com' -IPv4Address '192.168.1.1' -ZoneScope APACZoneScope\nAdd-DnsServerResourceRecord -A -Name www -ZoneName 'PLTEST.com' -IPv4Address '192.168.0.1' -ZoneScope EMEAZoneScope\nAdd-DnsServerQueryResolutionPolicy -Name EMEAPolicy -Action ALLOW -ClientSubnet 'eq,EMEA' -ZoneScope 'EMEAZoneScope,1' -ZoneName 'PLTEST.com'\nAdd-DnsServerQueryResolutionPolicy -Name APACPolicy -Action ALLOW -ClientSubnet 'eq,APAC' -ZoneScope 'APACZoneScope,1' -ZoneName 'PLTEST.com'\n\n# PLABWIN10\nipconfig /flushdns\nnslookup www.pltest.com\n\n# PLABDC01\nAdd-DnsServerQueryResolutionPolicy -Name Blocklist -Action IGNORE -Fqdn 'eq,*.pltest.com' -PassThru\n\n# PLABWIN10\n# Now the query does not work\nnslookup www.pltest.com\n\n# PLABDC01\nRemove-DnsServerQueryResolutionPolicy -Name Blocklist -Confirm\n</code></pre></p>"},{"location":"Misc/Windows/DNS-labs/#configuration","title":"Configuration","text":"<p>Configure DNS socket pool <pre><code>::PLABDC01\ndnscmd /info /socketpoolsize\ndnscmd /config /socketpoolsize 3500\nnet stop dns\nnet start dns\ndnscmd /info /socketpoolsize\n</code></pre> Manage DNS cache locking <pre><code>dnscmd /info /cachelockingpercent\ndnscmd /config /cachelockingpercent 90\ndnscmd /info /cachelockingpercent\nnet stop dns\nnet start dns\ndnscmd /info /cachelockingpercent\n</code></pre> Create a GlobalNames zone <pre><code>Set-DnsServerGlobalNameZone -AlwaysQueryServer $true\nAdd-DnsServerPrimaryZone -Name GlobalNames -ReplicationScope Forest\ndnscmd . /config /enableglobalnamessupport 1\n</code></pre> Create a resource record in the GlobalNames zone <pre><code>Add-DnsServerResourceRecordA -Name PLABDC01 -ZoneName GlobalNames -IPv4Address 192.168.0.1\n</code></pre> Enable response rate limiting <pre><code>Get-DNSServerResponseRateLimiting\nSet-DNSServerResponseRateLimiting -Mode Enable -Confirm\nGet-DNSServerResponseRateLimiting # confirming\nAdd-DNSServerResponseRateLimitingExceptionList -Name Whitelist1 -Fqdn 'eq, *.practicelabs.com'\nSet-DNSServerResponseRateLimiting -Mode Enable -Confirm\n</code></pre> Manage DNS logging <pre><code>Add-WindowsFeature dns -IncludeManagementTools -ComputerName PLABDM01\nSet-DnsServerDiagnostics -LogFilePath C:\\dnslog.txt\n# Some additional settings appear necessary in order to begin logging\n</code></pre> Enable zone transfers <pre><code>Set-DnsServerPrimaryZone -SecureSecondaries TransferAnyServer\n</code></pre> Create a secondary DNS zone <pre><code># PLABDM01\nAdd-DnsServerSecondaryZone -ComputerNAme PLABDM01 -MasterServers 192.168.0.1 -ZoneName practicelabs.com -ZoneFile practicelabs.com.dns\n</code></pre> Check DNS logs at text file and event viewer.</p>"},{"location":"Misc/Windows/DNS-labs/#manage-dns-zones-and-resource-records","title":"Manage DNS zones and resource records","text":"<p>Convert AD-integrated zone to file-based zone <pre><code>Get-DNSServerZone -ZoneName practicelabs.com | ConvertTo-DnsServerPrimaryZone -ZoneFile practicelabs.com.dns\n</code></pre> Manually add an A record <pre><code>Add-Content -Path C:\\Windows\\System32\\dns\\practicelabs.com.dns -Value \"PLABSVR   1200   A  192.168.0.105\"\n</code></pre> Re-integrate zone to AD <pre><code>ConvertTo-DnsServerPrimaryZone -ZoneName practicelabs.com -ReplicationScope Domain\n</code></pre> Promote a new DC <pre><code># PLABDM01\nAdd-WindowsFeature dns,ad-domain-services -IncludeManagementTools\nInstall-ADDSDomainController -Domain practicelabs.com\n</code></pre> Create a secondary zone <pre><code># PLABSA01\nAdd-WindowsFeature dns -IncludeManagementTools\nAdd-DnsServerSecondaryZone -ZoneName practicelabs.com -ZoneFile \"practicelabs.com.dns\" -MasterServers 192.168.0.1\n</code></pre> Enable zone transfer from master <pre><code># PLABDC01\nSet-DnsServerPrimaryZone -Name practicelabs.com -SecureSecondaries TransferAnyServer\n</code></pre> Manually initiate a zone transfer if needed <pre><code># PLABSA01\nStart-DnsServerZoneTransfer -ZoneName practicelabs.com\n</code></pre> Remove secondary zone <pre><code># PLABSA01\nRemove-DnsServerZone -ZoneName practicelabs.com\nAdd-DnsServerStubZone -ZoneName practicelabs.com -ZoneFile practicelabs.com.dns -MasterServers 192.168.0.1\n</code></pre> Create new resource records <pre><code># PLABDC01\nAdd-DnsServerResourceRecord -A -Name plabsa05 -IPv4Address 192.168.0.50 -ZoneName practicelabs.com\nAdd-DnsServerResourceRecord -CName -Name plabdmsrv01 -ZoneName practicelabs.com -HostNameAlias plabdm01.practicelabs.com\nAdd-DnsServerResourceRecord -MX -Name \".\" -ZoneName practicelabs.com -MailExchange mobilemail.practicelabs.com -Preference 10\nAdd-DnsServerResourceRecord -A -Name mobilemail -IPv4Address 192.168.0.21 -ZoneName practicelabs.com\n</code></pre></p>"},{"location":"Misc/Windows/Hyper-V/","title":"Hyper-V","text":""},{"location":"Misc/Windows/Hyper-V/#configure-vm","title":"Configure VM","text":"NIC HDD CPU RAM  Create Read List Update Delete <pre><code>Add-VMNetworkAdapter -VMName $vmName -SwitchName $switchName\n</code></pre> <pre><code>command get\n</code></pre> <pre><code>command list\n</code></pre> <pre><code>command set\n</code></pre> <pre><code>command remove\n</code></pre> <pre><code>Add-VMHardDiskDrive -VMName $vmName -ControllerType IDE -ControllerNumber 0 -Path $vhdPath\n</code></pre>"},{"location":"Misc/Windows/Labs/","title":"Labs","text":""},{"location":"Misc/Windows/Labs/#server-core","title":"Server Core","text":"<p>Configure VM <pre><code>Rename-VMSwitch Intel* External\nNew-VM PLABDMCORE02 1024 1 -SwitchName External -NewVHDPath 'D:\\VHD\\PLABDMCORE02\\Virtual Hard Disks\\PLABDMCORE02.vhdx' -NewVHDSize 127gb\nSet-VMDvdDrive ... # Can't find way to pass through host drive Z:\\ \n</code></pre> Add DVD drive Z: of host to VM's DVD drive (no Powershell equivalent found yet). <pre><code>Start-VM PLABDMCORE02\n</code></pre> Install Windows, then continue configuring VM <pre><code># PLABDMCORE02\nRename-Computer PLABDMCORE02\nNew-NetIpAddress 192.168.0.7 -PrefixLength 24 -InterfaceAlias Ethernet\nSet-DnsClientServerAddress -InterfaceAlias Ethernet -ServerAddresses 192.168.0.1\nRestart-Computer\n</code></pre> Join computer to domain <pre><code>Add-Computer -DomainName practicelabs.com -DomainCredential practicelabs\\administrator\nRestart-Computer\n</code></pre> Install packages remotely <pre><code># PLABDC01\nEnter-PSSession PLABDMCORE02\nAdd-WindowsFeature -Name dns,rsat-dns-server -IncludeManagementTools\n</code></pre> Add PLABDMCORE02 as a DNS server while remotely connected to DC (no Powershell equivalent found yet).</p> <p>Add a secondary lookup zone to PLABDMCORE02 (doesn't work; asks for Zonefile) <pre><code>Add-DnsServerSecondaryZone -Name practicelabs.com -MasterServers 192.168.0.1\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#nano-server","title":"Nano Server","text":"<p><pre><code># PLABDM01\nCopy-Item Z:\\NanoServer\\NanoServerImageGenerator\\*.ps* C:\\nanoserver\nImport-Module C:\\nNanoserver\\NanoServerImageGenerator.psm1\n</code></pre> Create the VHD image <pre><code>New-NanoServerImage -Edition Standard -MediaPath z:\\ -Basepath c:\\nanoserver -Targetpath c:\\nanoserver\\PLABNANOSRV01.vhdx -DeploymentType Guest -ComputerName PLABNANOSRV01 -Storage -Package Microsoft-NanoServer-DNS-Package\nSet-VMHardDiskDrive -VMName PLABNANOSRV01 -Path C:\\nanoserver\\PLABNANOSRV01.vhdx\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#dism","title":"DISM","text":"<p><pre><code># PLABSA01 \nSet-Location C:\\\nmkdir updates,images,mount,drivers\nCopy-Item \\\\plabdm01\\Win10\\sources\\install.wim C:\\updates\n(Get-Item C:\\updates\\install.wim).IsReadOnly = $false\n</code></pre> Move specified .msu installers to C:\\updates and uncompress device driver to C:\\drivers</p> <p>Using Powershell: <pre><code>Mount-WindowsImage -Path C:\\mount -ImagePath C:\\images\\install.wim -Index 1\nAdd-WindowsPackage -Path C:\\mount -PackagePath C:\\updates \nAdd-WindowsDriver -Path C:\\mount -Driver C:\\drivers\\display.driver\\nv_dispi.inf\nSave-WindowsImage -Path C:\\mount \nDismount-WindowsImage -Path C:\\mount -Save\n</code></pre> Using <code>dism.exe</code>: <pre><code>dism /mount-wim /wimfile:c:\\images\\install.wim /index:1 /mountdir:c:\\mount\ndism /image:c:\\mount /add-package /packagepath:c:\\updates\ndism /image:c:\\mount /add-driver /driver:c:\\drivers\\display.driver\\nv_dispi.inf\ndism /commit-wim /mountdir:c:\\mount\ndism /unmount-wim /commit /mountdir:c:\\mount\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#nlb-lab","title":"NLB lab","text":"<p>Configure a Network Load Balancing cluster. [Practice Lab][pl:70-740]</p> <p><pre><code># PLABDM01 and PLABSA01\nInstall-WindowsFeature web-server, web-webserver, web-mgmt-tools -IncludeManagementTools\n\n# PLABDM01\nNew-NetIpAddress 192.168.0.20 -PrefixLength 24 -InterfaceAlias Ethernet1\n\n# PLABSA01\nNew-NetIpAddress 192.168.0.40 -PrefixLength 24 -InterfaceAlias Ethernet1\nInstall-WindowsFeature -Name nlb -IncludeAllSubFeature -IncludeManagementTools\n</code></pre> Using the Network Load Balancing Manager, create a new cluster named PLAB-NLB1 specifying multicast operation mode at 192.168.0.25, and create an appropriate DNS record on PLABDC01.</p> <p>Install NLB on PLABDM01 and add it to the cluster through the NLB Manager. Edit the image located at <code>C:\\inetpub\\wwwroot\\iisstart.png</code> on either server. Once saved, these edits will now be visible when that server's website is visited at its hostname. Copy the contents of <code>C:\\inetpub\\wwwroot</code> to new directory <code>C:\\nlbport</code> on PLABDM01. Host that directory as a website on port 6789, opening the firewall appropriately. <pre><code>New-Website -Name nlbport -PhysicalPath \"c:\\nlbport\" -Port 6789\nNew-NetFirewallRule -DisplayName NLBPort -Protocol TCP -LocalPort 6789\n</code></pre> Returning to the NLB Manager, open Cluster Properties &gt; Port Rules and remove the single defined port rule. Add a new port rule that specifies port 80 for \"multiple host\" filtering mode, and another that specifies port 6789 for \"single host\" filtering mode. Then from the host-specific port rule dialog box, select a handling priority of 10.</p>"},{"location":"Misc/Windows/Labs/#iscsi-storage","title":"iSCSI Storage","text":"<p>Network topology <pre><code># PLABDC01\nNew-NetIpAddress 192.168.0.10 -PrefixLength 24 -InterfaceAlias Ethernet2\n\n# PLABDM01\nNew-NetIpAddress 192.168.0.20 -PrefixLength 24 -InterfaceAlias Ethernet1\nNew-NetIpAddress 192.168.1.20 -PrefixLength 24 -InterfaceAlias Ethernet2\nSet-DnsClientServerAddress -InterfaceAlias Ethernet1,Ethernet2 -ServerAddresses 192.168.0.1\n</code></pre> iSCSI target <pre><code># PLABDC01\nAdd-WindowsFeature fs-iscsitarget-server -IncludeManagementTools\nNew-iSCSIVirtualDisk -SizeBytes 5gb -Path 'C:\\CorporateHD.vhdx'\nNew-iSCSIServerTarget -TargetName plabdc01 -InitiatorId @('ipaddress:192.168.0.20','ipaddress:192.168.1.20')\nAdd-iSCSIVirtualDiskTargetMapping -Path 'C:\\CorporateHD.vhdx' -TargetName plabdc01\n</code></pre> iSCSI initiator <pre><code># PLABDM01\nStart-Service msiscsi\nGet-NetFirewallServiceFilter -Service msiscsi | Get-NetFirewallRule | Enable-NetFirewallRule\nConnect-iSCSITarget -NodeAddress (Get-iSCSITarget).NodeAddress\n</code></pre> Multipath ... Finally, mount the drive <pre><code>New-Volume -DiskNumber 5 -FriendlyName iSCSI-Volume1 -FileSystem NTFS -DriveLetter R\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#data-deduplication","title":"Data deduplication","text":"<pre><code># PLABDM01\nAdd-WindowsFeature fs-data-deduplication -IncludeManagementTools\nGet-DedupVolume\nGet-DedupStatus\nEnable-DedupVolume -Volume 'D:'\nSet-DedupVolume -Volume 'D:' -ExcludeFolder 'D:\\win81','D:\\virtual machines' \nNew-DedupSchedule $name -Days Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday -DurationHours 6 -Enabled $true -Type Optimization -Memory 50\nStart-DedupJob D: -Type Optimization -Memory 50\n</code></pre>"},{"location":"Misc/Windows/Labs/#failover-cluster-lab","title":"Failover cluster lab","text":"<p>Network topology <pre><code># PLABDM01\nNew-NetIpAddress 192.168.0.20 -PrefixLength 24 -InterfaceAlias Ethernet1\nNew-NetIpAddress 192.168.0.21 -PrefixLength 24 -InterfaceAlias \"vEthernet (Internal network 1)\"\nNew-NetIpAddress 192.168.1.20 -PrefixLength 24 -InterfaceAlias Ethernet2\nSet-DnsClientServerAddresses Ethernet1,Ethernet2 -ServerAddresses 192.168.0.1\nDisable-NetAdapter \"vEthernet (Internal network 1)\"\n\n# PLABSA01\nNew-NetIpAddress 192.168.0.40 -PrefixLength 24 -InterfaceAlias Ethernet1\nNew-NetIpAddress 192.168.0.41 -PrefixLength 24 -InterfaceAlias \"vEthernet (Internal network 1)\"\nNew-NetIpAddress 192.168.1.40 -PrefixLength 24 -InterfaceAlias Ethernet2\nSet-DnsClientServerAddress Ethernet1,Ethernet2 -Serveraddresses 192.168.0.1\nDisable-NetAdapter \"vEthernet (Internal network 1)\"\n</code></pre> iSCSI target <pre><code># PLABDC01\nAdd-WindowsFeature FS-iSCSITarget-Server -IncludeManagementTools\n</code></pre> Then go into Server Manager &gt; File and Storage Services &gt; iSCSI and start the New iSCSI Virtual Disk Wizard. Create a fixed 500 MB iSCSI virtual disk on C:\\ named \"QuorumHD\" and assign it to the <code>PLABDC01</code> iSCSI target server. Add <code>plabdm01.practicelabs.com</code> and <code>plabsa01.practicelabs.com</code> as initiators, and keep authentication disabled, and confirm the disk has been created. Create another virtual disk, 30 GB dynamic on D:\\ names \"CSVHD\", and assign it to the same <code>PLABDC01</code> iSCSI target server.</p>"},{"location":"Misc/Windows/Labs/#configure-iscsi-initiators-to-iscsi-target-server","title":"Configure iSCSI initiators to iSCSI Target Server","text":"<p>On PLABDM01, open Server Manager and click on Tools &gt; iSCSI Initiator and connect to <code>plabdc01.practicelabs.com</code>. Bring disks 5 and 6 online and initialize them with [MBR][MBR] partition style. This can be done within <code>diskmgmt.msc</code>, where the shared volumes that have been created will appear beneath the local disks, or using PowerShell: <pre><code># PLABDM01\nNew-Volume -DiskNumber 5 -DriveLetter Q -FileSystem NTFS -FriendlyName 'Quorum'\nNew-Volume -DiskNumber 6 -DriveLetter V -FileSystem NTFS -FriendlyName 'CSV'\n</code></pre> Only bring the disks online on the other client <pre><code># PLABSA01\nSet-Disk -Number 4,5 -IsOffline $false\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#install-failover-clusters","title":"Install failover clusters","text":"<p>On both PLABDM01 and PLABSA01: <pre><code>Install-WindowsFeature failover-clustering -IncludeManagementTools\n</code></pre> Then validate the installation through the Failover Cluster Manager (cluadmin.msc). Open the Validate Configuration wizard and enter <code>plabdm01.practicelabs.com</code> and <code>plabsa01.practicelabs.com</code> into the list of selected servers.</p> <p>Open the Create Cluster Wizard and create cluster \"PLHYPVCL01\" using those same two nodes, choosing 192.168.0.25 and 192.168.1.25 for the administrative access points.</p> <p>Open the Configure Cluster Quorum Wizard and configure a disk witness using the Quorum shared volume.</p> <p>Open Hyper-V Manager (virtmgmt.msc) and move PLABDC02 and PLABWIN811 to <code>V:\\PLABDC02</code> and <code>V:\\PLABWIN811</code> respectively, specifying the VM's storage. Confirm the move has taken place by inspecting each VM's hard drive in the settings.</p> <p>Add the Virtual Machine role to the Failover Cluster Manager, and select PLABDC02 and PLABWIN811. This will create the \"PLABWIN811\" Role, which actually includes both selected VMs. Open PLABWIN811 Properties, then the Failover tab, and select \"Allow failback\" specifying between 1 and 2 hours.</p> <p>Open Hyper-V Manager and start PLABDC02. Wait until it has booted completely, then return to Failover Cluster Manager, open Nodes, right-click on PLABDM01 and then Stop Cluster Service. This option forces a failover of the VM, which drains to PLABSA01. This can be confirmed by returning to PLABSA01 and opening Hyper-V Manager, where it is revealed that PLABDC02 is running.</p>"},{"location":"Misc/Windows/Labs/#scale-out-fileserver-lab","title":"Scale-Out Fileserver lab","text":"<p>Plan network topology <pre><code># PLABDM01\nNew-NetIpAddress 192.168.0.20 -PrefixLength 24 -InterfaceAlias Ethernet1\nNew-NetIpAddress 192.168.1.20 -PrefixLength 24 -InterfaceAlias Ethernet2\nSet-DnsClientServerAddress -InterfaceAlias Ethernet1,Ethernet2 -ServerAddresses 192.168.0.1\nDisable-NetAdapter -InterfaceAlias 'vethernet (internal network 1)'\n</code></pre> <pre><code># PLABSA01\nNew-NetIpAddress 192.168.0.40 -PrefixLength 24 -InterfaceAlias Ethernet1\nNew-NetIpAddress 192.168.1.40 -PrefixLength 24 -InterfaceAlias Ethernet2\nSet-DnsClientServerAddress -InterfaceAlias Ethernet1,Ethernet2 -ServerAddresses 192.168.0.1\n</code></pre> Configure iSCSI target <pre><code># PLABDC01\nInstall-WindowsFeature fs-iscsitarget-server -IncludeManagementTools\nNew-IscsiVirtualDisk -Fixed -SizeBytes 500mb -Path 'C:\\QuorumHD.vhdx'\nNew-IscsiVirtualDisk -SizeBytes 30gb -Path 'D:\\CSVHD.vhdx'\nNew-IscsiServerTarget -TargetName PLABDC01 -InitiatorId @('iqn:iqn.1991-05.com.microsoft:plabsa01.practicelabs.com','iqn:iqn.1991-05.com.microsoft:plabdm01.practicelabs.com')\nAdd-IscsiVirtualDiskTargetMapping -Path 'C:\\QuorumHD.vhdx' -TargetName plabdc01\nAdd-IscsiVirtualDiskTargetMapping -Path 'D:\\CSVHD.vhdx' -TargetName plabdc01\n</code></pre> Configure iSCSI initiator on both clients <pre><code># PLABDM01 and PLABSA01\nStart-Service msiscsi\nGet-NetFirewallServiceFilter -Service msiscsi | Get-NetFirewallRule | Enable-NetFirewallRule\nConnect-iSCSITarget -NodeAddress (Get-iSCSITarget).NodeAddress\n</code></pre> Install Failover Clustering role on nodes of the cluster <pre><code># PLABDM01 and PLABSA01\nInstall-WindowsFeature failover-clustering -IncludeManagementTools\n</code></pre> Create a failover cluster through the GUI (the Powershell commands for cluster creation appear not to support adding multiple network networks) <pre><code># PLABDM01\nNew-Cluster -Name PLABSCL01 -Node PLABDM01, PLABSA01 -StaticAddress 192.168.0.25 -IgnoreNetwork 192.168.1.0/24\nSet-ClusterQuorum -DiskWitness 'Cluster Disk 1'\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#hyper-v-storage-lab","title":"Hyper-V storage lab","text":"<p>Create a VM with VHDX disks <pre><code>New-VM -Name PLABWIN102 -Generation 1 -MemoryStartupBytes 1536mb -SwitchName 'Private network 1' -NewVHDPath 'C:\\Users\\Public\\Documents\\Hyper-V\\Virtual hard disks\\PLABWIN102.vhdx' -NewVHDSizeBytes 127gb\nSet-VMDvdDrive -VMName PLABWIN102 -Path C:\\Users\\Administrator.PRACTICELABS\\Documents\\Eval81.iso\nNew-VHD -Path 'D:\\Virtual Machines\\PLAB1.vhdx' -Dynamic -SizeBytes 127gb\nAdd-VMHardDiskDrive -VMName PLABWIN102 -ControllerType IDE -ControllerNumber 0 -Path 'D:\\Virtual Machines\\PLAB1.vhdx'\n</code></pre> Add a differencing disk <pre><code>New-VHD -Path 'D:\\Virtual Machines\\PLAB2.vhdx' -Differencing -ParentPath 'C:\\Users\\Public\\Documents\\Hyper-V\\Virtual hard disks\\PLABWIN102.vhdx'\nAdd-VMHardDrive PLABWIN102 SCSI -Path 'D:\\Virtual Machines\\PLAB2.vhdx'\n</code></pre> Add a passthrough disk <pre><code>Set-Disk -Number 1 -IsOffline $true\nAdd-VMHardDiskDrive PLABWIN102 IDE 1 -DiskNumber 1\n</code></pre> Create a SAN <pre><code>New-VMSan -Name \"PLABS-Fc\"\nAdd-VMFibreChannelHBA -VMName PLABDC02 -SanName \"PLABS-Fc\"\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#hyper-v-replica-lab","title":"Hyper-V replica lab","text":"<p>Emphasizes <code>VMReplication</code> cmdlets.</p> <p><pre><code># PLABDM01\nEnable-NetFirewallRule VIRT-HVRHTTPL-In-TCP-NoScope,VIRT-HVRHTTPSL-In-TCP-NoScope\n</code></pre> Enable incoming replication on the receiving server <pre><code>#PLABSA01\nEnable-NetFirewallRule VIRT-HVRHTTPL-In-TCP-NoScope,VIRT-HVRHTTPSL-In-TCP-NoScope\nSet-Disk -Number 1,3,4 -IsOffline $false -IsReadOnly $false\nNew-Volume -DiskNumber 1 -FileSystem NTFS -FriendlyName VMReplica -DriveLetter E\nSet-VmReplicationServer -ReplicationEnabled $true -AllowedAuthenticationType kerberos -ReplicationAllowedFromAnyServer $true -DefaultStorageLocation E:\\VHD\n</code></pre> Configure one VM and initiate initial replication <pre><code># PLABDM01\nTest-VMReplicationConnection PLABDC02 plabsa01.practicelabs.com 80 Kerberos\nEnable-VMReplication PLABDC02 plabsa01.practicelabs.com 80 Kerberos\nStart-VMInitialReplication PLABDC02\n</code></pre> Repeat for another VM <pre><code>Enable-VMReplication PLABWIN811 plabsa01.practicelabs.com 80 Kerberos\nStart-VMInitialReplication PLABWIN811\n</code></pre> Initiate a planned failover <pre><code>Start-VMFailover PLABDC02\nStart-VM PLABDC02\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#wsus-lab","title":"WSUS lab","text":"<p>Almost totally GUI configuration of WSUS server after installation <pre><code># PLABDM01\nAdd-WindowsFeature updateservices,updateservices-widdb,updateservices-services -IncludeManagementTools\nmkdir C:\\updates\n'C:\\Program Files\\Update Services\\Tools\\wsusutil.exe' postinstall content_dir=C:\\updates\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#wsus-sec","title":"WSUS (Sec+)","text":"<p><pre><code># PLABDM01\nSet-Disk -Number 1 -IsOffline $false\nSet-Disk -Number 1 -IsReadOnly $false\nNew-Volume -DiskNumber 1 -Filesystem NTFS - FriendlyName WSUS -DriveLetter E\nAdd-WindowsFeature updateservices,updateservices-widdb,updateservices-services -IncludeManagementTools\n'C:\\Program Files\\Update Services\\Tools\\wsusutil.exe' postinstall content_dir=E:\\updates\n$wsus = Get-WsusServer\n$config = $wsus.GetConfiguration()\n</code></pre> Proxy <pre><code>$config.UseProxy = $true\n$config.ProxyName = 'proxy'\n$config.ProxyServerPort = 80\n</code></pre> English language <pre><code>$config.AllUpdateLanguagesEnabled = $false\n$config.SetEnabledUpdateLanguages('en')\n$config.Save()\n</code></pre> Upstream server is Microsoft Update <pre><code>Set-WsusServerSynchronization \u2013SyncFromMU\n</code></pre> Select products and classifications <pre><code>Get-WSUSProduct | Where-Object {$_.Product.Title -In ('Windows 10','Windows 8.1')} | Set-WSUSProduct\nGet-WSUSClassification | Where-Object {$_.Classification.Title -eq 'Critical Updates'} | Set-WSUSClassification\n</code></pre> Get WSUS Subscription and perform initial synchronization <pre><code>$sub = $wsus.GetSubscription()\n$sub.StartSynchronization()\n$sub.SynchronizeAutomatically = $false\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#storage-replica-lab","title":"Storage replica lab","text":"<p>Actually from the [Practice test][mu:70-740]. <pre><code># On both origin and replica servers\nInstall-WindowsFeature storage-replica -Restart\n\nTest-SRTopology\nNew-SRGroup -ComputerName server1\nNew-SRPartnership -SourceComputerName server1 -SourceRGName rg1 -SourceVolumeName D: -SourceLogVolumeName E: -DestinationComputerName server2 -DestinationRGName rg2 -DestinationVolumeName D: -DestinationLogVolumeName E:\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#certificates","title":"Certificates","text":"<ul> <li>ADCSCertificationAuthority <code>Install</code>?</li> <li>ADCSWebEnrollment [<code>Install</code>][Install-AdcsWebEnrollment][?][msdocs:Install-AdcsWebEnrollment]</li> <li>WindowsFeature <code>Add</code>?</li> </ul> <p><pre><code>Add-WindowsFeature -Name ADCS-Cert-Authority,ADCS-Web-Enrollment -IncludeManagementTools\nInstall-ADCSCertificationAuthority -CAType EnterpriseRootCA\nInstall-ADCSWebEnrollment\n</code></pre> Make a duplicate of the \"User\" template named \"SecureUser\", with the following changes - In the Request Handling tab, select \"Prompt the user during enrollment\" - In the Security tab ensure that Authenticated Users has Autoenroll allowed - In the Superseded Templates tab, select User - In the Subject Name tab, clear checkboxes for \"Include e-mail name in subject name\" and \"E-mail name\" <pre><code>Add-CATemplate SecureUser\n</code></pre></p>"},{"location":"Misc/Windows/Labs/#hyperconverged-failover-cluster","title":"Hyperconverged failover cluster","text":"<p>[MeasureUp][mu:70-740] <pre><code>New-Cluster -Name HC-CLU1 -Node node1, node2, node3, node4 -NoStorage\nEnable-ClusterStorageSpacesDirect -CacheMode Disabled -AutoConfig:0 -SkipEligibilityChecks\nNew-StoragePool -StorageSubSystemFriendlyName *Cluster* -FriendlyName S2DPool -ProvisioningTyupeDefault Fixed -PhysicalDisk (Get-PhysicalDisk | Where-Object -Property CanPool -eq $true)\n$pool = Get-StoragePool S2DPool\nNew-StorageTier -StoragePoolUniqueID ($pool).UniqueID -FriendlyName Performance -MediaType HDD -ResiliencySettingName Mirror\nNew-StorageTier -StoragePoolUniqueID ($pool).UniqueID -FriendlyName Capacity -MediaType HDD -ResiliencySettingName Parity\nNew-Volume -StoragePool $pool -FriendlyName SharedVol1 -FileSystem CSVFS_REFS -StorageTierFriendlyNames Performance, Capacity -StorageTierSizes 2gb, 10gb\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/","title":"PowerShell","text":"<p>Functions are declared with the function keyword and the body in braces.</p> <pre><code>function Hello-World\n{\n    Write-Output \"Hello, World!\"\n}\n</code></pre> <p>Positional parameters can be referenced using the $args array, which contains all arguments passed to the function on invocation. PowerShell appears to automatically handle arrays passed in as the first argument and interpolates spaces between each item this way.</p> <pre><code>function Hello-World\n{\n    Write-Output \"Hello, $($args[0])!\"\n}\n</code></pre> <p>In order to set a default value, apparently a named parameter has to be used. There are two ways to do this, with or without the param keyword. These parameters are still usable as positional parameters, determined by the order in which they are defined (?), but note that the case of the identifier is preserved to define the option (i.e. \"$name\" becomes \"-name\", etc).</p> <pre><code>function Hello-World($Name='World')\n{\n    Write-Output \"Hello, $($Name)!\"\n}\n</code></pre> <p>Using param, multiple parameters can be defined in a param block, which would probably make more sense for complicated functions using multiple parameters. Here the single parameter is also typed.</p> <pre><code>function Hello-World\n{\n    param (\n        [string]$Name='World'\n    )\n    Write-Output \"Hello, $($Name)!\"\n}\n</code></pre> <p>&lt;!-- Documentation or comment-based help is incorporated by means of specially formatted comments within the body of the function. Even without comments, PowerShell will attempt to provide help to a user from the command-line using Get-Help.</p> <pre><code>``` --&gt;\n\n## Control flow\n\n```powershell\nif ($condition) { &lt;# ... #&gt; }\n\nswitch ($reference) \n{\n    $value1 { ... }\n    $value2 { ... }\n}\n\nwhile ($true) \n{\n    (++$Tick)\n    if ($Tick -gt 2) \n    { \n        break \n    } \n} # =&gt; @(1,2,3)\n\ndo \n{ \n    'Hello, world!' \n} while ($false) # =&gt; @('Hello, world!')\n</code></pre> <p>Loops are implemented with <code>ForEach-Object</code>.</p> <pre><code>1..5 | ForEach-Object {$_ + 2} # =&gt; @(3,4,5,6,7)\n</code></pre> <p>When values are stored in a variable at the end of a pipeline, it will create an array. <code>while</code> and <code>do while</code> loops are available, as well as <code>until</code> and <code>do until</code> loops which operate so long as their condition is false.</p>"},{"location":"Misc/Windows/PowerShell/#variables","title":"Variables","text":"<p>Variables are accessed by prefixing the identifier with <code>$</code>.</p> <ul> <li>[Automatic variables][Automatic variable] ($$, $_, $PSVersionTable, $IsLinux, etc) are PowerShell-specific.</li> <li>Windows environment variables are actually accessed through the <code>Env</code> virtual drive using syntax like <code>$Env:APPDATA</code>, <code>$Env:USERNAME</code>, etc.</li> </ul>"},{"location":"Misc/Windows/PowerShell/#typing","title":"Typing","text":"Typing<pre><code>[double]$Price\n[int]$Quantity\n[string]$Description\n</code></pre> Casting<pre><code>$Number = [int]'04'\n$FailedCast = [int]'Hello'\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#hash-tables","title":"Hash tables","text":"Hash tables<pre><code>$fruit = @{\n    Apple = 'red'\n    Orange = 'orange'\n    Eggplant = 'purple'\n}\n\n# Inline\n$fruit = @{ Apple = 'red'; Orange = 'orange'; Eggplant = 'purple' }\n</code></pre> Hashtable methods<pre><code>$fruit = @{}\n$fruit.Add('Apple','red')\n$fruit.Add('Orange','orange')\n$fruit.Add('Kiwi','green')\n\n# Deep copy or \"clone\" of a hashtable.\n$fruitclone = $fruit.Clone()\n\n$fruit.Keys # =&gt; @('Apple','Orange','Kiwi')\n$fruit.Values # =&gt; @('red','orange','green')\n$fruit.Count\n$fruit.Remove('Apple')\n</code></pre> <p>Unlike Python, a hash table can be made ordered, changing its data type:</p> <pre><code>$fruit = [ordered]@{ Apple = 'red'; Orange = 'orange'; Eggplant = 'purple' }\n$fruit.GetType().Name # =&gt; OrderedDictionary\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#documentation","title":"Documentation","text":"Documentation<pre><code>&lt;#\n.SYNOPSIS\nThis script coordinates the process of creating new employees\n\n.DESCRIPTION\nThis script creates new users in Active Directory...\n\n.PARAMETER UserName\nThe official logon name for the user...\n\n.PARAMETER HomeServer\nThe server name where the user's home folder will live...\n#&gt;\n\n&lt;#\n.EXAMPLE\nNew-CorpEmployee -UserName John-Doe -HomeServer HOMESERVER1\nThis example creates a single new employee...\n#&gt;\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#functions","title":"Functions","text":"<p>Named parameters can be declared in one of two ways. </p> <ul> <li>Within the function body using the param keyword, followed by the name of the variable representing the parameter's value, enclosed in <code>$(...)</code>:</li> <li>Directly after the function name in parentheses, with each parameter separated by a comma.</li> </ul> <p>The name of the variable becomes the named parameter used when invoking the function. Default values for parameters can be specified by placing them within the parentheses.</p> <p>Parameters can be made mandatory by preceding the parameter name with <code>[Parameter(Mandatory=$true)]</code>.  Parameters can be static typed by preceding the parameter identifier with the data type in brackets.</p> Positional parameterNamed parameterUsing paramDefault valueTypedInvocation <pre><code>function Get-LargeFiles \n{\n    Get-ChildItem C:\\Users\\Michael\\Documents |\n        where {$_.Length -gt $args[0] and !$_PSIscontainer} |\n        Sort-Object Length -Descending\n}\n</code></pre> <pre><code>function Get-LargeFiles($Size) \n{\n    # param ($Size)\n    Get-ChildItem C:\\Users\\Michael\\Documents |\n        where {$_.Length -gt $Size -and !$_.PSIsContainer} |\n        Sort-Object Length -Descending\n}\n</code></pre> <pre><code>function Get-LargeFiles \n{\n    param ($Size)\n    Get-ChildItem C:\\Users\\Michael\\Documents |\n        where {$_.Length -gt $Size -and !$_.PSIsContainer} |\n        Sort-Object Length -Descending\n}\n</code></pre> <pre><code>function Get-LargeFiles \n{\n    param ($Size=2000)\n    Get-ChildItem C:\\Users\\Michael\\Documents |\n        where {$_.Length -gt $Size -and !$_.PSIsContainer} |\n        Sort-Object Length -Descending\n}\n</code></pre> <pre><code>function Get-LargeFiles \n{\n    param ([int]$Size=2000)\n    Get-ChildItem C:\\Users\\Michael\\Documents |\n        where {$_.Length -gt $Size -and !$_.PSIsContainer} |\n        Sort-Object Length -Descending\n}\n</code></pre> <pre><code>Get-LargeFiles -Size 2000\n</code></pre> <p>Switch parameters are typed as a <code>switch</code> data type. Boolean values can be explicitly set upon invocation using this syntax:</p> Switch-ItemInvocation <pre><code>function Switch-Item \n{\n    param ([switch]$on)\n    if ($on) { \"Switch on\" }\n    else { \"Switch off\" }\n}\n</code></pre> <pre><code>Switch-Item             # =&gt; Switch off\nSwitch-Item -On         # =&gt; Switch on\nSwitch-Item -On:$false  # =&gt; Switch off\n</code></pre> <p>Attach common parameters to a custom function by placing the <code>[CmdletBinding()]</code> within the body of a function.  This allows use of options like <code>-Verbose</code> or <code>-Debug</code> with custom functions. Now, using <code>Write-Verbose</code> and <code>Write-Debug</code> within the function body serve the dual purpose of outputting additional information at the time of execution, when needed, as well as documentation.</p>"},{"location":"Misc/Windows/PowerShell/#remote-administration","title":"Remote administration","text":"<p>Powershell remoting can be done explicitly or implicitly. Remoting relies on WinRM, which is Microsoft's implementation of WSMAN.</p> <ul> <li>Explicit remoting is also 1-to-1 remoting, where an interactive Powershell prompt is brought up on a remote computer.</li> <li>One-to-many or fan-out remoting is possible with implicit remoting, where a command is transmitted to many computers.</li> </ul>"},{"location":"Misc/Windows/PowerShell/#unit-testing","title":"Unit testing","text":"<p>Pester tests are organized in a hierarchy of blocks and run with <code>Invoke-Pester</code>:</p> <pre><code>Describe\n{\n  Context # optional\n  {\n    It\n    {\n      Should # assertion statements accept a value passed in via pipe and **must** be called within a `Describe` block\n    }\n  }\n}\n</code></pre> <pre><code>New-Fixture deploy Foo\n\nfunction Foo \n{\n  # ...\n}\n\nDescribe 'Foo' \n{\n    $true | Should -Be $true \n}\n</code></pre> <p>The block in braces is actually an argument pass to the <code>-Fixture</code> parameter.</p> <pre><code>Describe \"Best airports in the USA\" -Fixture \n{\n    It -Name \"RDU is one of the best airports\" -Test \n    {\n        $Output = Get-Airport -City \"Raleigh\"\n        $Output | Should -BeOfType System.Collections.Hashtable\n    }\n}\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#tasks","title":"Tasks","text":"Display hostname<pre><code>Get-ComputerInfo -Property CsName # gin.CsName\n$Env:computername\n</code></pre> Generate password<pre><code>Add-Type -AssemblyName 'System.Web'\n[System.Web.Security.Membership]::GeneratePassword(20, 3)\n</code></pre> Save credential in variable<pre><code>$cred = Get-Credential\n\n$pw = ConvertTo-SecureString \"Password\" -AsPlainText -Force\n$cred = New-Object System.Management.Automation.PSCredential (\"FullerP\", $pw)\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#profile","title":"Profile","text":"Similar to a bashrc file, PowerShell has various profiles which can contain custom variable and function definitions, accessible through automatic variables like $PROFILE, etc. These are loaded using syntax similar to that of bash: Reload profile<pre><code>. $PROFILE\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#filtering","title":"Filtering","text":"<p>Filtering results can be done with 5 commands:</p> <ul> <li><code>Where-Object</code> (aliased to <code>where</code> and <code>?</code>): the most commonly used such command</li> <li><code>Select-Object</code> (aliased to <code>sc</code>ed to specify specific columns of information to be displayed</li> <li><code>Select-String</code> (aliased to <code>sls</code>)</li> <li><code>ForEach-Object</code> (aliased to <code>foreach</code> and <code>%</code>) There are two different ways to construct a <code>ForEach-Object</code> statement:<ol> <li>Script block, within which the variable <code>$_</code> represents the current object</li> <li>Operation statement, more naturalistic, where you specify a property value or call a method.</li> </ol> </li> </ul>"},{"location":"Misc/Windows/PowerShell/#loop-examples","title":"Loop examples","text":"Download files<pre><code>1..24 | ForEach-Object {\n    Invoke-WebRequest -OutFile (\"TGC_3466_Lect{0:d2}_FallPagansOriginsMedievalChristianity.m4v\" -f $_) (\"https://securedownloads.teach12.com/anon.eastbaymedia-drm/courses/3466/m4v/TGC_3466_Lect{0:d2}_FallPagansOriginsMedievalChristianity.m4v?userid=$USERID&amp;orderid=$ORDERID&amp;courseid=$COURSEID&amp;FName=TGC_3466_Lect{0:d2}_FallPagansOriginsMedievalChristianity\" -f $_)}\n</code></pre> Processing multiple files<pre><code>Get-ChildItem . | ForEach-Object { ffmpeg -i $_.Name $_.Name.Replace('m4a','mp3') }\n</code></pre> Alert when connection re-established<pre><code>while ($true) {\n    if ((Test-NetConnection 8.8.8.8 -WarningAction SilentlyContinue).PingSucceeded -eq $true) {\n        [System.Console]::Beep(1000,100)\n        break\n    }\n}\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#new-domain-controller","title":"New domain controller","text":"<p>[Jones][Jones] <pre><code>Install-WindowsFeature AD-Domain-Services,DHCP -IncludeManagementTools\nInstall-ADDSForest -DomainName corp.packtlab.com\nAdd-DhcpServerv4Scope -Name \"PacktLabNet\" -StartRange 10.0.0.50 -EndRange 10.0.0.100 -SubnetMask 255.255.255.0\nSet-DhcpServerv4OptionValue -DnsDomain corp.packtlab.com\nAdd-DhcpServerInDC -DnsName dc.corp.packtlab.com\nNew-AdUser -SamAccountName SysAdmin -AccountPassword (Read-Host \"Set user password\" -AsSecureString) -Name \"SysAdmin\" -Enabled $true -PasswordNeverExpires $true -ChangePasswordAtLogon $false\nAdd-ADPrincipalGroupMembership -Identity \"CN=SysAdmin,CN=Users,DC=corp,DC=packtlab,DC=com\",\"CN=Domain Admins,CN=Users,DC=corp,DC=packtlab,DC=com\"\nGet-ADPrincipalGroupMembership sysadmin\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#text-to-speech","title":"Text to speech","text":"Text to speech<pre><code>Add-Type \u2013AssemblyName System.Speech # (1)\n$tts = New-Object \u2013TypeName System.Speech.Synthesis.SpeechSynthesizer\n$tts.Speak('Hello, World!')\n\n# List available voices\nForeach ($voice in $SpeechSynthesizer.GetInstalledVoices()){\n    $Voice.VoiceInfo | Select-Object Gender, Name, Culture, Description\n}\n\n# Change voice\n$tts.SelectVoice(\"Microsoft Zira Desktop\")\n$tts.Speak('Hello, World!')\n\n# Save output\n$WavFileOut = Join-Path -Path $env:USERPROFILE -ChildPath \"Desktop\\thinkpowershell-demo.wav\" # (2)\n$SpeechSynthesizer.SetOutputToWaveFile($WavFileOut)\n</code></pre> <ol> <li>Powershell: Text To Speech in 3 lines of code</li> <li>Create Cortana Audio Files From Text Using PowerShell</li> </ol>"},{"location":"Misc/Windows/PowerShell/#vhdx-file","title":"VHDX file","text":"<p>Create a new 256 GB dynamic VHDX file, mount it, initialize it, and create and format the partition [Zacker][Zacker]: 91 <pre><code>New-VHD -Path C:\\Data\\disk1.vhdx -SizeBytes 256GB -Dynamic | \nMount-VHD -Passthru |\nInitialize-Disk -PassThru |\nNew-Partition -DriveLetter X -UseMaximumSize | \nFormat-Volume -Filesystem ntfs -FileSystemLabel data1 -Confirm:$False -Force\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#restart-wi-fi-adapter","title":"Restart Wi-Fi adapter","text":"<pre><code>$adaptor = Get-WmiObject -Class Win32_NetworkAdapter | Where-Object {$_.Name -like \"*Wireless*\"}\n$adaptor.Disable()\n$adaptor.Enable()\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#add-a-member-to-a-group","title":"Add a member to a group","text":"<pre><code>Add-ADGroupMember -Identity $group -Members $user1,$user2\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#add-a-new-local-admin","title":"Add a new local admin","text":"<pre><code>nlu ansible\nAdd-LocalGroupMember Administrators ansible\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#create-a-virtual-switch-with-set-enabled","title":"Create a virtual switch with SET enabled","text":"<p>Create a virtual switch with SET enabled. [Zacker][Zacker]: 254 <pre><code>New-VMSwitch -Name SETSwitch -NetAdapterName \"nic1\",\"nic2\" -EnableEmbeddedTeaming $true\n</code></pre> Add new virtual network adapters to VMs <pre><code>Add-VMNetworkAdapter -VMName server1 -SwitchName setswitch -Name set1\n</code></pre> Enable RDMA with [<code>Get-</code>][Get-NetAdapterRdma] and [<code>Enable-NetAdapterRdma</code>][Enable-NetAdapterRdma].</p>"},{"location":"Misc/Windows/PowerShell/#implement-nested-virtualization","title":"Implement nested virtualization","text":"<p>Both the physical host and the nested virtual host must be running Windows Server 2016, but before installing Hyper-V on the nested host, the following configurations must be made. [Zacker][Zacker]: 181</p> <p>Provide nested host's processor with access to virtualization technology on the physical host <pre><code>Set-VMProcessor -VMName server1 -ExposeVirtualizationExtensions $true\n</code></pre> Disable dynamic memory <pre><code>Set-VMMemory -VMName SRV01 -DynamicMemoryEnabled $false\n</code></pre> Configure 2 virtual processors <pre><code>Set-VMProcessor -VMName SVR01 -Count 2\n</code></pre> Turn on MAC address spoofing <pre><code>Set-VMNetworkAdapter -VMName SVR01 -Name \"NetworkAdapter\" -MACAddressSpoofing On\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#enable-credssp","title":"Enable CredSSP","text":"<p>On the remote (managed) server [Zacker][Zacker]: 176 <pre><code>Enable-PSRemoting\nEnable-WSManCredSSP\n</code></pre> Add the fully-qualified domain name of the Hyper-V server to be managed to the local system's WSMan trusted hosts list <pre><code>Set-Item WSMan:\\localhost\\client\\trustedhosts -Value \"hypervserver.domain.com\"\n</code></pre> Enable the use of CredSSP on the client  <pre><code>Enable-WSManCredSSP -Role client -DelegateComputer \"hypervserver.domain.com\"\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#configure-server-core","title":"Configure Server Core","text":"<p>Manually configure network interface, if a DHCP server is unavailable [Zacker][Zacker]: 19 <pre><code>New-NetIPAddress 10.0.0.3 -InterfaceAlias \"Ethernet' -PrefixLength 24\n</code></pre> Configure the DNS server addresses for the adapter <pre><code>Set-DnsClientServerAddress -InterfaceIndex 6 -ServerAddresses (\"192.168.0.1\",\"192.168.0.2\")\n</code></pre> Rename the computer and join it to a domain <pre><code>Add-Computer -DomainName adatum.com -NewName Server8 -Credential adatum\\administrator\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#update-server-core-image","title":"Update Server Core image","text":"<pre><code>Mount-WindowsImage -ImagePath .\\CoreServer.vhdx -Path .\\MountDir -Index 1\nAdd-WindowsPackage -Path .\\MountDir -PackagePath C:\\ServicingPackages_cabs\nDismount-WindowsImage -Path .\\MountDir -Save\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#implement-dda","title":"Implement DDA","text":"<p>Discrete Device Assignment (DDA) begins with finding the Instance ID of the device needed to be passed through. [Zacker][Zacker]: 212 <pre><code>Get-PnpDevice -PresentOnly\nDisable-PnpDevice -InstanceId                 # Remove host-installed drivers\nGet-PnpDeviceProperty                         # Provide `InstanceId` and `KeyName` values in order to get value for `LocationPath` parameter in next command\nDismount-VmHostAssignableDevice -LocationPath # Remove the device from host control\nAdd-VMAssignableDevice -VM -LocationPath      # Attach the device to a guest\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#configure-live-migration","title":"Configure live migration","text":"<p>Live migration is possible between Hyper-V hosts that are not clustered, but they must be within the same (or trusted) domains. [Zacker][Zacker]: 306 <pre><code>Enable-VMMigration\nSet-VMMigrationNetwork 192.168.4.0\nSet-VMHost -VirtualMachineMigrationAuthenticationType Kerberos\nSet-VMHost -VirtualMachineMigrationPerformanceOption smbtransport\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#configure-s2d-cluster","title":"Configure S2D cluster","text":"<pre><code>New-Cluster -Name cluster1 -node server1,server2,server3,server4 -NoStorage\nEnable-ClusterStorageSpacesDirect\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#install-docker-enterprise","title":"Install Docker Enterprise","text":"<p>[Zacker][Zacker]: 266 <pre><code>Install-Module -Name dockermsftprovider -repository psgallery -force\nInstall-Package -Name docker -ProviderName dockermsftprovider\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#handle-xml-files","title":"Handle XML files","text":"<p>Find a sample XML file here</p> <p>Assign the output of [<code>gc</code>][Get-Content] to a variable <pre><code>[xml]$xdoc = gc $xmlfile\n</code></pre> The XML tree can be viewed in VS Code using the XML Tools extension. The object itself can be treated as a first-class Powershell object using dot notation. red-gate.com <pre><code>$xdoc.catalog.book | Format-Table -Autosize\n</code></pre> Arrays of elements can be accessed by their index <pre><code>$xdoc.catalog.book[0]\n</code></pre> Nodes in the XML object can also be navigated using XPath notation with the <code>SelectNodes</code> and <code>SelectSingleNode</code> methods. <pre><code>$xdoc.SelectNodes('//author')\nThis produces the same output as the command above (in XPath nodes are 1-indexed).\n```powershell\n$xdoc.SelectSingleNode('//book[1]')\n</code></pre> [<code>Select-Xml</code>][Select-Xml] wraps the returned XML node with additional metadata, including the pattern searched. However, it can accept piped input. <pre><code>(Select-Xml -Xml $xdoc -Xpath '//book[1]').Node\n($xml | Select-Xml -Xpath '//book[1]').Node\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#update-server-core-images","title":"Update Server Core images","text":"<p>[MeasureUp Lab][pl:70-740] <pre><code>Mount-WindowsImage -ImagePath .\\CoreServer.vhdx -Path .\\MountDir -Index 1\nAdd-WindowsPackage -Path .\\MountDir PackagePath C:\\ServicingPackages_cabs\nDismount-WindowsImage -Path .\\MountDir -Save\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#pass-through-disk","title":"Pass-through disk","text":"<p>[Zacker][Zacker]: 226 <pre><code>Set-Disk -Number 2 -IsOffline $true\nAdd-VMHardDiskDrive -VMName server1 -ControllerType scsi -DiskNumber 2\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#site-aware-failover-cluster","title":"Site-aware failover cluster","text":"<p>Configure failover clusters for two offices [Zacker][Zacker]: 366 <pre><code>New-ClusterFaultDomain -Name ny -Type site -Description \"Primary\" -Location \"New York, NY\"\nNew-ClusterFaultDomain -Name sf -Type site -Description \"Secondary\" -Location \"San Francisco, CA\"\nSet-ClusterFaultDomain -Name node1 -Parent ny\nSet-ClusterFaultDomain -Name node2 -Parent ny\nSet-ClusterFaultDomain -Name node3 -Parent sf\nSet-ClusterFaultDomain -Name node4 -Parent sf\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#filter-ad-account-information","title":"Filter AD account information","text":"<pre><code>Get-aduser -filter {(SamAccountName -like \"*CA0*\")} -properties Displayname, SaMaccountName, Enabled, EmailAddress, proxyaddresses | \nWhere {($_.EmailAddress -notlike \"*@*\")} | \nWhere {($_.Enabled -eq $True)} | \nSelect Displayname, SaMaccountName, Enabled, EmailAddress, @{L=\u2019ProxyAddress_1'; E={$_.proxyaddresses[0]}}, @{L=\u2019ProxyAddress_2'; E={$_.ProxyAddresses[1]}} | \nExport-csv .\\usersnoemail2.csv -notypeinformation\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#create-vm-with-installation-media","title":"Create VM with installation media","text":"<p>[Practice Lab][pl:70-740] <pre><code>New-VM PLABWIN102 1536mb 1 -SwitchName 'Private network 1' -NewVHDPath 'C:\\Users\\Public\\Documents\\Hyper-V\\Virtual hard disks\\PLABWIN102.vhdx' -NewVHDSizeBytes 127gb\nSet-VMDvdDrive -VMName PLABWIN102 -Path C:\\Users\\Administrator.PRACTICELABS\\Documents\\Eval81.iso\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#registry","title":"Registry","text":"Description Affected key Fix Windows Search bar docs.microsoft.com HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Search Remove 3D Objects howtogeek.com HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\MyComputer\\NameSpace Display seconds in system clock howtogeek.com HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced Disable Aero Shake howtogeek.com HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced <p>Remove 3D Objects from This PC howtogeek.com <pre><code>Remove-Item 'HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\MyComputer\\NameSpace\\{0DB7E03F-FC29-4DC6-9020-FF41B59E513A}'\n</code></pre> Add seconds to clock howtogeek.com <pre><code>New-Item -Path HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Advanced -Name ShowSecondsInSystemClock -Value 1\nRestart-Computer\n</code></pre> <pre><code>New-Item -Path HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Search -Name BingSearchEnabled -Value 0\nNew-Item -Path HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Search -Name CortanaConsent -Value 0\n</code></pre> Safely combine related registry modifications using [<code>Start-Transaction</code>][Start-Transaction] and [<code>Complete-Transaction</code>][Complete-Transaction] [Holmes][Holmes]: 604 <pre><code>Start-Transaction\nNew-Item TempKey -UseTransaction\nComplete-Transaction\n</code></pre> Remove User UAC for local users. ref <pre><code>Set-ItemProperty -Path HKLM:\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\System -Name EnableLUA -Value 0\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#winforms","title":"WinForms","text":"<p>Pastebin <pre><code># Load required assemblies\n[void] [System.Reflection.Assembly]::LoadWithPartialName(\"System.Windows.Forms\")\n\n# Drawing form and controls\n$Form_HelloWorld = New-Object System.Windows.Forms.Form\n  $Form_HelloWorld.Text = \"Hello World\"\n  $Form_HelloWorld.Size = New-Object System.Drawing.Size(272,160)\n  $Form_HelloWorld.FormBorderStyle = \"FixedDialog\"\n  $Form_HelloWorld.TopMost = $true\n  $Form_HelloWorld.MaximizeBox = $false\n  $Form_HelloWorld.MinimizeBox = $false\n  $Form_HelloWorld.ControlBox = $true\n  $Form_HelloWorld.StartPosition = \"CenterScreen\"\n  $Form_HelloWorld.Font = \"Segoe UI\"\n\n# adding a label to my form\n$label_HelloWorld = New-Object System.Windows.Forms.Label\n  $label_HelloWorld.Location = New-Object System.Drawing.Size(8,8)\n  $label_HelloWorld.Size = New-Object System.Drawing.Size(240,32)\n  $label_HelloWorld.TextAlign = \"MiddleCenter\"\n  $label_HelloWorld.Text = \"Hello World\"\n  $Form_HelloWorld.Controls.Add($label_HelloWorld)\n\n# add a button\n$button_ClickMe = New-Object System.Windows.Forms.Button\n  $button_ClickMe.Location = New-Object System.Drawing.Size(8,80)\n  $button_ClickMe.Size = New-Object System.Drawing.Size(240,32)\n  $button_ClickMe.TextAlign = \"MiddleCenter\"\n  $button_ClickMe.Text = \"Click Me!\"\n  $button_ClickMe.Add_Click({\n    $button_ClickMe.Text = \"You did click me!\"\n    Start-Process calc.exe\n  })\n  $Form_HelloWorld.Controls.Add($button_ClickMe)\n\n# show form\n$Form_HelloWorld.Add_Shown({$Form_HelloWorld.Activate()})\n[void] $Form_HelloWorld.ShowDialog()\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#modules","title":"Modules","text":"<p>Create a new module by placing a .psm1 file in a directory of the same name <pre><code>.\\Starship\\Starship.psm1\n</code></pre> Functions defined within the module can be loaded with [<code>Import-Module</code>][Import-Module] (execution policy must allow this). <pre><code>ipmo .\\Starship\n</code></pre> To import classes, a different syntax must be used source <pre><code>Using module .\\Starship\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#sample-enumeration","title":"Sample enumeration","text":"<p>PowerShellMagazine <pre><code>Add-Type -AssemblyName System.Drawing\n$count = [Enum]::GetValues([System.Drawing.KnownColor]).Count\n[System.Drawing.KnownColor](Get-Random -Minimum 1 -Maximum $count)\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#migrate-a-vm","title":"Migrate a VM","text":"<pre><code>Enable-VMMigration\nSet-VMMigrationNetwork 192.168.10.1\nSet-VMHost -VirtualMachineMigrationAuthenticationType Kerberos\nSet-VMHost -VirtualMachineMigrationPerformanceOption SMBTransport\n</code></pre>"},{"location":"Misc/Windows/PowerShell/#storage-spaces-direct","title":"Storage Spaces Direct","text":"<p>[MeasureUp][mu:70-740] <pre><code>New-Cluster -Name HC-CLU1 -Node node1, node2, node3, node4 -NoStorage\nEnable-ClusterStorageSpacesDirect -CacheMode Disabled -AutoConfig:0 -SkipEligibilityChecks\nNew-StoragePool -StorageSubSystemFriendlyName *Cluster* -FriendlyName S2DPool -ProvisioningTypeDefault Fixed -PhysicalDisk (Get-PhysicalDisk | Where-Object -Property CanPool -eq $true)\n$pool = Get-StoragePool S2DPool\nNew-StorageTier -StoragePoolUniqueID ($pool).UniqueID -FriendlyName Performance -MediaType HDD -ResiliencySettingName Mirror\nNew-StorageTier -StoragePoolUniqueID ($pool).UniqueID -FriendlyName Capacity -MediaType HDD -ResiliencySettingName Parity\n</code></pre> The next step would be the creation of a new volume <pre><code>New-Volume -StoragePool $pool -FriendlyName SharedVol1 -FileSystem CSVFS_REFS -StorageTiersFriendlyNames Performance, Capacity -StorageTierSizes 2GB, 10GB\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#scheduled-task","title":"Scheduled task","text":"<p>Automatically run SSH server in WSL on system start <pre><code>$action = New-ScheduledTaskAction -Execute C:\\WINDOWS\\System32\\bash.exe -Argument '-c sudo service ssh start'\n$trigger = New-ScheduledTaskTrigger -AtLogon\n\nRegister-ScheduledTask -TaskName 'SSH server' -Trigger $trigger -Action $action\n</code></pre></p>"},{"location":"Misc/Windows/PowerShell/#network-connection-alert","title":"Network connection alert","text":""},{"location":"Misc/Windows/PowerShell/#cmdlets","title":"Cmdlets","text":""},{"location":"Misc/Windows/PowerShell/#select-string","title":"Select-String","text":"<pre><code>Select-String -Path *.yml -Pattern 'ansible_host' -Context 2,3\n</code></pre>"},{"location":"Misc/Windows/WDS-lab/","title":"WDS lab","text":"<p><pre><code># PLABDC01\nSet-DHCPServerv4Scope -ScopeId '192.168.0.0' -Type Both -State Active\nwdsutil.exe /initialize-server /remInst:\"D:\\RemoteInstall\"\nwdsutil.exe /enable-server\nwdsutil.exe /start-server\n</code></pre> Import install and boot images <pre><code>New-WDSInstallImageGroup -Name Win10-DVDImage\nGet-WindowsImage -ImagePath \\\\plabdm01\\win10\\sources\\install.wim\nImport-WDSInstallImage -Path \\\\plabdm01\\win10\\sources\\install.wim -ImageGroup Win10-DVDImage -ImageName 'Windows 10 Enterprise'\nImport-WdsBootImage -Path \\\\plabdm01\\win10\\sources\\boot.wim -NewImageName 'Microsoft Windows Setup (x64)' -NewDescription 'Microsoft Windows Setup (x64)'\n</code></pre> Configure server to accept clients <pre><code>::wdsutil.exe /start-transportserver\nwdsutil.exe /set-server /answerclients:all\nwdsutil.exe /set-server /authorize:yes\nwdsutil.exe /set-server /NewMachineNamingPolicy:PLABSA%#03\n</code></pre> Configure VM to boot from PXE <pre><code># PLABDM01\nRename-VMSwitch Intel* External\nAdd-VMNetworkAdapter -IsLegacy $true -VMName PLABSA02 -SwitchName External\nRemove-VMAssignableDevice -VMName PLABSA02\nStart-VM PLABSA02\n# While connected to VM, when prompted to \"press F12 for network service boot\", press F12.\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/","title":"Windows Server","text":""},{"location":"Misc/Windows/WS2016/#certification-exams","title":"Certification exams","text":"Number Title 70-740 Installation, storage and Compute with Windows Server 2016 70-741 Networking with Windows Server 2016 70-742 Identity with Windows Server 2016 <p>Find notes on labs here.  </p>"},{"location":"Misc/Windows/WS2016/#installation","title":"Installation","text":"<p>Windows Server 2016 installations are determined by the most suitable installation method, option, and edition.</p> <ul> <li>Installation methods: <ul> <li>An upgrade is an installation performed in-place with existing data intact and is opposed to a clean installation. </li> <li>A migration is a clean installation with old data transferred over. Migrations are facilitated by Powershell and [command prompt][SmigDeploy.exe] tools</li> </ul> </li> <li>Installation options include Desktop Experience, [Server Core][Server Core], and Nano Server.</li> <li>The most important installation edition is Windows Server 2016 Datacenter edition, which is the only edition to have several important features that figure prominently in the exam.<ul> <li>Storage Spaces Direct, </li> <li>Storage Replica</li> <li>Shielded VMs</li> <li>Network controller.</li> </ul> </li> <li>Various other installation options exist, including: Windows Server 2016 Standard, Essentials, Multipoint Premium, Storage, and Hyper-V editions.</li> </ul> <p>Server installations are also influenced by choice of  activation model . </p>"},{"location":"Misc/Windows/WS2016/#licensing","title":"Licensing","text":"<p>Servicing channels provide a way of separating users into deployment groups for feature and quality updates.</p> <ul> <li>Semi-Annual Channel - previously known as Current Branch for Business (CBB) - features updates twice a year. It is more appropriate for non-infrastructure workloads that can be deployed through automation.</li> <li>Long Term Servicing Channel (LTSC) has a minimum servicing lifetime of 10 years and was designed to be used only for specialized devices such as those that control medical equipment or ATM machines, receiving new feature releases every 2-3 years</li> </ul>"},{"location":"Misc/Windows/WS2016/#server-core","title":"Server Core","text":"<p>Installing the Windows Server 2016 Server Core foregoes the possibility of later switching back to Desktop Experience, as had been possible in previous editions.  Notably, WDS is incompatible with Server Core installations.</p> <p>Server Core installations can be managed with a GUI with the use of MMC snap-ins.  Because MMC is reliant on Distributed Component Object Model (DCOM) technology, firewall rules have to be enabled to allow DCOM traffic (ref. <code>Set-NetFirewallRule</code>).</p>"},{"location":"Misc/Windows/WS2016/#nano-server","title":"Nano Server","text":"<p>Nano Server, a new installation option introduced in Windows Server 2016, provides a much smaller footprint and attack surface than even Server Core, but supports only some roles and features. Installation is done by building a VHD image via PowerShell on another computer. That VHD is then deployed as a VM or used as a boot drive for a physical server.</p> <p>Booting a Nano Server VM produces a text-based interface called the Nano Server Recovery Console, a menu system that allows configuration of static network options (DHCP is enabled by default). The DNS server may not be configured interactively, but must be specified when building the image with the <code>Ipv4Dns</code> parameter.</p> <p>If a Nano Server is domain-joined a remote Powershell session will authenticate via Kerberos. If not, its name or IP address must be added to the Trusted Hosts list.</p> <p>The Windows Server 2016 installation media contains a NanoServer directory, from which the NanoServerImageGenerator Powershell module must be imported. It also contains a Packages subdirectory, with CAB files containing roles and features that correspond to named parameters or packages that are specified as values to the <code>Packages</code> named parameter when building a Nano Server image.</p> Cmdlet Description Edit-NanoServerImage Add a role or feature to an existing Nano Server VHD file New-NanoServerImage Used to create a Nano Server VHD file for Nano Server installation"},{"location":"Misc/Windows/WS2016/#activation","title":"Activation","text":"<p>Server installations are influenced by choice of activation model.  MAK is suitable for small networks, but large enterprises may opt for KMS. - MAK activations are subdivided into Independent and Proxy, based on whether or not a VAMT is used. - KMS activations, which distribute GVLKs, are valid for a period of time and require the installation of a role and management tools. KMS operates on TCP port 1688. - AVMA simplifies the process of activating Hyper-V VMs running Windows Server 2012 or 2016.</p> <p>Active Directory-based activation is an alternative for enterprises who opt to activate licenses through the existing AD DS domain infrastructure.</p> <p>Any domain-joined computers running a supported OS with a GVLK will be activated automatically and transparently. The domain must be extended to the Windows Server 2012 R2 or higher schema level, and a KMS host key must be added using the VAMT. After Microsoft verifies the KMS host key, client computers are activated by receiving an activation object from the DC. MS Docs</p>"},{"location":"Misc/Windows/WS2016/#images","title":"Images","text":"<p>Many enterprises have begun virtualizing their server environments to take advantage of the many cost, reliability, and performance benefits that this change creates.</p> <p>Migrations should start with systems that are peripheral to main business interests before moving on to those that are more vital. A carefully documented protocol should be developed to facilitate the conversion of physical hard disks to VHDs for use in Hyper-V guests. Supported guest OSes include Linux and FreeBSD.</p> <p>The Microsoft Assessment and Planning (MAP) Toolkit is a free software tool that intelligently constructs a database of the hardware, software, and performance of computers on a network to plan for an operating system upgrade or virtualization. MAP supports the following discovery methods:</p> <ul> <li>Active Directory Domain Services</li> <li>Windows networking protocols</li> <li>System Center Configuration Manager</li> <li>IP address range scanning</li> <li>Computer names entered manually or imported from a file</li> </ul> <p>Server Core relies on the command-line for system maintenance, including updates which must be installed directly to the image using <code>dism.exe</code> or equivalent Powershell commands.</p>"},{"location":"Misc/Windows/WS2016/#containers","title":"Containers","text":""},{"location":"Misc/Windows/WS2016/#dns","title":"DNS","text":""},{"location":"Misc/Windows/WS2016/#installation_1","title":"Installation","text":"<p>DNS server role requiremenets: - Statically assigned IP - Signed-in user must be member of local Administrators group</p> <p>There are several recommended DNS deployment scenarios, all of which involve installing DNS on a  Server Core  or  Nano Server  instance. This is because these installation options offer a reduced attack surface, a reduced resource footprint, and reduced patching requirements. - DNS on DC:  All DNS features are available and supports AD-integrated, primary, secondary, and stub zones. - DNS on RODC:  Passes DNS zone updates to a writeable DC - DNS on standalone member server:  Supports file-based primary, secondary, and stub zones but requiring zone replication  because there is no integration over AD.</p>"},{"location":"Misc/Windows/WS2016/#nano-server_1","title":"Nano Server","text":"<p>Installing DNS on a running Nano Server image requires running <code>Install-NanoServerPackage</code> as well as enabling the \"DNS-Server-Full-Role\" optional feature using <code>Enable-WindowsOptionalFeature</code>.</p> <p>As of early 2017, Nano Server only supported a few roles, including DNS, but was only able to do so with some limitations - Nano Server can only support file-based DNS and cannot host AD-integrated zones. - Nano Server only supports the Semi-Annual servicing channel license. - Nano Server is not suitable for primary zones, only caching-only, forwarder, or secondary zone DNS servers</p>"},{"location":"Misc/Windows/WS2016/#zones","title":"Zones","text":"<p>Zones can be considered one or more DNS domains or subdomains, associated with zone files, which compose the DNS database itself and contain two types of entries:</p> <ul> <li>Parser commands, which provide shorthand ways to enter records: <code>$ORIGIN</code>, <code>$INCLUDE</code>, and <code>$TTL</code></li> <li>Resource records are whitespace delimited text files with columns for name, time to live, class, type, and data</li> </ul> <p>The copies of zone files local to individual DNS servers can be primary (read/write) or secondary (read-only). A primary zone is a writable copy of a DNS zone that exists on a DNS server. A secondary zone is a read-only replica of a primary zone and necessitates the presence of a primary zone for the same zone. Defining a secondary zone via PowerShell requires specifying that zone's <code>MasterServers</code>.</p> <p>In Windows Server, zone files can also be integrated with Active Directory, making what is called an Active Directory Integrated Zone. These allow multi-master zones, meaning any DC can process zone updates and the zone can be replicated to any DC in the domain or forest.</p> <p>An AD-integrated zone can be specified by passing the <code>ReplicationScope</code> parameter to the <code>Add-DnsServerPrimaryZone</code> cmdlet.</p> <p>Stub zones contains only name server (NS) records of another zone, but unlike a forwarder is able to update when name servers in a target zone change.</p> <p>Reverse Lookup zones are used to resolve IP addresses to FQDNs. Reverse lookup zones for public IP address space are often administered by ISPs, and they are useful in spam filtering to double-check the source domain name with the IP address.</p> <p>GlobalNames zones provide \"single label name resolution\" (as opposed to a FQDN) and are intended to replace WINS servers.</p>"},{"location":"Misc/Windows/WS2016/#query-traffic","title":"Query traffic","text":"<p>The process of resolving a query by querying other DNS servers is called recursion. Recursion can be disabled outright but Windows Server 2016 supports recursion scopes which will allow recursion to be disabled unless certain conditions are met (such as receiving the request on a particular interface).</p> <p>There are two types of query in the context of recursion: - Recursive query sent by the petitioner: that is, the original query which begins recursion. - Iterative query: individual queries sent out to authoritative name servers in order to resolve a recursive query.</p> <p>Root hints are preconfigured root servers that are necessary to begin the recursion process. The DNS Server service stores root hints in <code>%systemroot%\\System32\\dns\\CACHE.DNS</code>. These can be edited through the GUI or by using the PowerShell commands <code>Add-</code>, <code>Import-</code>, <code>Remove-</code>, and <code>Set-DnsServerRootHint</code>. </p> <p>Forwarding of a request occurs when a petitioned DNS server is unable to resolve the query because it is both: - Non-authoritative for the specified zone, and - Does not have the response cached.</p> <p>Two actions are possible when forwarding: - Configure a DNS server only to respond to queries it can satisfy by referencing locally-stored zone information, forwarding all other requests. - Configure forwarding for specific zones through conditional forwarding</p> <p>A secondary zone is not to be confused with delegation, where a DNS server delegates authority over part of its namespace (i.e. a subdomain) to one or more other servers.</p> <p>Windows Server 2016 supports a DNS GlobalNames zone meant to supercede WINS, which served a role similar to DNS for the old NetBIOS naming standard. NetBIOS names use a nonhierarchical structure (i.e. are a single name and not divisible into sub-domains) based on a name up to 16 characters long (although the 16th character defines a particular service running on the host defined by the previous 15). An organization must share a single GlobalNames zone, which must be created in PowerShell manually.</p>"},{"location":"Misc/Windows/WS2016/#resource-records","title":"Resource records","text":"<p>Zone scavenging allows servers with stale records to remove them. This feature is disabled by default, but can be set at the server or zone level.</p> Type Description A IPv4 address record AAAA IPv6 address record CNAME Hostname or alias for hosts in the domain MX Where mail for the domain should be delivered NS Name servers PTR Reverse lookup SOA Each zone contains a single SOA record SRV Generalized service location record, used for newer protocols instead of protocol-specific records TXT Typically holds machine-readable data"},{"location":"Misc/Windows/WS2016/#security","title":"Security","text":"<ul> <li>DNSSEC offers security features using public key certificates.</li> <li>A socket pool can be used to configure the DNS server to use a random source port when issuing DNS queries.</li> <li>Response rate limiting can pose a defense against DNS DoS attacks by ignoring potentially malicious, repetitive requests.</li> <li>DNS-based Authentication of Named Entities (DANE) is supported by Windows Server 2016 to reduce man-in-the-middle attacks. DANE works by informing DNS clients requesting records from the domain which Certification Authoority they must expect digital certificates to be issued from.</li> </ul>"},{"location":"Misc/Windows/WS2016/#policies","title":"Policies","text":"<p>Zone transfer policies can prevent or allow zone transfers to any server, to name servers, or to servers specified by FQDN or IP address. DNS Policy is a new feature in Windows Server 2016 that can control DNS server behavior depending on certain criteria.</p> <p>These criteria include:</p> <ul> <li>Client subnet</li> <li>Recursion scope</li> <li>Zone scope</li> </ul>"},{"location":"Misc/Windows/WS2016/#dnssec","title":"DNSSEC","text":"<p>DNSSEC is a security setting for DNS that enables all DNS records in a zone to be digitally signed by a trust anchor which validates DNSKEY resource records. Root and top-level domain zones already have trust anchors configured and merely have to have it enabled.</p> <p>To implement trust anchors: - A TrustAnchors zone must be created, which will store public keys associated with specific zones. A trust anchor from the secured zone must be created on every DNS server that hosts the zone. - A Name Resolution Policy Table (NRPT) GPO must be created (Windows Settings\\Name Resolution Policy) This option can require DNSSEC based on computer name prefix or suffix, FQDN, or subnet. - DNSSEC key master is a special DNS server that generates and manages signing keys for DNSSEC protected zones. DANE allows you to publish certificate information within the DNS zone, rather than one of the thousands of trusted CAs. This protects against rogue/compromised CAs issuing illegitimate TLS certificates.</p> <p>Two cryptographic keys: - Zone Signing Key (ZSK) signs zone data including individual resource records other than DNSKEY. It is also used to create the KSK. - Key Signing Key (KSK) is used to sign all DNSKEY records at the zone root.</p> <p>DNSSEC record types: - RRSIG \"resource record signature\" each of which matches and provides a signature for an existing record in a zone - NSEC proves nonexistence of a record - NSEC3 NSEC replacement that prevents zone walking - NSEC3PARAM specifies the NSEC3 records included in response for DNS names that don't exist - DNSKEY stores public key used to verify a signature - DS delegation signer records secure delegations</p>"},{"location":"Misc/Windows/WS2016/#dsc","title":"DSC","text":"<p>IaaS management of servers is possible with Desired State Configuration (DSC), a feature of Windows PowerShell where script files stored on a central server can apply specific a specific configuration to nodes. These scripts are idempotent, meaning that they can be applied repeatedly without generating errors.</p> <p>The DSC model is composed of phases 1. Authoring Phase, where MOF definitions are created 2. Staging Phase, where declarative MOFs are staged and a Configuration calculated per node 3. \"Make It So\" Phase, where declarative Configurations are implemented through imperative providers</p> <p>Components of DSC scripts include: - Local Configuration Manager: engine running on the client system that received configurations from the DSC server and applies them to the target. - Node block specifies the names of target computers. - Resource block specifies settings or components and the values that the configuration script should assign to them.</p> <p>DSC configurations can be deployed in two different refresh modes </p> Pull architecture: target LCM periodically retrieves configuration from a Pull Server, which consolidates MOF files. Push architecture: configuration is sent to target in response to explicit invocation of <code>Start-DSCConfiguration</code> on the server. <p>LCM has to be configured to accept Configurations of either refresh mode.</p>"},{"location":"Misc/Windows/WS2016/#tasks","title":"Tasks","text":"<p>Set LCM to push mode <pre><code>[DSCLocalConfigurationManager()]\nConfiguration LCMConfig \n{\n  Node localhost \n  {\n    Settings \n    {\n      RefreshMode = 'Push'\n    }\n  }\n}\n</code></pre></p> <p>Install Telnet client <pre><code>Configuration InstallTelnetLocal { \n  Import-DscResource -ModuleName 'PSDesiredStateConfiguration'\n  Node localhost \n  {\n    WindowsOptionalFeature InstallTelnet \n    {\n      Name = \"Telnet-Client\"\n      Ensure = \"Present\"\n    }\n  }\n}\n</code></pre></p> <p>Install WSL <pre><code>Configuration InstallWSLLocal { \n  Import-DscResource -ModuleName 'PSDesiredStateConfiguration'\n  Node localhost   \n  {\n    WindowsOptionalFeature InstallWSL     \n    {\n      Name = \"Microsoft-Windows-Subsystem-Linux\"\n      Ensure = \"Present\" \n    }\n  }\n}\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#failover-clusters","title":"Failover clusters","text":"<p>Failover clusters are composed of computers called nodes and can be created using <code>New-Cluster</code>. which typically possess a secondary network adapter, used for cluster communications. </p> <p>Before Windows Server 2016, all cluster nodes had to belong to the same domain, but now this is but one of several possible cluster types called a single-domain cluster. A failover cluster can also be multi-domain, or workgroup, depending on how or if the servers are joined to domains. A cluster can also be detached from AD, even though its nodes are joined.</p> <p>A cluster whose servers are joined to a single domain is typically associated with a cluster name object in Active Directory, which serves as its administrative access point. A workgroup cluster or a detached cluster need to have the cluster's network name registered in DNS as its administrative access point, which can be specified in Powershell with the <code>AdministrativeAccessPoint</code> named parameter. Additionally, on a workgroup cluster the same local administrator account must be created on every node, preferably the builtin Administrator account, although a different account can be configured if a particular Registry key is [created][New-ItemProperty] on each node.</p> <p>Nodes that are domain-joined support CredSSP or Kerberos authentication, but workgroup nodes support NTLM authentication only.</p> <p>Three types of witness resources can help to ensure a quorum takes place in clusters.  This is necessary to prevent a split-brain situation, where communication failures between nodes cause separate segments of the clusters to continue operating independently of each other. A witness is created when a cluster has an even number of nodes, and only one can be configured. [pwsh][Set-ClusterQuorum] - Disk witness: dedicated disk in shared storage that contains a copy of the cluster database - File Share witness: SMB file share containing a Witness.log file with information about the cluster - Cloud witness: blob stored in Azure <p>Scale-out File Server (SoFS) is a clustered role providing highly available storage to cluster nodes. SoFS ensures continuous availability in the case of a node failure. Using SoFS, multiple nodes can also access the same block of storage at the same time, and for this reason is is an active/active or dual active system, as opposed to one where only one node provides accessible shares, or an active/passive system. </p> <p>SoFS is specifically recommended for use on Hyper-V and SQL Server clusters and can be installed with <code>Add-ClusterScaleOutFileServer</code>.</p> <p>SoFS shares are created with the [<code>New-SmbShare</code>][New-SmbShare] PowerShell cmdlet. SoFS shares are located on Cluster Shared Volumes (CSV), a shared disk containing an NTFS or ReFS volume that is made accessible for read and write operations by all nodes within a failover cluster.</p> <p>CSVs solved a historical problem with using NTFS volumes with VMs in previous versions of Windows Server. NTFS is designed to be accessed by only one operating system instance at a time. In Windows Server 2008 and earlier, this meant that only one node could access a disk at a time, which had to be mounted and dismounted for every VM.</p> <p>The solution was to create a pseudo-file system called CSVFS, sitting on top of NTFS, that enables multiple drives to modify a disk's content at the same time, but restricting access to the metada to the owner or coordinator. The coordinator node refers to the cluster node where NTFS for the clustered CSV disk is mounted, any other node is called a Data Server (DS).</p> <p>VM resiliency can be configured by adjusting settings in response to changes in VM state: - Unmonitored: VM owning a role is not being monitored by the Cluster Service - Isolated: Node is not currently an active member of the cluster, but still possess the role - Quarantine: Node has been drained of its roles and removed from the cluster for a specified length of time.</p> <p>Cluster Operating System Rolling Upgrade is a new feature that reduces downtime by making it possible for a cluster to have nodes running both Windows Server 2012 R2 and Window Server 2016. Using this feature, nodes can be brought down for an upgrade.</p> <p>When [Storage Spaces][Storage Spaces] is combined with a failover cluster, the solution is known as Clustered Storage Spaces.</p>"},{"location":"Misc/Windows/WS2016/#high-availability","title":"High availability","text":"<p>Hyper-V Replica allows simple failover to occur between Hyper-V hosts, without the need for a cluster. To configure a simple one-way failover solution using Hyper-V Replica, configure the destination VM as a replica server, either in Hyper-V Manager or PowerShell. [<code>Set-VMReplicationServer</code>][Set-VMReplicationServer] lab The destination host must also have firewall ports opened corresponding to the authentication method chosen. The source VM, which is to be replicated, must have its options configured through the Enable Replication wizard. [<code>Enable-VMReplication</code>][Enable-VMReplication] To use Hyper-V Replica as a (two-way) failover solution, configure both VMs as replica servers.</p> <p>Migrations can take place one of three methods: - Live Migration moves only the system state and live memory contents, not data files. Live migration requires that the hosts be, if not clustered, at least part of the same (or a trusted) domain. Live Migration requires that VHD files be placed on shared storage and both hosts have appropriate permissions to access said storage. An unpopulated VM is created on the destination with the same resources as the source before transferring memory pages.  Once the servers have an identical memory state, the source VM is suspended and the destination takes over.  Hyper-V  notifies the network switch of the change, diverting network traffic to the destination.  Authentication can be made by [CredSSP][CredSSP] or Kerberos.</p> <p>When a Hyper-V cluster is created, the Failover Cluster Manager launches the High Availability Wizard, which configures the VM to support Live Migration.  The same thing can be done with the PowerShell cmdlet <code>Add-ClusterVirtualMachineRole</code>.</p> <p>Additionally, using Kerberos authentication for live migration requires constrained delegation, which enables a server to act on behalf of a user for only certain defined services. This must be configured within Active Directory Users and Computers, by opening the Properties of the source Computer object, and changing the setting under the Delegation tab.   - An additional, outdated method of migration is quick migration, which was present in Windows Server prior to the introduction of live migration and persists in Windows Server 2016 for backward compatibility. A quick migration involves pausing the VM, saving its state, moving the VM to the new owner, and starting it again. A quick migration always involves a short period of VM downtime.</p> <ul> <li>Shared Nothing Live Migration requires that source and destination VMs be members of the same (or trusted) domain, and source and domain servers must be running the same processor family (Intel or AMD) and linked by an Ethernet network running a minimum of 1 Gbps.  Additionally, both Hyper-V hosts must be running idential virtual switches that use the same name; otherwise the migration process will be interrupted to prompt the operator to select a switch on the destination server.  The process of migrating is almost identical to a Live Migration, except that you select the \"Move the Virtual Machine's Data To a Single Location\" option on the Choose Move Options page of the Move Wizard.</li> <li>Storage Migration works by first creating new VHDs on the destination corresponding to those on the source server. While the source server continues to operate using local files, Hyper-V begins mirroring disk writes to the destination server and begins a single-pass copy of the source disks to the destination begins, skipping blocks that have already been copied. Once the copy has completed, the VM begins working from the destination server and the source files are deleted. For a VM that is shut off, storage migration is equivalent to simply copying files from source to destination.</li> </ul> <p>Site-aware clusters have failover affinity. Node fairnes evalutes memory and CPU loads on cluster nodes over time.</p>"},{"location":"Misc/Windows/WS2016/#cluster-management","title":"Cluster management","text":"<p>VM Monitoring allows specific services to be restarted or failed-over when a problem occurs. To use VM Monitoring: - The guest must be joined to the same domain as the host - The host administrator must be a member of the guest's local Administrators group - And Windows Firewall rules in the Virtual Machine Monitoring group must be enabled.</p> <p>The service can then be monitored using [<code>Add-ClusterVMMonitoredItem</code>][Add-ClusterVMMonitoredItem].</p>"},{"location":"Misc/Windows/WS2016/#migration","title":"Migration","text":"<p>VMs can be moved from node to node of a cluster using live, storage, or quick migrations.</p> <p>VM network health protection is a feature (enabled by default) that detects whether a VM on a cluster node has a functional connection to a designated network. If not, the cluster live migrates the VM role to another node that does have such a connection. This setting can be controlled in Hyper-V Manager &gt; VM Settings &gt; Advanced Features &gt; Protected network</p>"},{"location":"Misc/Windows/WS2016/#gpo","title":"GPO","text":"<p>Group Policy Objects (GPO) facilitate the uniform administration of large numbers of users and computers. GPOs can be local or domain-based.</p> <p>Local GPOs come in several varieties, applied in the following order (last takes highest precedence): - Local Group Policy applied to computers - Administrators and Non-Administrators Local Group Policy applied to users based on their membership in local Administrators group. - User-specific Local Group Policy:</p> <p>Domain-based GPOs consist of two components a [container][Group Policy container] and a [template][Group Policy template]. These are stored in different locations and replicated by different means. - Containers define the fundamental attributes of a GPO, each of which is assigned a GUID, and are stored in the AD DS database and replicated to other domain controllers using intrasite or intersite AD DS replication schedule. - Templates, a collection of files and folders that define the actual GPO settings, are stored in the <code>SYSVOL</code> shared folder (<code>%SystemRoot%\\SYSVOL\\Domain\\Poligicies\\{GUID}</code>) on all DCs. <code>SYSVOL</code> replication is handled by the DFS Replication Agent since Windows Server 2008.</p> <p>A GPO consists of 2 top-level nodes: - Computer Configuration contains settings that are applied to computer objects to which the GPO is linked - User Configuration containers user-related settings, applied when a user signs in and thereafter and automatically refreshed every 90-120 minutes</p> <p>Beneath each of these nodes are folders that group settings - Software Settings - Windows Settings allows basic configuration for computers or users - Administrative Templates contains Registry settings that control user, computer, and app behavior and settings, grouped logically into folders</p> <p>Although domain controllers store and serve GPOs, the client computer itself must request and apply the GPOs using the Group Policy Client service. Client-side extensions process the GPOs once downloaded</p> <p>Starter GPOs are intended for use in large organizations with a proliferation of GPOs that share settings. Starter GPOs can be imported from, and exported to, a .CAB file.</p> <p>Once a GPO is created it must be linked to a container object in AD DS for it to apply to objects, a process known as scoping. GPOs can be linked to Sites, Domains, and OUs. If multiple GPOs are linked to the same container, the link order must be configured.</p> <p>There are 2 default GPOs in an AD DS domain, which can be reset using arguments to the <code>dcgpofix</code> command. - Default Domain Policy, linked to the domain object - Default Domain Controllers Policy, linked to the Domain Controllers OU</p> <p>Although it is possible to link the same GPO to multiple containers, it is recommended to import (i.e. copy) a GPO from another domain. This process effecitvely restores the settings of another GPO into a newly created GPO, which is then linked to another container.</p>"},{"location":"Misc/Windows/WS2016/#hyper-v","title":"Hyper-V","text":"<p>[Hyper-V][Hyper-V] is a Type I hypervisor and role that allows a Windows Server 2016 host to create VMs, called guests. In Type I virtualization, the hypervisor forms an abstraction layer that interacts directly with the host hardware. In this model, the individual environments created by the hypervisor, including the host operating system and guest VMs, are called [partitions][partition].</p> <p>Hyper-V Server, a free product available for download is limited to the command-line Server Core interface, however it does include <code>Sconfig</code> to aid configuration.</p> <p>Hyper-V can be managed remotely using the GUI (Hyper-V Manager, <code>hyper-v-tools</code>), or Powershell (<code>hyper-v-powershell</code>). Authentication can be via Kerberos or Credential Security Support Provider (CredSSP), which must be enabled on both server and client.</p> <p>PowerShell remoting - Explicit remoting involves opening a PowerShell session to a remote session - Implicit remoting involves running a cmdlet specifying the <code>ComputerName</code> parameter. PowerShell Direct allows easy remoting to VMs by using the <code>-VmName</code> Powershell parameter using a PowerShell session.</p> <p>[Nested virtualization][Nested virtualization] is a new capability where a virtual host running Windows Server 2016 on a physical host also running Windows Server 2016 can host nested VMs.</p>"},{"location":"Misc/Windows/WS2016/#host-configuration","title":"Host configuration","text":"<p>[Hyper-V][Hyper-V] is a Type I hypervisor and role that allows a Windows Server 2016 host to create VMs, called guests. In Type I virtualization, the hypervisor forms an abstraction layer that interacts directly with the host hardware. In this model, the individual environments created by the hypervisor, including the host operating system and guest VMs, are called [partitions][partition].</p> <p>Hyper-V Server, a free product available for download is limited to the command-line Server Core interface, however it does include <code>Sconfig</code> to aid configuration.</p> <p>Hyper-V can be managed remotely using the GUI (Hyper-V Manager, <code>hyper-v-tools</code>), or Powershell (<code>hyper-v-powershell</code>). Authentication can be via Kerberos or Credential Security Support Provider (CredSSP), which must be enabled on both server and client.</p> <p>PowerShell remoting - Explicit remoting involves opening a PowerShell session to a remote session - Implicit remoting involves running a cmdlet specifying the <code>ComputerName</code> parameter. PowerShell Direct allows easy remoting to VMs by using the <code>-VmName</code> Powershell parameter using a PowerShell session.</p> <p>[Nested virtualization][Nested virtualization] is a new capability where a virtual host running Windows Server 2016 on a physical host also running Windows Server 2016 can host nested VMs.</p>"},{"location":"Misc/Windows/WS2016/#networking","title":"Networking","text":"<p>Virtual switches can be external, internal, or private (in order of decreasing access). Up to 8 network adapters can be [added][Add-VMNetworkAdapter] to a Windows Server 2016 Hyper-V VM.</p> <p>Hyper-V maintains a pool of MAC addresses which are assigned to virtual network adapters as they are created. Hyper-V MAC addresses begin with <code>00-15-5D</code>, followed by the last two bytes of the IP address assigned to the server's physical network adapter (i.e. last two octets), then a final byte.</p> <p>Generation 1 VMs supported synthetic and legacy virtual network adapters, but in Generation 2 VMs only synthetic adapters are used. Generation 1 VMs can only boot from network (PXE) when using a legacy adapter.</p> <p>Physical hosts running Windows Server 2016 can support teams of up to 32 NICs, but Hyper-V VMs are limited to teams of two. The team must first be configured in the host operating system and appears as a single interface in the Virtual Switch Manager. High-performance embedded teaming, reliant on RDMA, can only be configured with Powershell. - Teaming Mode    - Switch Independent: switch is unaware of presence of NIC team and does not load balance to members; Windows is performing the teaming   - Switch Dependent: switch determines how to distribute inbound network traffic; only supported by specialty hardware     - Static Teaming: switch and host are manually configured (typically supported by server-class switches)     - Link Aggregation Control Protocol (LACP): dynamically identifies links that are connected between the host and the switch - Load Balancing Mode   - Address Hash: a hash is created based on address components of the packet, which is used to reasonably balance adapters   - Hyper-V Port: NIC teams configured on Hyper-V hosts give VMs independent MAC addresses   - Dynamic: outbound loads are distributed based on a hash of the TCP ports and IP addresses</p> <p>Virtual machine queuing will enhance performance if a physical host supports it and it is enabled.</p> <p>Bandwidth management is achieved by setting limits on the virtual network adapter, in the GUI or in [Powershell][Set-VMNetworkAdapter].</p>"},{"location":"Misc/Windows/WS2016/#storage","title":"Storage","text":"<p>The New Virtual Machine Wizard presents different options for Generation 1 vs. Generation 2 VMs. - Generation 1 VMs provide two IDE controllers, which host the hard drive and a DVD drive, and an unpopulated SCSI controller which can host additional disks. - Generation 2 VMs, however, have only a single SCSI controller, which hosts all virtual drives.</p> <p>A new VHD can be created using  - Hyper-V Manager through the New Virtual Hard Disk Wizard - Disk Management (<code>diskmgmt.msc</code>), however the option to create a differencing disk is not available, nor can specific block or sector size be specified - PowerShell</p> <p>Shared virtual disk files are preferably created as VHD sets. Pass-through disks make exclusive use of a physical disk. pwsh</p> <p>Standard checkpoints (previously known as \"snapshots\" in Windows Server 2012 and before) with the extensions AVHD or AVHDX save the state, data, and hardware configuration of a VM. They are recommended for development and testing but are not a replacement for backup software nor recommended for production environmentsj, because restoring them in a production environment will interrupt running services. Production checkpoints do not save memory state, but use Volume Shadow Copy Service (Windows) or File System Freeze (Linux) inside the guest to create \"point in time\" images of the VM.</p>"},{"location":"Misc/Windows/WS2016/#shielded-vms","title":"Shielded VMs","text":"<p>Shielded VMs are a feature exclusive to the Datacenter Edition of Windows Server 2016.</p> <p>As a result of increased virtualization, physical servers that were once secured physically were migrated to Hyper-V hosts that are less secure because they are accessible to fabric administrators. Shielded VMs were introduced to protect tenant workloads from inspection, theft, and tampering as a result of being run on potentially compromised hosts.</p> <p>A security concept closely associated to shielded VMs is the guarded fabric, which is a collection of nodes cooperating to protect shielded Hyper-V guests. The guarded fabric consists of: - Host Guardian Service (HGS) utilizes remote attestation to confirm that a node is trusted; if so, it releases a key enabling the shielded VM to be started. HGS is typically a cluster of 3 nodes. - Guarded hosts: Windows Server 2016 Datacenter edition Hyper-V hosts that can run shielded VMs only if they can prove they are running in a known, trusted state to the Host Guardian Service. - Shielded VMs</p> <p>In a production environment, a fabric manager like Virtual Machine Manager would be used to deploy shielded VMs (which are signified by a shield icon).</p> <p>Shielded VMs must run Windows (8+) or Windows Server (2012+), although Linux shielded VMs are now also supported since version Windows Server version 1709.</p> <p>Shielded VMs are produced by a three-stage process (VHD -&gt; Shielded template -&gt; Shielded VMs) 1. Preparation: Install and configure an OS onto a virtual disk file 2. Templatization: Convert virtual disk file into a shielded template 3. Provisioning: Create one or more shielded VMs from the shielded template</p> <p>Configure HGS in its own new forest YouTube <pre><code>Install-WindowsFeature HostGuardianServiceRole -Restart\nInstall-HgsServer -HgsDomainName 'savtechhgs.net' -SafeModeAdministratorPassword $adminPassword -Restart\n</code></pre></p> <p>Shielding Data is created and owned by tenant VM owners and contains secrets needed to create shielded VMs that must be protected from the fabric admin.</p> <p>Resources:</p> <ul> <li>Intro to shielded VMs</li> <li>Create a shielded VM using Powershell</li> <li>Linux Shielded VM How To</li> <li>Shielded VM Demonstration and Quick Setup</li> <li>Guarded Fabric Deployment Guide for Windows Server 2016</li> <li>Deploying Shielded VMs and a Guarded Fabric with Windows Server 2016</li> </ul>"},{"location":"Misc/Windows/WS2016/#attestation","title":"Attestation","text":"<p>There are two modes of attestation supported by HGS: </p> <ul> <li>Hardware-trusted attestationHardware-trusted attestation mode requires: <ul> <li>Measured boot: TPMv2 to seal software and hardware configuration details measured at boot</li> <li>Code integrity enforcement to strictly define permissible software</li> <li>Platform Identity Verification: Active Directory is not sufficient to identify the host. Rather, an identity key rooted in the host TPM is used for identity.</li> </ul> </li> <li>Remote attestation based on asymmetric key pairs</li> <li>Admin-trusted attestation was previously based on guarded host membership in a designated AD DS security group, but is deprecated beginning with Windows Server 2019.<ul> <li>Host identity is [verified]](https://youtu.be/B2vFrdXd5jg?t=525) by checking security group permission</li> <li>No Measured Boot or Code Integrity Validation</li> <li>Intended to aid transition to Hardware-trusted attestation mode for hosts produced before TPMv2</li> </ul> </li> </ul>"},{"location":"Misc/Windows/WS2016/#vm-configuration","title":"VM configuration","text":"<p>VMs are associated with a variety of file types:</p> Extension Description .vmc XML-format VM configuration .vhd, .vhdx Virtual hard disks .vsv Saved-state files <p>VMs can be created in Hyper-V, and a machine's RAM can even be changed dynamically.</p> <p>Hyper-V guests can take advantage of a suite of features to enhance performance and functionality. - Virtualization of NUMA architecture - Smart paging for when VMs that use dynamic memory restart and temporarily need more memory than is available on the host, for example at boot - Monitoring resource usage, to minimize cost overruns when guests run in the cloud - Disk and GPU passthrough, and other PCI-x devices, with DDA pwsh - Increased performance of interactive sessions that use [VMConnect][VMConnect.exe]</p> <p>Microsoft supports some Linux distributions, like Ubuntu, with built-in Linux Integration Services, which improve performance by providing custom drivers to interface with Hyper-V. Some distributions like CentOS and Oracle come with integrated LIS packages, but free LIS packages provided by Microsoft for download from the Microsoft Download Center support additional features and come with the additional benefit of being versioned. These packages are provided as tarballs or ISO images, and must be loaded directly into the running guest operating system. FreeBSD has included full support for FreeBSD Integration Services (BIS) since version 10.</p> <p>Secure Boot has to be disabled when loading Hyper-V VMs running Linux distributions, since UEFI does not have certificates for non-Windows operating systems by default.  Some distributions supported by Microsoft do have certificates in the UEFI Certificate Authority.</p> <p>Different versions of Hyper-V create VMs associated with that version (Windows Server 2016 uses Hyper-V 8.0). VMs created by older versions of Hyper-V can be [updated][Update-VMVersion], but once updated they may no longer run on a host of a previous version.</p> <p>Importing an exported VM can be done in three ways:  - Register: exported files are left as-is and the guest's ID is maintained;  - Restore: exported files copied to the host's default locations or ones that are otherwise specified; ID is maintained - Copy: exported files are copied; new ID generated</p> <p>PXE boot is supported in two scenarios: - Generation 1 VMs with a legacy virtual network adapter support PXE boot (but not synthetic). Generation 1 VMs are limited to 2 TB in size and do not support many of the advanced features that Generation 2 VMs do. But PXE Boot remains one of the primary reasons to continue using a Generation 1 VM. - Generation 2 VMs with a synthetic network adapter also support PXE boot. would also support bandwidth management and VMQ.</p> <p>Generation 2 VMs also do not support 32-bit OSes, including: - Windows Server 2008, R2 - Windows 7 - Older Linux distros - FreeBSD (all)</p> <p>VMs cannot be upgraded from Generation 1 to Generation 2 easily, although a script named <code>Convert-VMGeneration</code> was once provided by Microsoft and can still be found. But the VM's version, referring to the version of Hyper-V used to create it, can be upgraded with  <code>Upgrade-VMVersion</code> .</p>"},{"location":"Misc/Windows/WS2016/#monitoring","title":"Monitoring","text":"<p>Performance Monitor is a program that allows realtime monitoring of hundreds of different system performance statistics, called performance counters. Counters can be viewed in several ways, including line graph, histogram bar graph, and report views. Every counter added to a graph is associated with a computer, a performance object (hardware or software component to be monitored), a performance counter (statistic), and an instance.</p> <p>A data collector set captures counter statistics for later review. A single data collector set can gather performance counter data from multiple VMs. Event trace data cannot be combined with performance data in the same data collector set. Expiration dates can be set for data collector sets, but if actively collecting data the expiration date will not stop collection.</p> <p>A performance alert is a type of data collector set that can track system performance and log events in the application event log.</p> <p>Alerts can be triggered when a performance counter value exceeds a certain threshold. Only members of the local groups Administrators and Performance Log Users can create alerts, but the Log on as a batch user right must be granted to members of Performance Log Users.</p> <p>A hard fault occurs when data is swapped between memory and disk.</p>"},{"location":"Misc/Windows/WS2016/#performance-counters","title":"Performance counters","text":"Counter Acceptable values Processor: % Processor Time &lt;85% Processor: Interrupts/Sec cf. baseline System: Processor Queue Length &lt;2 Server Work Queues: Queue Length &lt;4 Memory: Page Faults/Sec &lt;5 Memory: Pages/Sec &lt;20 Memory: Available MBytes &gt;5% of physical memory Memory: Committed Bytes &lt; physical memory Memory: Pool Non-Paged Bytes Stable PhysicalDisk: Disk Bytes/Sec cf. baseline PhysicalDisk: Avg. Disk Bytes/Transfer cf. baseline PhysicalDisk: Current Disk Queue Length &lt;2 per spindle PhysicalDisk: % Disk Time &lt;90% LogicalDisk: % Free Space &gt;20% Network Interface: Bytes Total/Sec cf. baseline Network Interface: Output Queue Length &lt;2 Server: Bytes Total/Sec 50% of total bandwidth"},{"location":"Misc/Windows/WS2016/#network-load-balancing","title":"Network Load Balancing","text":"<p>Cluster VMs can be configured to drain their workloads to other nodes when being shutdown using <code>Suspend-ClusterNode</code></p> <p>NLB Clusters are made of hosts, while Failover Clusters are made of nodes.</p> <p>NLB port rules control how the cluster functions and are defined by two operational parameters:</p> <ul> <li>Affinity: associate client requests to cluster hosts.  When no affinity is specified, all network requests are load-balanced across the cluster without regard to their source.</li> <li>Filtering mode: specify how the cluster handles traffic described by port range and protocols; can be single or multiple hosts.</li> </ul> <p>When a port rule is not configured, the default host will receive all network traffic.</p> <p>Windows Server NLB Clusters can be upgraded to Windows Server 2016 in two ways: - Rolling upgrade brings only a single host down at a time, upgrading it before adding it and proceeding to the next one - Simultaneous upgrade brings the entire NLB cluster goes down</p> <p>NLB clusters have a Cluster Operation Mode setting specifying what kind of TCP/IP traffic the cluster hosts should use - Unicast: NLB replaces the MAC address on the interface with the cluster's virtual MAC address, causing traffic to go to all hosts.  Cluster hosts are prevented from communicating with each other in this mode. In this case, a second network adapter must be installed in order to facilitate normal communication between NLB cluster hosts. - Multicast: NLB adds a multicast MAC address to the network interface on each host that does not replace the original.</p>"},{"location":"Misc/Windows/WS2016/#storage_1","title":"Storage","text":"<p>Every track of a hard drive platter is split into disk sectors, traditionally 512 bytes. A block is commonly called an \"allocation unit\" in Windows, but also commonly called a cluster. Storage left over unused in partially unused blocks is known as slack space.</p> <p>A new disk must first be initialized, that is, a partition table style must be chosen: - GPT: 128 partitions per disk, maximum volume size of 18 exabytes (260 bytes). Booting from a GPT drive is not possible  unless the computer architecture supports EFI-based boot partitions. - MBR: older format that is commonly used for removable media, supporting volumes up to 2 TB with up to 4 primary partitions, although a common workaround is to make one of these partitions an extended partition, which can be be further subdivided into logical drives</p> <p>Mounting a partition as a single filesystem produces a volume, although the distinction can often be lost. The exception would be a case where a volume spans multiple partitions or physical disks, as is possible with software RAID.</p> <p>Virtual hard disks can be created with [Powershell][New-VHD] or in <code>diskmgmt.msc</code> and come in two formats: - VHD - VHDX</p> <p>Only 2 filesystem options are available for modern servers: - NTFS supports volumes up to 16 TB with the default 4 KB allocation unit size (but 256 TB with the 64 KB allocation unit size) and is required by some Windows Server services like AD DS, File Replication Service, Volume Shadow Copy Service, and Distributed File System - ReFS uses the same system of permissions as NTFS and offers error checking and repair capabilities that NTFS does not, but it does not support NTFS features like file compression, Encrypted File System, and disk quotas. ReFS supports a maximum file size of 16 exabytes and volumes up to 1 yobibyte (280 bytes)</p> <p>Software RAID can be implemented by creating Spanned, Striped, or RAID-5 volumes in <code>diskmgmt.msc</code>. A more modern and preferred technique is to create storage pools in  [Storage Spaces][Storage Spaces].</p>"},{"location":"Misc/Windows/WS2016/#dedup","title":"Dedup","text":"<p>Data deduplication (\"dedup\") is a role service that conserves storage space by storing only one copy of redundant chunks of files. Data duplication is appropriate to specific workloads, like backup volumes and file servers. It is not appropriate for database storage or operating system data or boot volumes.</p> <p>Data deduplication had required NTFS, although ReFS is supported since 1709.</p> <p>Data deduplication runs as a low-priority background process when the system is idle, by default; however its behavior can be configured based on its intended usage. Deduplication works by scanning files, and breaking them into unique chunks of various sizes that are collected in a chunk store. The original locations of chunks are replaced by reparse points. When a file is recently written, it is written in the standard, unoptimized form; the accumulation of such files is known as churn. Other jobs associated with deduplication include garbage collection, integrity scrubbing, and (when disabling deduplication) unoptimization.</p> <p>There are several deployment scenarios considered for data deduplication: - General purpose file servers Users often store multiple copies of the same, or similar, documents and files. Up to 30-50% of this space can be reclaimed using deduplication. - Virtualized Desktop Infrastructre (VDI) deployments Virtual hard disks that are used for remote desktops are essentially identical. Data Deduplication can also amelioriate the drop in storage performance when many users simultaneously log in at the start of the day, called a VDI boot storm. - Backup snapshots are an ideal deployment scenario because of the data is so duplicative.</p> <p>Deduplication is especially useful for disk drive backups, since snapshots typically differ little from each other.</p>"},{"location":"Misc/Windows/WS2016/#file-shares","title":"File shares","text":"<p>Windows Server 2016 supports file shares via two protocols, both of which require the <code>fs-fileserver</code> role service: - SMB, long the standard for Windows networks - NFS, typically used in Linux, requires the installation of <code>fs-nfs-service</code> role service</p> <p>BranchCache enables client computers at remote locations to cache files accessed from shares, so that other computers at the same location can access them. Install the <code>FS-BranchCache</code> feature and enable the <code>File and Printer Sharing</code> and <code>Branchcache - Hosted Cache Server (uses HTTPS)</code> firewall display groups.</p>"},{"location":"Misc/Windows/WS2016/#media","title":"Media","text":"<p>Every track of a hard drive platter is split into disk sectors, traditionally 512 bytes. A block is commonly called an \"allocation unit\" in Windows, but also commonly called a cluster. Storage left over unused in partially unused blocks is known as slack space.</p> <p>A new disk must first be initialized, that is, a partition table style must be chosen: - GPT: 128 partitions per disk, maximum volume size of 18 exabytes (260 bytes). Booting from a GPT drive is not possible  unless the computer architecture supports EFI-based boot partitions. - MBR: older format that is commonly used for removable media, supporting volumes up to 2 TB with up to 4 primary partitions, although a common workaround is to make one of these partitions an extended partition, which can be be further subdivided into logical drives</p> <p>Mounting a partition as a single filesystem produces a volume, although the distinction can often be lost. The exception would be a case where a volume spans multiple partitions or physical disks, as is possible with software RAID.</p> <p>Virtual hard disks can be created with [Powershell][New-VHD] or in <code>diskmgmt.msc</code> and come in two formats: - VHD - VHDX</p> <p>Only 2 filesystem options are available for modern servers: - NTFS supports volumes up to 16 TB with the default 4 KB allocation unit size (but 256 TB with the 64 KB allocation unit size) and is required by some Windows Server services like AD DS, File Replication Service, Volume Shadow Copy Service, and Distributed File System - ReFS uses the same system of permissions as NTFS and offers error checking and repair capabilities that NTFS does not, but it does not support NTFS features like file compression, Encrypted File System, and disk quotas. ReFS supports a maximum file size of 16 exabytes and volumes up to 1 yobibyte (280 bytes)</p> <p>Software RAID can be implemented by creating Spanned, Striped, or RAID-5 volumes in <code>diskmgmt.msc</code>. A more modern and preferred technique is to create storage pools in  [Storage Spaces][Storage Spaces].</p>"},{"location":"Misc/Windows/WS2016/#s2d","title":"S2D","text":"<p>Although a cluster can normally be created in the GUI Failover Cluster Manager, in order to use Storage Spaces Direct the system must be prevented from automatically creating storage, which necessitates creation in PowerShell with the <code>NoStorage</code> switch parameter, and then S2D must be enabled using <code>Enable-ClusterStorageSpacesDirect</code>. This command scans all cluster nodes for local, unpartitioned disks, which are added to a single storage pool and classified by media type in order to use the fastest disks for caching.</p> <p>The recommended drive configuration for a node in an S2D cluster is a minimum of six drives, with at least 2 SSDs and at least 4 HDDs, with no RAID or other intelligence that cannot be disabled.</p> <p>Caching is configured automatically, depending on the combination of drives present - NVMe + SSD: NVMe drives are configured as a write-only cache for the SSD drives - NVMe + HDD: NVMe drives are read/write cache - NVME + SSD + HDD: NVME are write-only for the SSD drives and read/write for HDD drives - SSD + HDD: SSD drives are read/write cache</p> <p>Microsoft defined two deployment scenarios for Storage Spaces Direct: - Disaggregated which creates two separate clusters, one of which is a Scale-out File Server dedicated to storage, essentially functioning as a SAN. This solution requires the [DCB][DCB] role for traffic management. At least two 10Gbps Ethernet adapters are recommended per node, preferably adapters that use RDMA. - Hyper-converged, where a single cluster node hosts VMs and storage. This solution is much less expensive because it requires less hardware and generates much less network traffic, but storage and compute can't scale independently: adding a node to storage necessarily entails adding one to the Hyper-V hosts, and vice versa.</p>"},{"location":"Misc/Windows/WS2016/#storage-replica","title":"Storage Replica","text":"<p>Storage Replica supports one-way replication between standalone servers, between clusters, and between storage devices within an [asymmetric (stretch) cluster][asymmetric cluster]. - Synchronous replication is possible when the replicated volumes can mirror data immediately, ensuring no data loss in case of failover - Asynchronous replication is preferable when the replication partner is located over a WAN link</p> <p>Storage Replica improves on DFS Replication, which is exclusively asynchronous and file-based, by using SMBv3 (port 445). Storage Replica requires two virtual disks, one for logs and one for data, which are the same size for each replication partner, and all the physical disks must use the same sector size.</p>"},{"location":"Misc/Windows/WS2016/#wsus","title":"WSUS","text":"<p>Windows Server Update Services (WSUS) can be configured from the command-line with wsusutil.exe.</p> <p>There are 5 basic WSUS architecture configurations</p> <ul> <li>Single WSUS Server downloads updates from Microsoft Update, and all the computers on the network download updates from it. A single server can usupport up to 25,000 clients.</li> <li>Replica WSUS Servers: a central WSUS server downloads from Microsoft Update, and after approval the updates are distributed to downstream servers at remote locations.</li> <li>Autonomous WSUS Servers: a central WSUS server downloads from Microsoft Update, all of which are distributed to remote servers; each remote site's administrators are individually responsible for evaluating and approving updates.</li> <li>Low-bandwidth WSUS Servers at remote sites download only the list of approved updates, which are then retrieved from Microsoft Update over the Internet, minimizing WAN traffic.</li> <li>Disconnected WSUS Servers have updates imported from offline media (DVD-ROMs, portable drives, etc), utilizing no WAN or Internet bandwidth whatsoever.</li> </ul> <p>When a computer first communicates with a WSUS server, it is added to the All Computers and and Unassigned Computers group automatically, which is created by default.</p>"},{"location":"Misc/Windows/WS2016/#windows-server-backup","title":"Windows Server Backup","text":"<p>To back up a VM without any downtime, integration services must be installed and enabled, and all disks must be basic disks formatted with NTFS.</p> <p>Windows Server Backup - System state includes boot files, Active Directory files, <code>SYSVOL</code> (when run on a DC), the registry, and other data. - System reserved is a special partition containing Boot Manager and Boot Configuration data.</p>"},{"location":"Misc/Windows/WS2016/#glossary","title":"\ud83d\udcd8 Glossary","text":""},{"location":"Misc/Windows/WS2016/#adfind","title":"adfind","text":"<p>Query the schema version associated with Active Directory [Desmond][Desmond2009]: 53 <pre><code>adfind -schema -s base objectVersion\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#adprep","title":"adprep","text":"<p>Prepare Active Directory for Windows Server upgrades. Must be run on the Infrastructure Master role owner with the flag <code>/domainprep</code>. [Desmond][Desmond2009]: 29</p>"},{"location":"Misc/Windows/WS2016/#arp","title":"arp","text":"<p> <code>a</code> <code> </code> <code> </code> <code>d</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code>s</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> </p>"},{"location":"Misc/Windows/WS2016/#bcdedit","title":"bcdedit","text":"<p>Change Windows bootloader to Linux, while dual booting <pre><code>::Manjaro\nbcdedit /set {bootmgr} path \\EFI\\manjaro\\grubx64.efi\n\n::Fedora\nbcdedit /set {bootmgr} path \\EFI\\fedora\\shim.efi\n</code></pre> Enable or disable Test Signing Mode ref <pre><code>bcdedit /set testsign on\nbcdedit /set testsign off\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#bootrec","title":"bootrec","text":"<p>Windows Recovery Environment command that repairs a system partition</p> <p>Use when boot sector not found <pre><code>bootrec /fixboot\n</code></pre> Use when BCD file has been corrupted <pre><code>bootrec /rebuildbcd\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#cmdkey","title":"cmdkey","text":"<p><code>add</code> <code>delete</code> <code>generic</code> <code>list</code> <code>pass</code> <code>smartcard</code> <code>user</code></p> <p>Add a user name and password for user <code>Mikedan</code> to access computer <code>Server01</code> with the password <code>Kleo</code> docs.microsoft.com <pre><code>cmdkey /add:server01 /user:mikedan /pass:Kleo\n</code></pre>"},{"location":"Misc/Windows/WS2016/#dism","title":"dism","text":"<p><code>Add-Driver</code> <code>Add-Package</code> <code>Add-ProvisionedAppxPackage</code> <code>Append-Image</code> <code>Apply-Image</code> <code>Apply-Unattend</code> <code>Capture-Image</code> <code>Cleanup-Image</code> <code>Commit-Image</code> <code>Disable-Feature</code> <code>Enable-Feature</code> <code>Export-Driver</code> <code>Export-Image</code> <code>Get-Driverinfo</code> <code>Get-Drivers</code> <code>Get-Featureinfo</code> <code>Get-Features</code> <code>Get-ImageInfo</code> <code>Get-MountedImageInfo</code> <code>Get-Packageinfo</code> <code>Get-Packages</code> <code>Get-ProvisionedAppxPackages</code> <code>List-Image</code> <code>Remount-Image</code> <code>Remove-Driver</code> <code>Remove-Image</code> <code>Remove-Package</code> <code>Remove-ProvisionedAppxPackage</code> <code>Set-ProvisionedAppxDataFile</code> <code>Unmount-Image</code></p> <p>Mount an image Zacker: 71 <pre><code>dism /mount-image /imagefile:$FILENAME /index:$N /name:$IMAGENAME /mountdir:$PATH\n</code></pre> Practice Labs <pre><code>dism /mount-wim /wimfile:c:\\images\\install.wim /index:1 /mountdir:c:\\mount\n</code></pre> Add a driver to an image file that you have already mounted Zacker: 72 <pre><code>dism /image:$FOLDERNAME /add-driver /driver:$DRIVERNAME /recurse\n</code></pre> Commit changes and unmount the image Zacker: 75 <pre><code>dism /unmount-image /mountdir:c:\\mount /commit\n</code></pre> Determine exact name of Windows features that can be enabled and disabled Zacker: 75 <pre><code>dism /image:c:\\mount /get-features\n</code></pre> Scan an image, checking for corruption <pre><code>dism /Online /Cleanup-Image /ScanHealth\n</code></pre> Check an image to see whether any corruption has been detected <pre><code>dism /Online /Cleanup-Image /CheckHealth\n</code></pre> Repair an offline dicsk using a mounted image as a repair source <pre><code>dism /Image:C:\\offline /Cleanup-Image /RestoreHealth /Source:C:\\test\\mount\\windows\n</code></pre> Zacker: 71-75 <pre><code>dism /mount-image /imagefile:C:\\images\\install.wim /index:1 /mountdir:C:\\mount\ndism /add-package /image:C:\\mount /packagepath:C:\\updates\ndism /add-driver /image:C:\\mount /driver:C:\\drivers\\display.driver\\nv_dispi.inf\ndism /commit-image /image:C:\\mount\ndism /unmount-image /image:C:\\mount\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#djoin","title":"djoin","text":"<p>Perform an offline domain join for a Nano Server Zacker: 46 <pre><code>djoin /provision /domain practicelabs /machine PLABNANOSRV01 /savefile .\\odjblob\n</code></pre> Load the <code>odjblob</code> file created offline on the Nano Server. <pre><code>djoin /requestodj /loadfile c:\\odjblob /windowspath c:\\windows /localos\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#dnscmd","title":"dnscmd","text":"<p>Replicate an AD-integrated DNS zone to specific DCs ref <pre><code>dnscmd . /CreateDirectoryPartition FQDN\n</code></pre> Enable GlobalNames zone support <pre><code>dnscmd &lt;servername&gt; /config /enableglobalnamessupport 1\n</code></pre> Observe status of socket pool <pre><code>dnscmd /info /socketpoolsize\n</code></pre> Configure DNS socket pool size (0 through 10,000) <pre><code>dnscmd /Config /SocketPoolSize &lt;value&gt;\n</code></pre>"},{"location":"Misc/Windows/WS2016/#dsquery","title":"dsquery","text":"<p>Find the Active Directory Schema version from the command-line ref pwsh</p> <pre><code>dsquery * cn=schema,cn=configuration,dc=domain,dc=com -scope base -attr objectVersion\"\n</code></pre>"},{"location":"Misc/Windows/WS2016/#jea","title":"JEA","text":"<p>Just Enough Administration (JEA) allows special remote sessions that limit which cmdlets and parameters can be used in a remote PowerShell session. These are implemented as restricted endpoints, to which only members of a specific security group can gain access. This offers a way to administer remote servers and move away from the traditional method using RDP.</p>"},{"location":"Misc/Windows/WS2016/#net","title":"net","text":"<p>Map a network location to a drive letter Practice Lab <pre><code>net use x: \\\\192.168.0.35\\c$\n</code></pre> Stop/start a service <pre><code>net stop dns\nnet start dns\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#netdom","title":"netdom","text":"<p>Rename a computer <pre><code>netdom renamecomputer %computername% /newname: newcomputername\n</code></pre> Join a computer to a domain cf. <code>Add-Computer</code>, Zacker: 21 <pre><code>netdom join %computername% /domain: domainname /userd: username /password:*\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#netsh","title":"netsh","text":"<p>Enable port forwarding (\"<code>portproxy</code>\") to a WSL2 distribution (src) <pre><code>netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=2222 connectaddress=172.23.129.80 connectport=2222\n</code></pre> Configure DNS to be dynamically assigned <pre><code>netsh interface ip set dns \"Wi-Fi\" dhcp\n</code></pre> Delete Wi-Fi profiles <pre><code>netsh wlan delete profile name=*\n</code></pre> Turn off Windows firewall <pre><code>netsh advfirewall set allprofiles state off\n</code></pre> Enable firewall rule group  <pre><code>netsh advfirewall firewall set rule group=\u201dFile and Printer Sharing\u201d new enable=yes\n</code></pre> Show Wi-Fi passwords (src <pre><code>netsh wlan show profile wifi key=clear\n</code></pre> Check/reset WinHTTP proxy  <pre><code>netsh winhttp show proxy\nnetsh winhttp reset proxy\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#ntdsutil","title":"ntdsutil","text":"<p>Used to transfer FSMO roles between domain controllers. [Desmond: 30][Desmond2009]</p>"},{"location":"Misc/Windows/WS2016/#regsvr32","title":"regsvr32","text":"<p>Register a DLL dependency in order to enable the Active Directory Schema MMC snap-in on a DC [Desmond][Desmond2009]: 54 <pre><code>regsvr32 schmmgmt.dll\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#route","title":"route","text":"<p> <code>p</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code>print</code> <code>add</code> <code>change</code> <code>delete</code></p> <p>Basic usage <pre><code>route add 192.168.2.1 mask (255.255.255.0) 192.168.2.4\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#runas","title":"runas","text":"<p><code>env</code> <code>netonly</code> <code>profile</code>/<code>no profile</code> <code>savecred</code> <code>showtrustlevels</code> <code>smartcard</code> <code>trustlevel</code> <code>user:</code></p>"},{"location":"Misc/Windows/WS2016/#settings","title":"Settings","text":"<p><code>appsfeatures</code> <code>personalization</code> <code>printers</code> <code>windowsupdate</code></p> <p>about activation apps-volume appsforwebsites assignedaccess autoplay backup batterysaver bluetooth camera clipboard colors connecteddevices cortana crossdevice datausage dateandtime defaultapps delivery-optimization developers deviceencryption devices-touchpad display easeofaccess-display emailandaccounts findmydevice fonts keyboard lockscreen maps messaging mobile-devices mousetouchpad multitasking network network-wifi nfctransactions nightlight notifications optionalfeatures otherusers pen personalization-background personalization-colors personalization-start personalization-start-places phone powersleep privacy project proximity quiethours quietmomentsgame quietmomentspresentation quietmomentsscheduled recovery regionformatting regionlanguage remotedesktop savelocations screenrotation signinoptions signinoptions-launchfaceenrollment sound speech speech startupapps storagepolicies storagesense surfacehub-accounts surfacehub-calling surfacehub-devicemanagenent surfacehub-sessioncleanup surfacehub-welcome sync tabletmode taskbar themes troubleshoot typing usb videoplayback wheel windowsdefender windowsinsider workplace yourinfo</p>"},{"location":"Misc/Windows/WS2016/#sfc","title":"sfc","text":"<pre><code>sfc /scannow\n</code></pre>"},{"location":"Misc/Windows/WS2016/#shutdown","title":"shutdown","text":"<p>Immediate restart <pre><code>shutdown /r /t 0\n</code></pre> Log off <pre><code>shutdown /L\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#slmgr","title":"slmgr","text":"<p><code>ato</code> <code>dli</code> <code>dlv</code> <code>ipk</code> <code>rearm</code> <code>upk</code> <code>xpr</code></p>"},{"location":"Misc/Windows/WS2016/#sysdm","title":"sysdm","text":"<p><code>2</code> <code>3</code> <code>4</code> <code>5</code></p>"},{"location":"Misc/Windows/WS2016/#tracert","title":"tracert","text":"<p>On Windows, this command is aliased to <code>traceroute</code> which is the Linux command. [Lammle][Lammle]: 112</p>"},{"location":"Misc/Windows/WS2016/#wbadmin","title":"wbadmin","text":"<p><code>enable backup</code> <code>get items</code> <code>get versions</code> <code>start backup</code> <code>start recovery</code> <code>start systemstaterecovery</code></p> <p><code>-backupTarget</code> <code>-hyperv</code> <code>-vsscopy</code>|<code>-vssFull</code></p> <p>Backup the entire drive, excluding some VMs <pre><code>wbadmin enable backup -backupTarget \\\\backups\\hostdr\\temp\\ -include:c: -exclude: C:\\VMs\\VM1.vhdx, C:\\VMs\\VMAR.vhd -vsscopy -quiet\n</code></pre></p> <p>Zacker: 325-326 <pre><code>wbadmin get versions\nwbadmin get items -version: 11/14/2016:05:09\nwbadmin start recovery -itemtype:app items:cluster -version:01/01/2008-00:00\n</code></pre> Zacker: 422 <pre><code>wbadmin start systemstaterecovery -version:11/27/2016-11:07\nwbadmin get versions\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#wdsutil","title":"wdsutil","text":"<p><code>initialize-server</code> <code>remInst</code></p> <pre><code>wdsutil /initialize-server /remInst:\"D:\\RemoteInstall\"\n</code></pre>"},{"location":"Misc/Windows/WS2016/#winrm","title":"winrm","text":"<pre><code># List all WinRM listeners  \nwinrm enumerate winrm/config/listener\n\n# Display WinRM configuration\nwinrm get winrm/config\n\n# Add an address to Trusted Hosts list\nwinrm set winrm/config/client @{TrustedHosts=\"192.168.10.41\"}\n</code></pre>"},{"location":"Misc/Windows/WS2016/#winver","title":"winver","text":""},{"location":"Misc/Windows/WS2016/#wmic","title":"wmic","text":"<p><code>bios</code> <code>logicaldisk</code> <code>memorychip</code> <code>os</code> <code>path</code></p> <p>Recover Windows product key [fossbytes.com][https://fossbytes.com/how-to-find-windows-product-key-lost-cmd-powershell-registry/] <pre><code>wmic path softwarelicensingservice get OA3xOriginalProductKey\n</code></pre> Display information about installed RAM <pre><code>wmic memorychip list full\n</code></pre> List all objects of type <code>Win32_LogicalDisk</code> using that class's alias <code>logicaldisk</code>. [Desmond][Desmond2009]: 642 pwsh <pre><code>wmic logicaldisk list brief\n</code></pre> Recover serial number of a Lenovo laptop [pcsupport.lenovo.com][https://pcsupport.lenovo.com/us/en/solutions/find-product-name] <pre><code>wmic bios get serialnumber\n</code></pre> Display BIOS version <pre><code>wmic bios get biosversion\n</code></pre> Display operating system architecture <pre><code>wmic os get osarchitecture\n</code></pre> Display operating system type (48 is Windows 10) <pre><code>wmic os get operatingsystemsku\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#wslmsdocswslexe","title":"[wsl][msdocs:wsl.exe]","text":"<p> <code>l</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code>s</code> <code>t</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code>\\ <code>export</code> <code>import</code> <code>set-default-version</code></p>"},{"location":"Misc/Windows/WS2016/#wsusutilmsdocswsusutilexe","title":"[wsusutil]][msdocs:wsusutil.exe]","text":"<p>Specify a location for downloaded updatesZacker: 393 <pre><code>C:\\Program Files\\Update Services\\Tools\\wsusutil.exe postinstall content_dir=d:\\wsus\n</code></pre> Specify SQL server, when not using the default WID database <pre><code>C:\\Program Files\\Update Services\\Tools\\wsusutil.exe postinstall sql_instance_name=\"db1\\sqlinstance1\"- content_dir=d:\\wsus\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#wt","title":"wt","text":"<p> <code>d</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code>p</code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code> </code> <code>split-pane</code> <code>focus-tab</code></p> <p>Open the default Windows Terminal profile and also an Ubuntu WSL tab [bleepingcomputer.com][https://www.bleepingcomputer.com/news/microsoft/windows-terminal-09-released-with-command-line-arguments-and-more/] <pre><code>wt; new-tab -p \"Ubuntu-18.04\"\n</code></pre> Open a split pane of the default profile in the D:\\ folder and the <code>cmd</code> profile in the E:\\ folder [bleepingcomputer.com][https://www.bleepingcomputer.com/news/microsoft/windows-terminal-09-released-with-command-line-arguments-and-more/] <pre><code>wt -d d:\\ ; split-pane -p \"cmd\" -d e:\n</code></pre> Open the default profile and an Ubuntu WSL profile, but with the first tab focused [bleepingcomputer.com][https://www.bleepingcomputer.com/news/microsoft/windows-terminal-09-released-with-command-line-arguments-and-more/] <pre><code>wt ; new-tab -p \"Ubuntu-18.04\"; focus-tab -t0\n</code></pre></p>"},{"location":"Misc/Windows/WS2016/#xcopy","title":"xcopy","text":"<p>Copy from one directory to another Practice Lab <pre><code>xcopy /s c:\\inetpub\\wwwroot c:\\nlbport\n</code></pre></p>"},{"location":"Misc/Windows/diskpart/","title":"Diskpart","text":""},{"location":"Misc/Windows/diskpart/#diskpart","title":"diskpart","text":"<p>Moffitt disk formatting script <pre><code>SELECT DISK 0\nCLEAN\nCONVERT gpt\nCREATE PARTITION primary SIZE=1024\nFORMAT QUICK FS=NTFS LABEL=\"Recovery\"\nSET ID=\"de94bba4-06d1-4d40-a16a-bfd50179d6ac\"\nCREATE PARTITION efi SIZE=750\nASSIGN LETTER=K\nFORMAT QUICK FS=FAT32 LABEL=\"System\"\nCREATE PARTITION MSR SIZE=128\nCREATE PARTITION PRIMARY\nASSIGN LETTER=C\nFORMAT QUICK FS=NTFS\nEXIT\n</code></pre></p>"},{"location":"Python/","title":"\ud83d\udc0d Python","text":""},{"location":"Python/#decorators","title":"Decorators","text":"<p>A decorator is any function that accepts a function and returns a function. Decorators are one of the main ways that Python implements functional programming principles.</p> <p>Functions are first-class objects and can be passed as parameters. <pre><code>import logging\n\ndef hello_wrapper(name, func):\n    func(f'Hello {name}')\n\nhello_wrapper(\"world\", func=print) # Hello world\nhello_wrapper(\"logs\", func=logging.warning) # WARNING:root:Hello logs\n</code></pre></p> <pre><code>with open('hello.txt', 'w') as f:\n    hello_wrapper('everyone!', func=f.write)\n</code></pre> <p><pre><code>import random\n\ndef anagram(t):\n    l = [c for c in t]\n    random.shuffle(l)\n    print(\"\".join(l))\n\nhello_wrapper('Japushku', anagram) #  eHoulhluaskpJ\n</code></pre> The function has to be passed as a reference, actually calling it will cause the wrapper function to attempt to execute the value returned by the inner function. <pre><code>hello_wrapper(\"world\", func=print()) # Error\n</code></pre> <pre><code>def outer():\n  print('Hi from the outer function')\n  def inner():\n    print('Hello from the inner function')\n  inner()\n</code></pre></p> <p>We can use the <code>__name__</code> attribute to access a passed function's name. <pre><code>def hello(func):\n  print(f'Hello {func.__name__}')\n\nhello(outer) # Hello outer\n</code></pre> We can also return functions, which can then be invoked <pre><code>def hello(func):\n  print(f'Hello {func.__name__}')\n  return func\n\nhello(outer)()  \n'''\nHi from the outer function\nHello from the inner function\n'''\n\nnew_outer = hello(outer)\nnew_outer is outer # True\n</code></pre></p> <p><pre><code>def wrapper(func):\n  print(f'Before {func.__name__}')\n  func()\n  print(f'After {func.__name__}')\n\nwrapper(outer)\n'''\nBefore outer\nHi from the outer function\nHello from the inner function\nAfter outer\n'''\n</code></pre> The true decorator pattern appears here, where <code>wrapper</code> is called the decorator and <code>outer</code> has been decorated. <pre><code>def wrapper(func):\n  def _wrapper():\n    print(f'Before {func.__name__}')\n    func()\n    print(f'After {func.__name__}')\n  return _wrapper\n\nouter = wrapper(outer)\n</code></pre> But the usual syntax since Python 2.4 is to place the decorator on the line above the decorated function, preceded by <code>@</code>: <pre><code>@wrapper\ndef outer():\n  print('Hi from the outer function')\n  def inner():\n    print('Hello from the inner function')\n  inner()\n</code></pre> <code>_wrapper</code> here does not accept any positional arguments, so wrapping functions that take arguments will produce a <code>TypeError</code> <pre><code>@wrapper\ndef say_hello(name):\n  print(f'Hello {name}!') # error\n</code></pre> The solution is to incorporate <code>*args, **kwargs</code> into the definition of the inner function, as well as the invocation of the function passed in. <pre><code>def wrapper(func):\n  def _wrapper(*args, **kwargs):\n    print(f'Before {func.__name__}')\n    func(*args, **kwargs)\n    print(f'After {func.__name__}')\n  return _wrapper\n</code></pre> Returned values are not captured yet: <pre><code>def wrapper(func):\n  def _wrapper(*args, **kwargs):\n    print(f'Before {func.__name__}')\n    value = func(*args, **kwargs)\n    print(f'After {func.__name__}')\n    return value\n  return _wrapper\n</code></pre> Inspecting the decorated function's <code>__name__</code> attribute reveals that it is still named <code>_wrapper</code> <pre><code>say_hello.__name__ # '_wrapper'\n</code></pre> This is also true for other attributes, including docstring. <code>functools.wraps</code> is a decorator factory to reassign attributes to the wrapped function. This is considered superior to the <code>functools.update_wrapper</code> function which is also available. <pre><code>def wrapper(func):\n  @functools.wraps(func)\n  def _wrapper(*args, **kwargs):\n    print(f'Before {func.__name__}')\n    value = func(*args, **kwargs)\n    print(f'After {func.__name__}')\n    return value\n  return _wrapper\n</code></pre> This forms an ideal starting template for the creation of custom decorators.</p>"},{"location":"Python/#classes","title":"Classes","text":""},{"location":"Python/#properties","title":"Properties","text":"<p>In the Python documentation, attributes accessed with accessor functions are called managed attributes, which makes the term equivalent to properties in C#.</p> <p>Three methods can be defined using the <code>@property</code> decorator</p> ConstructorGetterSetterDeleter <pre><code>def __init__(self, price):\n    self._price = price\n</code></pre> <pre><code>@property\ndef price(self):\n  return self._price\n</code></pre> <pre><code>@price.setter\ndef price(self, new_price):\n    if new_price &gt; 0:\n        self._price = new_price\n    else:\n        raise ValueError\n</code></pre> <pre><code>@price.deleter\ndef price(self):\n    del self._price\n</code></pre>"},{"location":"Python/#class-methods","title":"Class methods","text":"<p>The <code>@classmethod</code> decorator prevents the interpreter from passing in the instantiated object using <code>self</code>, rather the class itself is passed in as the <code>cls</code> argument. This means that the methods decorated as such must take not <code>self</code> as the first argument but <code>cls</code></p> <pre><code>@classmethod\ndef classmethod(cls):\n  pass\n</code></pre> <p>The <code>@staticmethod</code> decorator prevents the interpreter from passing any additional arguments whatsoever. The resulting method has no access to the object itself nor the class and functions like a procedurally defined function.</p>"},{"location":"Python/#formatting","title":"Formatting","text":"<p>flake8, black, and yapf are CLI tools used to automatically format Python code.</p>"},{"location":"Python/#virtual-environments","title":"Virtual environments","text":""},{"location":"Python/#pipenv","title":"pipenv","text":"<pre><code>pipenv --python 3.6\n</code></pre>"},{"location":"Python/#venv","title":"venv","text":"<p>Create a virtual environment named project <pre><code>python -m venv project\n</code></pre></p>"},{"location":"Python/#virtualenv","title":"virtualenv","text":"<p>Create a virtual environment named <code>project</code> using a different version of Python <pre><code>virtualenv -p /usr/bin/python2 project\n</code></pre></p>"},{"location":"Python/#testing","title":"Testing","text":"<p>Pytest is a popular testing framework preferred to unittest by many Python developers because it follows Pythonic conventions more closely. In contrast to unittest's custom methods, pytest relies on the builtin <code>assert</code> statement.</p> pytestunittestClass under test <p><pre><code>from phonebook import PhoneBook\nimport pytest\n\n@pytest.fixture\ndef phonebook():\n    phonebook = PhoneBook()\n    yield phonebook\n    phonebook.clear()\n\ndef test_lookup_by_name(phonebook):\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre> <pre><code>python -m pytest\n</code></pre></p> <p><pre><code>import unittest\n\nfrom phonebook import PhoneBook\n\n\nclass PhoneBookTest(unittest.TestCase):\n\n    def test_lookup_by_name(self):\n        self.phonebook.add(\"Bob\", \"12345\")\n        number = self.phonebook.lookup(\"Bob\")\n        self.assertEqual(\"12345\", number)\n\n    def test_missing_name(self):\n        with self.assertRaises(KeyError):\n            self.phonebook.lookup(\"missing\")\n\n    def test_empty_phonebook_is_consistent(self):\n        self.assertTrue(self.phonebook.is_consistent())\n\n    def setUp(self) -&gt; None:\n        self.phonebook = PhoneBook()\n\n    def tearDown(self) -&gt; None:\n        self.phonebook.clear()\n</code></pre> <pre><code>python -m unittest\n</code></pre></p> <pre><code>import os\n\nclass PhoneBook:\n    def __init__(self, cache_directory = os.getcwd()):\n        self.numbers = {}\n        self.filename = os.path.join(cache_directory, \"phonebook.txt\")\n        self.cache = open(self.filename, \"w\")\n\n    def add(self, name, number):\n        self.numbers[name] = number\n\n    def lookup(self, name):\n        return self.numbers[name]\n\n    def is_consistent(self):\n        return True\n\n    def names(self):\n        return set(self.numbers.keys())\n\n    def clear(self):\n        self.cache.close()\n        os.remove(self.filename )\n</code></pre>"},{"location":"Python/#doctest","title":"Doctest","text":"<p>A doctest is a docstring containing what looks like interactive Python sessions. Python Docs <pre><code>\"\"\"\nReturn the factorial of n, an exact integer &gt;= 0.\n\n&gt;&gt;&gt; [factorial(n) for n in range(6)]\n[1, 1, 2, 6, 24, 120]\n&gt;&gt;&gt; factorial(30)\n265252859812191058636308480000000\n&gt;&gt;&gt; factorial(-1)\nTraceback (most recent call last):\n    ...\nValueError: n must be &gt;= 0\n\nFactorials of floats are OK, but the float must be an exact integer:\n&gt;&gt;&gt; factorial(30.1)\nTraceback (most recent call last):\n    ...\nValueError: n must be exact integer\n&gt;&gt;&gt; factorial(30.0)\n265252859812191058636308480000000\n\nIt must also not be ridiculously large:\n&gt;&gt;&gt; factorial(1e100)\nTraceback (most recent call last):\n    ...\nOverflowError: n too large\n\"\"\"\n</code></pre> This can then be run  <pre><code>if __name__ == '__main__':\n  import doctest\n  doctest.testmod()\n</code></pre></p>"},{"location":"Python/#pytest","title":"pytest","text":"<p>PyTest relies on the built-in <code>assert</code> statement.</p>"},{"location":"Python/#fixtures","title":"Fixtures","text":"<p>The <code>@pytest.fixture</code> decorator facilitiates the creation of test fixtures. The fixture function's name is used as argument to the test case, and the value returned can be used by the logic within.  (src)</p> <p>Any clean-up logic can be invoked in this fixture as well by replacing <code>return</code> with <code>yield</code>. Pytest also provides its own <code>tmpdir</code> test fixture for temporary directories. (src)</p> BeforeAftertmpdir <pre><code>from phonebook import PhoneBook\nimport pytest\n\n\n\n\n\n\n\ndef test_lookup_by_name(phonebook):\n    phonebook=PhoneBook()\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    phonebook = PhoneBook()\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre> <pre><code>from phonebook import PhoneBook\nimport pytest\n\n@pytest.fixture\ndef phonebook():\n    phonebook = PhoneBook()\n    yield phonebook\n    phonebook.clear()\n\ndef test_lookup_by_name(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    # phonebook = PhoneBook()\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre> <pre><code>from phonebook import PhoneBook\nimport pytest\n\n@pytest.fixture\ndef phonebook(tmpdir):\n    phonebook = PhoneBook(tmpdir)\n    return phonebook\n\n\ndef test_lookup_by_name(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\",\"1234\")\n    assert \"1234\" == phonebook.lookup(\"Bob\")\n\ndef test_phonebook_contains_all_names(phonebook):\n    # phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"1234\")\n    assert \"Bob\" in phonebook.names()\n\ndef test_missing_name_raises_error(phonebook):\n    # phonebook = PhoneBook()\n    with pytest.raises(KeyError):\n        phonebook.lookup(\"Bob\")\n</code></pre>"},{"location":"Python/#unittest","title":"unittest","text":"<p>unittest is a testing framework built into Python's Standard Library that was based on JUnit.  unittest came out in 2001, when JUnit was being ported and adapted to many languages. Collectively, these frameworks were referred to as the xUnit family. unittest's method names do not follow Python conventions because it predates the PEP-8 naming standard.</p> <p>unittest allows you to create test classes that inherit from <code>TestCase</code>.</p>"},{"location":"Python/#assertions","title":"Assertions","text":"<p>Assertions are implemented in individual methods of the TestCase subclass through unittest methods like <code>assertEqual</code> and <code>assertRaises</code>, etc. Notably, TestCase subclasses must not have an <code>__init__()</code> constructor method defined.</p> <pre><code>def test_lookup_by_name(self):\n    phonebook = PhoneBook()\n    phonebook.add(\"Bob\", \"12345\")\n    number = phonebook.lookup(\"Bob\")\n    self.assertEqual(\"12345\", number)\n</code></pre> <p><code>assertRaises</code> must be placed in a context manager. Here, the test case will run the code within the <code>with</code> block and check to make sure it raises the specified exception: <code>KeyError</code>: (src)</p> <pre><code>def test_missing_name(self):\n    fleet = Fleet()\n    with self.assertRaises(KeyError):\n        fleet.lookup(\"bla\")\n</code></pre>"},{"location":"Python/#fixtures_1","title":"Fixtures","text":"<p><code>setUp</code> is run before every test method, allowing a test fixture to be created to avoid repetitive code. <code>tearDown</code> is called after every method, which allows these resources to be released, even if the test case raises an exception. However, if it is <code>setUp</code> that raises the exception, then neither the test case nor <code>tearDown</code> will run. (src, src)</p> BeforeAfter <pre><code>import unittest\n\nfrom phonebook import PhoneBook\n\n\nclass PhoneBookTest(unittest.TestCase):\n\n\n\n\n\n\n    def test_lookup_by_name(self):\n        phonebook = PhoneBook()\n        phonebook.add(\"Bob\", \"12345\")\n        number = phonebook.lookup(\"Bob\")\n        self.assertEqual(\"12345\", number)\n\n    def test_missing_name(self):\n        phonebook = PhoneBook()\n        with self.assertRaises(KeyError):\n            phonebook.lookup(\"missing\")\n\n    @unittest.skip(\"WIP\")\n    def test_empty_phonebook_is_consistent(self):\n        phonebook = PhoneBook()\n        self.assertTrue(phonebook.is_consistent())\n</code></pre> <pre><code>import unittest\n\nfrom phonebook import PhoneBook\n\n\nclass PhoneBookTest(unittest.TestCase):\n    def setUp(self) -&gt; None:\n        self.phonebook = PhoneBook()\n\n    def tearDown(self) -&gt; None:\n        self.phonebook.clear()\n\n    def test_lookup_by_name(self):\n        # phonebook = PhoneBook()\n        self.phonebook.add(\"Bob\", \"12345\")\n        number = self.phonebook.lookup(\"Bob\")\n        self.assertEqual(\"12345\", number)\n\n    def test_missing_name(self):\n        # phonebook = PhoneBook()\n        with self.assertRaises(KeyError):\n            self.phonebook.lookup(\"missing\")\n\n    @unittest.skip(\"WIP\")\n    def test_empty_phonebook_is_consistent(self):\n        # phonebook = PhoneBook()\n        self.assertTrue(self.phonebook.is_consistent())\n</code></pre> <p>The <code>@unittest.skip</code> decorator will tell the test runner to skip the decorated test case (src)</p> <pre><code>@unittest.skip(\"WIP\")\ndef test_empty_phonebook_is_consistent(self):\n    phonebook = PhoneBook()\n    self.assertTrue(phonebook.is_consistent())\n</code></pre> <p>The command line entry point is made with a call to <code>unittest.main()</code>, which executes the tests. (src)</p> <pre><code>import unittest\n\nfrom my_sum import sum\n\nclass TestSum(unittest.TestCase):\n  def test_list_int(self):\n\"\"\"\n    Test that it can sum a list of integers\n    \"\"\"\n    data = [1, 2, 3]\n    result = sum(data)\n    self.assertEqual(result, 6)\n\nif __name__ == '__main__':\n  unittest.main()\n</code></pre>"},{"location":"Python/#integration-tests","title":"Integration tests","text":"<p>By convention, tests are put in their own directory as sibling to the main module ( in order to be able to import it ). Integration and unit tests should be organized separately.</p> <pre><code>.\n\u251c\u2500\u2500 project\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 integration\n    \u2514\u2500\u2500 unit\n</code></pre> <p>Run all integration tests within specified directory. <pre><code>python -m unittest discover -s tests/integration\n</code></pre></p>"},{"location":"Python/#tasks","title":"Tasks","text":"<p>Deserialize</p> YAML JSON <pre><code>import yaml\n\n\nwith open('./starships.yaml') as f:\nstarships = yaml.safe_load(f)\n</code></pre> <pre><code>import json\n\n\nwith open('./starships.json') as f:\n    data=json.load(f)\n</code></pre> <p>Serialize</p> YAML JSON <pre><code>import yaml\n\n\nwith open('./starships.yaml','w') as f:\n    yaml.dump(starships, f)\n</code></pre> <pre><code>import json\n\n\nwith open('/starships.json',\"w\") as f:\n    json.dump(data,f)\n</code></pre>"},{"location":"Python/#modules","title":"Modules","text":"<p>When learning unfamiliar packages and importing them in a demonstration script, care must be taken that the  demonstration script does not have the same name as the package being studied.  If so, attempting to import the package while in an interpreter within that directory will cause the interpreter to try  importing the incomplete script and not the package.</p> <p>When running a Python interpreter within this directory, the files \"calc\" and \"main\" can be imported as modules by specifying their names with no file extension. <pre><code>. \n\u251c\u2500\u2500 calc.py \n\u2514\u2500\u2500 main.py\n</code></pre> <pre><code>import calc # No errors\nimport main # No errors\n</code></pre> Specifying the full filename including extension does produce an error <pre><code>import calc.py # Error\nimport main.py # Error\n</code></pre></p>"},{"location":"Python/#glossary","title":"Glossary","text":"Method resolution order Method resolution order (MRO) is the order of base classes that are searched when using super().  It is accessed with <code>__mro__</code>, which returns a tuple of base classes in order of precedence, ending in <code>object</code> which is the root class of all classes. Non-interactive debugging Non-interactive debugging is the most basic form of debugging, dependent on <code>print</code> or <code>log</code> statements placed within the body of code. Type slot A type slot is any of a number of fields within each magic method, including <code>__new__()</code>, <code>__init__()</code>, and <code>__prepare__()</code> (which returns a dictionary-like object that's used as the local namespace for all code from the class body)"},{"location":"Python/Modules/Argparse/","title":"Argparse","text":"<p>The ArgumentParser object exposes an attribute that contains the value passed in from the command-line. This attribute takes its identifier from the dest keyword argument when invoking the add_argument() method.</p> <pre><code>import argparse\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        dest='bar',\n        description=helptext, # (1)\n    )\n    return parser.parse_args()\n\ndef main():\n    args = get_args().bar\n</code></pre> <ol> <li>The optional value assigned to <code>description</code> will be displayed when running the script with the options -h or --help</li> </ol> <p>A help string can be provided as a keyword argument to <code>help</code>. <pre><code>parser.add_argument(\"foo\", help=\"bar\")\n</code></pre></p> <p>A data type can be specified as an argument to <code>type</code>: <pre><code>parser.add_argument(\"foo\", type=int)\n</code></pre> An alternative name for the <code>dest</code> value on the command-line (but which does not affect the identifier of the attribute on which the value is exposed) can be specified by <code>metavar</code>. <pre><code>parser.add_argument(\"foo\", metavar=\"bar\")\n</code></pre></p> <p>The examples above used positional parameters (i.e. an argument). A named parameter (an option or flag, i.e. <code>-h</code>, <code>--help</code>, etc) requires - at the beginning of the string and values from the command-line to be passed after <code>=</code> or Space. <code>add_argument</code> supports the <code>required</code> keyword argument for named parameters. Note that use of the option on the command-line at all requires an argument to it, even if the option is not required itself. <pre><code>parser.add_argument('-r','--radius',type=int,required=True,help='radius')\n</code></pre></p> <p>A flag option can be created by defining an <code>action</code> keyword parameter. (src) <pre><code>parser.add_argument('-o', '--on', help='A boolean flag', action='store_true')\n</code></pre></p> <p><code>add_mutually_exclusive_group()</code> can be used to add a group of mutually exclusive arguments. In this case, <code>add_argument()</code> is invoked on the new object returned by this method and not directly on the <code>ArgumentParser()</code> object. <pre><code>g=ArgumentParser.add_mutually_exclusive_group()\ng.add_argument(\"-v\",\"--verbose\", action=\"store_true\")\ng.add_argument(\"-q\",\"--quiet\",\"-s\",\"--silent\", action=\"store_true\",help='quiet/silent mode')\n</code></pre></p> <p>User input can be restricted by providing a value for <code>choices</code>, which will accept any iterable value including lists, ranges, and strings: <pre><code>parser.add_argument(\"foo\", choices=[\"bar\",\"baz\"])\nparser.add_argument(\"foo\", choices=range(1,10))\nparser.add_argument(\"foo\", choices='Hello, world!') # equivalent to ['H','e', ...]\n</code></pre></p> <p>Sources</p> <ul> <li> Python documentation</li> </ul>"},{"location":"Python/Modules/Asyncio/","title":"Asyncio","text":"<p>The asyncio module offers an implementation of coroutines which allow tasks to control context switching to implement concurrency.</p> <p>The await keyword is a checkpoint that indicates where it is safe for the process to go to another coroutine, allowing total control over context switching.</p> <pre><code>import asyncio\nimport time\n\ncounter = 0\n\nasync def func1():\n    global counter\n\n    while True:\n        counter += 1\n        counter -= 1\n        await asyncio.sleep(0)\n\nasync def func2():\n    global counter\n\n    while True:\n        counter += 1\n        counter -= 1\n        await asyncio.sleep(0)\n\nasyncio.gather(func1(), func2())\nasyncio.get_event_loop().run_forever()\n</code></pre> <pre><code>async def get_users():\n    users = await client.do_query('select * from users')\n    return users\n\nasync def main():\n    task = asyncio.create_task(get_users())\n    # ...\n    await task\n\nasyncio.run(main())\n</code></pre> <p>Allows the joining of multiple threads. <pre><code>async def get_users():\n    users = await client.do_query('select * from users')\n    return users\n\nasync def main():\n    await asyncio.gather(\n        get_users(),\n        get_users(),\n    )\n\nasyncio.run(main())\n</code></pre> <pre><code>async def get_users():\n    users = await client.do_query('select * from users')\n    return users\n\nasyncio.run(get_users())\n</code></pre></p> <pre><code>async def main():\n    users = await get_users()\n    print(users)\n\nasyncio.run(main())\n</code></pre> <p>Sources:</p> <ul> <li>Demistifying Python's Async and Await keywords</li> </ul>"},{"location":"Python/Modules/Azure.cosmos/","title":"Azure.cosmos","text":"<pre><code>import azure.cosmos\nfrom azure.cosmos.partition_key import PartitionKey\n\ndatabase = cosmos_client.create_database('RetailDemo')\ncontainer = database.create_container(id='WebsiteData', partition_key=PartitionKey(path='/CartID'))\nprint('Container WebsiteData created')\n</code></pre>"},{"location":"Python/Modules/Bullet/","title":"Bullet","text":"<p><code>bullet.Check()</code> implements a checkbox widget: <pre><code>cli = bullet.Check(prompt = \"Choose from the following items: \", choices=['pepperoni','sausage','green peppers'])\n</code></pre> <code>bullet.Bullet()</code> implements a radio button widget: <pre><code>cli = bullet.Bullet(prompt = \"Choose from the following items: \", choices=['red','white','blue'])\n</code></pre> The resulting object then exposes a <code>launch()</code> method. <pre><code>cli.launch()\n</code></pre></p>"},{"location":"Python/Modules/Click/","title":"Click","text":"<p>Click modifies functions using decorators whch determine the command-line arguments elements that the decorated function can see.</p> <p>Hello, World <pre><code>import click\n\n@click.command()\ndef hello():\n  click.echo('Hello World!')\n\nif __name__ = '__main__':\n  hello()\n</code></pre> Modified Hello World <pre><code>import click\n\n@click.command()\n@click.option('--count', default=1, help='number of greetings')\n@click.argument('name')\ndef hello(count, name):\n  for x in range(count):\n    click.echo('Hello %s!' % name)\n\nif __name__ == '__main__':\n  hello()\n</code></pre></p> <p>Developing the pdfcropper tool; passing --examref changes the numbers. <pre><code>import click\n\n@click.command()\n@click.option('--examref',is_flag=True)\ndef hello(examref):\n  top, right, bottom, left = 0,0,0,0\n  if examref:\n    top, right, bottom, left = 1, 2, 3, 4\n  click.echo(f'Your numbers are: top ({top}), right {right}, bottom {bottom}, left {left}')\n\nif __name__ == '__main__':\n  hello()\n</code></pre> @click.group() decorators allow nested command groups to be created. There are two ways of adding commands to command groups: - Using the group as a decorator, whereby the name of the function decorated by <code>@click.group()</code> is then used to  decorate commands: <pre><code>@click.group()\ndef group1()\n  pass\n\n@group1.command()\ndef command1():\n  pass\n</code></pre></p> <ul> <li>Using the <code>add_command</code> method <pre><code>@click.group()\ndef group1()\n  pass\n\n@click.command()\ndef command1():\n  pass\n\ngroup1.add_command(command1)\n</code></pre></li> </ul> <p>For example, to imitate the nested commands available in <code>netsh</code>: <pre><code>netsh interface ip\n</code></pre></p> <pre><code>@click.group()\ndef interface():\n  pass\n\n@interface.command('ip')\n@click.argument('args', nargs=-1) # All arguments passed in as tuple \"args\"\ndef interface_ip(args):\n  pass\n</code></pre> <p>Docstrings of groups and commands show up as progressive help messages when they are invoked from the command-line.</p> <p><pre><code>@click.group()\ndef cli():\n  pass\n\n@click.command()\ndef initdb():\n  click.echo('Initialized the database')\n\n@click.command()\ndef dropdb():\n  click.echo('Dropped the database')\n\ncli.add_command(initdb)\ncli.add_command(dropdb)\n\nif __name__ == '__main__':\n  cli()\n</code></pre> CommandCollection flattens the structure of grouped commands so that the commands in all the contained groups appear in a single tier. It also becomes the entry-point of the script.</p> <p>Example from GitHub: <pre><code># Three command groups cli1, cli2, and cli3 declared:\n\n@click.group()\ndef cli1():\n  pass\n\n@click.group()\ndef cli2():\n  pass\n\n@click.group()\ndef cli3():\n  pass\n\n# Three commands each belonging to a separate group\n\n@cli1.command()\ndef server():\n  pass\n\n@cli2.command()\ndef console():\n  pass\n\n@cli3.command()\ndef routes():\n  pass\n\n# CommandCollection flattens the grouped commands such that all the commands are available at once:\n\ncli = click.CommandCollection(sources=[cli1,cli2,cli3])\n\nif __name__ == '__main__':\n  cli()\n</code></pre></p>"},{"location":"Python/Modules/Collections/","title":"Collections","text":"<pre><code>from collections import namedtuple\n\nCard = namedtuple('Card',['rank','suit'])`\nCity = namedtuple('City', 'Name Country Population Coordinates'.split(' ')]\n</code></pre>"},{"location":"Python/Modules/Colorama/","title":"Colorama","text":"<p>Colorama provides a set of enums that resolve to terminal codes when concatenated with strings. <pre><code>colorama.Fore.GREEN\n</code></pre> <pre><code>colorama.Style.RESET_ALL\n</code></pre></p>"},{"location":"Python/Modules/Csv/","title":"Csv","text":"<p><pre><code>with open('file.csv', newline=''):\n    data = [row for row in csv.reader(f)]\n</code></pre> csv.DictReader <pre><code>with open('greeks.csv') as f:\n    reader = csv.DictReader(f)\n    for row in reader:\n        print(row['name'],row['city'],row['dob'])\n</code></pre></p>"},{"location":"Python/Modules/Datetime/","title":"Datetime","text":"<pre><code>datetime.date(2016,7,24)\ndatetime.date.today()\n</code></pre> <p>Difference between <code>datetime</code> objects is a <code>timedelta</code> Parse strings into datetime objects <pre><code>datetime.strptime(datestring,formatstring)\n</code></pre> <pre><code># Various metacharacters are defined for `strptime`\ndatetime.datetime.strptime('06/30/1992','%m/%d/%Y')\n</code></pre></p>"},{"location":"Python/Modules/Discord_py/","title":"discord.py","text":"<p><pre><code>pip install discord.py\nclient = discord.Client()\n</code></pre> <code>Client</code> objects expose a decorator that is used for event handlers, functions named after various events: - <code>on_ready</code> - <code>on_member_join</code> - <code>on_error</code> - <code>on_message</code> <pre><code>@client.event\nasync def on_ready():\n  print(f'{client.user} has connected to Discord!')\n</code></pre> Another decorator is exposed for in-chat commands (<code>commands.Bot</code> has to be instantiated first.) <pre><code>@bot.command(name='roll_dice', help='Simulates rolling dice.')\nasync def roll(ctx, number_of_dice: int, number_of_sides: int):\n  dice = [\n    str(random.choice(range(1, number_of_sides + 1)))\n    for _ in range(number_of_dice)\n  ]\n  await ctx.send(', '.join(dice))\n</code></pre> <pre><code>client.run(token)\n</code></pre></p> <pre><code>bot = comands.Bot(command_prefix='!')\n</code></pre>"},{"location":"Python/Modules/Django/","title":"Django","text":"<p>A typical Django project contains multiple apps, which are Python packages containing their own models, views, templates, and urls.</p> <ul> <li>A model is the single definitive source of information about your data, and contains the essential fields and behaviors of the data you're storing. </li> <li> <p>Migrations are necessary when Model classes are updated. And for projects sufficiently advanced, migration scripts must be developed for any such changes.</p> </li> <li> <p>Async Server Gateway Interface (ASGI) is the spiritual successor to, and superset of, WSGI. It implements the new Python standard for asynchronous web servers and applications, which resembles that of websockets.  From WSGI to ASGI</p> </li> <li>WSGI is coupled tightly with the synchronous request-response model familiar from HTTP 1.1.</li> </ul> <p>URL patterns (stored in the <code>urlpatterns</code> list defined in the project-level urls.py file) can be parameterized. Here, the template <code>&lt;int:x&gt;</code> specifies an integer to be assigned to the view parameter <code>x</code>. <pre><code>from app.views import my_view\n\nurlpatterns = [\n  path('/example/&lt;int:x&gt;', my_view)\n]\n</code></pre> <code>modelform_factory</code> can be used to automatically produce a webform from a Model class. <pre><code># views.py\n\nMeetingForm = modelform_factory(Meeting, exclude=[])\n</code></pre> This can be placed into a template using the <code>{{ form }}</code> template tag. Note, a <code>{% csrf_token %}</code> template tag must also be present for a submit button to work. <pre><code>{% block content %}\n&lt;h1&gt;Plan a new meeting&lt;/h1&gt;\n&lt;form method=\"POST\"&gt;\n  &lt;table&gt;\n    {{form}}\n  &lt;/table&gt;\n  {% csrf_token %}\n  &lt;button type=\"submit\"&gt;Create&lt;/button&gt;\n&lt;/form&gt;\n{% endblock content %}\n</code></pre> When the <code>modelform_factory</code> class has been defined, it is instantiated within the view function. This object exposes several methods: - is_valid data validation is strongly recommended for any form input - save imports the validated form data into the database <pre><code>def new(request):\n  if request.method == 'POST':\n    form = MeetingForm(request.POST)\n    if form.is_valid():\n      form.save()\n      return redirect(\"home\")\n  else:\n    form = MeetingForm()\n\n  return render(request, \"meetings/new.html\", {\"form\": form})\n</code></pre></p>"},{"location":"Python/Modules/Django/#template","title":"Template","text":"<p>Django templates are HTML files with additional markup to signify places where data can be dynamically inserted. The data used by the views file is called the template context.</p> <p>Templates must be placed within the /templates folder within the app, and it is considered best practice to place templates within a nested subdirectory within it, e.g. /templates/app.</p> <p>Django template tags are specified beween <code>{% .. %}</code> and allow for interpolation of data.</p> <pre><code>&lt;ul&gt;\n  {% for m in meetings %}\n\n  {% endfor %}\n&lt;/ul&gt;\n</code></pre> <p>URLs can be built by using the <code>url</code> template tag, specifying the name of a URL <pre><code>urlpatterns = [\n  path('', home, name='home')\n]\n</code></pre> <pre><code>&lt;a href=\"{% url 'home' %}\"&gt;Home&lt;/a&gt;\n</code></pre></p>"},{"location":"Python/Modules/Django/#models","title":"Models","text":"<p>In Django, a Model class is mapped to a database table. Each object is a record in that table.</p> <p>Model objects expose several attributes and methods</p> <p>Get all objects <pre><code>meetings = Meeting.objects.all()\n</code></pre> Get count of objects in database <pre><code>count = Meeting.objects.count()\n</code></pre> Query for a specific object <pre><code>meeting = Meeting.objects.get(pk=id)\n</code></pre> <code>get_object_or_404</code> may be better for most cases <pre><code>meeting = get_object_or_404(Meeting, pk=id)\n</code></pre></p> <p>Adding a new app <pre><code>python manage.py startapp app\n</code></pre> Then add to settings.py in project directory <pre><code>INSTALLED_APPS = [\n  # ...\n  'app',\n]\n</code></pre></p> <p>There appears to be much flexibility in the arrangement of input controls in a form.</p> <p>So long as the Submit button is child to the <code>form</code> element, tasks are accepted in the To-Do app.</p> <p>Per Bulma documentation, the <code>field</code> class is intended as a container for <code>label.label</code>s, <code>.control</code>s, and optional <code>p.help</code> text. </p> <p>In contrast, <code>control</code> is a block container meant to enhance single form controls and can only contain <code>input</code>, <code>select</code>, <code>button</code>, or <code>icon</code> elements.  <pre><code>form.field(method=\"POST\", action=\"/\")\n  label.label Enter something to do\n  .control\n| {{form.title}}\n    | {% csrf_token %}\n  button.button.is-primary(type=\"submit\") Submit\n</code></pre></p>"},{"location":"Python/Modules/Dotenv/","title":"Dotenv","text":"<pre><code>pip install -U python-dotenv\n</code></pre> <p>Load a .env file placed in the current working directory. <pre><code>load_dotenv()\nvalue =  os.getenv('key')\n</code></pre></p>"},{"location":"Python/Modules/FastAPI/","title":"FastAPI","text":"<p>Variables values can be taken from the route or from query parameters following a question mark.</p> RoutesQuery parameters <pre><code>from fastapi import FastAPI\n\nstarships = FastAPI()\n\n@starships.get(\"/starships/{registry}\")\ndef get_starship(name: str):\n    return {\"response\": f\"Hello, {name}\"}\n</code></pre> <pre><code>from fastapi import FastAPI\n\nstarships = FastAPI()\n\n@starships.get(\"/\")\ndef get_starship(name: str = \"world\"):\n    return {\"response\": f\"Hello, {name}\"}\n</code></pre> <p>FastAPI is notable for being able to use type hints to construct data models, which are much lighter than the object relational models used by other frameworks.</p> FastAPIDjango <pre><code>from pydantic import BaseModel\n\nclass Starship(BaseModel):\n    name : str\n    registry : str\n    crew : int\n</code></pre> <pre><code>from django.db import models\n\nclass Starship(models.Model):\n    name = models.CharField(max_length=50)\n    registry = models.CharField(max_length=15)\n    crew = models.IntegerField()\n</code></pre> <p>Dogfood data can be incorporated by using the keyword argument unpacking or \"double splat\" operator (<code>**</code>)</p> <pre><code>data = {\"name\": \"USS Enterprise\", \"registry\" : \"NCC-1701\", \"crew\" : 203}\nenterprise = Starship(**data)\n</code></pre> <p>POST method definitions then can use this newly defined class to validate posted data</p> <pre><code>db = []\n\n@app.post(\"/starships\")\nasync def create_starship(starship : Starship):\n    db.append(starship)\n</code></pre> <p>FastAPI supports Jinja templates to serve HTML templates <pre><code>import fastapi\nfrom fastapi.templating import Jinja2Templates\n\n# specifies the directory where templates are to be found\ntemplates = Jinja2Templates(\"templates\") \n\napi = fastapi.APIRouter()\n\n@api.get('/')\ndef index(request: starlette.requests.Request):\n    return templates.TemplateResponse(\"helloworld.html\", {\"request\" : request})\n</code></pre></p> <p>By default, FastAPI also exposes web applications at /docs where you can test out all the exposed API methods.</p> <p>FastAPI integrates with ASGI servers like Uvicorn and Hypercorn, which can run a specific web application by name from the command-line or from within the script:</p> ShellPython <pre><code>uvicorn main:starships --port 7000\n</code></pre> <pre><code>import uvicorn\n\nuvicorn.run(starships, port=7000)\n</code></pre>"},{"location":"Python/Modules/Functools/","title":"Functools","text":"<p>For higher-order functions (functions that act on or return other functions)</p> <p>Apply function of two arguments cumulatively to the items of iterable in order to reduce it to a single value <pre><code>functools.reduce(function, iterable [, initializer])\n</code></pre></p> <p>Calculate a cumulative sum <pre><code>functools.reduce(lambda x, y: x+y, [1,2,3,4,5])\n</code></pre></p>"},{"location":"Python/Modules/Glob/","title":"Glob","text":"<p>Produce a list of strings <pre><code>glob.glob('*.py')\n</code></pre></p>"},{"location":"Python/Modules/Heapq/","title":"Heapq","text":"<p>Support heaps, data objects where each node is either greater than or equal to its parent (max-heap) or less than or equal to its parent (min-heap) Create a heap from {iterable} <pre><code>heapq.heapify(iterable)\n</code></pre> Remove and return the smallest element of {heap} <pre><code>heapq.heappop(heap)\n</code></pre> Replace the smallest element of {heap} with {element} <pre><code>heapq.heapreplace(heap,element)\n</code></pre></p>"},{"location":"Python/Modules/Http/","title":"http","text":"<p>Start an HTTP server for the current directory <pre><code>python http.server\n</code></pre></p>"},{"location":"Python/Modules/Itertools/","title":"itertools","text":"<p>cycle() works like next(), but it restarts from the beginning of the iterable that is passed as argument after the last element has been reached. <pre><code>with open('raven') as f:\n    raven = [ l for l in f ]\n\nitertools.cycle(raven)\n</code></pre></p>"},{"location":"Python/Modules/Json/","title":"Json","text":"Deserialize Serialize <pre><code>import json\n\n\nwith open('starships.json') as f:\n    data=json.load(f)\n</code></pre> <pre><code>import json\n\n\nwith open('starships.json',\"w\") as f:\n    json.dump(data,f)\n</code></pre>"},{"location":"Python/Modules/Logging/","title":"Logging","text":"<pre><code>import logging\n\ndef main():\n    logging.basicConfig(filename='/tmp/learn-logging.log', level=logging.ERROR, format='%(asctime)s %(levelname)s: %(message)s')\n    logging.info(\"Once upon a midnight dreary,\")\n    logging.warning('While I pondered weak and weary,')\n    logging.error('Over many a quaint and curious volume of forgotten lore,')\n\nif __name__ == '__main__':\n    main()\n</code></pre>"},{"location":"Python/Modules/Npyscreen/","title":"Npyscreen","text":"<p>Widget library and application framework built on top of <code>ncurses</code>. Documentation] <p>Three main types of object compose <code>npyscreen</code> applications: - Application objects manage forms and other classes - Form objects form the canvas upon which widgets are arrayed   - <code>Form</code> general-purpose   - <code>FormMutt</code> - Widget objects are individual controls   - <code>TitleText</code> text entry   - <code>TitleSelectOne</code> equivalent to radio buttons   - <code>TitleDateCombo</code> allows picking of date on a small calendar</p> <p><code>npyscreen.wrapper_basic</code> is the main entry point <pre><code>import npyscreen\n\ndef myFunction(*args):\n  pass\n\nif __name__ == '__main__':\n  npyscreen.wrapper_basic(myFunction)\n  print \"Blink and you missed it!\"\n</code></pre> <code>npyscreen.Form</code> is equivalent to the <code>Tk()</code> object, which is typically instantiated as <code>win</code> in GUI frameworks. <pre><code>F = npyscreen.Form(name='My Test Application')\n</code></pre> Several important methods are key: - <code>create()</code> The standard constructor calls this method, which does nothing by default and is meant to be overriden in subclasses. Widgets are defined here.</p> <p><code>npyscreen.FormMutt</code> imitates a UI layout popularized by applications like <code>mutt</code>, <code>irssi</code>, and <code>vim</code>, with a title bar at the top, a command line at the bottom, and a status line directly above the command line.</p> <p><code>ACTION_CONTROLLER</code> can be defined in the <code>FormMutt</code> subclass as the name of a subclass of <code>ActionControllerSimple</code>. Commands for the application can be defined as callbacks in the <code>create()</code> method. <pre><code>self.add_action(ident,call_back, True)\n</code></pre> Callbacks are called with the following arguments: <pre><code>call_back(command_line, control_widget_proxy, live=True)\n</code></pre> <pre><code>class ActionControllerSearch(npyscreen.ActionControllerSimple):\n    def create(self):\n        self.add_action('^/.*', self.set_search, True)\n\n    def set_search(self, command_line, widget_proxy, live):\n        self.parent.value.set_filter(command_line[1:])\n        self.parent.wMain.values = self.parent.value.get()\n        self.parent.wMain.display()\n\nclass FmSearchActive(npyscreen.FormMuttActiveTraditional):\n    ACTION_CONTROLLER = ActionControllerSearch\n</code></pre></p> <p><code>npyscreen.NPSAppManaged</code> is the preferred superclass to support object-oriented implementation. <pre><code>class MyApplication(npyscreen.NPSAppManaged):\n  pass\n</code></pre> Calling <code>run()</code> method of application object as main entry point. <code>run()</code> activates the default form, which should be given an id of <code>MAIN</code> <pre><code>if __name__ == '__main__':\n  TestApp = MyApplication().run()\n  print \"All objects, baby.\"\n</code></pre> Using a <code>try</code>/<code>except</code> block to allow for well-mannered exit in case of <code>KeyboardInterrupt</code> (Ctrl+C)GitHub <pre><code>try:\n  App().run()\nexcept KeyboardInterrupt:\n  sys.exit(0)\n</code></pre> There are three methods for registering a <code>Form</code> object with a <code>NPSAppManaged</code> instance; - <code>addForm()</code> creates a new form and returns a <code>weakref.proxy</code> to it - <code>addFormClass()</code> register a class of <code>Form</code> rather than an instance - <code>registerForm()</code></p> <p>It continually displays the Form named by its <code>NEXT_ACTIVE_FORM</code> attribute. Use the <code>afterEditing</code> method to allow exiting. <pre><code>class myEmployeeForm(npyscreen.Form):\n  def afterEditing(self):\n    self.parentApp.setNextForm(None)\n</code></pre></p>"},{"location":"Python/Modules/Optparse/","title":"optparse","text":"<p>Instantiate the parser object <pre><code>parser = optparse.OptionParser(usage=__doc__.strip())\n\n# add an option\nparser.add_option('--timeout')\n</code></pre></p>"},{"location":"Python/Modules/Os/","title":"os","text":"<p>Execute shell command given by string.  The value returned is actually the exit code, not the output of the command to STDOUT. <pre><code>os.system('ls -la')\n</code></pre> Store output in a variable <pre><code>os.popen('ls -la').read()\n</code></pre> Navigate filesystem <pre><code>os.getcwd()\nos.chdir(path)\n</code></pre> Test for existence of a file <pre><code>os.path.isfile(file)\n</code></pre></p>"},{"location":"Python/Modules/Pygobject/","title":"Pygobject","text":""},{"location":"Python/Modules/Pygobject/#tasks","title":"Tasks","text":""},{"location":"Python/Modules/Pygobject/#development-environment","title":"Development environment","text":"Red Hat Ubuntu <pre><code>dnf install python3-venv python3-wheel\ndnf install gcc zlib-devel bzip2 bzip2-devel readline-devel sqlite sqlite-devel openssl-devel tk-devel git python3-cairo-devel cairo-gobject-devel gobject-introspection-devel\npip install pygobject\n</code></pre> <pre><code>apt install python3-gi python3-gi-cairo gir1.2-gtk-3.0 libgirepository1.0-dev\npip install pygobject\n</code></pre>"},{"location":"Python/Modules/Pygobject/#boilerplate","title":"Boilerplate","text":"Interface<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.40\"/&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;property name=\"title\"&gt;My GTK App&lt;/property&gt;\n&lt;property name=\"default-width\"&gt;300&lt;/property&gt;\n&lt;property name=\"default-height\"&gt;300&lt;/property&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre> <pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk  # (1)\n\nclass ApplicationWindow(Gtk.ApplicationWindow): # (2)\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs) # (3)\n        self.set_size_request(300,300)\n        self.set_title(\"My GTK App\")\n        self.show_all()\n        self.present()\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.learning-gtk') # (4)\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n\nif __name__ == '__main__':\n    app = Application() # (5)\n    app.run()\n    # (6)\n</code></pre> <ol> <li>Note that the gi module's <code>require_version()</code> function must be called before importing Gtk.</li> <li>The recommended way of using the PyGTK API is to subclass and modify the Application and ApplicationWindow classes. These were introduced in GTK+ versions 3.0 and 3.4 respectively and are meant to be used as base classes. PyGTK also offers an alternative Gtk.Window class, which like ApplicationWindow is a subclass of Gtk.Container, and which still appears in many tutorials.</li> <li>The ApplicationWindow subclass calls the superclass's constructor. The UI is composed by adding widgets to this subclass by calling <code>self.add()</code>. Typically a single Box container is added to the top-level container and controls are added to that container.</li> <li>The Application subclass also calls its superclass's constructor and exposes a <code>do_activate()</code> method that instantiates the ApplicationWindow subclass and assigns that object to <code>self.window</code> before calling <code>self.window.present()</code>. The Application subclass essentially acts as a wrapper around ApplicationWindow.</li> <li>At the script's entrypoint, the Application subclass itself is instantiated and its <code>run</code> method is called.</li> <li>In online tutorials that use Window, typically the Application wrapper class does not appear. The <code>Gtk.main()</code> method must be called somewhere in the script in order for the UI to appear.</li> </ol>"},{"location":"Python/Modules/Pygobject/#dice-roller","title":"Dice roller","text":"<pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport random\nfrom math import floor\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        scale_adj = Gtk.Adjustment.new(1, 0, 6, 1, 2, 0)\n        self.scale = Gtk.Scale.new(Gtk.Orientation.HORIZONTAL, scale_adj)\n        self.scale.set_digits(0)\n\n        button = Gtk.Button.new_with_label(\"Throw\")\n        button.connect(\"clicked\", self.on_button_clicked)\n        self.label = Gtk.Label.new()\n\n\n        box = Gtk.Box.new(Gtk.Orientation.VERTICAL,5)\n        box.pack_start(self.scale, False, True, 0)\n        box.pack_start(button, False, True, 0)\n        box.pack_start(self.label, False, True, 0)\n\n        self.add(box)\n        self.set_size_request(200,200)\n\n    def on_button_clicked(self, button):\n        dice = floor(self.scale.get_value())\n        results = [random.randrange(6) for i in range(dice)]\n        self.label.set_text(str(results))\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Python/Modules/Pygobject/#menubar","title":"MenuBar","text":"<pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass AppWindow(Gtk.ApplicationWindow):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(250, -1)\n        menubar = Gtk.MenuBar.new()\n        self.add(menubar)\n\n        file = Gtk.MenuItem.new_with_label(\"File\")\n        menubar.append(file)\n        filemenu = Gtk.Menu.new()\n        file.set_submenu(filemenu)\n        new = Gtk.MenuItem.new_with_label(\"New\")\n        open = Gtk.MenuItem.new_with_label(\"Open\")\n        filemenu.append(new)\n        filemenu.append(open)\n\n        edit = Gtk.MenuItem.new_with_label(\"Edit\")\n        menubar.append(edit)\n        editmenu = Gtk.Menu.new()\n        edit.set_submenu(editmenu)\n        cut = Gtk.MenuItem.new_with_label(\"Cut\")\n        copy = Gtk.MenuItem.new_with_label(\"Copy\")\n        paste = Gtk.MenuItem.new_with_label(\"Paste\")\n        editmenu.append(cut)\n        editmenu.append(copy) \n        editmenu.append(paste)\n\n        help = Gtk.MenuItem.new_with_label(\"Help\")\n        menubar.append(help)\n        helpmenu = Gtk.Menu.new()\n        help.set_submenu(helpmenu)\n        contents = Gtk.MenuItem.new_with_label(\"Help\")\n        about = Gtk.MenuItem.new_with_label(\"About\")\n        helpmenu.append(contents)\n        helpmenu.append(about)\n\nclass Application(Gtk.Application):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Menu Bars\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Python/Modules/Pygobject/#login","title":"Login","text":"<pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(300,300)\n        grid = Gtk.Grid.new()\n        image = Gtk.Image.new_from_icon_name(\"dialog-password\", Gtk.IconSize.DIALOG)\n        grid.attach(image, 0, 0, 1, 1)\n        grid.attach(Gtk.Label(label=\"Enter your credentials.\"), 0, 1, 2, 1)\n        grid.attach(Gtk.Label(label=\"User name:\"), 0, 2, 1, 1)\n        grid.attach(Gtk.Entry(), 1, 2, 1, 1)\n        grid.attach(Gtk.Label(label=\"Password:\"), 0, 3, 1, 1)\n        grid.attach(Gtk.Entry(visibility=False), 1, 3, 1, 1)\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id=\"org.example.myapp\")\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, title=\"Hello, World!\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Python/Modules/Pygobject/#hello-world","title":"Hello, World!","text":"Window titleLabelButton revealInteractiveHeaderBar <pre><code>import sys\nimport gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, name, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_default_size(300,300)\n        self.set_title(f\"Hello, {name}!\")\n        self.show_all()\n\n\nclass Application(Gtk.Application):\n    def __init__(self, name):\n        super().__init__(application_id=\"com.example.learning-gtk\")\n        self.name = name\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, name=self.name)\n\n\nif __name__ == '__main__':\n    if len(sys.argv) &gt; 1:\n        app = Application(sys.argv[-1])\n    else:\n        app = Application(\"World\")\n    app.run()\n</code></pre> <pre><code>import sys\nimport gi\ngi.require_version(\"Gtk\",\"3.0\")\nfrom gi.repository import Gtk\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, name, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(300, 300)\nself.add(Gtk.Label(label=f\"Hello, {name}!\"))\nclass Application(Gtk.Application):\n    def __init__(self, name = \"World\", *args, **kwargs):\n        self.name = name\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, name = self.name, title = \"Hello, World!\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    if len(sys.argv) &gt; 1:\n        app = Application(sys.argv[-1])\n    else:\n        app = Application(\"World\")\n    app.run() \n</code></pre> Interface<pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.40\"&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;property name=\"title\"&gt;My GTK App&lt;/property&gt;\n&lt;property name=\"default-width\"&gt;300&lt;/property&gt;\n&lt;property name=\"default-height\"&gt;300&lt;/property&gt;\n&lt;child&gt;\n&lt;object class=\"GtkButton\" id=\"button\"&gt;\n&lt;property name=\"label\"&gt;Press me!&lt;/property&gt;\n&lt;property name=\"margin-top\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-bottom\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-start\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-end\"&gt;12&lt;/property&gt;  &lt;/object&gt;\n&lt;/child&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        builder = Gtk.Builder.new_from_file('hw-button.ui')\n        self.window = builder.get_object('window')\n        self.button = builder.get_object('button')\n        self.button.connect('clicked', self.on_button_clicked)\n        self.window.connect('destroy', Gtk.main_quit)\n        self.window.show_all()\n        self.window.present()\n\n    def on_button_clicked(self, button):\n        self.button.set_label('Hello, World!')\n\n    def run(self):\n        super().run()\n        Gtk.main()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        box = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=10)\n        self.add(box)\n\n        question = Gtk.Label.new(\"What is your name?\")\n        box.add(question)\n\n        self.entry = Gtk.Entry(text=\"World\")\n        box.add(self.entry)\n\n        button = Gtk.Button.new_with_mnemonic(\"Greet\")\nbutton.connect(\"clicked\", self.on_button_clicked, self)\nbox.add(button)\n\ndef on_button_clicked(self, button, parent):\ndialog = Gtk.MessageDialog(\nmessage_type=Gtk.MessageType.INFO,\ntext=f\"Hello, {parent.entry.get_text()}\",\nparent=parent,\n)\ndialog.add_button(\"OK\", Gtk.ResponseType.OK)\ndialog.run()\ndialog.destroy()\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport sys\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_default_size(-1, -1)\n        # headerbar = Gtk.HeaderBar(title=f\"Hello, {name}!\", subtitle=\"HeaderBar example\", show_close_button=True)\nheaderbar = Gtk.HeaderBar()\nheaderbar.set_title(f\"Hello, World!\")\nheaderbar.set_subtitle(\"HeaderBar example\")\nheaderbar.set_show_close_button(True)\nself.set_titlebar(headerbar)\nbutton = Gtk.Button(label=\"Greet\")\n        button.connect(\"clicked\", self.on_button_clicked, self)\n        headerbar.add(button)\n\n        self.entry = Gtk.Entry(text=\"World\", name=\"entry\")\n        headerbar.add(self.entry)\n\n    def on_button_clicked(self, button, parent):\n        dialog = Gtk.MessageDialog(\n            message_type=Gtk.MessageType.INFO,\n            text=f\"Hello, {parent.entry.get_text()}!\",\n            parent=parent,\n        )\n        dialog.add_button(\"O_K\", Gtk.ResponseType.OK)\n        dialog.run()\n        dialog.destroy()\n\nclass HeaderBar(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id=\"org.example.headerbar\")\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = HeaderBar()\n    app.run()\n</code></pre>"},{"location":"Python/Modules/Pygobject/#starships","title":"Starships","text":"Hardcoded dataCSV importSortable columnsEvent handlerMessageDialog <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        ships = ['USS Enterprise', 'USS Defiant', 'USS Voyager']\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,)))\n\n        column = Gtk.TreeViewColumn(\"Ship\", Gtk.CellRendererText(), text=0)\n        self.treeview.append_column(column)\n        for s in ships:\n            self.treeview.get_model().append((s,))\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\nwith open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\nreader = csv.reader(f)\nself.headers = [h.title() for h in next(reader)]\nself.data = [r for r in reader]\nself.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n\nfor h in self.headers:\ncolumn = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\nself.treeview.append_column(column)\nfor r in self.data:\nself.treeview.get_model().append(r)\nself.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        with open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\n            reader = csv.reader(f)\n            self.headers = [h.title() for h in next(reader)]\n            self.data = [r for r in reader]\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n        for h in self.headers:\n            column = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\ncolumn.set_sort_column_id(self.headers.index(h))\nself.treeview.append_column(column)\n\n        for r in self.data:\n            self.treeview.get_model().append(r)\n\n        self.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        with open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\n            reader = csv.reader(f)\n            self.headers = [h.title() for h in next(reader)]\n            self.data = [r for r in reader]\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n        for h in self.headers:\n            column = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\n            column.set_sort_column_id(self.headers.index(h))\n            self.treeview.append_column(column)\n\n        for r in self.data:\n            self.treeview.get_model().append(r)\n\n        self.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\ndef on_row_activated(self, treeview, path, col):\nmodel = treeview.get_model()\nprint(f'Using path object as index to model: {model[path][:]}')\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\nimport csv\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        with open('/home/jasper/dogfood/csv/starships.csv',mode='r') as f:\n            reader = csv.reader(f)\n            self.headers = [h.title() for h in next(reader)]\n            self.data = [r for r in reader]\n\n        self.treeview = Gtk.TreeView(model=Gtk.ListStore.new((str,str,str,str)))\n        for h in self.headers:\n            column = Gtk.TreeViewColumn(h, Gtk.CellRendererText(), text=self.headers.index(h))\n            column.set_sort_column_id(self.headers.index(h))\n            self.treeview.append_column(column)\n\n        for r in self.data:\n            self.treeview.get_model().append(r)\n\n        self.treeview.connect('row-activated', self.on_row_activated)\n\n        self.add(self.treeview)\n        self.set_size_request(-1,-1)\n\ndef on_row_activated(self, treeview, path, col):\nmodel = treeview.get_model()\ndialog = Gtk.MessageDialog(\nmessage_type=Gtk.MessageType.INFO,\ntext=model[path][:],\nparent = self\n)\ndialog.add_button(\"OK\", Gtk.ResponseType.OK)\ndialog.run()\ndialog.destroy()\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Python/Modules/Pyinstaller/","title":"Pyinstaller","text":"<p>Source: RealPython tutorial</p> <p>Installing PyInstaller, even in a virtual environment, will install the pyinstaller executable to $HOME/.local/bin. On Windows, it is installed to another directory within  <code>LOCALAPPDATA</code>. <pre><code>pip install pyinstaller\n</code></pre> PyInstaller creates primarily 3 items: - .spec file, named after the CLI script - build/ folder, which can be ignored - dist/ folder, containing the final artifact at dist/cli/cli or dist/cli/cli.exe</p> <p>Several options are available <code>hidden-import</code> <code>name</code> <code>onefile</code> <pre><code>pyinstaller script.py --onefile\n</code></pre> On Windows, if PyInstaller is run from a virtual environment without necessary modules installed, they may not be available for compilation into the artifact. This does not appear to be an issue with Linux.</p> <p>This problem appears to be specific to certain modules, like emoji.</p>"},{"location":"Python/Modules/Pythonnet/","title":"pythonnet","text":"<ul> <li>Docs: ? ! Developers recommend Mono version 5.20.1 Issues 939</li> </ul> <p>On Ubuntu, the <code>eoan</code> <code>universe</code> repository has to be added  <pre><code>deb https://archive.ubuntu.com/ubuntu/ eoan universe\ndeb https://archive.ubuntu.com/ubuntu/ eoan-updates universe\n</code></pre> But I can't figure out how to add the older version, because the recommended syntax produces the error \"Unable to correct problems, you have held broken packages\" <pre><code>sudo apt install mono-devel=5.18.0.240+dfsg-3\n</code></pre> Maybe try the tarballs on Mono's website... Or maybe there's another repo I don't know about.. <pre><code>apt install clang libglib2.0-dev python3-dev\n</code></pre> <pre><code>pip install pycparser pythonnet\npip install -U setuptools\n</code></pre></p>"},{"location":"Python/Modules/Random/","title":"random","text":"<p>Random choice with replacement <pre><code>random.choice(iterable)\n</code></pre> Shuffle elements of an iterable in-place [FP:42] <pre><code>random.shuffle(iterable)\n</code></pre></p>"},{"location":"Python/Modules/Scrapy/","title":"scrapy","text":"<p>Best used to obtain one \"stream\" of data at a time, without trying to obtain data from different pages <pre><code>scrapy runspider spider.py -o file.json\n</code></pre> Display HTML source of the scraped page <pre><code>print(response.txt)\n</code></pre> Get <code>{URL}</code> <pre><code>fetch('url')\n</code></pre> Select a CSS selector <pre><code># Returns a `SelectorList`\nresponse.css('p')\n# Retrieve full HTML elements\nresponse.css('p').extract()\n</code></pre> Retrieve only the text within the element <pre><code>response.css('p::text').extract()\nresponse.css('p::text').extract_first()\nresponse.css('p::text').extract()[0]\n</code></pre> Get the <code>href</code> attribute value for an anchor tag <pre><code>response.css('a').attrib['href']\n</code></pre> Launch Scrapy shell and scrape <code>$URL</code> <pre><code>scrapy shell $URL\n</code></pre> Make a default spider named {quotes} that will be restricted to {domain} <pre><code>scrapy genspider quotes domain\n</code></pre> <pre><code>scrapy runspider scrapy1.py\n</code></pre> Run a spider, saving scraped data to a JSON file <pre><code>scrapy runspider spider.py -o items.json\n</code></pre> Method which contains most of the logic of the spider, especially after the <code>yield</code> keyword. For multiple items, a structural basis for iteration must be found and for each iteration, data is yielded</p> <p>Extract URL from link using standard CSS selection techniques</p> <p>Add the domain name to a relative link <pre><code>response.urljoin()\n</code></pre> Recursively call the <code>parse</code> method again on the next page <pre><code>yield scrapy.Request(url=next_page_url, callback=self.parse)\n</code></pre> Scrape detail pages   - <code>parse_details</code> would be a spider method sibling to the main <code>parse</code> method   - if a detail page has more information than the main, then the <code>yield</code> keyword should be in <code>parse_details</code> <pre><code>yield scrapy.Request(url={url}, callback=self.parse_details)\n</code></pre></p>"},{"location":"Python/Modules/Setuptools/","title":"setuptools","text":"<p>Setuptools is for uploading to PyPi. To create self-contained executable files, use pyinstaller.</p> <pre><code>PROJECT\n\u251c\u2500\u2500 PROJECT # (1)\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 init.py\n\u2514\u2500\u2500 setup.py # (2)\n\n1 directory, 2 files\n</code></pre> <ol> <li>Additional code files will be placed in here</li> <li>Containing a call to setuptools.setup() setup.py<pre><code>import setuptools\n\nsetuptools.setup(\n    name='funniest',\n    version='0.1',\n    description='The funniest joke in the world',\n    url='http://github.com/storborg/funniest',\n    author='Flying Circus',\n    author_email='flyingcircus@example.com',\n    license='MIT',\n    packages=['funniest'],\n    zip_safe=False\n)\n</code></pre> If the package has dependencies, they can be added by appending an install_requires keyword argument passing an array of the module names <pre><code>setup(\n  install_requires=[ 'markdown', ],\n)\n</code></pre></li> </ol> <p>Reserve the name, upload package metadata, and create the pypi.python.org webpage <pre><code>python setup.py register\n</code></pre> Create a source distribution, producing a tarball inside the top-level directory <pre><code>python setup.py sdist\n</code></pre> Upload the source distribution <pre><code>python setup.py sdist upload\n</code></pre> Do all the above in a single step <pre><code>python setup.py register sdist upload\n</code></pre></p>"},{"location":"Python/Modules/Socket/","title":"socket","text":"<p>The socket module is Python's standard interface for the transport layer. Sockets can be classified by <code>family</code></p> <ul> <li><code>AF_INET</code> Internet</li> <li><code>AF_UNIX</code> for UNIX sockets</li> </ul> <p>and <code>type</code>:   - <code>SOCK_STREAM</code> TCP   - <code>SOCK_DGRAM</code> UDP</p> <p>These enum values are required upon initialization of a socket object: [Ortega][Ortega]: 25</p> <pre><code>client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n</code></pre> <p>Sources: </p> <ul> <li>Sockets tutorial</li> </ul> TCP serverTCP ClientUDP serverUDP client <pre><code>import socket\n\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.bind((HOST,PORT))\n</code></pre> <pre><code>import socket\n\n\nwith socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n    s.connect((HOST,PORT))\n</code></pre> <pre><code>import socket\n\n\nwith socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n    s.bind((HOST,PORT))\n</code></pre> <pre><code>import socket\n\nmsg = \"Hello, world!\"\nwith socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n    s.sendto(msg.encode(), (HOST,PORT))\n</code></pre> <p>Define port on which to listen for connections. <pre><code>serversocket.bind(('localhost',80))\n</code></pre> Connect to a remote socket in one direction <pre><code>client_socket.connect(('www.packtpub.com',80))\n</code></pre> Convert a domain name into IPv4 address <pre><code>socket.gethostbyname('packtpub.com') # '83.166.169.231'\n</code></pre> Defaults to localhost with no arguments <pre><code>s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ns.bind((socket.gethostname(),1234))\n</code></pre> Get protocol name from port number <pre><code>socket.getservbyport(80) # 'http'\n</code></pre> Listen to a maximum of 10 connections <pre><code>serversocket.listen(10)\n</code></pre> Receive bytestream from server <pre><code>msg = s.recv(1024)\nprint(msg.decode('utf-8'))\n</code></pre></p>"},{"location":"Python/Modules/Sqlite3/","title":"sqlite3","text":"<p>Create a <code>Connect</code> connection object and employee.db (binary) if it doesn't exist <pre><code>conn = sqlite.connect('employee.db')\n</code></pre> Create a <code>Connect.Cursor</code> object <pre><code>c = conn.cursor()\n</code></pre> Perform SQL commands with <code>Connect.Cursor.execute()</code>. Create <code>tablename</code> with fields <code>field</code> of type <code>type</code> (<code>null</code>, <code>integer</code>, <code>real</code>, <code>text</code>, <code>blob</code>); never use Python's native string operations (f-strings, etc) to form commands, because this method is vulnerable to SQL injection. YouTube <pre><code>c.execute('''CREATE TABLE {tablename} ({field} {type}, {field} {type} ...))\n</code></pre> Save changes <pre><code>conn.commit()\n</code></pre> Close connection <pre><code>conn.close()\n</code></pre></p>"},{"location":"Python/Modules/Subprocess/","title":"subprocess","text":"<p>subprocess modules allows you to spawn new processes, interact with file descriptors, and obtain exit codes. The recommended approach is to use the <code>run()</code> function as default, which runs a CLI command with options as a list of strings and returns a <code>CompletedProcess</code> instance.\\ Execute shell command Unlike <code>os.system</code>, <code>subprocess.run()</code> takes a list of arguments.  <pre><code>subprocess.run(['ls','-l,'.'], 0)\n</code></pre> Set <code>capture_output</code> to <code>True</code> to save output, stored as property <code>stdout</code> of the returned object.  <pre><code>data = subprocess.run(['ls,'-l','.'], 0, capture_output=True)\n</code></pre> The data is stored as a bytestring, which can be decoded to a normal string. <pre><code>data.stdout.decode('utf-8')\n</code></pre> This return a <code>CompletedProcess</code> instance with the command's output stored under the <code>stdout</code> property <pre><code>subprocess.run(['ls','-l','/dev/null'], capture_output=True)\n</code></pre> This will raise a <code>CalledProcessError</code> exception because of the non-zero exit code <pre><code>subprocess.run('exit 1', shell=True, check=True)\n</code></pre></p>"},{"location":"Python/Modules/Sys/","title":"sys","text":"<p>Return site-specific directory where Python files are installed  <pre><code>sys.prefix # (1)\n</code></pre></p> <ol> <li>/usr/local/ by default</li> </ol>"},{"location":"Python/Modules/Termcolor/","title":"termcolor","text":"<p>Print <code>text</code> in a color code <pre><code>termcolor.cprint(text,color)\n</code></pre></p>"},{"location":"Python/Modules/Threading/","title":"threading","text":"<p> Docs</p> <p><pre><code>counter = 0\nlock = threading.RLock()\n\ndef func1():\n  global counter\n\n  while True:\n    with lock:\n      counter += 1\n      counter -= 1\n\ndef func2():\n  global counter\n\n  while True:\n    with lock:\n      counter += 1\n      counter -= 1\n\nthreading.Thrad(target=func1).start()\nthreading.Thrad(target=func2).start()\n</code></pre> <pre><code>counter = 0\n\ndef func1():\n  global counter\n\n  while True:\n    counter += 1\n    counter -= 1\n\ndef func2():\n  global counter\n\n  while True:\n    counter += 1\n    counter -= 1\n\nthreading.Thrad(target=func1).start()\nthreading.Thrad(target=func2).start()\n</code></pre></p>"},{"location":"Python/Modules/Weakref/","title":"Weakref","text":"<p>Weak references are references to objects which return exceptions when that object has been garbage collected Create a weak reference to {object}  <pre><code># A weak reference created using `ref` must be dereferenced \nr = weakref.ref(obj) \nr().method() \nr.method()          # will not work\n\n# A weak reference created using `proxy` does not need to be dereferenced:\nweakref.proxy(obj)\n</code></pre></p>"},{"location":"Python/Modules/Winrm/","title":"Winrm","text":"<p>Winrm allows you to connect Linux and Windows hosts over WinRM. adamtheautomator.com  Begin a WinRM session. If no errors are thrown, the session has been successfully established <pre><code>session = winrm.Session(ipaddress, auth = (username, password) )\n</code></pre></p>"},{"location":"Python/Modules/Xml/","title":"xml","text":"books.xml <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;catalog&gt;\n&lt;book id=\"bk101\"&gt;\n&lt;author&gt;Gambardella, Matthew&lt;/author&gt;\n&lt;title&gt;XML Developer's Guide&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;44.95&lt;/price&gt;\n&lt;publish_date&gt;2000-10-01&lt;/publish_date&gt;\n&lt;description&gt;An in-depth look at creating applications with XML.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk102\"&gt;\n&lt;author&gt;Ralls, Kim&lt;/author&gt;\n&lt;title&gt;Midnight Rain&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-16&lt;/publish_date&gt;\n&lt;description&gt;A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk103\"&gt;\n&lt;author&gt;Corets, Eva&lt;/author&gt;\n&lt;title&gt;Maeve Ascendant&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2000-11-17&lt;/publish_date&gt;\n&lt;description&gt;After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk104\"&gt;\n&lt;author&gt;Corets, Eva&lt;/author&gt;\n&lt;title&gt;Oberon's Legacy&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2001-03-10&lt;/publish_date&gt;\n&lt;description&gt;In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk105\"&gt;\n&lt;author&gt;Corets, Eva&lt;/author&gt;\n&lt;title&gt;The Sundered Grail&lt;/title&gt;\n&lt;genre&gt;Fantasy&lt;/genre&gt;\n&lt;price&gt;5.95&lt;/price&gt;\n&lt;publish_date&gt;2001-09-10&lt;/publish_date&gt;\n&lt;description&gt;The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon's Legacy.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk106\"&gt;\n&lt;author&gt;Randall, Cynthia&lt;/author&gt;\n&lt;title&gt;Lover Birds&lt;/title&gt;\n&lt;genre&gt;Romance&lt;/genre&gt;\n&lt;price&gt;4.95&lt;/price&gt;\n&lt;publish_date&gt;2000-09-02&lt;/publish_date&gt;\n&lt;description&gt;When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk107\"&gt;\n&lt;author&gt;Thurman, Paula&lt;/author&gt;\n&lt;title&gt;Splish Splash&lt;/title&gt;\n&lt;genre&gt;Romance&lt;/genre&gt;\n&lt;price&gt;4.95&lt;/price&gt;\n&lt;publish_date&gt;2000-11-02&lt;/publish_date&gt;\n&lt;description&gt;A deep sea diver finds true love twenty thousand leagues beneath the sea.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk108\"&gt;\n&lt;author&gt;Knorr, Stefan&lt;/author&gt;\n&lt;title&gt;Creepy Crawlies&lt;/title&gt;\n&lt;genre&gt;Horror&lt;/genre&gt;\n&lt;price&gt;4.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-06&lt;/publish_date&gt;\n&lt;description&gt;An anthology of horror stories about roaches,\n        centipedes, scorpions  and other insects.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk109\"&gt;\n&lt;author&gt;Kress, Peter&lt;/author&gt;\n&lt;title&gt;Paradox Lost&lt;/title&gt;\n&lt;genre&gt;Science Fiction&lt;/genre&gt;\n&lt;price&gt;6.95&lt;/price&gt;\n&lt;publish_date&gt;2000-11-02&lt;/publish_date&gt;\n&lt;description&gt;After an inadvertant trip through a Heisenberg\n        Uncertainty Device, James Salway discovers the problems of being quantum.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk110\"&gt;\n&lt;author&gt;O'Brien, Tim&lt;/author&gt;\n&lt;title&gt;Microsoft .NET: The Programming Bible&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;36.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-09&lt;/publish_date&gt;\n&lt;description&gt;Microsoft's .NET initiative is explored in detail in this deep programmer's reference.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk111\"&gt;\n&lt;author&gt;O'Brien, Tim&lt;/author&gt;\n&lt;title&gt;MSXML3: A Comprehensive Guide&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;36.95&lt;/price&gt;\n&lt;publish_date&gt;2000-12-01&lt;/publish_date&gt;\n&lt;description&gt;The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.&lt;/description&gt;\n&lt;/book&gt;\n&lt;book id=\"bk112\"&gt;\n&lt;author&gt;Galos, Mike&lt;/author&gt;\n&lt;title&gt;Visual Studio 7: A Comprehensive Guide&lt;/title&gt;\n&lt;genre&gt;Computer&lt;/genre&gt;\n&lt;price&gt;49.95&lt;/price&gt;\n&lt;publish_date&gt;2001-04-16&lt;/publish_date&gt;\n&lt;description&gt;Microsoft Visual Studio 7 is explored in depth,\n        looking at how Visual Basic, Visual C++, C#, and ASP+ are integrated into a comprehensive development environment.&lt;/description&gt;\n&lt;/book&gt;\n&lt;/catalog&gt;\n</code></pre> <p>The etree submodule contains the ElementTree object which can open a string filename to deserialize XML data using <code>parse()</code>, which returns an ElementTree object, representing an XML document. A Python string can also be parsed with <code>fromstring()</code>, which actually returns an Element object.</p> FileString <pre><code>tree = xml.etree.ElementTree.parse('books.xml')\n</code></pre> <pre><code>tree = xml.etree.ElementTree.fromstring(books)\n</code></pre> <p>The <code>getroot()</code> method returns an Element object of the XML document's root node. <pre><code>root = tree.getroot()\n</code></pre></p> <p>The parsed data can be displayed using the <code>tostring()</code> static method, providing an Element as argument. <pre><code>ElementTree.tostring(root)\n</code></pre></p> <p>Children of an element can be filtered using <code>findall()</code>. This returns a list of Elements. <pre><code>books = root.findall('book')\n</code></pre></p> <p>Any Element object exposes an <code>attrib</code> property which returns a dictionary of attributes. <pre><code>[b.attrib for b in books]\n</code></pre></p> <p>Attributes can be written to an Element using the <code>set()</code> method. <pre><code>root.set('foo','bar')\n</code></pre></p> <p>Attributes can also be manipulated on the attrib property with normal Python dictionary operations.</p> SettingDeleting <pre><code>root.attrib['foo'] = 'bar'\n</code></pre> <pre><code>del(root.attrib['hello'])\n</code></pre> <p>Commit changes to disk. The argument can be a string representing the filename or a file object (in which case the file must be opened as a binary). Encoding can be specified (default is UTF-8) and a XML declaration can also be automatically generated.</p> StringFile object <pre><code>tree.write('books.xml', encoding='UTF-16', xml_declaration=True)\n</code></pre> <pre><code>with open('books.xml', 'wb') as f:\n    tree.write(f)\n</code></pre> <p>Find elements by element name <pre><code>tree.findall('book')\n</code></pre></p>"},{"location":"Python/Modules/Yaml/","title":"Yaml","text":"<pre><code>pip install pyyaml\n</code></pre>  Deserialize Serialize <pre><code>import yaml\n\n\nwith open('./starships.yaml') as f:\nstarships = yaml.safe_load(f)\n</code></pre> <p>There is a <code>load</code> method but it requires specifying one of four possible values for the Loader kwarg.</p> <pre><code>import yaml\n\n\nwith open('./starships.yaml','w') as f:\nyaml.dump(starships, f)\n</code></pre> Resources <ul> <li>Introduction to YAML</li> </ul>"},{"location":"Rust/","title":"Overview","text":"<p>Rust's distinguishing feature as a programming language is its ability to prevent invalid data access at compile time.</p> <p>\u2014Tim McNamara</p> <p>Rust offers zero-cost abstractions, where using the abstraction imposes no additional runtime overhead.</p>"},{"location":"Rust/#documentation","title":"Documentation","text":"<p>Rust uses C-style line comments using <code>//</code> and block comments using <code>/*</code>, <code>*/</code></p> <p>Doc comments support markdown and are used to generate documentation with the use of <code>cargo doc</code>.</p> <p>Markdown code blocks containing test cases are known as doc tests and can be run with <code>cargo test</code>, for library crates only. Note that markdown code blocks in Rust doc comments don't need a language annotation.</p> <ul> <li>Outer doc comments are preceded by <code>///</code> and are written immediately preceding the code blocks they document</li> <li>Inner doc comments are preceded by <code>//!</code> and are written within code blocks, similar to docstrings in Python</li> </ul>"},{"location":"Rust/#data","title":"Data","text":"<p>Variable declarations are called bindings in Rust, and by convention variable names are in snake_case (lower-case letters with words delimited by _). They are globally scoped by default unless they are declared in a code block.</p> <p>Variables are immutable by default, so if their values are to change they must be marked with <code>mut</code>. However, immutable variables are distinct from constants declared using <code>const</code>, which cannot be made mutable at all. <code>const</code> identifiers are conventionally written in capitalized snake_case.</p> <pre><code>let language = \"&amp;nbsp;\";        // Immutable\nlet mut language = \"&amp;nbsp;\";    // Mutable\nconst language = \"&amp;nbsp;\";      // Constant\n</code></pre> <p>Data type is explicitly specified on initialization after colon, and this same syntax is used to type function parameters and return types:</p> <pre><code>let language: String = \"&amp;nbsp;\";\n</code></pre> <p>A special <code>!</code> type indicates that the function never returns</p> <pre><code>// RIA p. 78\nfn read(f: &amp;mut File, save_to: &amp;mut Vec&lt;u8&gt;) -&gt; ! {\nunimplemented!();\n}\n</code></pre> <p>Numbers can be typed by appending the data type to the value itself. Digits can be separated with <code>_</code></p> <pre><code>let x = 255i8;\nlet y = 1_024_i16;\n</code></pre> <p>Because implicit integer conversions are a well-known source of bugs and security holes, conversion must be explicit using the as keyword: <pre><code>do_something(x as i32);\n</code></pre></p> <p>Common mathematical calculations are implemented as methods, which can be called directly on variables or literals or as associated functions of the type:</p> <pre><code>let x = (4.5_f64).floor()\n\nlet y = 4.0_f64;\nlet z = y.sqrt();\n\nlet a = f64::sqrt(4.0);\n</code></pre> <p>Common constants can be found in each type's consts module, i.e. std::f32::consts. Other values like <code>MIN</code>, <code>MAX</code>, <code>INFINITY</code>, <code>NEG_INFINITY</code>, and <code>NAN</code> (not-a-number) are also implemented as consts.</p> <p>Shadowing and masking are terms that refer to using a locally scoped variable with the same identifier as a global variable. When in the local variable's block, the local variable is said to be masking the global one, which conversely is shadowing the local. Once the local scope is exited, the global variable's variable is accessible again and the local variable is destroyed.</p> <p>Shadowing is used in the Guessing Game coding task to parse the input string as an integer.</p> <p>Integers can be fixed-length or variable-length. Fixed-size integers can be signed (<code>i</code>) or unsigned (<code>u</code>) and 8, 16, 32, or 64 bits: i.e. <code>i8</code>, <code>u64</code> etc. Variable-size integers can be pointer-sized signed <code>isize</code> or pointer-sized unsigned <code>usize</code>, the size of both of which depend on the architecture of the host system.</p> <p>Arrays and Tuples are considered primitive data types, albeit Compound ones. Integer and Float are considered Numeric Scalars, while Boolean and Chars are considered Non-Numeric Scalars.</p> <ul> <li>Floating point numbers can be single-precision <code>f32</code> or double-precision <code>f64</code>.</li> <li>Booleans are <code>true</code> or <code>false</code> (lower-case).</li> </ul> <p>Arrays are homogeneous sequences of elements and must be of a fixed length, declared at initialization, although the type can be determined implicitly.</p> <p>Type can be inferred by the compiler or explicitly annotated after a colon:</p> ImplicitExplicit <pre><code>let var = 0;\nlet arr = [0 ; 4];\nlet person = (\"John\", 35, \"Doe\");\n</code></pre> <pre><code>let var:u8 = 0;\nlet arr:[i32; 4] = [0, 0, 0, 0];\nlet person : (&amp;str, i32, &amp;str) = (\"John\", 35, \"Doe\");\n</code></pre> <p>Array length can be given by the <code>len()</code> method.</p> <p>Array slicing </p> <pre><code>let arr:[i32;4] = [1, 2, 3, 4]; let slice_array2:&amp;[i32] = &amp;arr[0..2];\n</code></pre> <p>Tuples, like arrays, are fixed-length. But unlike arrays they are heterogeneous sequences of elements.</p> <p>Tuples can be destructured (i.e. unpacked) <pre><code>let person = (\"John\", 35, \"Doe\");\nlet (first_name, age, last_name) = person;\n</code></pre></p> <p>Tuples can be made mutable with the <code>mut</code> keyword.</p> <p>Rust's standard library includes a number of collections</p> <ul> <li>A vector stores a variable number of values of a single type in a sequence</li> <li>A String is a collection of characters</li> <li>A hash map is a key-value store</li> </ul>"},{"location":"Rust/#ownership","title":"Ownership","text":"<p>One of the key and unique features of Rust is the concept of ownership, which achieves memory safety without the use of a garbage collector.</p> <p>Stack versus heap</p> <p>The stack and heap are locations in memory that are available to the application at runtime.</p> <ul> <li>The stack is a LIFO that is used for sizes that are known at compile-time. It is comparable to a stack of plates of uniform size from which plates can be removed only from the top. Values are said to be \"pushed onto\" or \"popped off\" the stack. </li> <li>The heap is less organized and less efficient, and is used for sizes that are known only at runtime. The operating system must search for an appropriate memory location based on the application's request at runtime, returning a pointer, and this process makes the heap less efficient than the stack. Memory locations are said to be \"allocated on\" the heap. </li> </ul> <p>Some complex data types like <code>String</code> are composed of a pointer, stored in the stack because its size is known at compile-time, that points to a location on the heap that holds the String's contents, which are known only at runtime.</p> <p>In other languages these statements would cause s2 to become a shallow copy of s1, pointing to the same location in memory where the String contents are stored. However, ownership rules in Rust cause s1 to be invalidated because s2 becomes the owner of the data contents on the heap, and this is called a move. <pre><code>let s1 = String::from(\"Hello, world!\");\nlet s2 = s1;\nprintln(\"{}\", s1); // compiler error\n</code></pre></p> <p>This allows Rust to avoid the double free error caused by attempting to free the same memory location twice, which can cause corruption and security issues. When the variable goes out of scope, its backing memory is freed.</p> <p>A deep copy is still possible with the common <code>clone</code> method:</p> <pre><code>let s2 = s1.clone();\n</code></pre> <p>This behavior is only for data that is stored on the heap, not the stack. The size of integers is known at compile-time, so they are stored entirely on the stack, and therefore copies of the values are efficiently made.</p> <pre><code>let x = 5;\nlet y = x;\nprintln!(\"{}\",x); // no error\n</code></pre> <p>More specifically, certain types have a special annotation called the <code>Copy</code> trait which enable this behavior. For types that \"are <code>Copy</code>\" - i.e. have the <code>Copy</code> trait - an older variable is still usable after assignment. <code>Copy</code> types include integers, booleans, chars, floats, and tuples containing only other <code>Copy</code> types.</p> <p>Function calls also exhibit move behavior; after a variable is passed as argument to a function, the function owns it and it may not be used again in its original context unless ownership is returned. If the value is not returned, the argument's contents are consumed and it may not be used again in the calling context.</p> <p>This is why most function calls in Rust use references, prefixing the variable identifier with <code>&amp;</code>, a process called borrowing.</p> <p>Passing a value to a function while transferring ownership is called \"passing by value\" or a move, whereas using a reference is called \"passing by reference\".</p> Passing by valueReturning valueBy reference <pre><code>fn main() {\nlet s = String::from(\"Dgiapusccu\");\nhello_world(s);\nprintln!(\"Hello again, {}!\", s); // compiler error\n}\n\nfn hello_world(s:String) {\nprintln!(\"Hello, {}!\", s)\n\n}\n</code></pre> <pre><code>fn main() {\nlet s = String::from(\"Dgiapusccu\");\nlet s = hello_world(s);\nprintln!(\"Hello again, {}!\", s);\n}\n\nfn hello_world(s:String) -&gt; String {\nprintln!(\"Hello, {}!\", s);\ns\n}\n</code></pre> <pre><code>fn main() {\nlet s = String::from(\"Dgiapusccu\");\nhello_world(&amp;s);\nprintln!(\"Hello again, {}!\", s);\n}\n\nfn hello_world(s:&amp;String) {\nprintln!(\"Hello, {}!\", s)\n\n}\n</code></pre>"},{"location":"Rust/#references","title":"References","text":"<p>Pointer types like <code>Box&lt;T&gt;</code> and those internal to String and Vec are owning pointers: when the owner is dropped the referent is deallocated. Nonowning pointer types are called references and have no effect on their referents' lifetimes.</p> <p>There are two types of reference:</p> <ul> <li>Shared references let you read but not modify the referent Multiple shared references to the same value can be created.</li> <li>Mutable references allow both reading and modifying of the referent To prevent data races only one mutable reference to a location in a scope can exist.</li> </ul> <p>A mutable reference and an immutable one cannot coexist in the same scope. Moves after a borrow are also forbidden, for this same reason.</p> <p>Here, the call to push() causes the vector to be reallocated on the heap after an immutable borrow was made. <pre><code>let mut data = vec![1, 2, 3];\nlet x = &amp;data[0];\ndata.push(4);\n\nprintln!(\"{}\", x);\n</code></pre></p>"},{"location":"Rust/#copy-and-clone","title":"Copy and Clone","text":"<p>Rust provides two traits that relate to the copying of data: Copy and Clone.</p> <ul> <li>Copy allows values stored on the stack only to be duplicated. Any type whose parts all implement Copy can also derive Copy. However, this trait is rarely required since primitives stored on the stack already have optimizations available. In the background this relies on the memcpy syscall.</li> <li>Clone is for explicitly creating a deep copy of values, especially those allocated on the heap. Types that implement Copy also trivially implement Clone. </li> </ul>"},{"location":"Rust/#collections","title":"Collections","text":"<p>Accessing tuple elements is done with the <code>.</code> operator</p> <pre><code>let coord: (i8, i8) = (10, 20);\nprintln!(\"{}, {}\", coord.0, coord.1);\n</code></pre>"},{"location":"Rust/#paradigms","title":"Paradigms","text":""},{"location":"Rust/#oop","title":"OOP","text":"<p>Strictly speaking, OOP is not actually implemented in Rust because there is no inheritance. However, objects that combine data with logic can be created <code>struct</code>s and <code>impl</code>s.</p> <p>A group of methods that are shared by multiple types can have their signatures defined by a trait. Types then implement the trait, and functions can be defined that accept any type that does so by specifying the trait instead of a single concrete type.</p> <pre><code>pub fn notify(item: impl Summary) {\nprintln!(\"Breaking news! {}\", item.summarize());\n}\n</code></pre>"},{"location":"Rust/#tdd","title":"TDD","text":"<p>Tests are functions annotated with the <code>#[test]</code> attribute. Tests fail when the test function panics.</p> <pre><code>#[test]\nfn math_works() {\nassert_eq!(2+2, 4);\n}\n\n#[test]\nfn fails() {\npanic!(\"This test will fail\");\n}\n</code></pre> <p>Tests can also be incorporated in documentation as markdown code blocks.</p>"},{"location":"Rust/#concurrency","title":"Concurrency","text":"<p>std::sync::atomic provides thread-safe types modeled on the atomics of C++20. This model introduces the concept of atomic accesses which tell the hardware and compiler what ordering it has with relation to other accesses.  This largely boils down to preventing reordering of instructions and determining how writes are propagated to other threads.</p> <p>std::sync::RwLock is a reader-writer lock, which allows a number of readers or at most one writer at any point in time. A Mutex, by comparison, does not distinguish between readers or writers and blocks any threads waiting for the lock to become available.</p> <pre><code>let lock = std::sync::RwLock::new(1);\n\nlet mut n = lock.write().unwrap(); // (1)\n*n = 2;\n\nassert!(lock.try_read().is_err()); // (2)\n</code></pre> <ol> <li>write attempts to acquire the rwlock with exclusive write access and returns a LockResult, which is really just a type alias for a Result.</li> <li>try_read attempts to acquire the rwlock with shared read access.</li> </ol>"},{"location":"Rust/Cargo/","title":"Cargo","text":"<p>Cargo is Rust's package manager.</p> <p>New crates can be created with the <code>cargo</code> command-line utility. <pre><code>cargo new hello_cargo\ncargo new hello_cargo --vcs none # Prevent creation of a Git repo\n</code></pre></p> <p>Extensions to Cargo are available, which add subcommands like add and watch <pre><code>cargo install cargo-edit\ncargo install cargo-watch\n</code></pre></p> <p>During development, a crate can be compiled and run <pre><code>cargo run\n</code></pre></p> <p>If behind a corporate firewall, where SSL certificates are substituted, a special flag must be set in ~/.cargo/config.toml to allow package downloads. <pre><code>[http]\ncheck-revoke = false\n</code></pre></p> <p>Generate documentation from doc comments using a built-in static site generator, and then open it. <pre><code>cargo doc --open\n</code></pre></p> <p>Other commands:</p> <ul> <li><code>cargo fmt</code> format code</li> <li><code>cargo test</code> run doctests</li> </ul>"},{"location":"Rust/Cargo/#features","title":"Features","text":"<p>Every crate has features that can be enabled in the Cargo.toml. Crate features are declared in the Cargo.toml <pre><code>rocket = {version = \"0.5.0-rc.1\", default-features = false, features = [\"json\"]}\n</code></pre></p> <p>These can also be added from the command-line <pre><code>cargo add rocket --features json --no-default-features\n</code></pre></p> <p>These are distinct from the \"feature flag\" inner attributes referring to features of unstable Rust.</p>"},{"location":"Rust/Crates/","title":"Modules","text":"<p>Projects and code dependencies in Rust are called crates, equivalent to modules in Python. The term modules in Rust allow code to be organized for readability and controlled for privacy. A package contains one or more crates and contains a Cargo.toml file.</p> <ul> <li>mod declares a module, which can be nested</li> <li>crate is the root of the module tree, equivalent to <code>cd /</code></li> <li>super moves up the module tree one node, similar to <code>cd ..</code></li> <li>use .. as is similar to creating a shortcut or symlink. Rust convention is to bring a function's parent into scope in order to mark function calls as unmistakeably belonging to external code. However, for structs and other data structures the full path is specified.sdfsdf</li> <li>pub use statements are used to construct a convenient API by allowing the namespace to be flattened</li> </ul>"},{"location":"Rust/Crates/#rust-2018","title":"Rust 2018","text":"<p>The module system was simplified in Rust 2018.</p> <p>One of the main changes was the elimination of the <code>extern crate</code> keywords which used to be necessary while importing a crate into a project. The only thing that is necessary now is to add the crate to Cargo.toml</p>"},{"location":"Rust/Error/","title":"Error handling","text":"<p>Error handling in Rust is closely tied to a specific type, the Result enum: <pre><code>enum Result&lt;T, E&gt; {\nOk(T),\nErr(E),\n}\n</code></pre> Plainly, Results encapsulate the success or failure of an operation, and the idiomatic \"Rustic\" way to return a value from a function is to wrap it in Ok (or an error wrapped in Err).</p> <p>Results expose many methods to handle errors.  Some like unwrap and expect are familiar to Rust learners, and they are commonly used at the beginning stages of development as crude forms of error handling.</p> <p>Other methods include the family of combinators which allow operations to be conducted on wrapped values, including errors, and for these operations to be chained together in a way that is fluent and intuitive.</p> <p>Rust distinguishes between recoverable and unrecoverable errors. Recoverable errors can be handled by program logic, whereas unrecoverable errors result in a crash (ref. panic).</p>"},{"location":"Rust/Error/#question-mark-operator","title":"Question mark operator","text":"<p>The question mark operator (?) is used only within the body of functions that return Results and only at the end of function calls that also return results. It is similar to using a match expression in that the value wrapped by Result is returned to the calling code. </p> <pre><code>fn main() {\nmatch outer() {\nErr(e) =&gt; eprintln!(\"inner() returned an error!\"),\n_ =&gt; println!(\"No error!\")\n};\n}\n\nfn outer() -&gt; Result&lt;T, E&gt; {\nlet value = inner()?; // (1)\n}\n\nfn inner() -&gt; Result&lt;T, E&gt; {\nErr()\n}\n</code></pre> <ol> <li>If inner() returns an Error (which it does), it is immediately returned as the return value of outer()</li> </ol> <p>If the error types are mismatched then the compiler will automatically attempt to convert them using from, so the From trait for the inner error type should be implemented for the outer error type.</p> <pre><code>use std::io;\nuse std::io::Read;\nuse std::fs::File;\n\nfn read_username_from_file() -&gt; Result&lt;String, io::Error&gt; {\nlet mut s = String::new();\nFile::open(\"hello.txt\")? // (1)\n.read_to_string(&amp;mut s)?; // (2)\nOk(s)\n}\n</code></pre> <ol> <li>Equivalent to: <pre><code>let mut f = match File::open(\"hello.txt\") {\nOk(file) =&gt; file,\nErr(e) =&gt; return Err(e),\n};\n</code></pre></li> <li>Equivalent to: <pre><code>let mut s = String::new();\nmatch f.read_to_string(&amp;mut s) {\nOk(_) =&gt; Ok(s),\nErr(e) =&gt; Err(e),\n}\n</code></pre></li> </ol>"},{"location":"Rust/Error/#combinators","title":"Combinators","text":"<p>Combinators are a functional programming approach to error handling that use a variety of Result methods to run operations on wrapped types, especially errors.</p>"},{"location":"Rust/Error/#and_then","title":"and_then","text":"<p>The and_then combinator can be used to take a value wrapped in Ok and pass it to another function. An error short circuits this method and is returned immediately.</p> <p>Here, it is used trivially to display a greeting after receiving a string interactively.</p> <pre><code>fn main() {\nget_name().and_then(display_name);\n}\n\nfn get_name() -&gt; Result&lt;String, std::io::Error &gt; {\nlet mut name = String::new();\nstd::io::stdin().read_line(&amp;mut name)?;\nOk(name.trim().to_string())\n}\n\nfn display_name(name: String) -&gt; Result&lt;(), std::io::Error&gt; {\nprintln!(\"Hello, {}!\", name);\nOk(())\n}\n</code></pre> <p>and_then also figures prominently in Ken Youens-Clark's Command-Line Rust, where he uses it to pass a Config object containing values parsed from the command-line using clap.</p> Standard entrypoint in KYC's Rust CLI programs<pre><code>fn main() {\nif let Err(e) = catr::get_args().and_then(catr::run) {\neprintln!(\"{}\", e);\nstd::process::exit(1);\n}\n}\n</code></pre>"},{"location":"Rust/Error/#map","title":"map","text":"<p>The map combinator runs a function on the wrapped value, changing its type, or passes along the Error.</p> Naivemap() <pre><code>struct Person {\nname: String,\nage: i32,\n}\n\nfn display(person: Option&lt;Person&gt;) {\nmatch person {\nSome(person) =&gt;println!(\"{:?}\",person),\nNone =&gt; println!(\"No person\")\n}\n}\n\nfn main() {\nlet person = Some(Person {\nname: \"Amita\".to_string(),\nage: 16\n});\n\ndisplay(person);\n}\n</code></pre> <pre><code>struct Person {\nname: String,\nage: i32,\n}\n\nfn display(person: Option&lt;Person&gt;) {\nlet result: Option&lt;String&gt; = person.map(|p| p.name)\n.filter(|x| x.contains(\"Ami\"))\n.take();\nprintln!(\"{:?}\", result.unwrap());\n}\n\nfn main() {\nlet person: Option&lt;Person&gt; = Some(Person {\nname: \"Amita\".to_string(),\nage: 16,\n});\n\ndisplay(person);\n}\n</code></pre>"},{"location":"Rust/Glossary/","title":"Glossary","text":"Associated type <p>Associated types connect a type placeholder with a trait such that the trait method definitions use these placeholder types in their signatures.</p> <p>With generics, we must annotate the types in each implementation, but using an associated type forces a single implementation.</p> Associated typeGeneric <pre><code>pub trait Iterator {\ntype Item;\nfn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;;\n}\n</code></pre> <pre><code>pub trait Iterator&lt;T&gt; {\nfn next(&amp;mut self) -&gt; Option&lt;T&gt;;\n}\n</code></pre>"},{"location":"Rust/Glossary/#attribute","title":"Attribute","text":"<p>There are several types of attribute:</p> <ul> <li>Inner attributes apply to the item that the attribute is declared in and begin with a shebang Feature flags<pre><code>#![feature(proc_macro_hygiene, decl_macro)]\n</code></pre> Suppress compiler warnings about unused variables<pre><code>#![allow(unused_variables)]\n</code></pre></li> <li>Outer attributes apply to the item that directly follows the attribute Allow pretty printing of a struct<pre><code>#[derive(Debug)]\n</code></pre> Suppress warnings about unused functions<pre><code>#[allow(dead_code)\n</code></pre></li> </ul>"},{"location":"Rust/Glossary/#box","title":"Box","text":"<p>The most straightforward and commonly used smart pointer, allowing data to be stored on the heap rather than the stack. Boxes can be dereferenced just like references.</p> <pre><code>let x = 5;\nlet y = Box::new(x); // Equivalent to: let y = &amp;x;\nassert_eq!(5, *y);\n</code></pre>"},{"location":"Rust/Glossary/#cell","title":"Cell","text":"<p><code>Cell&lt;T&gt;</code> is a smart pointer that allows mutation inside an immutable struct (\"interior mutability\").</p> <p>To access the referenced value, unlike other pointers it does not take the dereferencing operator <code>*</code> but exposes various getter and setter methods such as get(), set(), etc.</p> <pre><code>use std::cell::Cell;\n\nfn main() {\nlet num: i8 = 20;\nlet cell: Cell&lt;i8&gt; = Cell::new(num);\nprintln!(\"Value of number: {}\", num);\nprintln!(\"Value of cell:   {}\", cell.get());\n}\n</code></pre> <p>Immutable structs can be made partially mutable using Cells. In this example, the crew value is changed despite the fact that the object is immutable. Cell is used less often than the similar RefCell</p> CellRefCell <pre><code>use std::cell::Cell;\n#[derive(Debug)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: Cell&lt;i16&gt;\n}\n\nfn main() {\nlet enterprise = Starship { name : \"USS Enterprise\".to_string(), registry : \"NCC-1701\".to_string(), crew : Cell::new(400)\n};\ndbg!(&amp;enterprise);\nenterprise.crew.set(405);\ndbg!(&amp;enterprise);\n}\n</code></pre> <pre><code>use std::cell::RefCell;\n#[derive(Debug)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: RefCell&lt;i16&gt;\n}\n\nfn main() {\nlet enterprise = Starship { name : \"USS Enterprise\".to_string(), registry : \"NCC-1701\".to_string(), crew : RefCell::new(400)\n};\ndbg!(&amp;enterprise);\n*enterprise.crew.borrow_mut() = 405;\ndbg!(&amp;enterprise);\n}\n</code></pre>"},{"location":"Rust/Glossary/#clap","title":"Clap","text":"<p>Clap is a CLI framework.</p> <p>Also see structopt.</p>"},{"location":"Rust/Glossary/#closure","title":"Closure","text":"<p>Closures are anonymous functions that can be saved in a variable or passed as arguments to functions. Closure definitions in Rust use pipe characters <code>|</code> to enclose the parameter list, followed by a code block.  Because this code block is placed on the right side of a variable assignment statement, the closing curly bracket is followed by a semicolon. Type annotations are optional with closures because the compiler is typically able to infer type information from the context.</p> ClosureFunction <pre><code>let do_stuff = |arg| {\n// ...\n};\n</code></pre> <pre><code>fn do_stuff(arg: u8) -&gt; u32 {\n// ...\n}\n</code></pre> <p>This variable is then called like a function. <pre><code>do_stuff(\"bla\");\n</code></pre></p> <p>Compute-expensive closures can be memoized by placing them in a struct that caches the resulting value:</p> <pre><code>struct Cacher&lt;T&gt;\nwhere T: Fn(u32) -&gt; u32 {\ncalculation: T,\nvalue: Option&lt;u32&gt;,\n}\n\nimpl&lt;T&gt; Cacher&lt;T&gt;\nwhere T: Fn(u32) -&gt; u32\n{\nfn new(calculation: T) -&gt; Cacher&lt;T&gt; {\nCacher {\ncalculation,\nvalue: None,\n}\n}\n\nfn value(&amp;mut self, arg: u32) -&gt; u32 {\nmatch self.value {\nSome(v) =&gt; v,\nNone =&gt; {\nlet v = (self.calculation)(arg);\nself.value=Some(v);\nv\n}\n}\n}\n}\n</code></pre> <p>Closures can access variables from their environment, or enclosing scope, something which functions are forbidden to do.</p> <p>Here, the compiler will raise an error when using the function and suggest the closure form in the error message.</p> FunctionClosure <pre><code>fn main() {\nlet x = 4;\n\nfn equal_to_x(z: i8) -&gt; bool { z == x }\n\nlet y = 4;\n\nassert!(equal_to_x(y));\n}\n</code></pre> <pre><code>fn main() {\nlet x = 4;\n\nlet equal_to_x(z: i8) = |z| z == x;\n\nlet y = 4;\n\nassert!(equal_to_x(y));\n}\n</code></pre> <p>The <code>move</code>  keyword makes a closure take ownership of all captured variables</p> <p>Here, using <code>move</code> produces a compile-time error because <code>println!()</code> attempts to borrow x after it is moved in the closure definition. Commenting this line removes the error.</p> <code>move</code>Without <code>move</code> <pre><code>fn main() {\nlet x = vec![1, 2, 3];\nlet equal_to_x = move |z| z == x;\nprintln!(\"can't use x here: {:?}\", x);\nlet y = vec![1, 2, 3];\nassert!(equal_to_x(y));\n}\n</code></pre> <pre><code>fn main() {\nlet x = vec![1, 2, 3];\nlet equal_to_x = |z| z == x;\n\nlet y = vec![1, 2, 3];\nassert!(equal_to_x(y));\n}\n</code></pre>"},{"location":"Rust/Glossary/#combinator","title":"Combinator","text":""},{"location":"Rust/Glossary/#copy","title":"Copy","text":"<p>Copy is a trait that is implemented on simple types that are allocated on the stack alone. These types include integer and floating-point number types, char, bool, and fixed-size arrays and tuples.</p> <p>It can be implemented on other types very simply, with the use of derive.</p> Crate <p>A crate is a component of a package which produces a library or executable.</p> <p>There are two types of crate:</p> <ul> <li>Library crates, of which there may at most one in a package</li> <li>Binary crates, of which there may be many in a package</li> </ul> <p>The crate root is the source file that the compiler uses to create the root module of the crate.</p> Custom derive <p>One of the three types of macro in Rust that specifies code added with the <code>derive</code> attribute.</p> <p>Feature where the default implementation of a trait is generated by annotating a struct with an attribute.</p> <p>Here, <code>#[derive(Debug)]</code> supports the use of the <code>{:?}</code> placeholder for pretty-printing.</p> <pre><code>#[derive(Debug)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: i16,\ncaptain: Officer,\nclass: StarshipClass,\n}\n</code></pre> <code>cfg</code> <p>The <code>cfg</code> macro is used for conditional compilation and evaluates configuration at compile-time.</p> <p>Debug-only code not to be used in release builds</p> <pre><code>if cfg!debug_assertions) {\neprintln!(\"debug: {:?} -&gt; {:?}\", record, fields);\n}\n</code></pre> <pre><code>let my_directory = if cfg!(windows) {\n\"windows-specific-directory\"\n} else {\n\"unix-directory\"\n};\n</code></pre>"},{"location":"Rust/Glossary/#dbg","title":"dbg","text":"<p>Not to be confused with the Debug trait, which is used with the normal println!() macro!</p> <p><code>dbg!</code> allows evaluation and printing of expressions during debugging or running with <code>cargo run</code>.</p> CodeOutput <pre><code>fn main() {\nlet mut a:i32 = 0;\nwhile a &lt; 100 {\na += 1;\ndbg!(a);\n}\nprintln!(\"Done\");\n}\n</code></pre> <pre><code>[src/main.rs:5] a = 1\n[src/main.rs:5] a = 2\n[src/main.rs:5] a = 3\n[src/main.rs:5] a = 4\n...\n</code></pre> Enum <p>The variants of an enum can have different types and associated data.</p> <pre><code>enum IpAddr {\nV4 ( u8, u8, u8, u8 ),\nV6(String)\n}\n</code></pre>"},{"location":"Rust/Glossary/#extern","title":"extern","text":"<p><code>extern</code> facilitates the creation and use of FFI.</p> <p>Here, the \"C\" ABI, which specifies how to call the function at the assembly level, is specified: <pre><code>extern \"C\" {\nfn abs(input: i32) -&gt; i32;\n}\n\nfn main() {\nunsafe {\nprintln!(\"Absolute value of -3 according to C: {}\", abs(-3));\n}\n}\n</code></pre></p> <p><code>extern crate</code> specifies a dependency on an external crate. This is no longer needed in Rust since 2018.</p> futures Rust's main mechanism for asynchronous programming, implemented in the Tokio crate"},{"location":"Rust/Glossary/#hashmap","title":"HashMap","text":"<pre><code>use std::collections::HashMap;\n\nlet mut scores = HashMap::new();\n\nscores.insert(String::from(\"Blue\"), 10);\nscores.insert(String::from(\"Yellow\"), 20);\n</code></pre> <p>Hash maps are homogeneous: all keys must be of one type and all values of another. A hash map can be zipped from two vectors:</p> <p><pre><code>use std::collections::HashMap;\n\nlet teams = vec![String::from(\"Blue\"), String::from(\"Yellow\")];\nlet initial_scores = vec![10,50];\n\nlet scores:HashMap&lt;_, _&gt; = teams.iter().zip(initial_scores.iter()).collect();\n</code></pre> For non-Copy types, the hash map becomes the new owner of data values on assignment.</p>"},{"location":"Rust/Glossary/#if-let","title":"if let","text":"<p><code>if let</code> is syntactic sugar for a pattern that matches one pattern while ignoring the rest. Notably, the syntax takes the pattern before the expression similar to a <code>match</code> arm.</p> <p>if let<pre><code>if let Some(3) = some_u8_value {\nprintln!(\"three\");\n}\n</code></pre> match<pre><code>let some_u8_value = Some(0u8);\nmatch some_u8_value {\nSome(3) =&gt; println!(\"three\"),,\n_ =&gt; (),\n}\n</code></pre></p> <p>It is used to provide a default value for a string in the following example.</p> <pre><code>fn main() {\nlet mut name = String::new();\nif let Some(s) = std::env::args().nth(1) {\nname = s;\n} else {\nname = String::from(\"World\");\n}\nprintln!(\"Hello, {}!\", name);\n}\n</code></pre>"},{"location":"Rust/Glossary/#iterator","title":"Iterator","text":"<p>The iterator pattern is one that allows logic to be performed on a sequence of items in turn.</p> <p>An iterator in Rust is anything that implements the <code>Iterator</code> trait. This trait only requires implementation of a single method: <code>next()</code>, which returns one item of the iterator at a time wrapped in <code>Some</code> and <code>None</code> when the iterator is consumed.</p> <p>Many types return an iterator by calling the <code>iter()</code> method, which can then be iterated over using a <code>for .. in</code> loop. Alternatively, the <code>next()</code> method can be called directly.</p> Loop<code>next()</code> <pre><code>let v1 = vec![1, 2, 3];\n\nfor i in v1.iter() {\nprintln!(\"{}\", i);\n}\n</code></pre> <pre><code>let v1 = vec![1, 2, 3];\nlet v1_iter = v1.iter();\n\nassert_eq!(v1_iter.next(),Some(&amp;1));\nassert_eq!(v1_iter.next(),Some(&amp;2));\nassert_eq!(v1_iter.next(),Some(&amp;3));\nassert_eq!(v1_iter.next(),None);\n</code></pre> <p>Other methods are defined on the Iterator trait.</p> <ul> <li>Consuming iterators are those that call <code>next()</code>: <ul> <li><code>sum</code></li> <li><code>collect</code>  transforms an iterator into a collection</li> </ul> </li> <li>Iterator adapters change iterators into different kinds of iterators:<ul> <li><code>map</code> </li> <li><code>filter</code> </li> </ul> </li> </ul> summap <pre><code>fn iterator_sum() {\nlet v1 = vec![1, 2, 3];\n\nlet total: i32 = v1.iter().sum();\nassert_eq!(total, 6);\n}\n</code></pre> <pre><code>fn main() {\nlet v1 = vec![1, 2, 3];\nlet v2 : Vec&lt;_&gt; = v1.iter().map(|x| x + 1).collect();\nlet total: i32 = v2.iter().sum();\nprintln!(\"{}\", total);\n}\n</code></pre> <p>Notably, a for loop consumes an iterator because it is implicitly converted to an iterator with into_iter().</p> ErrorCorrect <pre><code>fn main () {\nlet v = vec!['H','e','l','l','o'];\nfor i in v {\nprint!(\"{}\", i);\n} println!();\n\nprintln!(\"{:?}\", v); // (1)\n}\n</code></pre> <ol> <li>Because each value of the vector is moved, it is consumed. The compiler will produce error E0382 at this line.</li> </ol> <pre><code>fn main () {\nlet v = vec!['H','e','l','l','o'];\nfor i in &amp;v {\nprint!(\"{}\", i);\n} println!();\n\nprintln!(\"{:?}\", v);\n}\n</code></pre>"},{"location":"Rust/Glossary/#lifetimes","title":"Lifetimes","text":"<p>Every reference must have a lifetime, which helps the compiler avoid dangling references, a known source of bugs and vulnerabilities.</p> <p>The Rust compiler has a borrow checker that compares scopes to ensure that all scopes are valid. But when a function has references to code from outside the function, it is impossible for Rust to determine the lifetimes of parameters or return values on its own.</p> <p>Reference parameters must be annotated with lifetime annotations with an unusual syntax using a single single-quotation character <code>'</code> followed by a very short identifier, conventionally the letter a:</p> <p><pre><code>&amp;i32        // immutable reference\n&amp;'a i32     // immutable reference with explicit lifetime\n&amp;'a mut i32 // mutable reference with explicit lifetime\n</code></pre> However, lifetime annotations are only understood in a function signature where more than one is used. </p> <p>This example tells the compiler that the function takes two parameters and returns a value that all live at least as long as lifetime <code>'a</code>. When concrete references are passed to this function, the smaller of the two concrete lifetimes passed in the arguments is substituted for the generic value:</p> <pre><code>fn do_something&lt;'a&gt;(x: &amp;'a str, y: &amp;'a str) -&gt; &amp;'a str { // --snip--\n}\n</code></pre> <p>The lifetime for the returned value must match that of one of the parameters.  If not, the value would necessarily refer to a value created within the function, which would go out of scope at the end of the function and creating a dangling reference.</p> <p>Structs that hold references must also hold lifetime annotations and cannot outlive the referenced values. Function definitions also take the lifetime annotation on the <code>impl</code> keyword, i.e. <code>impl&lt;'a&gt;</code></p> structmethod <pre><code>struct Starship&lt;'a&gt; {\nname: &amp;'a str\n\n}\n\nfn main() {\nlet name = \"USS Enterprise\";\nlet enterprise = Starship{ name: &amp;name };\nprintln!(\"{}\", enterprise.name); // =&gt; \"USS Enterprise\"\n}\n</code></pre> <pre><code>struct Starship&lt;'a&gt; {\nname: &amp;'a str,\nregistry: &amp;'a str,\n}\n\nimpl&lt;'a&gt; std::fmt::Display for Starship&lt;'a&gt; {\nfn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; std::fmt::Result {\nwrite!(f, \"{} {}\", self.name, self.registry)\n}\n}\n\nfn main() {\nlet name = \"USS Enterprise\";\nlet registry = \"NCC-1701\";\nlet enterprise = Starship { name: &amp;name , registry: &amp;registry};\nprintln!(\"{}\", enterprise); // =&gt; \"USS Enterprise NCC-1701\"\n}\n</code></pre>"},{"location":"Rust/Glossary/#macro","title":"macro","text":"<p>Referring to a family of features in Rust:</p> <ul> <li>Declarative macros with <code>macro_rules!</code></li> <li> <p>procedural macros:</p> <ul> <li>Custom <code>#[derive]</code> macros that specify code added with the <code>derive</code> attribute used on structs and enums</li> <li>Attribute-like macros that define custom attributes usable on any item</li> <li>Function-like macros that look like function calls but operate on the tokens specified as their argument</li> </ul> </li> <li> <p>[assert!()]](https://doc.rust-lang.org/std/macro.assert.html) invoke panic!() if the provided expression cannot be evaluated to true at runtime</p> </li> <li>cfg!() compiles code based on compile-time evaluation of configuration</li> <li>dbg!()</li> <li>eprintln!() print to STDERR</li> <li>format!() concatenate strings</li> <li>panic!() terminates the program with code 101 and should be used when the program reaches an unrecoverable state</li> <li>println!() print to STDOUT</li> <li>[unimplemented!()]](https://doc.rust-lang.org/core/macro.unimplemented.html)</li> <li>try!() for which the <code>?</code> operator is syntactic sugar</li> </ul>"},{"location":"Rust/Glossary/#match","title":"match","text":"<p><code>match</code> is a powerful control flow operator that resembles a <code>switch</code> statement. <code>match</code> works on integers, ranges of integers, bools, enums, tuples, arrays, and structs. <code>match</code> allows a value to be compared against a series of patterns, which can be literal values as well as numerous other things. Each pattern is within a <code>match</code> arm, which is composed of the pattern and some code, here an expression.</p> <p>Recursive Fibonacci sequence implementation:</p> if/else<code>match</code> <pre><code>const FIB_ZERO: u64 = 1;\nconst FIB_ONE: u64 = 1;\n\nfn fib(n: u64) -&gt; u64 {\nif n == 0 {\nFIB_ZERO\n} else if n==1 {\nFIB_ONE\n} else {\nfib(n-1) + fib(n-2)\n}\n}\n\nfn main() {\nlet n: u64 = std::env::args().nth(1).unwrap().parse().unwrap();\nfor i in 1..n {\nprintln!(\"{}: {}\", i, fib(i));\n}\n}\n</code></pre> <pre><code>const FIB_ZERO: u64 = 1;\nconst FIB_ONE: u64 = 1;\n\nfn fib(n: u64) -&gt; u64 {\nmatch n {\n0 =&gt; FIB_ZERO,\n1 =&gt; FIB_ONE,\n_ =&gt; fib(n-1) + fib(n-2)\n}\n}\nfn main() {\nlet n: u64 = std::env::args().nth(1).unwrap().parse().unwrap();\nfor i in 1..n {\nprintln!(\"{}: {}\", i, fib(i));\n}\n}\n</code></pre> <p>Patterns can also bind to parts of the values that match the pattern.</p> Simple enumNested enum <pre><code>enum Coin {\nPenny,\nNickel,\nDime,\nQuarter\n}\n\n\n\n\n\n\n\nfn value_in_cents(coin: Coin) -&gt; u8 {\nmatch coin {\nCoin::Penny =&gt; 1,\nCoin::Nickel =&gt; 5,\nCoin::Dime =&gt; 10,\nCoin::Quarter =&gt; 25,\n\n\n\n}\n}\n</code></pre> <pre><code>enum Coin {\nPenny,\nNickel,\nDime,\nQuarter(UsState)\n}\n\nenum UsState {\nAlabama,\nAlaska,\n// --snip--\n}\nfn value_in_cents(coin: Coin) -&gt; u8 {\nmatch coin {\nCoin::Penny =&gt; 1,\nCoin::Nickel =&gt; 5,\nCoin::Dime =&gt; 10,\nCoin::Quarter =&gt; {\nprintln!(\"State quarter from {:?}!\", state);\nreturn 25;\n}\n}\n}\n</code></pre> <p>In this example, the match statement only announces when a <code>Coin::Quarter(state)</code> is encountered, but all other cases are handled by the placeholder <code>_</code>. The <code>if let</code> syntax is equivalent:</p> matchif let <pre><code>let mut count = 0;\nmatch coin {\nCoin::Quarter(state) =&gt; println!(\"State quarter from {:?}!\", state),\n_ =&gt; count += 1,\n}\n</code></pre> <pre><code>let mut count = 0;\nif let Coin::Quarter(state) = coin {\nprintln!(\"State quarter from {:?}!\", state);\n} else {\ncount += 1;\n}\n</code></pre>"},{"location":"Rust/Glossary/#option","title":"Option","text":"<p><pre><code>enum Option&lt;T&gt; {\nSome(T),\nNone\n}\n</code></pre> Option serves as a wrapper around a value.</p> <p>Rust doesn't have the same implementation of null values that other languages do because handling null values is complicated and when unexpected they cause bugs. Rather than null values, Rust implements null as a variant <code>None</code> of the enum <code>Option&lt;T&gt;</code></p> <p>The reason for this is because Rust conventionally handles enums in a <code>match</code> statement, which requires exhaustive enumeration of all possible cases. The compiler itself will raise an error if you compose a match statement which leaves some potential cases unhandled.</p>"},{"location":"Rust/Glossary/#rc","title":"Rc","text":"<p><code>Rc&lt;T&gt;</code> is a reference-counting pointer that will keep track of how many owners it has. This number is exposed using Rc::strong_count(), passing a reference to the Rc pointer being interrogated.</p> <p>This smart pointer allows multiple owners of the same value. However, the dereferenced value may not be modified because the DerefMut trait is not implemented for Rc.</p> <pre><code>use std::rc::Rc;\n\nfn main() {\nprintln!(\"Hello, world!\");\nlet num: i8 = 7;\nlet pointer1: Rc&lt;i8&gt; = Rc::new(num);\nlet pointer2: Rc&lt;i8&gt; = Rc::clone(&amp;pointer1);\nlet pointer3: Rc&lt;i8&gt; = Rc::clone(&amp;pointer2);\n*pointer3 += 1; // Error!\nprintln!(\"Number of references: {}\", Rc::strong_count(&amp;pointer1)); // 3\nprintln!(\"Value of num: {}\", *pointer1);\n}\n</code></pre> <p>To achieve interior mutability, Rc is paired with RefCell or Cell.</p>"},{"location":"Rust/Glossary/#refcell","title":"RefCell","text":"<p>RefCell is a mutable memory location with dynamically checked borrow rules (i.e. at runtime). Unlike the getter and setter methods of its cousin Cell, RefCell can be treated like any pointer by using the dereferencing operator <code>*</code>. RefCell does expose methods that determine how the wrapped value is returned.</p> <p>The <code>borrow_mut()</code> method is used to change the value of a RefCell which must be dereferenced because it returns a memory location.</p> RefCellCell <pre><code>use std::cell::RefCell;\n#[derive(Debug)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: RefCell&lt;i16&gt;\n}\n\nfn main() {\nlet enterprise = Starship { name : \"USS Enterprise\".to_string(), registry : \"NCC-1701\".to_string(), crew : RefCell::new(400)\n};\ndbg!(&amp;enterprise);\n*enterprise.crew.borrow_mut() = 405;\ndbg!(&amp;enterprise);\n}\n</code></pre> <pre><code>use std::cell::Cell;\n#[derive(Debug)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: Cell&lt;i16&gt;\n}\n\nfn main() {\nlet enterprise = Starship { name : \"USS Enterprise\".to_string(), registry : \"NCC-1701\".to_string(), crew : Cell::new(400)\n};\ndbg!(&amp;enterprise);\nenterprise.crew.set(405);\ndbg!(&amp;enterprise);\n}\n</code></pre> <p>Here a mutable struct is owned by two Rc pointers, and a change applied through one pointer can be investigated using the other one. Note that there is no dereferencing operator because the Rc itself points to the RefCell which returns a memory location.</p> <pre><code>use std::rc::Rc;\nuse std::cell::RefCell;\n\n#[derive(Debug)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: i16\n}\n\nfn main() {\nlet enterprise = Starship {\nname: \"USS Enterprise\".to_string(),\nregistry: \"NCC-1701\".to_string(),\ncrew: 400\n};\n\nlet enterprise_ptr1 = Rc::new(RefCell::new(enterprise));\nlet enterprise_ptr2 = Rc::clone(&amp;enterprise_ptr1);\n\nenterprise_ptr1.borrow_mut().crew=405;\ndbg!(&amp;enterprise_ptr2);\n}\n</code></pre> <p>I'm not sure what to make of this...</p> VectorRefCell <pre><code>use std::cell::RefCell;\nuse std::rc::Rc;\n\nfn main () {\nlet v = vec!['H','e','l','l','o'];\n\nfor i in v {\nprint!(\"{}\", i);\n}\nprintln!(\"\");\n}\n</code></pre> <pre><code>use std::cell::RefCell;\nuse std::rc::Rc;\n\nfn main () {\nlet ptr = Rc::new(RefCell::new(vec!['H','e','l','l','o']));\n\nfor i in &amp;*ptr.borrow() { // (1)\nprint!(\"{}\", i);\n}\nprintln!(\"\");\n}\n</code></pre> <ol> <li>A for loop in Rust consumes the iterable's elements because it is really a syntactic sugar for a call to IntoIterator, which Vector implements. In other words the values are moved.</li> </ol>"},{"location":"Rust/Glossary/#result","title":"Result","text":"See Error handling"},{"location":"Rust/Glossary/#smart-pointer","title":"Smart pointer","text":"<p>Smart pointers are data structures that act like references (which is but one of and the simplest pointer) but provide additional functionality and metadata. The smart pointer pattern is used frequently in Rust.</p> <p>In Rust, smart pointers are structs that implement two traits: Deref (which allows an instance of the smart pointer struct to behave like a reference) and Drop (which allows you to run custom logic when the pointer goes out of scope)</p> <p>Here a custom pointer is implemented.</p> <pre><code>struct MyBox&lt;T&gt;(T) {\ndata: String,\n}\n\nimpl&lt;T&gt; MyBox&lt;T&gt; {\nfn new(x: T) -&gt; MyBox&lt;T&gt; {\nMyBox(x)\n}\n}\n\nimpl&lt;T&gt; std::ops::Deref for MyBox&lt;T&gt; {\n// Define an **associated type** for the Deref trait to use\ntype Target = T; fn deref(&amp;self) -&gt; &amp;T {\n&amp;self.0\n}\n}\n\nimpl&lt;T&gt; Drop for MyBox&lt;T&gt; {\nfn drop(&amp;mut self) {\nprintln!(\"Dropping MyBox\");\n}\n}\n</code></pre> <p>Now the smart pointer supports the dereferencing operator <code>*</code> and a message is displayed when it goes out of scope.</p> <pre><code>fn main() {\nlet x = 5;\nlet y = MyBox::new(x);\nassert_eq!(5, *y); // (1)\n}\n</code></pre> <ol> <li>Behind the scenes, the compiler is really dereferencing the value returned by <code>deref()</code>: <pre><code>*(y.deref())\n</code></pre></li> </ol> <p>The <code>drop()</code> method cannot be called explicitly in order to avoid the double free error that would occur when the variable eventually goes out of scope. Alternatively, <code>std::mem::drop()</code> (already in the prelude) can be called explicitly.</p> <pre><code>drop(y);\n</code></pre> <p>Other smart pointers in the standard library include:</p> <ul> <li>Box</li> <li><code>Rc&lt;T&gt;</code> which enables multiple owners of the same data and is used to count references, but only in single-threaded contexts</li> <li><code>RefCell&lt;T&gt;</code> which enforces borrowing rules but only at runtime</li> </ul>"},{"location":"Rust/Glossary/#string","title":"String","text":"<p>The String type provided by Rust's standard library is implemented as a series of bytes and is distinct from string slices (<code>&amp;str</code>) which are implemented in the core language.</p> <p>Strings can be initialized with the <code>new()</code> method just like vectors.</p> <p>String slices expose a <code>to_string()</code> method for conversion to a String. Alternatively, you can use <code>String::from()</code> to convert a string slice to a string.</p> to_stringString::from() <pre><code>let s = \"initial contents\".to_string();\n</code></pre> <pre><code>let s = String::from(\"initial contents\");\n</code></pre> <p>Mutable strings can be concatenated with the <code>push_str()</code> method or with the <code>+</code> operator, which results in a move of the left operand and requires a reference for the right operand. The <code>format!</code> macro, which returns a String, is also available for more complicated concatenations.</p> push_str<code>+</code> operator <pre><code>let mut s = String::from(\"Hello, \");\ns.push_str(\"world!\");\n</code></pre> <pre><code>let s1 = String::from(\"Hello, \");\nlet s2 = String::from(\"world!\");\nlet s = s1 + &amp;s2;\n</code></pre> <p>Strings do not support indexing because they do not have the <code>std::ops::Index</code> trait. However, the <code>chars()</code> method returns an iterator that can be looped:</p> <pre><code>for c in \"Hello, world!\".chars() {\nprintln!(\"{}\", c);\n}\n</code></pre> <p>String slices can be generated from Strings using slice operator <code>..</code>, which is equivalent to the <code>:</code> operator in languages like Python.</p> <pre><code>let s = String::from(\"Hello, world!\");\nlet w1 = s[..5]; // equivalent to s[0..5]\nlet w2 = s[7..]; // equivalent to s[7..len]\n</code></pre> <p>Because the compiler implicitly converts String to <code>&amp;str</code>, as a practical matter functions that accept strings should be refactored to accept string slices.</p> <p>Strings must be initialized with the constructor. In the following example, for some reason, the compiler produces a \"borrow after move\" error if the constructor is not called. This might be because without the constructor, the <code>Copy</code> trait is not implemented in the initialized object.</p> Compiler errorNo error <pre><code>fn main() {\nlet mut v: Vec&lt;String&gt; = Vec::new();\n\nloop {\nlet mut input: String;\nprintln!(\"Enter to-do list item ('q' to quit): \");\nstd::io::stdin().read_line(&amp;mut input).unwrap();\nmatch input.trim() {\n\"q\" =&gt; break,\ns =&gt; v.push(s.trim().to_string()),\n}\n}\nfor i in v {\nprintln!(\"{}\", i);\n}\n}\n</code></pre> <pre><code>fn main() {\nlet mut v: Vec&lt;String&gt; = Vec::new();\n\nloop {\nlet mut input: String = String::new();\nprintln!(\"Enter to-do list item ('q' to quit): \");\nstd::io::stdin().read_line(&amp;mut input).unwrap();\nmatch input.trim() {\n\"q\" =&gt; break,\ns =&gt; v.push(s.trim().to_string()),\n}\n}\nfor i in v {\nprintln!(\"{}\", i);\n}\n}\n</code></pre> <p>String methods:</p> <ul> <li><code>push_str</code> append a string slice</li> <li><code>lines</code> returns an iterator of string slices</li> <li><code>replace</code> replace a pattern     <pre><code>let s = String::from(\"Hello, World!\");\nlet s = &amp;s.replace(\"World\", \"Planet\");\n</code></pre></li> </ul>"},{"location":"Rust/Glossary/#struct","title":"Struct","text":"..."},{"location":"Rust/Glossary/#structopt","title":"structopt","text":"<p>structopt is a CLI framework.</p> <p>Also see clap.</p>"},{"location":"Rust/Glossary/#trait","title":"Trait","text":"<p>A trait defines functionality that can be shared with many types in a way that recalls dunder methods in Python.</p> <p>For example, default output to the terminal using println!() is implemented in the Display trait (analogous to the __str__ method in Python).</p> Display trait<pre><code>struct Starship&lt;'a&gt; {\n// --snip--\n}\n\nimpl&lt;'a&gt; std::fmt::Display for Starship&lt;'a&gt; {\nfn fmt(&amp;self, f: &amp;mut std::fmt::Formatter) -&gt; std::fmt::Result {\nwrite!(f, \"{} {}\", self.name, self.registry)\n}\n}\n\nfn main() {\nlet enterprise = Starship::new();\nprintln!(enterprise);\n}\n</code></pre> <p>A trait defines the signature of a method intended to be implemented by many types, similar to virtual methods or interfaces.</p> <p>Traits are implemented in impl blocks that specify the type.</p> <pre><code>trait Summary {\nfn summary(&amp;self) -&gt; String; // (1)\n}\n\nimpl Summary for NewsArticle {\nfn summary(&amp;self) -&gt; &amp;str {\nformat!(\"{}, by {} ({})\", self.headline, self.author, self.location);\n}\n}\n</code></pre> <ol> <li>A trait definition looks similar to the signature of a function with no code block.</li> </ol> <p>Default implementations of a trait can be provided in the trait definition.</p> <pre><code>pub trait Summary {\nfn summarize(&amp;self) -&gt; String {\nString::from(\"(Read more...)\");\n}\n}\n</code></pre> <p>Common traits include: Copy, Deref, Drop, Display, Fn, and Iterator</p> <p>Implementing a trait:</p> <pre><code>#[derive(Debug)]\nstruct Wrapper {\nwrapped: String\n}\n\nimpl std::convert::From&lt;String&gt; for Wrapper {\nfn from(item: String) -&gt; Self {\nWrapper { wrapped: item }\n}\n}\n\nimpl std::convert::From&lt;Wrapper&gt; for String {\nfn from(item: Wrapper) -&gt; String {\nitem.wrapped\n}\n}\n\nfn main() {\nlet bar = String::from(\"Bar\");\nprintln!(\"{:?}\", Foo::from(bar));\n\nlet wrapper = Wrapper { wrapped: String::from(\"Hello, World!\") };\nprintln!(\"{}\", String::from(wrapper));\n}\n</code></pre> trait bound <p>A trait bound allows functions to accept any type that implements a trait.  Multiple traits by delimiting trait names with <code>+</code>. A simpler syntax accommodates simple cases by specifying the <code>impl</code> keyword followed by the trait name, rather than a concrete type.</p> Trait boundSyntactic sugar <pre><code>pub fn notify&lt;T: Summary&gt;(item: T) { // ...\npub fn notify&lt;T: Summary + Display&gt;(item: T) { // ...\n</code></pre> <pre><code>pub fn notify(item: impl Summary) { // ...\npub fn notify(item: impl Summary + Display) { // ...\n</code></pre> <p>Multiple trait bounds can clutter the function signature, reducing legibility. In these cases, a <code>where</code> clause can be used:</p> <pre><code>fn some_function&lt;T, U&gt;(t: T, u: U) -&gt; i32\n    where T: Display + Clone,\nU: Clone + Debug\n{ // ...\n</code></pre> <p>The <code>impl Trait</code> syntax is also available for return values:</p> <pre><code>fn returns_summarizable() -&gt; impl Summary { // ...\n</code></pre>"},{"location":"Rust/Glossary/#tuple-struct","title":"Tuple struct","text":"<p>Tuple structs are constructed using the struct keyword and function similar to named tuples in other languages. Their fields are not named but rather numbered.</p> <pre><code>enum Cargo { Stuff, Things, Crap }\n\nimpl From&lt;Cargo&gt; for String {\nfn from(item: Cargo) -&gt; String {\nmatch item {\nCargo::Stuff =&gt; String::from(\"stuff\"),\nCargo::Things =&gt; String::from(\"things\"),\nCargo::Crap =&gt; String::from(\"crap\"),\n}\n}\n}\n\nstruct Ship(Cargo);\nstruct Train(Cargo);\nstruct Truck(Cargo);\n\nfn main () {\nlet freight = Truck(Cargo::Stuff);\nprintln!(\"We got a truckload of {}\", String::from(freight.0));\n}\n</code></pre>"},{"location":"Rust/Glossary/#vector","title":"Vector","text":"<p>A vector is most often built using the vec! macro or by instantiating it and adding elements with push() method.</p> <pre><code>let v = vec![1, 2, 3];\n\nlet mut v = Vec::new();\nv.push(1);\nv.push(2);\nv.push(3);\n</code></pre> <p>Referencing elements can be done with the index operator, which panics on an invalid index, or the <code>get()</code> method, which returns None without panicking.</p> <pre><code>let invalid = &amp;v[100];\n\nlet invalid = v.get(100);\n</code></pre> <p>The <code>for .. in</code> loop works well with a vector. If vector elements are going to be changed, the reference must be made mutable and the dereference operator must be used.</p> ImmutableMutable <pre><code>let v = vec![100, 32, 57];\nfor i in &amp;v {\nprintln!(\"{}\", i);\n}\n</code></pre> <pre><code>let v = vec![100, 32, 57];\nfor i in &amp;mut v {\n*i += 50;\n}\n</code></pre> <p>Although a vector's elements must be of the same type, because enum variants can be associated with a type and value they can be combined with <code>match()</code> to create collections with many types.</p> <pre><code>enum SpreadsheetCell {\nInt(i32),\nFloat(f64),\nText(String)\n}\n\nlet row = vec![\nSpreadsheetCell::Int(3),\nSpreadsheetCell::Text(String::from(\"blue\")),\nSpreadsheetCell::Float(10.12),\n]\n</code></pre> <p>Methods:</p> <ul> <li>reserve  reserves space in memory for more elements, greater than or equal to <code>self.len()</code> + argument (<code>usize</code>)</li> </ul>"},{"location":"Rust/Scratchpad/","title":"Scratchpad","text":""},{"location":"Rust/Scratchpad/#errors","title":"Errors","text":"<pre><code>fn main() {\ndo_error().expect(\"Error!\");\n}\n\nfn do_error() -&gt; Result&lt;String, String&gt; {\nErr(\"This error is on purpose!\".to_string())\n}\n</code></pre>"},{"location":"Rust/Crates/Actix/","title":"actix","text":""},{"location":"Rust/Crates/Actix/#tasks","title":"Tasks","text":""},{"location":"Rust/Crates/Actix/#hello-world","title":"Hello, World!","text":"<pre><code>use actix_web::{App, HttpServer};\nuse actix_web::{web, HttpResponse, Responder};\n\n#[actix_web::main]\nasync fn main() -&gt; std::io::Result&lt;()&gt; {\nHttpServer::new(|| {\nApp::new()\n.route(\"/\", web::get().to(hello))\n})\n.bind((\"127.0.0.1\", 8000))? // (1)\n.run()\n.await\n}\n\nasync fn hello() -&gt; impl Responder {\nHttpResponse::Ok().body(\"Hello, World!\")\n}\n</code></pre> <ol> <li>Note the address and port can be defined as a tuple or as a string <pre><code>.bind(\"127.0.0.1:8000\")?\n</code></pre></li> </ol>"},{"location":"Rust/Crates/Actix/#static-file-server","title":"Static file server","text":"<pre><code>use actix_web::{App, HttpServer};\nuse actix_files::Files;\n\n#[actix_web::main]\nasync fn main() -&gt; std::io::Result&lt;()&gt; {\nHttpServer::new(|| {\nApp::new()\n.service(Files::new(\"/\", \"./static/\").index_file(\"index.html\"))\n.wrap(actix_web::middleware::Logger::default())\n})\n.bind((\"127.0.0.1\", 8000))? .run()\n.await\n}\n</code></pre>"},{"location":"Rust/Crates/Clap/","title":"clap","text":"<p>Clap is a command-line parser with both declarative (preferred, using Parser) and procedural APIs.</p> DeclarativeProcedural <pre><code>use clap::Parser; // (1)\n\n#[derive(Parser)]\n#[clap(name = \"Hello, World!\", version, author)] // (2)\nstruct Cli {\n#[clap(short, long, default_value_t = String::from(\"Hello\"))]\ngreeting: String,\n\n#[clap(default_value_t = String::from(\"World\"))]\nname: String,\n}\n\nfn main() {\nlet cli = Cli::parse();\nprintln!(\"{}, {}!\", cli.greeting, cli.name);\n}\n</code></pre> <ol> <li>Parser requires the derive and std features: Cargo.toml<pre><code>clap = { version = \"3.0.12\", features = [\"std\", \"derive\"], default-features = false}\n</code></pre></li> <li>Without providing arguments to version or author, the relevant values will be pulled from the crate itself, similar to the crate_authors and crate_version macros for the procedural API.</li> </ol> <pre><code>use clap::{App, Arg, crate_version, crate_authors};\n\nfn main() {\nlet args = App::new(\"Say hello\")\n.version(crate_version!()) // (1)\n.author(crate_authors!())\n.arg(Arg::new(\"name\") // (2)\n.default_value(\"World\")\n.arg(Arg::new(\"greeting\")\n.default_value(\"Hello\")\n.short('g')\n.long(\"greeting\")\n.get_matches();\n\nprintln!(\"{}, {}!\", args.value_of(\"greeting\").unwrap(), args.value_of(\"name\").unwrap());\n}\n</code></pre> <ol> <li>The crate_authors and crate_version macros allow you to pull information from the Cargo.toml at compile time.</li> <li>Since clap 3.0.0, new() takes the place of with_name(), which is now deprecated.</li> </ol>"},{"location":"Rust/Crates/Clap/#api","title":"API","text":""},{"location":"Rust/Crates/Clap/#parser","title":"Parser","text":"<p>Using the Parser derive allows command-line arguments and options to be defined on a struct with an attribute. Any Command, Arg, or PossibleValue method can be used as an attribute.</p> OptionCommand <pre><code>use clap::Parser;\n\n#[derive(Parser)]\n#[clap(name = \"Hello, World!\")]\nstruct Args {\n#[clap(short, long, default_value_t = String::from(\"Hello\"))]\ngreeting: String,\n\n#[clap(default_value_t = String::from(\"World\"))]\nname: String,\n}\n\nfn main() {\nlet args = Args::parse();\nprintln!(\"{}, {}!\", args.greeting, args.name);\n}\n</code></pre> <pre><code>use clap::{Parser, Subcommand};\n\n#[derive(Parser)]\n#[clap(name = \"Hello, World!\")]\nstruct Args {\n#[clap(subcommand)]\ngreeting: Greeting,\n\n#[clap(default_value_t = String::from(\"World\"))]\nname: String\n}\n\n#[derive(Subcommand)]\nenum Greeting {\nHello,\nGreetings\n}\n\nfn main() {\nlet args = Args::parse();\nprintln!(\"{}, {}!\", args.greeting, args.name); // (1)\n}\n</code></pre> <ol> <li>This requires the Display trait to be implemented <pre><code>impl std::fmt::Display for Greeting {\nfn fmt(&amp;self, _: &amp;mut std::fmt::Formatter) -&gt; std::fmt::Result {\nmatch self {\nGreeting::Hello =&gt; { print!(\"Hello\"); Ok(()) },\n_               =&gt; { print!(\"Greetings\"); Ok(()) }\n}\n}\n}\n</code></pre></li> </ol>"},{"location":"Rust/Crates/Clap/#clap_app","title":"clap_app","text":"<p>The (now deprecated) clap_app macro was used to create simple applications.</p> <p>Boolean values can be set to true with <code>+</code> and false with <code>!</code>: <pre><code>+required // Arg::required(true)\n!required // Arg::required(false)\n</code></pre></p>"},{"location":"Rust/Crates/Clap/#api_1","title":"API","text":""},{"location":"Rust/Crates/Clap/#parser_1","title":"Parser","text":"<p>ArgEnum and Subcommand can be used in very similar ways. ArgEnum variants do show up in the help output but inline with the Subcommand.</p> ArgEnumSubcommand <pre><code>use clap::{ArgEnum, Parser};\n\n#[derive(Parser)]\nstruct Cli {\n#[clap(arg_enum)]\ncommand: Actions,\n}\n\n#[derive(Copy, Clone, ArgEnum)]\nenum Actions {\nEat,\nDrink,\n}\n\nfn main() {\nlet cli = Cli::parse();\n\nmatch cli.command {\nActions::Eat    =&gt; println!(\"Eating\"),\nActions::Drink  =&gt; println!(\"Drinking\"),\n}\n}\n</code></pre> <pre><code>use clap::{Subcommand, Parser};\n\n#[derive(Parser)]\nstruct Cli {\n#[clap(subcommand)]\ncommand: Actions,\n}\n\n#[derive(Subcommand)]\nenum Actions {\nEat,\nDrink,\n}\n\nfn main() {\nlet cli = Cli::parse();\n\nmatch cli.command {\nActions::Eat    =&gt; println!(\"Eating\"),\nActions::Drink  =&gt; println!(\"Drinking\"),\n}\n}\n</code></pre> <p>Apparently they may not be used together, enums with a Subcommand derive attribute require variants that contain Args derived values:</p> <pre><code>use clap::{Args, Parser, Subcommand};\n\n#[derive(Parser)]\nstruct Cli {\n#[clap(subcommand)]\ncommand: Actions,\n}\n\n#[derive(Subcommand)]\nenum Actions {\n#[clap(arg_enum)]\nEat(Foods),\n#[clap(arg_enum)]\nDrink(Drinks),\n}\n\n#[derive(Args)]\nstruct Foods {\nname: String,\n}\n\n#[derive(Args)]\nstruct Drinks {\nname: String\n}\n\nfn main() {\nlet cli = Cli::parse();\n\nmatch cli.command {\nActions::Eat(f) =&gt; {\nprintln!(\"Eating {}\", f.name);\n}\nActions::Drink(d) =&gt; {\nprintln!(\"Drinking {}\", d.name);\n}\n}\n}\n</code></pre> <pre><code>use std::string::ParseError;\n\nuse clap::{ArgEnum, Args, Parser, Subcommand, };\n\n#[derive(Parser)]\nstruct Cli {\n#[clap(subcommand)]\ncommand: Actions,\n}\n\n#[derive(Subcommand)]\nenum Actions {\n#[clap(arg_enum)]\nEat(Food),\n#[clap(arg_enum)]\nDrink(Drink),\n}\n\n#[derive(Args)]\nstruct Food {\nname: String,\n}\n\n#[derive(Args)]\nstruct Drink {\ndrink: Drinks\n}\n\n#[derive(ArgEnum, Clone)]\nenum Drinks {\nCoke,\nPepsi,\nOther\n}\n\nimpl std::str::FromStr for Drinks {\ntype Err = ParseError;\n\nfn from_str(s: &amp;str) -&gt; Result&lt;Self, Self::Err&gt; {\nmatch s {\n\"coke\" =&gt; Ok(Self::Coke),\n\"pepsi\" =&gt; Ok(Self::Pepsi),\n_ =&gt; Ok(Self::Other),\n}\n}\n}\n\nimpl From&lt;Drinks&gt; for String {\nfn from(item: Drinks) -&gt; String {\nmatch item {\nDrinks::Coke =&gt; String::from(\"Coke\"),\nDrinks::Pepsi =&gt; String::from(\"Pepsi\"),\n_ =&gt; String::from(\"Other\")\n}\n}\n}\n\nfn main() {\nlet cli = Cli::parse();\n\nmatch cli.command {\nActions::Eat(f) =&gt; {\nprintln!(\"Eating {}\", f.name);\n}\nActions::Drink(d) =&gt; {\nprintln!(\"Drinking {}\", String::from(d.drink));\n}\n}\n}\n</code></pre>"},{"location":"Rust/Crates/Clap/#starships","title":"Starships","text":"<pre><code>#[macro_use] extern crate diesel;\nuse diesel::prelude::*;\nuse diesel::result::QueryResult;\nuse diesel::sqlite::SqliteConnection;\n\nmod models; // (1)\nuse models::Starship;\nmod schema; // (2)\nuse schema::starships::dsl::*;\n\nuse clap::{Parser, Subcommand};\n\n#[derive(Parser)]\nstruct Cli {\n#[clap(subcommand)]\ncommand: Commands,\n}\n\n#[derive(Subcommand)]\nenum Commands {\nAdd(Starship),\nUpdate,\nRemove,\nList,\n}\n\nfn main() {\nlet app = Cli::parse();\nmatch app.command {\nCommands::Add(s)    =&gt; add_ship(&amp;s),\nCommands::List      =&gt; list_ships(),\nCommands::Remove    =&gt; println!(\"Removing\"),\nCommands::Update    =&gt; println!(\"Updating\"),\n}\n}\n\nfn add_ship(s: &amp;Starship) {\nlet conn = get_connection().unwrap();\nprintln!(\"Adding {:?}\", s);\ns.insert_into(starships)\n.execute(&amp;conn)\n.unwrap();\n}\n\nfn list_ships() {\nprintln!(\"{:?}\", get_ships().unwrap());\n}\n\nfn get_connection() -&gt; ConnectionResult&lt;SqliteConnection&gt; {\ndotenv::dotenv().expect(\"Couldn't load .env file\");\nlet url = &amp;std::env::var(\"DATABASE_URL\").unwrap();\nSqliteConnection::establish(url)\n}\n\nfn get_ships() -&gt; QueryResult&lt;Vec&lt;Starship&gt;&gt; {\nlet conn = get_connection().unwrap();\nstarships\n.load::&lt;Starship&gt;(&amp;conn)\n}\n</code></pre> <ol> <li>Not that the order of the fields matters (for both postgres as well as sqlite connections), and the primary key should be the first field defined. <pre><code>use crate::schema::starships;\nuse clap::Args;\n\n#[derive(Args,Debug, Queryable, Insertable, Identifiable, Clone)]\n#[primary_key(registry)]\npub struct Starship {\n#[clap(long, short)]\npub registry: String,\n#[clap(long, short)]\npub name: String,\n#[clap(long, short)]\npub crew: i32,\n}\n</code></pre> 2. <pre><code>table! {\nstarships (registry) {\nregistry -&gt; Text,\nname -&gt; Text,\ncrew -&gt; Integer,\n}\n}\n</code></pre></li> </ol>"},{"location":"Rust/Crates/Failure/","title":"failure","text":"<p>The failure crate is an error-handling library</p>"},{"location":"Rust/Crates/Failure/#api","title":"API","text":""},{"location":"Rust/Crates/Failure/#fail","title":"Fail","text":"<p>The Fail trait extends errors with a variety of traits and methods.</p> <pre><code>use failure_derive::Fail;\n\n#[derive(Fail)]\nenum CustomErr {\n#[fail(display=\"Foo error\")]\nCustomErrorFoo(String),\n#[fail(display=\"Bar error\")]\nCustomErrorBar(String),\n}\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/","title":"gtk-rs","text":""},{"location":"Rust/Crates/Gtk-rs/#tasks","title":"Tasks","text":""},{"location":"Rust/Crates/Gtk-rs/#development-environment","title":"Development environment","text":"Red Hat<pre><code>dnf install gtk4-devel gcc\n</code></pre> Ubuntu<pre><code>apt install libgtk-4-dev build-essential\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#boilerplate","title":"Boilerplate","text":"Interface <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.40\"/&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;property name=\"title\"&gt;My GTK App&lt;/property&gt;\n&lt;property name=\"default-width\"&gt;300&lt;/property&gt;\n&lt;property name=\"default-height\"&gt;300&lt;/property&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre> <pre><code>use gtk4::{Application, ApplicationWindow};\n\nfn main() {\nlet app = Application::builder()\n.application_id(\"com.example.learning-gtk\")\n.build();\n\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet window = ApplicationWindow::builder()\n.application(app)\n.default_width(300)\n.default_height(300)\n.title(\"My GTK App\")\n.build();\n\nwindow.present();\n}\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#clicker","title":"Clicker","text":"<p>This appears to be a common demonstration of data binding in various GUI frameworks, the code below is taken from here.</p> <pre><code>use gtk4::prelude::*;\nuse gtk4::{glib, Application, ApplicationWindow, Box, Button, Orientation};\nuse std::{cell::Cell, rc::Rc};\n\nfn main() {\n// Create a new application\nlet app = Application::builder()\n.application_id(\"org.gtk-rs.example\")\n.build();\n\n// Connect to \"activate\" signal of `app`\napp.connect_activate(build_ui);\n\n// Run the application\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\n// Create two buttons\nlet button_increase = Button::builder()\n.label(\"Increase\")\n.margin_top(12)\n.margin_bottom(12)\n.margin_start(12)\n.margin_end(12)\n.build();\nlet button_decrease = Button::builder()\n.label(\"Decrease\")\n.margin_top(12)\n.margin_bottom(12)\n.margin_start(12)\n.margin_end(12)\n.build();\n\n// Reference-counted object with inner mutability\nlet number = Rc::new(Cell::new(0)); // (1)\n\n// Connect callbacks\n// When a button is clicked, `number` and label of the other button will be changed\nbutton_increase.connect_clicked(glib::clone!(@weak number, @weak button_decrease =&gt; // (2)\nmove |_| {\nnumber.set(number.get() + 1);\nbutton_decrease.set_label(&amp;number.get().to_string());\n}));\nbutton_decrease.connect_clicked(glib::clone!(@weak button_increase =&gt; // (3)\nmove |_| {\nnumber.set(number.get() - 1);\nbutton_increase.set_label(&amp;number.get().to_string());\n}));\n\n// Add buttons to `gtk_box`\nlet gtk_box = Box::builder().orientation(Orientation::Vertical).build();\ngtk_box.append(&amp;button_increase);\ngtk_box.append(&amp;button_decrease);\n\n// Create a window\nlet window = ApplicationWindow::builder()\n.application(app)\n.title(\"My GTK App\")\n.child(&amp;gtk_box)\n.build();\n\n// Present the window\nwindow.present();\n}\n</code></pre> <ol> <li>It appears number must be an Rc&lt;Cell&gt;. Changing it to a raw i8 causes compilation errors within glib::clone.</li> <li>Removing the weak reference to number causes a compilation error.</li> <li>Adding a weak reference to number here also causes a compilation error.</li> </ol>"},{"location":"Rust/Crates/Gtk-rs/#hello-world","title":"Hello, World!","text":""},{"location":"Rust/Crates/Gtk-rs/#window-frame","title":"Window frame","text":"<p>TODO</p> <p>At the moment, this example is broken because I don't know how to pass the string into the Application struct for string interpolation.</p> <pre><code>use gtk4::prelude::*;\nuse gtk4::{Application, ApplicationWindow};\n\nfn main() {\nlet name = String::new();\nif let Some(s) = 42std::env::args().nth(1) {\nname = s;\n} else {\nname = String::from(\"World\");\n};\n\nlet app = Application::builder()\n.application_id(\"com.example.learning-gtk\")\n.build();\napp.connect_activate(build_ui);\nprintln!(\"{}\", app.name);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet window = ApplicationWindow::builder()\n.application(app)\n.title(\"Hello, World!\")\n.default_height(300)\n.default_width(300)\n.build();\nwindow.present();\n}\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#button-reveal","title":"Button reveal","text":"Interface <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;interface&gt;\n&lt;requires lib=\"gtk+\" version=\"3.40\"&gt;\n&lt;object class=\"GtkApplicationWindow\" id=\"window\"&gt;\n&lt;property name=\"title\"&gt;My GTK App&lt;/property&gt;\n&lt;property name=\"default-width\"&gt;300&lt;/property&gt;\n&lt;property name=\"default-height\"&gt;300&lt;/property&gt;\n&lt;child&gt;\n&lt;object class=\"GtkButton\" id=\"button\"&gt;\n&lt;property name=\"label\"&gt;Press me!&lt;/property&gt;\n&lt;property name=\"margin-top\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-bottom\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-start\"&gt;12&lt;/property&gt;\n&lt;property name=\"margin-end\"&gt;12&lt;/property&gt;  &lt;/object&gt;\n&lt;/child&gt;\n&lt;/object&gt;\n&lt;/interface&gt;\n</code></pre> <pre><code>use gtk::prelude::*;\nuse gtk::{Application, ApplicationWindow, Button};\n\nfn main() {\nlet app = Application::builder()\n.application_id(\"org.gtk-rs.example\")\n.build();\n\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application) {\nlet builder = gtk::Builder::from_string(include_str!(\"window.ui\"));\nlet window: ApplicationWindow = builder\n.object(\"window\")\n.expect(\"Could not get object `window` from builder.\");\nlet button: Button = builder\n.object(\"button\")\n.expect(\"Could not get object `button` from builder.\");\n\nwindow.set_application(Some(app));\n\nbutton.connect_clicked(move |button| { // (1)\nbutton.set_label(\"Hello World!\");\n});\n\nwindow.set_child(Some(&amp;button));\nwindow.show_all();\nwindow.present();\n}\n</code></pre> <ol> <li>This <code>move</code> keyword appears to be unnecessary.</li> </ol>"},{"location":"Rust/Crates/Gtk-rs/#api","title":"API","text":""},{"location":"Rust/Crates/Gtk-rs/#glibclone","title":"glib::clone","text":"<p>glib::clone! is used to create closures using strong or weak references.</p> StrongWeak <pre><code>use glib;\nuse glib_macros::clone;\nuse std::rc::Rc;\n\nlet v = Rc::new(1);\nlet closure = clone!(@strong v =&gt; move |x| {\nprintln!(\"v: {}, x: {}\", v, x);\n});\n\nclosure(2);\n</code></pre> <pre><code>use glib;\nuse glib_macros::clone;\nuse std::rc::Rc;\n\nlet u = Rc::new(2);\nlet closure = clone!(@weak u =&gt; move |x| {\nprintln!(\"u: {}, x: {}\", u, x);\n});\n\nclosure(3);\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#glibwrapper","title":"glib::wrapper","text":"<p>glib::wrapper is used to wrap GObjects and figures prominently in the To-Do App. Parent classes must be provided after @extends and any interfaces implemented must be provided after @implements</p> <pre><code>wrapper! {\npub struct $name($kind&lt;$foreign&gt;); // (2)\n\nmatch fn {\n$fn_name =&gt; /* (1) */,\n...\n}\n}\n</code></pre> <ol> <li>Closure-like expressions in the match fn block allow copying, freeing, referencing, and dereferencing the value that is being wrapped.</li> <li>There are three possible values for $kind: Boxed (heap allocated types), Shared (records with reference-counted, shared ownership), or Object (classes)</li> </ol> <pre><code>wrapper! {\npub struct Button(Object&lt;ffi::GtkButton&gt;)\n@extends Bin, Container, Widget,\n@implements Buildable, Actionable;\n\nmatch fn {\ntype_ =&gt; || ffi::gtk_button_get_type(), // (1)\n}\n}\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#action","title":"Action","text":"<p>Gio.Action is a way to expose any single task an application or widget does by a name. Classes like Gio.MenuItem and Gtk.ModelButton support properties to set an action name. These actions can be collected into a Gio.ActionGroup.</p> <ul> <li>Gio.ActionMap are interfaces implemented by Gtk.ApplicationWindow</li> </ul>"},{"location":"Rust/Crates/Gtk-rs/#actiongroup_1","title":"ActionGroup","text":""},{"location":"Rust/Crates/Gtk-rs/#adjustment","title":"Adjustment","text":"PyGobject  gtk-rs  gtk <p>Gtk.Adjustment is not a widget per se but is used in many widgets, including spin buttons, view ports, and children of Gtk.Range.</p> <ul> <li>page increment and page size refer to actions taken when the user presses PgUp or PgDn <pre><code>Gtk.Adjustment.new(initial_value, lower_range, upper_range, step_increment, page_increment, page_size)\n</code></pre></li> </ul>"},{"location":"Rust/Crates/Gtk-rs/#alignment","title":"Alignment","text":"PyGobject  gtk-rs  gtk <p>Gtk.Alignment controls the alignment and size of its child widget.</p>"},{"location":"Rust/Crates/Gtk-rs/#application","title":"Application","text":"PyGobject  gtk-rs  gtk Gtk.Application gtk4::Application GtkApplication <p>Subclasses of Gtk.Application encapsulate application behavior, including application startup and CLI processing. In practice it is simply a wrapper for the ApplicationWindow class which is instantiated in the <code>do_activate()</code> hook. Notably, the Application subclass provides the value for the <code>application_id</code> kwarg passed to the Gtk.Application constructor. This value is validated, and any simple string is not silently accepted.</p> <p>Application must expose several important methods:</p> <ul> <li><code>do_activate()</code> <pre><code>def do_activate(self):\nself.window = ApplicationWindow(application=self, title=\"Hello, World!\")\nself.window.show_all()\nself.window.present()\n</code></pre></li> <li><code>do_startup()</code></li> </ul>"},{"location":"Rust/Crates/Gtk-rs/#applicationwindow","title":"ApplicationWindow","text":"PyGobject  gtk-rs  gtk Gtk.ApplicationWindow gtk4::ApplicationWindow GtkApplicationWindow <p>The Gtk.ApplicationWindow class is the main visible window for the application, and the only window for \"single-instance\" applications (which is the default). The ApplicationWindow class was introduced in GTK 3.4.</p> <p>When an action has the prefix <code>win.</code> it specifies that the ApplicationWindow subclass will process the signal.</p>"},{"location":"Rust/Crates/Gtk-rs/#assistant","title":"Assistant","text":"PyGobject  gtk-rs  gtk Gtk.Assistant gtk4::Assistant GtkAssistant <p>Gtk.Assistant widgets are used to implement the wizard pattern.</p>"},{"location":"Rust/Crates/Gtk-rs/#box","title":"Box","text":"PyGobject  gtk-rs  gtk Gtk.Box gtk4::Box GtkBox"},{"location":"Rust/Crates/Gtk-rs/#builder","title":"Builder","text":"PyGobject  gtk-rs  gtk Gtk.Builder gtk4::Builder GtkBuilder <p>Gtk.Builder allows the use of interfaces to define widget layouts. Individual UI elements can be bound if they have an id attribute assigned.</p>  Rust Python <pre><code>fn main() {\nlet app = gtk::Application::builder()\n.application_id(\"org.example.gtk-app\")\n.build();\n\napp.connect_activate(build_ui);\napp.run();\n}\n\nfn build_ui(app: &amp;Application):{\nlet builder = gtk::Builder::from_string(include_str!(\"window.ui\"));\nlet window: ApplicationWindow = builder.object(\"window\")\n.expect(\"Error loading ApplicationWindow!\");\nwindow.set_application(Some(app));\nwindow.show_all();\nwindow.present();\n}\n</code></pre> <pre><code>class Application(Gtk.Application):\n    def __init__(self, *args, **kwargs):\n        super().__init__(application_id = \"org.example.gtk-app\")\n\n    def do_activate(self):\nbuilder = Gtk.Builder.new_from_file(\"window.ui\")\nself.window = builder.get_object(\"window\")\nself.window.show_all()\n        self.window.present()\n\n    def run(self):\n        super().run()\n        Gtk.main()\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#checkbutton","title":"CheckButton","text":"PyGobject  gtk-rs  gtk Gtk.CheckButton gtk4::CheckButton GtkCheckButton <p>Gtk.CheckButtons include checkboxes and (when placed into groups) radio buttons.</p>"},{"location":"Rust/Crates/Gtk-rs/#container","title":"Container","text":"PyGobject  gtk-rs  gtk Gtk.Container gtk::Container GtkContainer (3.0) <p>Both Gtk.ApplicationWindow and Gtk.Window classes indirectly derive from the abstract class Gtk.Container. The main purpose of a container subclass is to allow a parent widget to contain one or more child widgets, and there are two types:</p>"},{"location":"Rust/Crates/Gtk-rs/#dialog","title":"Dialog","text":"PyGobject  gtk-rs  gtk <p>Gtk.Dialog  provides a convenient way to prompt the user for a small amount of input. It is a widget that can be instantiated and customized in its own right as well as a parent to various subclasses.  <pre><code>dialog = Gtk.Dialog(title=\"Hello, World!\", parent=parent)\n</code></pre></p> <p>Dialogs are split into two parts:</p> <ul> <li>Content area containing interactive widgets</li> <li>Action area containing buttons</li> </ul> <p>These areas are both combined in a vertical Box that is assigned to the <code>vbox</code> field. The action area is packed to the end of this vbox, so the <code>pack_start()</code> method is used to add widgets to the content area.</p> <p>Dialog boxes can be modal, meaning they prevent interaction with the main window while open, or nonmodal.</p> ModalNonmodal <pre><code>dialog = Gtk.Dialog(title=\"Hello, World!\", parent=parent, modal=True)\n</code></pre> <pre><code>dialog = Gtk.Dialog(title=\"Hello, World!\", parent=parent, modal=False)\n</code></pre> <p>Gtk.MessageDialog is a subtype of Dialog meant to simplify the process of creating simple dialogs.</p> <p>Buttons are added procedurally using <code>add_button()</code>, passing a display string (with support for mnemonics using <code>_</code>) and a ResponseType enum (they once could be added on instantiation by passing a tuple to the <code>buttons</code> keyword argument).</p> <pre><code>dialog.add_button(\"_OK\", Gtk.ResponseType.OK)\n</code></pre> <p>Methods:</p> <ul> <li>add_button() </li> </ul>"},{"location":"Rust/Crates/Gtk-rs/#entry","title":"Entry","text":"PyGobject  gtk-rs  gtk <p>Unlike other widgets, Gtk.Entry can be instantiated without using a specific constructor. <pre><code>entry = Gtk.Entry()\n</code></pre></p> <p>Default text can be provided by passing a string to the text keyword argument or with the <code>set_text()</code> setter method:</p> kwargsetter <pre><code>entry = Gtk.Entry(text=\"Hello, World!\")\n</code></pre> <pre><code>entry.set_text(\"Hello, World!\")\n</code></pre> <p>A password field can be made by concealing text by passing False to  visibility or with the <code>set_visibility()</code> setter:</p> kwargsetter <pre><code>password = Gtk.Entry(visibility=False)\n</code></pre> <pre><code>password.set_visibility(False)\n</code></pre> <ul> <li><code>get_text()</code>  retrieve contents (string)</li> <li><code>set_visibility(bool)</code>  conceal text</li> </ul>"},{"location":"Rust/Crates/Gtk-rs/#eventbox","title":"EventBox","text":"PyGobject  gtk-rs  gtk <p>Gtk.EventBox is a container widget that allows event handling for widgets like Gtk.Label that do not have an associated GDK window. The event box can be positioned above or below the windows of its child with <code>set_above_child()</code> (False by default.) An EventBox must also have a Gtk.EventMask enum set to specify the type of events the widget may receive. This enum is passed as a value to <code>set_events()</code>.</p> <p>In the following example, an event handler is connected to the EventBox to handle <code>button_press_event</code>.  This event handler changes the text of the Label after a double-click.</p> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk, Gdk\n\n\nclass AppWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_border_width(10)\n        self.set_size_request(200, 50)\neventbox = Gtk.EventBox.new()\nlabel = Gtk.Label.new(\"Double-Click Me!\")\neventbox.set_above_child(False)\neventbox.connect(\"button_press_event\", self.on_button_pressed, label)\neventbox.add(label)\nself.add(eventbox)\neventbox.set_events(Gdk.EventMask.BUTTON_PRESS_MASK)\neventbox.realize()\ndef on_button_pressed(self, eventbox, event, label):\n        if event.type == Gdk.EventType._2BUTTON_PRESS:\n            text = label.get_text()\n            if text[0] == 'D':\n                label.set_text(\"I Was Double-Clicked!\")\n            else:\n                label.set_text(\"Double-Click Me Again!\")\n        return False\n\nclass Application(Gtk.Application):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Hello World!\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#filechooserdialog","title":"FileChooserDialog","text":"PyGobject  gtk-rs  gtk <p>Gtk.FileChooserDialog is one of the important subtypes of Gtk.Dialog. Like other dialogs, it is provided a title and parent window on instantiation. Additionally a FileChooserAction enum must be specified.</p> <p>FileChooserActions include:</p> <ul> <li>Gtk.FileChooserAction.SAVE</li> <li>Gtk.FileChooserAction.OPEN</li> <li>Gtk.FileChooserAction.SELECT_FOLDER</li> <li>Gtk.FileChooserAction.CREATE_FOLDER</li> </ul> <pre><code>dialog = Gtk.FileChooserDialog(\n    title=\"Save file as ...\",\n    parent=parent,\n    action=FileChooserAction.SAVE\n)\n</code></pre> <p>Selected files are then retrieved using <pre><code>dialog.get_filenames()\n</code></pre></p> <p>| Setter                                                                                                                            | Property          | Description                                                                           | | --------------------------------------------------------------------------------------------------------------------------------- | ----------------- | | <code>set_current_folder</code> |                   | Specify directory in filesystem where FileChooser will start                          | | <code>set_current_name</code>         |                   | For FileChooserAction.SAVE, suggest a filename                                        | | <code>set_select_multiple</code>   | <code>select_multiple</code> | For FileChooserAction.OPEN or SELECT_FOLDER, allow multiple file or folder selections |</p>"},{"location":"Rust/Crates/Gtk-rs/#grid","title":"Grid","text":"PyGobject  gtk-rs  gtk <p>Gtk.Grid allows children to be packed in a two-dimensional grid. Grids are instantiated with <code>new()</code> and widgets are laid out by calling <code>attach()</code> (see Login for an example).</p> <ul> <li><code>attach()</code> lay out a widget providing column and row numbers followed by column and row spans <pre><code>grid.attach(label, 0, 0, 1, 1)\n</code></pre></li> </ul>"},{"location":"Rust/Crates/Gtk-rs/#headerbar","title":"HeaderBar","text":"PyGobject  gtk-rs  gtk <p>Gtk.HeaderBar allows the titlebar to be customized. Like other widgets, it can be configured on instantiation by providing values to keyword arguments or by using setters.</p> <p>Adding to a window</p> <p>HeaderBars are added with <code>set_titlebar()</code>. This is unlike other widgets which are assigned to an ApplicationWindow or Window using <code>pack_start()</code>, <code>pack_end()</code>, or <code>add()</code>, </p> kwargsetter <pre><code>class ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\nheaderbar = Gtk.HeaderBar(title=f\"Hello, World!\", \nsubtitle=\"HeaderBar example\", \nshow_close_button=True)\nself.set_titlebar(headerbar)\n</code></pre> <pre><code>class ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\nheaderbar = Gtk.HeaderBar()\nheaderbar.set_title(f\"Hello, World!\")\nheaderbar.set_subtitle(\"HeaderBar example\")\nheaderbar.set_show_close_button(True)\nself.set_titlebar(headerbar)\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#label","title":"Label","text":"PyGobject  gtk-rs  gtk <p>Note that Gtk.Label sets its text with \"label\" and not \"text\" as you may expect from the corresponding setter.</p> kwargsetter <pre><code>label = Gtk.Label(label=\"Hello, World!\")\n</code></pre> <pre><code>label.set_text(\"Hello, World!\")\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#listbox","title":"ListBox","text":"PyGobject  gtk-rs  gtk <p>Gtk.ListBox is a vertical container of Gtk.ListBoxRow children used as an alternative to TreeView when the children need to be interactive, as in a list of settings. ListBox </p>"},{"location":"Rust/Crates/Gtk-rs/#liststore","title":"ListStore","text":"PyGobject  gtk-rs  gtk <p>Gtk.ListStore is one of the two major classes that serves as combination schema and database backing Gtk.TreeView, the other being Gtk.TreeStore.</p> <p>It is instantiated with a sequence of data types, similar to a database schema.  These can be standard Python types or GObjects (which are mapped to the Python types anyway):</p> Python typesGObject types <pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\nliststore = Gtk.ListStore((str, int, str))\n</code></pre> <pre><code>import gi\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk, GObject\nliststore = Gtk.ListStore((GObject.TYPE_STRING, GOBject).TYPE_INT, GObject.TYPE_STRING))\n</code></pre> <p>This object then exposes an <code>append</code> method which is used to add records: <pre><code>liststore.append([\"Socrates\", 350, \"Athens\"])\n</code></pre></p> <p>The store is then associated with the treeview with <code>set_model</code> <pre><code>treeview.set_model(liststore)\n</code></pre></p>"},{"location":"Rust/Crates/Gtk-rs/#menubar","title":"MenuBar","text":"PyGobject  gtk-rs  gtk <p>Gtk.MenuBar is populated with Gtk.MenuItems, corresponding to the expandable menu items (i.e. \"File\", \"Edit\", and \"Help\"). Gtk.Menu is actually used for the submenu, which like MenuBar is also populared with MenuItems.  A Menu is attached to the MenuItem of a MenuBar by using the <code>set_submenu()</code> method on the Menu object. This setter does not have a corresponding kwarg, so all menus have to be constructed procedurally.</p> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\nclass AppWindow(Gtk.ApplicationWindow):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_size_request(250, -1)\n        menubar = Gtk.MenuBar.new()\n        self.add(menubar)\n\n        file = Gtk.MenuItem.new_with_label(\"File\")\n        menubar.append(file)\n        filemenu = Gtk.Menu.new()\n        file.set_submenu(filemenu)\n        new = Gtk.MenuItem.new_with_label(\"New\")\n        open = Gtk.MenuItem.new_with_label(\"Open\")\n        filemenu.append(new)\n        filemenu.append(open)\n\n        edit = Gtk.MenuItem.new_with_label(\"Edit\")\n        menubar.append(edit)\n        editmenu = Gtk.Menu.new()\n        edit.set_submenu(editmenu)\n        cut = Gtk.MenuItem.new_with_label(\"Cut\")\n        copy = Gtk.MenuItem.new_with_label(\"Copy\")\n        paste = Gtk.MenuItem.new_with_label(\"Paste\")\n        editmenu.append(cut)\n        editmenu.append(copy) \n        editmenu.append(paste)\n\n        help = Gtk.MenuItem.new_with_label(\"Help\")\n        menubar.append(help)\n        helpmenu = Gtk.Menu.new()\n        help.set_submenu(helpmenu)\n        contents = Gtk.MenuItem.new_with_label(\"Help\")\n        about = Gtk.MenuItem.new_with_label(\"About\")\n        helpmenu.append(contents)\n        helpmenu.append(about)\n\nclass Application(Gtk.Application):\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, application_id=\"org.example.myapp\", **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window = AppWindow(application=self, title=\"Menu Bars\")\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#notebook","title":"Notebook","text":"PyGobject  gtk-rs  gtk <p>Gtk.Notebook is a layout container that organizes content into tabbed pages. It is instantiated with the <code>new()</code> method and pages are appended with the <code>append_page()</code> method, passing content and label widgets as arguments.</p> <p>The tab bar can be placed using <code>set_tab_pos()</code>, passing a Gtk.PositionType enum</p> TopRightBottomLeft <pre><code>notebook = Gtk.Notebook.new()\n# notebook.set_tab_pos(Gtk.PositionType.TOP)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nnotebook.set_tab_pos(Gtk.PositionType.RIGHT)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nnotebook.set_tab_pos(Gtk.PositionType.BOTTOM)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nnotebook.set_tab_pos(Gtk.PositionType.LEFT)\n</code></pre> <p></p> <pre><code>notebook = Gtk.Notebook.new()\nlabel = Gtk.Label.new(\"Tab title\")\nchild = Gtk.Label.new(\"Tab content\")\nnotebook.append_page(child, label)\n</code></pre> <p>The label widget is commonly Gtk.Label but can also be a Gtk.Box.</p> <p>The tab bar can be made scrollable using <code>set_scrollable()</code>, passing a bool.</p>"},{"location":"Rust/Crates/Gtk-rs/#scale","title":"Scale","text":"PyGobject  gtk-rs  gtk <p>Gtk.Scale widgets are sliders, and they can be instantiated in one of two ways:</p> <ul> <li><code>new()</code> passing an Adjustment object</li> <li><code>new_with_range(min, max, step)</code> passing values for minimum, maximum, and step</li> </ul> <p>Scale values are stored as doubles, so integers have to be simulated by reducing the number of digits to 0 using <code>set_digits()</code>. By default, the number of digits is set to that of the step value.</p>"},{"location":"Rust/Crates/Gtk-rs/#scrolledwindow","title":"ScrolledWindow","text":"PyGobject  gtk-rs  gtk <p>Gtk.ScrolledWindow is a decorator container that accepts a single child widget. Widgets that implement the Gtk.Scrollable interface have native scrolling suppport, like Gtk.TreeView, Gtk.TextView, and Gtk.Layout. Other widgets have to use Gtk.Viewport as an adaptor, and must be added to a Viewport which is then added to the ScrolledWindow.</p> <p>It is instantiated with the <code>new()</code> method, optionally passing two Adjustment objects that affect horizontal and vertical scrolling behavior when stepping or paging. <pre><code>scrolled_win = Gtk.ScrolledWindow.new(None,None)\n</code></pre></p>"},{"location":"Rust/Crates/Gtk-rs/#statusbar","title":"Statusbar","text":"PyGobject  gtk-rs  gtk Gtk.Statusbar gtk4::Statusbar GtkStatusbar (4.0) <p>Gtk.Statusbar (note the lowercase b ) stores a stack of messages, the topmost of which is displayed. Before adding messages, a context identifier, a unique unsigned integer associated with a context description string, must be retrieved from the newly created Statusbar by passing a string value to <code>get_context_id()</code>.  This allows messages to be categorized and pushed to separate stacks. <pre><code>statusbar.push(context_id, message)\n</code></pre></p>"},{"location":"Rust/Crates/Gtk-rs/#switch","title":"Switch","text":"PyGobject  gtk-rs  gtk Gtk.Switch gtk4::Switch GtkSwitch (4.0) <p>Gtk.Switch allows a user to toggle a boolean value. Switch exposes getters and setters for both state (which is represented by the trough color) and active (switch position) properties. State is the backend to activ, and they are kept in sync.</p> <pre><code>import gi\n\ngi.require_version(\"Gtk\", \"3.0\")\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.set_border_width(10)\n\n        box_outer = Gtk.Box(orientation=Gtk.Orientation.VERTICAL, spacing=6)\n        listbox = Gtk.ListBox(selection_mode=Gtk.SelectionMode.NONE)\n        row = Gtk.ListBoxRow()\n        hbox = Gtk.Box(orientation=Gtk.Orientation.HORIZONTAL, spacing=50)\n        label1 = Gtk.Label(label=\"Automatic Date &amp; Time\", xalign=0)\n\n        hbox.add(label1)\n        self.switch = Gtk.Switch(valign=Gtk.Align.CENTER, state=False)\n        hbox.add(self.switch)\n        row.add(hbox)\n        listbox.add(row)\n        box_outer.add(listbox)\n        self.add(box_outer)\n        button = Gtk.Button(label=\"Click\")\n        button.connect(\"clicked\", self.on_button_clicked)\n        box_outer.add(button)\n\n    def on_button_clicked(self, button):\n        print(f\"Value of get_active(): {self.switch.get_active()}\")\n        print(f\"Value of get_state(): {self.switch.get_state()}\")\n\n\nclass Application(Gtk.Application):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.window = None\n\n    def do_activate(self):\n        if not self.window:\n            self.window=ApplicationWindow(application=self)\n        self.window.show_all()\n        self.window.present()\n\nif __name__ == \"__main__\":\n    app = Application()\n    app.run()\n</code></pre>"},{"location":"Rust/Crates/Gtk-rs/#treeview","title":"TreeView","text":"PyGobject  gtk-rs  gtk Gtk.TreeView gtk4::TreeView GtkTreeView (4.0) GtkTreeView (3.0) <p>In order to create a tree or list in GTK, the Gtk.TreeView widget is paired with a Gtk.TreeModel interface, the most typical implementation of which is Gtk.ListStore or Gtk.TreeStore. TreeView is a complicated widget that must be constructed procedurally:</p> <ol> <li>Gtk.TreeView is instantiated. A ListStore is specified as data model and passed in as the value of the model kwarg. The ListStore specifies the schema of the data as a collection of types. <pre><code>treeview = Gtk.TreeView(model=Gtk.ListStore.new((str)))\n</code></pre> Alternatively, the ListStore can be specified after instantiation. <pre><code>treeview = Gtk.TreeView.new()\ntreeview.set_model(Gtk.ListStore.new([str]))\n</code></pre></li> <li>A Gtk.TreeViewColumn is created for every column in the model. These require a Gtk.CellRenderer to be defined. The TreeViewColumn is added to the treeview by calling the <code>append_column()</code> method on the treeview. The text kwarg appears to refer to the column of the data store to use for the column's values. <pre><code>treeview.append_column(Gtk.TreeViewColumn(\"Greeks\", Gtk.CellRendererText.new(), text=0))\n</code></pre></li> <li>Items are added to the ListStore procedurally using the <code>append()</code> method. Note that the method takes only a single argument, so collections like lists or tuples must be used. <pre><code>liststore.append((\"Socrates\",))\nliststore.append((\"Plato\",))\nliststore.append((\"Aristotle\",))\n</code></pre></li> </ol> <p>Changing the number of columns affects the types used to define the ListStore, the appended records, as well as the number of columns added to the TreeView itself.</p> 1 column2 columns <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.gen_treeview()\n\n        scrolled_win = Gtk.ScrolledWindow.new(None,None)\n        scrolled_win.set_policy(Gtk.PolicyType.AUTOMATIC, Gtk.PolicyType.AUTOMATIC)\n        scrolled_win.add(self.treeview)\n\n        self.add(scrolled_win)\n        self.set_size_request(200,200)\n\n    def get_liststore(self):\n        store = Gtk.ListStore.new((str,))\n        store.append((\"Socrates\",))\n        store.append((\"Plato\",))\n        store.append((\"Aristotle\",))\n        return store\n\n    def gen_treeview(self):\n        self.treeview = Gtk.TreeView.new()\n        self.treeview.set_model(self.get_liststore())\n        self.treeview.append_column(Gtk.TreeViewColumn(\"Greeks\", Gtk.CellRendererText.new(), text=0))\n\n\n\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, title=\"Greeks\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <pre><code>import gi\ngi.require_version('Gtk', '3.0')\nfrom gi.repository import Gtk\n\n\nclass ApplicationWindow(Gtk.ApplicationWindow):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self.gen_treeview()\n\n        scrolled_win = Gtk.ScrolledWindow.new(None,None)\n        scrolled_win.set_policy(Gtk.PolicyType.AUTOMATIC, Gtk.PolicyType.AUTOMATIC)\n        scrolled_win.add(self.treeview)\n\n        self.add(scrolled_win)\n        self.set_size_request(200,200)\n\n    def get_liststore(self):\nstore = Gtk.ListStore.new((str, str))\nstore.append([\"Socrates\", \"Athens\"])\nstore.append([\"Plato\", \"Athens\"])\nstore.append([\"Aristotle\", \"Athens\"])\nreturn store\n\n    def gen_treeview(self):\n        self.treeview = Gtk.TreeView.new()\n        self.treeview.set_model(self.get_liststore())\n        self.treeview.append_column(Gtk.TreeViewColumn(\"Greeks\", Gtk.CellRendererText.new(), text=0))\nself.treeview.append_column(Gtk.TreeViewColumn(\"Place of birth\", Gtk.CellRendererText.new(), text=1))\nclass Application(Gtk.Application):\n    def __init__(self):\n        super().__init__(application_id='org.example.myapp')\n\n    def do_activate(self):\n        self.window = ApplicationWindow(application=self, title=\"Greeks\")\n        self.window.show_all()\n        self.window.present()\n\n\nif __name__ == '__main__':\n    app = Application()\n    app.run()\n</code></pre> <p>The model backing a TreeView (usually a ListStore), can be retrieved with the <code>get_model()</code> method. <pre><code>treeview.get_model().append(('foo','bar'))\n</code></pre></p> <p>TreeView emits several signals:</p> <ul> <li><code>row_activated</code> when a row is double-clicked, with the following implicit argument<ul> <li><code>widget</code> refering to the emitting TreeView widget itself</li> <li><code>path</code> is a TreePath. </li> <li><code>column</code> is of type TreeViewcolumn <pre><code>treeview.connect(\"row_activated\", self.on_row_activated, widget, path, column)\n</code></pre> <pre><code>def on_row_activated(self, widget, path, column):\n    row = path.get_indices()[0]\n    print(f\"row={path.get_indices()[0]},col={column.props.title}\")\n    print(widget.get_model()[row][:])\n</code></pre></li> </ul> </li> </ul>"},{"location":"Rust/Crates/Gtk-rs/#treepath","title":"TreePath","text":"PyGobject  gtk-rs  gtk <p>Gtk.TreePath is a type used to implement the rows of a TreeView. Although it prints to an integer with the print statement, it cannot be treated as one.</p> <p>A path object can be passed as the index to a TreeModel like ListStore, as can an integer. The row number of a TreePath from a normal list-style TreeView can be retrieved with the <code>get_indices()</code> method.</p> <pre><code>row = path.get_indices()[0]\n\n# Using TreePath object as index to model\nmodel[path][:]\n\n# Using row integer as index to model\nmodel[row][:]\n</code></pre> <p>Another method on TreePath, <code>get_depth()</code> always returns 1 for list-style TreeViews, but may be more useful for tree-style TreeViews.</p>"},{"location":"Rust/Crates/Gtk-rs/#treeselection","title":"TreeSelection","text":"PyGobject  gtk-rs  gtk <p>Gtk.TreeSelection objects represent selection information for each tree view.</p>"},{"location":"Rust/Crates/Gtk-rs/#treeviewcolumn_1","title":"TreeViewColumn","text":"PyGobject  gtk-rs  gtk Gtk.TreekViewColumn gtk4::TreeViewColumn GtkTreeViewColumn (4.0) GtkTreeViewColumn (3.0) <p>Gtk.TreeViewColumn represents a visible column in a Treeview. Its props property exposes many associated values, including title. <pre><code>print(column.props.title)\n</code></pre> A column is made sortable by calling <code>set_sort_column_id()</code>, passing the column of the model to sort by. <pre><code>column.set_sort_column_id(0)\n</code></pre></p>"},{"location":"Rust/Crates/Gtk-rs/#window","title":"Window","text":"PyGobject  gtk-rs  gtk Gtk.Window gtk4::Window GtkWindow (4.0) GtkWindow (3.0)"},{"location":"Rust/Crates/Rnd/","title":"rnd","text":"<ul> <li>gen_ratio() return true based on the probability defined by the fraction defined by the arguments (i.e. <code>gen_ratio(1,5)</code> returns true 20% of the time)</li> </ul>"},{"location":"Rust/Crates/Rocket/","title":"Rocket","text":""},{"location":"Rust/Crates/Rocket/#rocket","title":"Rocket","text":"API changes <p>Major API changes are in store in the transition from 0.4.10 (current stable version as of the time of this writing) and 0.5.0-rc.1. The guide is written for 0.4 and there is no 0.5 version published yet.</p> <p>These changes include a reorganization of some traits, such as FromForm from request to the new form module.</p> <p>Rocket is a web framework for Rust, along the lines of Flask for Python.</p> <p>The lifecyle of a Rocket request is as follows: Routing -&gt; Validation -&gt; Processing -&gt; Response</p> <p>The process of building a Rocket application has several stages:</p> <ul> <li>Mounting routes</li> <li>Managing state</li> <li>Attach fairings</li> </ul>"},{"location":"Rust/Crates/Rocket/#tasks","title":"Tasks","text":""},{"location":"Rust/Crates/Rocket/#configuration","title":"Configuration","text":"Rocket can be configured using a Rocket.toml file placed at the crate root to specify host address, port, etc.  Some of these settings appear to be necessary for certain REST clients. Rocket.toml<pre><code>[development]\naddress = \"127.0.0.1\"\nport = 8000\n</code></pre>"},{"location":"Rust/Crates/Rocket/#hello-world","title":"Hello, World!","text":""},{"location":"Rust/Crates/Rocket/#simple","title":"Simple","text":"<pre><code>#[macro_use]\nextern crate rocket;\n\n#[launch] // (1)\nfn rocket() -&gt; _ {\nrocket::build()\n.mount(\"/\", routes![index])\n}\n\n#[get(\"/\")]\nfn index() -&gt; &amp;'static str {\n\"Hello, World!\"\n}\n</code></pre> <ol> <li>The #[launch] attribute actually generates an async runtime.  <pre><code>#[macro_use]\nextern crate rocket;\n\n#[rocket::main]\nasync fn main() {\nrocket::build()\n.mount(\"/\", routes![index])\n.launch().await;\n}\n\n#[get(\"/\")]\nasync fn index() -&gt; &amp;'static str {\n\"Hello, World!\"\n}\n</code></pre></li> </ol>"},{"location":"Rust/Crates/Rocket/#parameterized","title":"Parameterized","text":"<p>Parameterization is enabled by dynamic routes:</p> <pre><code>#[macro_use]\nextern crate rocket;\n\n#[launch]\nfn rocket() -&gt; _ {\nrocket::build()\n.mount(\"/\", routes![index])\n}\n\n#[get(\"/&lt;name&gt;\")] // (1)\nfn index(name: String) -&gt; String {\nformat![\"Hello, {}!\", name]\n}\n</code></pre> <ol> <li>Alternatively, using a query segment: <pre><code>#[get(\"/?&lt;name&gt;)\"]\n</code></pre> In which case the handler would only to the path \"<code>/?name=...</code>\", i.e. <pre><code>curl localhost:8000/?name=Jasper\n</code></pre></li> </ol> State<pre><code>use rocket::{get, routes, launch, State};\n\nstruct MyConfig {\nmsg: String\n}\n\n#[launch]\nfn rocket() -&gt; _ {\nrocket::build()\n.mount(\"/\", routes![index,])\n.manage(MyConfig { msg: \"Hello, World!\".to_string() })\n}\n\n#[get(\"/\")]\nfn index(state: &amp;State&lt;MyConfig&gt;) -&gt; String { // (1)\nString::from(&amp;state.msg)\n}\n</code></pre> <ol> <li>State generally appears only in the parameter list of route handlers as a reference which must be initialized in the rocket crate itself.</li> </ol> File server<pre><code>use rocket::launch; // (2)\nuse rocket::fs::FileServer;\n\n#[launch]\nfn rocket() -&gt; _ {\nrocket::build()\n.mount(\"/\", FileServer::from(\"site\"))\n}\n</code></pre> Template<pre><code>use rocket::{get, routes, launch, };\nuse rocket_dyn_templates::Template; // (3)\n#[derive(serde::Serialize)] // (1)\nstruct Message {\nmsg: String\n}\n\n#[launch]\nfn rocket() -&gt; _ {\nrocket::build()\n.attach(Template::fairing()) // (2)\n.mount(\"/\", routes![index,])\n}\n\n#[get(\"/\")]\nfn index() -&gt; Template {\nlet context = Message {\nmsg: String::from(\"Hello, World!\")\n};\nTemplate::render(\"index\", &amp;context) // (4)\n}\n</code></pre> <ol> <li>The context struct used to insert information into the template must have the Serialize derive.</li> <li>Template::fairing() must be attached to the running Rocket instance. A fairing in Rocket parlance refers to structured middleware which expose hooks that allow callbacks to be placed into the request lifecycle to rewrite incoming requests and outgoing responses.</li> <li>Prior to 0.5, the Template struct was in the rocket_contrib crate.  Since 0.5, the rocket_dyn_templates crate requires at least one of two features to be enabled to use Template. Cargo.toml<pre><code>rocket_dyn_templates = {version = \"0.1.0-rc.1\", features = [\"handlebars\", \"tera\"]}\n</code></pre></li> <li>Template names passed to Template::render() must correspond to files placed in the path set by the template_dir configuration parameter. The process of Rocket finding these templates is called discovery. index.html.hbs<pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;{{msg}}&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;p&gt;{{msg}}&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre></li> </ol> Styled template<pre><code>use rocket::{get, routes, launch, };\nuse rocket_dyn_templates::Template; // (2)\nuse rocket::fs::FileServer;\n\n#[derive(serde::Serialize)]\nstruct Message {\nmsg: String\n}\n\n#[launch]\nfn rocket() -&gt; _ {\nrocket::build()\n.attach(Template::fairing())\n.mount(\"/\", FileServer::from(\"static\"))\n.mount(\"/\", routes![index,])\n\n}\n\n#[get(\"/\")]\nfn index() -&gt; Template {\nlet context = Message {\nmsg: String::from(\"Hello, World!\")\n};\nTemplate::render(\"index\", &amp;context) // (1)\n}\n</code></pre> <ol> <li>This template is themed using the Bulma CSS framework, which is served as a static file above. index<pre><code>head\nhead\nlink rel=\"stylesheet\" href=\"bulma.css\"\n    title {{msg}}\n  body\nsection.hero.is-primary\n.hero-body\n.container\nh1.title {{msg}}\n</code></pre></li> <li>Cargo.toml<pre><code>rocket_dyn_templates = { version = \"0.1.0-rc.1\", features = [\"handlebars\"], default-features = false }\n</code></pre></li> </ol>"},{"location":"Rust/Crates/Rocket/#starships","title":"Starships","text":"<p>A naive list-details application can be implemented using the lazy_static module to create a trivial in-memory database.</p> <pre><code>#[macro_use]\nextern crate rocket;\n\nuse lazy_static::lazy_static;\nuse std::collections::HashMap;\n\nlazy_static! {\nstatic ref STARSHIPS: HashMap&lt;&amp;'static str, Starship&gt; = {\nlet mut map = HashMap::new();\nmap.insert(\n\"NCC-1701\",\nStarship {\nname: String::from(\"USS Enterprise\"),\nregistry: String::from(\"NCC-1701\"),\ncrew: 203,\n},\n);\nmap.insert(\n\"NX-74205\",\nStarship {\nname: String::from(\"USS Defiant\"),\nregistry: String::from(\"NX-74205\"),\ncrew: 50,\n}\n);\nmap\n};\n}\n\n#[derive(Debug)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: usize,\n}\n\n#[launch]\nfn rocket() -&gt; _ {\nrocket::build().mount(\"/\", routes![ship,])\n}\n\n#[get(\"/&lt;registry&gt;\")]\nfn ship(registry: &amp;str) -&gt; String {\nlet starship = STARSHIPS.get(registry); // (1)\nmatch starship {\nSome(s) =&gt; format![\"Found starship: {:?}\", s],\nNone =&gt; String::from(\"No starship found!\"),\n}\n}\n</code></pre> <ol> <li>TODO: This is a good opportunity to use simple string manipulation to make the query case-insensitive, but I can't seem to get it to work. I have to figure out a way to incorporate case-insensitivity here. Also potentially a place to implement regex..</li> </ol>"},{"location":"Rust/Crates/Rocket/#benchmarking","title":"Benchmarking","text":"Web applications can be benchmarked using the benchrs tool <pre><code>cargo install benchrs\nbenchrs -c 30 -n 3000 -k http://127.0.0.1:8000/\n</code></pre>"},{"location":"Rust/Crates/Rocket/#glossary","title":"Glossary","text":""},{"location":"Rust/Crates/Rocket/#catcher","title":"Catcher","text":"<p>A route handler returning an Option will trigger the 404 error handler or catcher when the None variant is returned. <pre><code>#[catch(404)]\nfn not_found(req: &amp;Request) -&gt; String {\nformat!(\"{} not found\", req.uri())\n}\n</code></pre></p> <p>Analogous to the mount method and routes! macro for routes, catchers are associated with a Rocket application using the register method and catchers! macro. <pre><code>#[launch]\nfn rocket() -&gt; _ {\nrocket::build()\n.mount(\"/\", routes![index,])\n.register(\"/\", catchers![not_found,])\n}\n</code></pre></p>"},{"location":"Rust/Crates/Rocket/#fairing","title":"Fairing","text":"<p>Fairings are Rocket's approach to structured middleware which hook into the request lifecycle and expose callbacks for events such as incoming requests and outgoing responses. The default builtin fairing is Shield, which injects HTTP security and privacy headers to all responses by default.</p> <p>Fairings (callbacks) are attached (registered) to the application's Rocket instance with the <code>attach()</code> method. Some structs like Template expose a fairing() method.</p> <pre><code>#[launch]\nfn rocket() -&gt; _ {\nrocket::build()\n.attach(Template::fairing())\n}\n</code></pre> <p>Fairings can be created from a function or closure using the AdHoc struct.</p>"},{"location":"Rust/Crates/Rocket/#forms","title":"Forms","text":"Forms refers to data submitted by users, referring to the information provided by users on e.g. a subscription page. In rocket these are processed into structs which are decorated with the FreeForm derivable trait, making them form guards. FreeForm is used for collections, that is when more than one form field is available for parsing. Types with a single form field should implement FromFormField instead."},{"location":"Rust/Crates/Rocket/#guards","title":"Guards","text":"<p>Request guards are used to arbitrarily validate requests, particularly API keys.  Types that implement the FromRequest trait (and specifically the from_request method, returning an Outcome enum) are request guards. Builtin request guards include CookieJar. They appear as additional parameters in the signature of a route handler. <pre><code>#[get(\"/&lt;param&gt;\")]\nfn index(param: isize, a: A, b: B, c: C)  { /* .. */ } // (1)\n</code></pre></p> <ol> <li>Here, a, b, and c are request guards.</li> </ol> <p>The term data guard refers to types that implement FromData (i.e. rocket::serde::json::Json which is also a form guard).</p> <pre><code>use rocket::serde::json::Json;\nuse serde::Deserialize;\n\n#[derive(Deserialize)]\nstruct User {\n/* ... */\n}\n\n#[post(\"/user\", format = \"json\", data = \"&lt;user&gt;\")]\nfn new_user(user: Json&lt;User&gt;) {\n/* ... */\n}\n</code></pre>"},{"location":"Rust/Crates/Rocket/#databases","title":"Databases","text":"Integration with database libraries is done through feature flags on the rocket_sync_db_pools crate. Diesel Postgres database pool<pre><code>rocket_sync_db_pools = {version = \"0.1.0-rc.1\", default-features = false, features = [\"diesel_postgres_pool\",]}\n</code></pre>"},{"location":"Rust/Crates/Rocket/#launch","title":"Launch","text":"<p>A Rocket instance represents a web server and its state, and occupies one of three phases during its lifecycle, each of which is identifiable with a trait:</p> <ul> <li>Build enables setting configuration, mounting and registering routes, managing state, and attaching fairings.</li> <li>Ignite represents finalized configuration.</li> <li>Orbit represents a running server.</li> </ul> <p>The boilerplate for a Rocket instance in fact returns the application in the Build phase</p> <pre><code>#[macro_use]\nextern crate rocket;\n\nuse rocket::{Rocket, Build};\n\n#[launch]\nfn rocket() -&gt; Rocket&lt;Build&gt; {\nrocket::build()\n}\n</code></pre> <p>Rocket instance in either Build or Ignite phases can be launched by running Rocket::launch()</p>"},{"location":"Rust/Crates/Rocket/#response","title":"Response","text":""},{"location":"Rust/Crates/Rocket/#route","title":"Route","text":"<p>Routes are associated with handler functions and are typically composed of an HTTP method (GET, POST, etc) and a URI which is further composed of a path and a query. </p> <pre><code>#[get(\"/\")]\nfn index() -&gt; &amp;'static str {\n\"Hello, World!\"\n}\n</code></pre> <p>Both paths and queries can be decomposed into segments, delimited by slashes in the path and ampersands in the query. Any segment can be static or dynamic.</p> <p>Dynamic segments correspond with an eponymous variable that is passed to the route handler. The data type must implement FromParam. Many common primitives, including numbers and Strings, already implement this trait by default.</p> Path segmentQuery segment <pre><code>#[get(\"/&lt;name&gt;\")]\nfn index(name: String) -&gt; String {\nformat![\"Hello, {}!\", name]\n}\n</code></pre> <pre><code>#[get(\"/?&lt;name&gt;\")]\nfn index(name: String) -&gt; String {\nformat![\"Hello, {}!\", name]\n}\n</code></pre> <p>Another dynamic form exists with trailing <code>..</code> called multiple segments, i.e. <code>#[get(\"/&lt;name..&gt;)\"]</code>. Such types must implement FromSegments. The existing FromSegments implementation for PathBuf already prevents insecure traversal paths using <code>..</code>.</p> <p>Finally the ignored segment <code>&lt;_&gt;</code> or <code>&lt;_..&gt;</code> is a special case which will not appear in the argument list. <pre><code>#[get(\"/&lt;_&gt;\")]\n</code></pre></p> <p>Multiple handlers can also be defined for the same route, in which case each must have a rank.</p> <p>Routes can also define a format, which is useful in POST, PUT, and DELETE requests where there is a payload. These formats are IANA media types (lowercase), as well as some aliases, such as \"html\" for \"text/html; charset=utf-8\" etc.</p>"},{"location":"Rust/Crates/Rocket/#state","title":"State","text":"A Rocket instance can manage any type that implements Send and Sync with the manage method. A managed state is typically used to handle a persistent database connection. <pre><code>use std::sync::atomic::AtomicU64;\n\nstruct VisitorCounter { visitor: AtomicU64,\n}\n\nfn rocket() -&gt; _ {\nlet counter = VisitorCounter {\nvisitor: AtomicU64::new(0),\n};\nrocket::build()\n.manage(counter)\n.mount(\"/\", &lt;!-- ... --&gt;)\n}\n</code></pre> This state is exposed as the State request guard: <pre><code>#[get(\"/\")]\nfn route(counter: &amp;State&lt;VisitorCounter&gt;,) {\ncounter.visitor.fetch_add(1, Ordering::Relaxed);\nprintln!(\"The number of visitors is: {}\", counter.visitor.load(Ordering::Relaxed));\n}\n</code></pre>"},{"location":"Rust/Crates/Rusqlite/","title":"rusqlite","text":"<p>rusqlite is a wrapper for using SQLite from Rust. Similar to the sqlite3 module in the Python standard library, procedural SQL commands are passed as strings to the execute method of a Connection object.</p>"},{"location":"Rust/Crates/Rusqlite/#tasks","title":"Tasks","text":""},{"location":"Rust/Crates/Rusqlite/#boilerplate","title":"Boilerplate","text":"<pre><code>fn main() -&gt; Result&lt;()&gt; {\nlet conn = rusqlite::Connection::open(\"database.db\")?;\nconn.execute(\"SELECT * FROM TABLE\", [])?;\nOk(())\n}\n</code></pre>"},{"location":"Rust/Crates/Rusqlite/#create-table","title":"Create table","text":"<pre><code>use rusqlite::{Connection, Result};\n\nfn main() -&gt; Result&lt;()&gt; {\nlet conn = Connection::open(\"starships.db\")?; // (1)\n\nconn.execute(\n\"CREATE TABLE IF NOT EXISTS starships (\n            registry TEXT PRIMARY KEY,\n            name TEXT NOT NULL,\n            crew INTEGER\n        )\",[]\n)?;\n\nOk(())\n}\n</code></pre> <ol> <li>This will create the database file if it does not exist.</li> </ol>"},{"location":"Rust/Crates/Rusqlite/#populate-table","title":"Populate table","text":"<pre><code>use rusqlite::{Connection, Result};\n\nstruct Starship {\nname: String,\nregistry: String,\ncrew: u32\n}\n\nfn main() -&gt; Result&lt;()&gt; {\nlet conn = Connection::open(\"starships.db\")?;\n\nlet enterprise = Starship {\nname: \"USS Enterprise\".to_string(),\nregistry: \"NCC-1701\".to_string(),\ncrew: 401\n};\n\nconn.execute(\n\"INSERT INTO starships (name, registry, crew) values (?1, ?2, ?3)\", // (1)\n[enterprise.name, enterprise.registry, enterprise.crew.to_string()] // (2)\n)?;\n\nOk(())\n}\n</code></pre> <ol> <li>Note the unusual template syntax.</li> <li>All passed values must be passed as String structs.</li> </ol>"},{"location":"Rust/Crates/Serde/","title":"serde","text":"<p>The serde_json crate  provides a rich API for interacting with JSON files.</p> <p>The json macro can be used to serialize any struct decorated with Serialize. <pre><code>use serde_json::{json, Value};\nuse serde::{Deserialize, Serialize}; // (1)\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct Starship {\nname: String,\nregistry: String,\ncrew: u64\n}\n\nfn main() {\nlet starship: Starship = Starship{\nname: \"USS Enterprise\".to_string(), registry: \"NCC-1701\".to_string(), crew: 400 };\n\nprintln!(\"{}\", json!(\"Enterprise\": {starship}));\n}\n</code></pre></p> <ol> <li>The derive attributes Serialize and Deserialize are included from  serde directly but only after enabling the derive feature (and not the serde_derive crate). <pre><code>[dependencies]\nserde = {version = \"^1.0\", features = [\"derive\"]}\n</code></pre></li> </ol> <p>Although a simpler and more naive implementation is possible, the recommended use of the API is to define a struct that reflects the model of the JSON document and to type the destination variable accordingly.</p> <p>?</p> <p>There appears to be some bizarre error in the example using &amp;str below.</p> String&amp;str <pre><code>#[derive(Debug, serde_derive::Deserialize)]\nenum Series {\nTOS,\nDS9,\nVOY,\n}\n\n#[derive(Debug, serde_derive::Deserialize)]\nstruct Starship {\nname: String,\nregistry: String,\nseries: Series,\n}\n\nfn main() {\nlet ships: Vec&lt;Starship&gt; = gen_ships(\"starships.json\");\nprintln!(\"{:?}\", ships);\n}\n\nfn gen_ships(fname: &amp;str) -&gt; Vec&lt;Starship&gt; {\nlet file = std::fs::read_to_string(&amp;fname).unwrap();\nlet ships : Vec&lt;Starship&gt; = serde_json::from_str(&amp;file).unwrap();\nships\n}\n</code></pre> <pre><code>#[derive(Debug, serde_derive::Deserialize)]\nenum Series {\nTOS,\nDS9,\nVOY,\n}\n\n#[derive(Debug, serde_derive::Deserialize)]\nstruct Starship&lt;'a&gt; {\nname: &amp;'a str,\nregistry: &amp;'a str,\nseries: Series,\n}\n\nfn main() {\nlet ships: Vec&lt;Starship&gt; = gen_ships(\"starships.json\");\nprintln!(\"{:?}\", ships);\n}\n\nfn gen_ships(fname: &amp;str) -&gt; Vec&lt;Starship&gt; {\nlet file = std::fs::read_to_string(&amp;fname).unwrap();\nlet ships : Vec&lt;Starship&gt; = serde_json::from_str(&amp;file).unwrap(); // (1)\nships\n}\n</code></pre> <ol> <li>For some reason, the compiler produces an error here, saying that &amp;file is borrowed. Furthermore the compiler will not allow ships to be returned from the function because it \"returns a value referencing data owned by the current function\".</li> </ol>"},{"location":"Rust/Crates/Structopt/","title":"structopt","text":""},{"location":"Rust/Crates/Structopt/#tasks","title":"Tasks","text":""},{"location":"Rust/Crates/Structopt/#hello-world","title":"Hello, World!","text":"<pre><code>extern crate structopt;\n\nuse structopt::StructOpt;\n\n#[derive(StructOpt)]\nstruct Options {\n#[structopt(default_value = \"World\")]\n/// Name to greet\nname: String\n}\n\nfn main() {\nlet options = Options::from_args();\nlet name = options.name;\nprintln!(\"Hello, {}!\", name);\n}\n</code></pre>"},{"location":"Rust/Crates/lazy_static/","title":"lazy_static","text":"<pre><code>use lazy_static::lazy_static;\nuse std::collections::HashMap;\n\nlazy_static! {\nstatic ref STARSHIPS: HashMap&lt;&amp;'static str, Starship&gt; = {\nlet mut map = HashMap::new();\nmap.insert(\n\"NCC-1701\",\nStarship {\nname: String::from(\"USS Enterprise\"),\nregistry: String::from(\"NCC-1701\"),\ncrew: 203,\n},\n);\nmap.insert(\n\"NX-74205\",\nStarship {\nname: String::from(\"USS Defiant\"),\nregistry: String::from(\"NX-74205\"),\ncrew: 50,\n},\n);\nmap\n};\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/","title":"Overview","text":"<p>Cursive is a TUI framework.</p> <ul> <li>Cursive widgets are called Views (i.e. TextView).</li> <li>Each screen's view tree has a StackView as root. Children are layers that can be pushed and popped.</li> <li>Callbacks are typically closures.</li> </ul> <p>Key presses are represented by Event enums.</p> <ul> <li>Alphanumeric keypresses are represented by the char itself.</li> <li>Single and multiple modifier key presses are represented by <code>Ctrl(Key)</code>, <code>Alt(Key)</code>, <code>CtrlAlt(Key)</code>, etc.</li> </ul> <p>Global keybindings are applied by calling <code>Cursive::add_global_callback()</code> on the application object.</p> <p>Keybindings that are effective only on particular Views are created by wrapping the View in OnEventView.</p>"},{"location":"Rust/Crates/Cursive/API/","title":"API","text":""},{"location":"Rust/Crates/Cursive/API/#dialog","title":"Dialog","text":"<p>Dialog can be constructed with new() or with the (barely) more concise around() helper method.</p> around()new() <pre><code>use cursive::{Cursive, CursiveExt};\nuse cursive::views::{TextView, Dialog};\n\nfn main() {\nlet mut siv = Cursive::new();\nsiv.add_global_callback('q', |s| s.quit());\n\nsiv.add_layer(\nDialog::around(TextView::new(\"Hello, world!\"))\n.button(\"Ok\", |s| s.quit())\n);\n\nsiv.run();\n}\n</code></pre> <pre><code>use cursive::{Cursive, CursiveExt};\nuse cursive::views::{TextView, Dialog};\n\nfn main() {\nlet mut siv = Cursive::new();\nsiv.add_global_callback('q', |s| s.quit());\n\nsiv.add_layer(\nDialog::new()\n.content(TextView::new(\"Hello, world!\"))\n.button(\"Ok\", |s| s.quit())\n);\n\nsiv.run();\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/API/#dummyview","title":"DummyView","text":"<p>A DummyView is used as a spacer.</p> <pre><code>use cursive::views::{DummyView, TextView, Dialog, LinearLayout};\nuse cursive::{Cursive, CursiveExt};\n\nfn main() {\nlet mut siv = Cursive::new();\nsiv.add_global_callback('q', |s| s.quit());\n\nsiv.add_layer(Dialog::new()\n.title(\"Hello, world!\")\n.content(\nLinearLayout::vertical()\n.child(TextView::new(\"Hello, World!\"))\n.child(DummyView)\n.child(TextView::new(\"Hello again!\"))\n)\n);\n\nsiv.run();\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/API/#hexview","title":"HexView","text":"<p>Hexview is available from the cursive_hexview crate.</p> <pre><code>use cursive::view::{Scrollable,Resizable};\nuse cursive_hexview::{DisplayState, HexView,HexViewConfig};\nuse std::env;\nuse std::fs::File;\nuse std::io::{self, Read};\nuse std::path::Path;\n\nfn read_file(path: &amp;Path) -&gt; Result&lt;Vec&lt;u8&gt;, io::Error&gt; {\nlet mut file = File::open(path)?;\nlet mut buf = Vec::new();\nfile.read_to_end(&amp;mut buf)?;\nOk(buf)\n}\n\nfn main() {\nlet arg = env::args()\n.nth(1)\n.expect(\"Provide a valid filename\");\nlet path = Path::new(&amp;arg);\n\nlet mut cur = cursive::default();\nlet view = HexView::new_from_iter(read_file(path).expect(\"Cannot read file\")).display_state(DisplayState::Enabled)\n.config(HexViewConfig {\nbytes_per_line: 48,\nbytes_per_group: 8,\n..Default::default()\n})\n.scrollable().full_screen();\n\ncur.add_layer(view);\ncur.run();\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/API/#linearlayout","title":"LinearLayout","text":"<p>A LinearLayout supports horizontal or vertical layout similar to a StackPanel in WinUI.</p> <pre><code>use cursive::views::{DummyView, TextView, Dialog, LinearLayout};\nuse cursive::{Cursive, CursiveExt};\n\nfn main() {\nlet mut siv = Cursive::new();\nsiv.add_global_callback('q', |s| s.quit());\n\nsiv.add_layer(Dialog::new()\n.title(\"Hello, world!\")\n.content(\nLinearLayout::vertical()\n.child(TextView::new(\"Hello, World!\"))\n.child(DummyView)\n.child(TextView::new(\"Hello again!\"))\n)\n);\n\nsiv.run();\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/API/#oneventview","title":"OnEventView","text":"<p>OnEventView allows keybindings to take effect on wrapped Views.</p> <pre><code>use cursive::views::{OnEventView, TextView};\nuse cursive::event::{Key, Event, EventTrigger};\nuse cursive::Cursive;\n\nfn main() {\nlet mut siv = cursive::default();\nsiv.add_layer(\nOnEventView::new(TextView::new(\"Hello, World!\\n(Q to quit)\"))\n.on_event('q', Cursive::quit )  // (1)\n.on_event(Event::Key(Key::Enter), |s| { // (2)\ns.pop_layer();\ns.add_layer(TextView::new(\"Enter key pressed!\"));\n})\n.on_event(Event::CtrlChar('a'), |s| { // (3)\ns.pop_layer();\ns.add_layer(TextView::new(\"Ctrl+A pressed!\"))\n})\n.on_event(EventTrigger::mouse(), |s| { // (4)\ns.pop_layer();\ns.add_layer(TextView::new(\"Mouse clicked!\"));\n})\n);\nsiv.run();\n}\n</code></pre> <ol> <li>Alphanumeric keypresses are represented by the char itself.</li> <li>Non-alphanumeric keypresses are represented by Event::Key wrapping a Key variant (<code>Enter</code>, <code>Esc</code>, etc.).</li> <li>Single and multiple modifier key presses are represented by particular Event variants that wrap Key variants for nonalphanumeric keypresses, i.e. <code>Event::Ctrl(Key)</code>, <code>Event::Alt(Key)</code>, <code>Event::CtrlAlt(Key)</code>. Separate Event variants are used for alphanumeric characters (i.e. <code>Event::CtrlChar(char)</code>, <code>Event::Alt(char)</code>, <code>Event::CtrlAltChar(char)</code>, etc) which wrap the char value of the keypress.</li> <li>EventTrigger::mouse() will respond to any mouse click. More specific mouse events may be specified by a MouseEvent variant containing a MouseButton variant (TODO).</li> </ol> <p>In fact there are a variety of methods available that affect how Events are routed.</p> <ul> <li>on_event() and on_event_inner() register callbacks that are ignored by the wrapped View (?).</li> <li>on_pre_event() and on_pre_event_inner() register callbacks that need preprocessing and control whether the wrapped View should be given the Event.</li> </ul> <p>In this example, it appears not to matter which of the methods is used to register callbacks, possibly because the wrapped View ultimately receives the Event in either case.</p> on_event_inner()on_pre_event_inner() <pre><code>use cursive::traits::{Scrollable, Resizable};\nuse cursive::views::{Dialog, SelectView, TextView,OnEventView};\nuse cursive::event::EventResult;\n\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nsiv.pop_layer();\n\nlet mut select = SelectView::new();\nselect.add_all_str(vec![\"USS Enterprise\", \"USS Voyager\", \"USS Reliant\"]);\nselect.set_on_submit(show_ship);\n\nlet select = OnEventView::new(select)\n.on_event_inner('k', |s, _| {\nlet cb = s.select_up(1);\nSome(EventResult::Consumed(Some(cb)))\n})\n.on_event_inner('j', |s, _| {\nlet cb = s.select_down(1);\nSome(EventResult::Consumed(Some(cb)))\n});\nsiv.add_layer(\nDialog::around(\nselect.scrollable()         // \n.fixed_size((20, 10))   // \n).title(\"Choose a ship\"),\n);\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, starship: &amp;str) {\nsiv.pop_layer();\nlet starship = String::from(starship).replace(\"USS \", \"\");\nlet text = format!(\"The {} is a fine ship!\", starship);\nsiv.add_layer(\nDialog::around(\nTextView::new(text))\n.button(\"OK\", |s| list_ships(s))\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n</code></pre> <pre><code>use cursive::traits::{Scrollable, Resizable};\nuse cursive::views::{Dialog, SelectView, TextView,OnEventView};\nuse cursive::event::EventResult;\n\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nsiv.pop_layer();\n\nlet mut select = SelectView::new();\nselect.add_all_str(vec![\"USS Enterprise\", \"USS Voyager\", \"USS Reliant\"]);\nselect.set_on_submit(show_ship);\n\nlet select = OnEventView::new(select)\n.on_pre_event_inner('k', |s, _| {\nlet cb = s.select_up(1);\nSome(EventResult::Consumed(Some(cb)))\n})\n.on_pre_event_inner('j', |s, _| {\nlet cb = s.select_down(1);\nSome(EventResult::Consumed(Some(cb)))\n});\nsiv.add_layer(\nDialog::around(\nselect.scrollable()         // \n.fixed_size((20, 10))   // \n).title(\"Choose a ship\"),\n);\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, starship: &amp;str) {\nsiv.pop_layer();\nlet starship = String::from(starship).replace(\"USS \", \"\");\nlet text = format!(\"The {} is a fine ship!\", starship);\nsiv.add_layer(\nDialog::around(\nTextView::new(text))\n.button(\"OK\", |s| list_ships(s))\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/API/#paddedview","title":"PaddedView","text":"<p>PaddedView wraps a single View and applies a margin specified in terminal cells. It can be instantiated with new() or the somewhat abbreviated lrtb() help method.</p> lrtb()new() <pre><code>use cursive::{Cursive, CursiveExt};\nuse cursive::views::{TextView, PaddedView};\n\nfn main() {\nlet mut siv = Cursive::new();\nsiv.add_global_callback('q', |s| s.quit());\n\nsiv.add_layer(\nPaddedView::lrtb(2, 2, 1, 1, TextView::new(\"Hello, World!\"))\n);\n\nsiv.run();\n}\n</code></pre> <pre><code>use cursive::{Cursive, CursiveExt};\nuse cursive::views::{TextView, PaddedView};\nuse cursive::view::Margins;\nfn main() {\nlet mut siv = Cursive::new();\nsiv.add_global_callback('q', |s| s.quit());\n\nsiv.add_layer(\nPaddedView::new(Margins::lrtb(2, 2, 1, 1), TextView::new(\"Hello, World!\"))\n);\n\nsiv.run();\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/API/#radiogroup","title":"RadioGroup","text":"<p>RadioGroup&lt;T&gt; is used to coordinate multiple radio buttons.</p> <p>Because RadioGroup is a View which does not implement Nameable, a closure will always be used to retrieve the user's choice with selection(). It is possible to abstract some of the logic of creating a new View using the user's selection, with some bizarre syntax.</p> ClosureClosure and function <pre><code>use cursive::views::{Dialog,LinearLayout,RadioGroup,TextView};\n\nfn main() {\nlet mut siv = cursive::default();\nlet mut options : RadioGroup&lt;String&gt; = RadioGroup::new(); // (1)\nsiv.add_layer(\nDialog::around(\nLinearLayout::vertical()\n.child(options.button_str(\"Plato\"))\n.child(options.button_str(\"Aristotle\")) // (2)\n.child(options.button_str(\"Socrates\")),\n).button(\"Ok\", move |s| { // (3)\ns.pop_layer();\ns.add_layer(\nDialog::around(\nTextView::new(format!(\"You chose {}!\", options.selection()))\n).button(\"Ok\", |s| s.quit())\n);\n})\n);\nsiv.run();\n}\n</code></pre> <ol> <li>RadioGroup is a generic and must be typed (according to its values?)</li> <li>The button_str() method adds a button where the value equals its label. A button() method is also available which takes an additional argument, the value to be passed back upon selection.</li> <li>The move keyword must be used because the closure may outlive the current function but it captures options from the environment of the current function's scope.</li> </ol> <pre><code>use cursive::views::{Dialog,LinearLayout,RadioGroup,TextView};\n\nfn main() {\nlet mut siv = cursive::default();\nlet mut options : RadioGroup&lt;String&gt; = RadioGroup::new();\nsiv.add_layer(\nDialog::around(\nLinearLayout::vertical()\n.child(options.button_str(\"Plato\"))\n.child(options.button_str(\"Aristotle\"))\n.child(options.button_str(\"Socrates\")),\n).button(\"Ok\", move |s| {\nlet selection = &amp;*options.selection(); // (1)\ndisplay_selection(s, selection);\n})\n);\nsiv.run();\n}\n\nfn display_selection(siv: &amp;mut cursive::Cursive, selection: &amp;String) {\nsiv.pop_layer();\nsiv.add_layer(\nDialog::around(\nTextView::new(format!(\"You chose {}!\", selection))\n).button(\"Ok\", |s| s.quit())\n);\n}\n</code></pre> <ol> <li>This is apparently needed to dereference the Rc returned by selection()</li> </ol> <p></p>"},{"location":"Rust/Crates/Cursive/API/#resizedview","title":"ResizedView","text":"<p>A ResizedView functions as a container around a single view, similar to a Box in GTK. ResizedView can be initiated with a variety of methods that define its appearance.</p> <ul> <li>Helper methods like with_fixed_size() take a tuple of two integers defining the size of the view in columns and rows as well as an inner View.</li> <li>Helper methods like with_fixed_height() take a single integer and an inner View.</li> <li>Finally, methods like with_full_screen() take only the contained View.</li> </ul>"},{"location":"Rust/Crates/Cursive/API/#selectview","title":"SelectView","text":"<p>SelectView allows an item to be selected from a list and so is equivalent to widgets like ListView in WinUI.</p> <pre><code>use cursive::traits::{Scrollable, Resizable};\nuse cursive::views::{Dialog, SelectView, TextView};\nuse cursive::Cursive;\n\nfn main() {\nlet mut siv = cursive::default();\n\nlet mut select = SelectView::new();\nselect.add_all_str(vec![\"USS Enterprise\", \"USS Voyager\", \"USS Reliant\"]);\nselect.set_on_submit(show_next_window); // (1)\n\nlet select = OnEventView::new(select)\n.on_pre_event_inner('k', |s, _| {\nlet cb = s.select_up(1);\nSome(EventResult::Consumed(Some(cb)))\n})\n\nsiv.add_layer(\nDialog::around(\nselect.scrollable()         // (2)\n.fixed_size((20, 10))   // (3)\n) .title(\"Where are you from?\"),\n);\nsiv.run();\n}\n\nfn show_next_window(siv: &amp;mut Cursive, starship: &amp;str) {\nsiv.pop_layer();\nlet starship = String::from(starship).replace(\"USS \", \"\");\nlet text = format!(\"The {} is a fine ship!\", starship);\nsiv.add_layer(\nDialog::around(TextView::new(text)).button(\"Quit\", |s| s.quit()),\n);\n}\n</code></pre> <ol> <li>Sets the callback for when ++Enter++ is pressed.</li> <li>scrollable() is included in cursive::traits::Scrollable.</li> <li>fixed_size() is included in cursive::traits::Resizable</li> </ol> <p>autojump() will change the selection in response to keypresses. This will interfere with the global callback set for <code>q</code>.</p>"},{"location":"Rust/Crates/Cursive/API/#tabpanel","title":"TabPanel","text":"TabPanel is an ease-of-use wrapper around TabView from the cursive-tabs crate."},{"location":"Rust/Crates/Cursive/Tasks/","title":"Tasks","text":""},{"location":"Rust/Crates/Cursive/Tasks/#boilerplate","title":"Boilerplate","text":"<p>Cursive apps are constructed procedurally using a succession of method calls, which require the main Cursive object (conventionally named \"siv\" in documentation) to be mutable.</p> <p>The default() function which sits at the root of the cursive module streamlines some of the boilerplate involved with calling Cursive::new() explicitly.</p> default()Cursive::new() <pre><code>fn main() {\nlet mut siv = cursive::default();\nsiv.add_global_callback('q', |s| s.quit());\n\n// ...\n\nsiv.run();\n}\n</code></pre> <pre><code>use cursive::{Cursive, CursiveExt}; // (1)\nfn main() {\nlet mut app = Cursive::new();\napp.add_global_callback('q', |s| s.quit());\n\n// ...\n\napp.run();\n}\n</code></pre> <ol> <li>CursiveExt must be imported in order to call the run() method.</li> </ol> <p>Because Cursive depends on the ncurses backend, it won't work on Windows without additional modifications to Cargo.toml</p> Cargo.toml<pre><code>[dependencies.cursive]\nversion = \"0.16.3\"\ndefault-features = false\n\n[features]\ndefault = [\"pancurses-backend\"]\npancurses-backend = [\"cursive/pancurses-backend\"]\n</code></pre>"},{"location":"Rust/Crates/Cursive/Tasks/#hello-world","title":"Hello, World!","text":"TextViewDialogEditViewChoice of greetingCLI integration <pre><code>use cursive::views::TextView;\n\nfn main() {\nlet mut siv = cursive::default();\nsiv.add_layer(\nTextView::new(\"Hello World!\")\n);\nsiv.run();\n}\n</code></pre> <pre><code>use cursive::views::TextView;\n\nfn main() {\nlet mut siv = cursive::default();\nsiv.add_layer(\nDialog::around(\nTextView::new(\"Hello World!\")\n)\n);\nsiv.run();\n}\n</code></pre> <pre><code>use cursive::view::Nameable;\nuse cursive::views::{Dialog, EditView, TextView };\n\nfn main() {\nlet mut siv = cursive::default();\nget_name(&amp;mut siv);\nsiv.run();\n}\n\nfn get_name(siv: &amp;mut cursive::Cursive) { // (1)\nsiv.pop_layer();\nsiv.add_layer(\nDialog::new()\n.title(\"Please enter name\")\n.content(EditView::new().with_name(\"message\")) // (2)\n.button(\"OK\", |s| {\ngreet_user(s)\n})\n.button(\"Quit\", cursive::Cursive::quit)\n);\n}\n\nfn greet_user(siv: &amp;mut cursive::Cursive) {\nlet greeting = format!(\"Hello, {}!\", siv.call_on_name(\"message\", |t: &amp;mut EditView| t.get_content()) // (3)\n.unwrap());\nsiv.pop_layer(); // (4)\nsiv.add_layer(\nDialog::around(TextView::new(greeting))\n.title(\"Greetings!\")\n.button(\"OK\", |s| { get_name(s) }  ), // (5)\n);\n}\n</code></pre> <ol> <li>In order to implement multiple pages, the Cursive object must be passed as a mutable reference from function to function.</li> <li>with_name(), only accessible after including the Nameable trait, implicitly wraps the the view in a NamedView.</li> <li>call_on_name() allows a named View to be accessed.</li> <li>Each function in turn runs pop_layer() on the Cursive object to remove the previous View.</li> <li>This callback sends the user back to the first View, to repeat the process.</li> </ol> <pre><code>use cursive::view::Nameable;\nuse cursive::views::{Dialog, EditView, LinearLayout, ListView, RadioGroup, TextView};\n\nfn main() {\nlet mut siv = cursive::default();\nget_name(&amp;mut siv);\nsiv.run();\n}\n\nfn get_name(siv: &amp;mut cursive::Cursive) {\nsiv.pop_layer();\nlet mut options: RadioGroup&lt;String&gt; = RadioGroup::new();\nsiv.add_layer(\nDialog::around(\nListView::new()\n.child(\"Name\", EditView::new().with_name(\"name\"))\n.child(\n\"Greeting\",\nLinearLayout::vertical()\n.child(options.button_str(\"Hello\"))\n.child(options.button_str(\"Greetings\")),\n),\n)\n.button(\"Ok\", move |s| {\nlet selection = &amp;*options.selection();\ngreet_user(s, selection);\n})\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n\nfn greet_user(siv: &amp;mut cursive::Cursive, greeting: &amp;String) {\nlet name = siv\n.call_on_name(\"name\", |t: &amp;mut EditView| t.get_content())\n.unwrap();\n\nsiv.pop_layer();\nsiv.add_layer(\nDialog::around(TextView::new(format!(\"{}, {}!\", greeting, name)))\n.button(\"Ok\", |s| get_name(s)),\n);\n}\n</code></pre> <pre><code>use cursive::view::Nameable;\nuse cursive::views::{Dialog, EditView, LinearLayout, ListView, RadioGroup, TextView};\n\nfn main() {\nlet mut siv = cursive::default();\nget_name(&amp;mut siv);\nsiv.run();\n}\n\nfn get_name(siv: &amp;mut cursive::Cursive) {\nsiv.pop_layer();\nlet mut options: RadioGroup&lt;String&gt; = RadioGroup::new();\n\nlet name = match std::env::args().nth(1) {\nSome(s) =&gt; s,\n_ =&gt; String::from(\"World\")\n};\nlet editview = EditView::new()\n.content(name)\n.with_name(\"name\");\nsiv.add_layer(\nDialog::around(\nListView::new()\n.child(\"Name\", editview)\n.child(\n\"Greeting\",\nLinearLayout::vertical()\n.child(options.button_str(\"Hello\"))\n.child(options.button_str(\"Greetings\")),\n),\n)\n.button(\"Ok\", move |s| {\nlet selection = &amp;*options.selection();\ngreet_user(s, selection);\n})\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n\nfn greet_user(siv: &amp;mut cursive::Cursive, greeting: &amp;String) {\nlet name = siv\n.call_on_name(\"name\", |t: &amp;mut EditView| t.get_content())\n.unwrap();\n\nsiv.pop_layer();\nsiv.add_layer(\nDialog::around(TextView::new(format!(\"{}, {}!\", greeting, name)))\n.button(\"Ok\", |s| get_name(s)),\n);\n}\n</code></pre>"},{"location":"Rust/Crates/Cursive/Tasks/#installation-wizard","title":"Installation wizard","text":""},{"location":"Rust/Crates/Cursive/Tasks/#starships","title":"Starships","text":"SelectViewEnumsStructsVim keybindingsJSONPostgreSQL <pre><code>use cursive::traits::{Scrollable, Resizable};\nuse cursive::views::{Dialog, SelectView, TextView};\n\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nsiv.pop_layer();\n\nlet mut select = SelectView::new();\nselect.add_all_str(vec![\"USS Enterprise\", \"USS Voyager\", \"USS Reliant\"]);\nselect.set_on_submit(show_ship);\n\nsiv.add_layer(\nDialog::around(\nselect.scrollable()\n.fixed_size((20, 10))\n).title(\"Choose a ship\"),\n);\n\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, starship: &amp;str) {\nsiv.pop_layer();\nlet starship = String::from(starship).replace(\"USS \", \"\");\nlet text = format!(\"The {} is a fine ship!\", starship);\nsiv.add_layer(\nDialog::around(\nTextView::new(text))\n.button(\"OK\", |s| list_ships(s))\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n</code></pre> <pre><code>use cursive::traits::{Scrollable, Resizable};\nuse cursive::views::{Dialog, SelectView, TextView};\n\nmod models;\nuse models::Starships; // (1)\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nsiv.pop_layer();\n\nlet select = SelectView::new()\n.with_all_str(vec![Starships::Enterprise, Starships::Voyager, Starships::Defiant])\n.on_submit(show_ship);\n\nsiv.add_layer(\nDialog::around(\nselect.scrollable()\n.fixed_size((20, 10))\n).title(\"Choose a ship\"),\n);\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, starship: &amp;str) {\nsiv.pop_layer();\nlet starship = String::from(starship).replace(\"USS \", \"\");\nlet text = format!(\"The {} is a fine ship!\", starship);\nsiv.add_layer(\nDialog::around(\nTextView::new(text))\n.button(\"OK\", |s| list_ships(s))\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n</code></pre> <ol> <li>Implementing the list of starships as an enum is possible so long as the From&lt;Starships&gt; trait is implemented for String. <pre><code>enum Starships { Enterprise, Defiant, Voyager, }\n\nimpl&lt;'a&gt; std::convert::From&lt;Starships&gt; for String {\nfn from(item: Starships) -&gt; String {\nmatch item {\nStarships::Enterprise =&gt; String::from(\"USS Enterprise\"),\nStarships::Defiant =&gt; String::from(\"USS Defiant\"),\nStarships::Voyager =&gt; String::from(\"USS Voyager\"),\n}\n}\n}\n</code></pre></li> </ol> <pre><code>use cursive::traits::{Scrollable, Resizable};\nuse cursive::views::{Dialog, SelectView, TextView, ListView};\n\nmod models; // (1)\nuse models::Starship;\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn get_ships&lt;'a&gt;() -&gt; Vec&lt;Starship&lt;'a&gt;&gt; {\nlet output = vec![\nStarship { name: \"USS Enterprise\", registry: \"NCC-1701\", series: Series::TOS},\nStarship { name: \"USS Defiant\", registry: \"NX-74205\", series: Series::DS9 },\nStarship { name: \"USS Voyager\", registry: \"NCC-74656\", series: Series::VOY },\n];\noutput\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nlet ships = get_ships();\nsiv.pop_layer();\n\nlet select = SelectView::new()\n.with_all(ships.into_iter().map(|ship| (ship.name, ship))) // (2)\n.on_submit(show_ship); // (3)\n\nsiv.add_layer(\nDialog::around(\nselect.scrollable()\n.fixed_size((20, 10))\n).title(\"Choose a ship\"),\n);\n\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, starship: &amp;Starship) {\nsiv.add_layer(\nDialog::around(\nListView::new()\n.child(\"Name:\",TextView::new(starship.name))\n.child(\"Registry:\", TextView::new(starship.registry))\n.child(\"Series:\", TextView::new(starship.series))\n)\n.button(\"OK\", list_ships)\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n</code></pre> <ol> <li>The Series enum must implement the Copy trait because it may not be moved in the detailed view. This is the simpler method. <pre><code>#[derive(Clone, Copy)]\nenum Series { TOS,VOY, DS9 }\n\nimpl std::convert::From&lt;Series&gt; for String {\nfn from(item: Series) -&gt; String {\nString::from(match item {\nSeries::TOS =&gt; \"The Original Series\",\nSeries::VOY =&gt; \"Voyager\",\nSeries::DS9 =&gt; \"Deep Space Nine\",\n})\n}\n}\n\nstruct Starship&lt;'a&gt; {\nname: &amp;'a str,\nregistry: &amp;'a str,\nseries: Series\n}\n</code></pre></li> <li>Using with_all() or set_with_all() apparently requires a Map struct, created by the map on Iterator.  The keys of this object define the text that appears in the SelectView, and the values define the data passed to the callback specified in on_submit().</li> <li>Sometimes a bizarre and unhelpful compiler error will occur when this second value does not match the signature of the specified callback.  For example, changing ship to a unit type () will raise a compiler error: <pre><code>.on_submit(show_ship),\n --------- ^^^^^^^^^ expected signature of `for&lt;'r, 's&gt; fn(&amp;'r mut Cursive, &amp;'s ()) -&gt; _`\n |\n required by a bound introduced by this call\n</code></pre></li> </ol> <pre><code>use cursive::traits::{Scrollable, Resizable};\nuse cursive::views::{Dialog, SelectView, TextView, ListView, OnEventView};\nuse cursive::event::EventResult;\nmod models; // (1)\nuse models::Starship;\n\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn get_ships&lt;'a&gt;() -&gt; Vec&lt;Starship&lt;'a&gt;&gt; {\nlet output = vec![\nStarship { name: \"USS Enterprise\", registry: \"NCC-1701\", series: Series::TOS},\nStarship { name: \"USS Defiant\", registry: \"NX-74205\", series: Series::DS9 },\nStarship { name: \"USS Voyager\", registry: \"NCC-74656\", series: Series::VOY },\n];\noutput\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nlet ships = get_ships();\nsiv.pop_layer();\n\nlet select = SelectView::new()\n.with_all(ships.into_iter().map(|ship| (ship.name, ship)))\n.on_submit(show_ship);\n\nlet select = OnEventView::new(select)\n.on_event_inner('k', |s, _| {\nlet cb = s.select_up(1);\nSome(EventResult::Consumed(Some(cb)))\n})\n.on_event_inner('j', |s, _| {\nlet cb = s.select_down(1);\nSome(EventResult::Consumed(Some(cb)))\n});\nsiv.add_layer(\nDialog::around(\nselect.scrollable()\n.fixed_size((20, 10))\n).title(\"Choose a ship\"),\n);\n\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, starship: &amp;Starship) {\nsiv.add_layer(\nDialog::around(\nListView::new()\n.child(\"Name:\",TextView::new(starship.name))\n.child(\"Registry:\", TextView::new(starship.registry))\n.child(\"Series:\", TextView::new(starship.series)) // ...\n)\n.button(\"OK\", list_ships)\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n</code></pre> <ol> <li>models.rs<pre><code>#[derive(Clone, Copy)]\nenum Series { TOS, TNG, VOY, }\n\nimpl std::convert::From&lt;Series&gt; for String {\nfn from(item: Series) -&gt; String {\nString::from(match item {\nSeries::TOS =&gt; \"The Original Series\",\nSeries::TNG =&gt; \"The Next Generation\",\nSeries::VOY =&gt; \"Voyager\",\n})\n}\n}\n\nstruct Starship&lt;'a&gt; {\nname: &amp;'a str,\nregistry: &amp;'a str,\nseries: Series\n}\n</code></pre></li> </ol> <pre><code>use cursive::event::EventResult;\nuse cursive::traits::{Resizable, Scrollable};\nuse cursive::views::{Dialog, ListView, OnEventView, SelectView, TextView};\n\nmod models; // (1)\nuse models::Starship;\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn get_ships() -&gt; Vec&lt;Starship&gt; {\nlet f = std::fs::read_to_string(\"starships.json\").unwrap();\nlet output: Vec&lt;Starship&gt; = serde_json::from_str(&amp;f).unwrap();\noutput\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nlet ships: Vec&lt;Starship&gt; = get_ships();\nsiv.pop_layer();\n\nlet select = SelectView::new()\n.with_all(ships.into_iter().map(|ship| (ship.name.clone(), ship))) // (2)\n.on_submit(show_ship);\n\nlet select = OnEventView::new(select)\n.on_event_inner('k', |s, _| {\nlet cb = s.select_up(1);\nSome(EventResult::Consumed(Some(cb)))\n})\n.on_event_inner('j', |s, _| {\nlet cb = s.select_down(1);\nSome(EventResult::Consumed(Some(cb)))\n});\n\nsiv.add_layer(Dialog::around(select.scrollable().fixed_size((20, 10))).title(\"Choose a ship\"));\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, starship: &amp;Starship) {\nsiv.add_layer(\nDialog::around(\nListView::new()\n.child(\"Name:\", TextView::new(&amp;starship.name)) // (3)\n.child(\"Registry:\", TextView::new(&amp;starship.registry))\n.child(\"Series:\", TextView::new(starship.series)), )\n.button(\"OK\", list_ships)\n.button(\"Quit\", cursive::Cursive::quit),\n);\n}\n</code></pre> <ol> <li>The serde_derive::Deserialize derive is necessary for the mapped struct as well as the Series enum because it appears as a member of the Starship struct. models.rs<pre><code>#[derive(Clone, Copy, serde_derive::Deserialize)]\nenum Series {\nTOS,\nDS9,\nVOY,\n}\n\nimpl std::convert::From&lt;Series&gt; for String {\nfn from(item: Series) -&gt; String {\nString::from(match item {\nSeries::TOS =&gt; \"The Original Series\",\nSeries::DS9 =&gt; \"Deep Space Nine\",\nSeries::VOY =&gt; \"Voyager\",\n})\n}\n}\n\n#[derive(serde_derive::Deserialize)]\nstruct Starship {\nname: String,\nregistry: String,\nseries: Series,\n}    </code></pre></li> <li>A clone() is necessary here, although I'm not sure why. A reference is not accepted.</li> <li>References are accepted here, as is a clone().</li> </ol> <pre><code>#[macro_use] extern crate diesel;\nuse diesel::prelude::*;  use diesel::pg::PgConnection;\nuse diesel::result::QueryResult;\nuse cursive::view::{Nameable, Resizable};\nuse cursive::views::{Dialog, EditView, ListView, SelectView, TextView};\n\nmod models; // (3)\nuse models::Starship;\nmod schema;\nuse schema::starships::dsl::*;\nfn main() {\nlet mut siv = cursive::default();\nlist_ships(&amp;mut siv);\nsiv.run();\n}\n\nfn get_ships() -&gt; QueryResult&lt;Vec&lt;Starship&gt;&gt; {\ndotenv::dotenv().expect(\"Couldn't load .env file\");\nlet url = &amp;std::env::var(\"DATABASE_URL\")\n.expect(\"Couldn't retrieve DATABASE_URL environment variable\");\nlet conn = PgConnection::establish(url).unwrap();\nstarships.load::&lt;Starship&gt;(&amp;conn)\n}\n\nfn list_ships(siv: &amp;mut cursive::Cursive) {\nlet ships: Vec&lt;Starship&gt; = get_ships().unwrap();\nsiv.pop_layer();\nsiv.add_layer(\nDialog::around(\nSelectView::new()\n.with_all(\nships\n.into_iter()\n.map(|ship| (format!(\"{} ({})\", ship.name, ship.registry), ship)),\n)\n.on_submit(show_ship)\n)\n.button(\"Quit\", cursive::Cursive::quit)\n.button(\"Add\", add_ship)\n);\n}\n\nfn show_ship(siv: &amp;mut cursive::Cursive, ship: &amp;Starship) {\nsiv.add_layer(\nDialog::around(\nListView::new()\n.child(\"Name:\", TextView::new(&amp;ship.name))\n.child(\"Registry:\", TextView::new(&amp;ship.registry))\n.child(\"Crew:\", TextView::new(format!(\"{}\", ship.crew))),\n)\n.button(\"OK\", list_ships),\n)\n}\n\nfn add_ship(siv: &amp;mut cursive::Cursive) {\nlet conn = get_connection().unwrap();\nsiv.add_layer(\nDialog::around(\nListView::new()\n.child(\"Name:\", EditView::new().with_name(\"name\"))\n.child(\"Registry:\", EditView::new().with_name(\"registry\"))\n.child(\"Crew:\", EditView::new().with_name(\"crew\")),\n)\n.button(\"Ok\", move |s| {\nlet input_name = s\n.call_on_name(\"name\", |t: &amp;mut EditView| t.get_content())\n.unwrap();\nlet input_registry = s\n.call_on_name(\"registry\", |t: &amp;mut EditView| t.get_content())\n.unwrap();\nlet input_crew = s\n.call_on_name(\"crew\", |t: &amp;mut EditView| t.get_content())\n.unwrap()\n.parse::&lt;i32&gt;()\n.unwrap();\nlet input: Starship = Starship {\nname:       (*input_name).clone(), // (2)\nregistry:   (*input_registry).clone(),\ncrew:       input_crew,\n};\ninput.insert_into(starships) // (4)\n.get_result::&lt;Starship&gt;(&amp;conn) // (5)\n.unwrap();\nlist_ships(s);\n}).min_width(30)\n);\n}\n</code></pre> <ol> <li><pre><code>use crate::schema::starships;\n\n#[derive(Debug, Queryable, Insertable)]\npub struct Starship {\npub name: String,\npub registry: String,\npub crew: i32,\n}\n</code></pre></li> <li>Struct intiializations move values, so the String must be deeply copied, here using String::clone</li> <li><pre><code>use crate::schema::starships;\n\n#[derive(Debug, Queryable, Insertable)]\npub struct Starship {\npub name: String,\npub registry: String,\npub crew: i32,\n}\n</code></pre></li> <li>insert_into is a method on the Insertable trait Equivalent to: <pre><code>diesel::insert_into(starships)\n.values(&amp;input)\n.get_result::&lt;Starship&gt;(&amp;conn)\n.unwrap();\n</code></pre></li> <li> <p>Diesel collects various methods that execute a query into the RunQueryDsl trait. These methods include:</p> <ul> <li>get_result which returns the affected row</li> <li>get_results which returns a Vec of affected rows</li> <li>execute which returns a usize of affected rows.</li> </ul> </li> </ol>"},{"location":"Rust/Crates/Cursive/Tasks/#raven","title":"Raven","text":"<p>A multi-page wizard can be constructed with the cursive-tabs crate.</p> <pre><code>use cursive::views::{TextView};\nuse cursive::view::Nameable;\nuse cursive_tabs::TabPanel;\n\nfn main() {\nlet mut siv = cursive::default();\nsiv.add_global_callback('q', |s| s.quit());\n\nlet tabs = TabPanel::new()\n.with_tab(TextView::new(include_str!(\"assets/raven1\")).with_name(\"1\"))\n.with_tab(TextView::new(include_str!(\"assets/raven2\")).with_name(\"2\"))\n.with_tab(TextView::new(include_str!(\"assets/raven3\")).with_name(\"3\"))\n.with_tab(TextView::new(include_str!(\"assets/raven4\")).with_name(\"4\"))\n.with_tab(TextView::new(include_str!(\"assets/raven5\")).with_name(\"5\"))\n;\n\nsiv.add_layer(tabs);\nsiv.run();\n}\n</code></pre> <p>Key bindings are added as global callbacks. This functionality works because the TabPanel is nameable and can be retrieved by the callback by its name.</p> <pre><code>use cursive::views::{TextView};\nuse cursive::view::Nameable;\nuse cursive::event::Key;\nuse cursive_tabs::TabPanel;\n\nfn main() {\nlet mut siv = cursive::default();\nsiv.add_global_callback('q', |s| s.quit());\n\nlet tabs = TabPanel::new()\n.with_tab(TextView::new(include_str!(\"assets/raven1\")).with_name(\"1\"))\n.with_tab(TextView::new(include_str!(\"assets/raven2\")).with_name(\"2\"))\n.with_tab(TextView::new(include_str!(\"assets/raven3\")).with_name(\"3\"))\n.with_tab(TextView::new(include_str!(\"assets/raven4\")).with_name(\"4\"))\n.with_tab(TextView::new(include_str!(\"assets/raven5\")).with_name(\"5\"))\n;\n\nsiv.add_layer(tabs.with_name(\"Tabs\"));\nsiv.add_global_callback(Key::PageUp, |s| {\nlet mut tabs: cursive::views::ViewRef&lt;TabPanel&gt; = s.find_name(\"Tabs\").unwrap();\ntabs.prev();\n});\nsiv.add_global_callback(Key::PageDown, |s| {\nlet mut tabs: cursive::views::ViewRef&lt;TabPanel&gt; = s.find_name(\"Tabs\").unwrap();\ntabs.next();\n});\nsiv.run();\n}\n</code></pre>"},{"location":"Rust/Crates/Diesel/","title":"Index","text":""},{"location":"Rust/Crates/Diesel/#overview","title":"Overview","text":"<p>Learning Diesel is harder than other crates because of the amount of setup that is required.</p> <ul> <li>Reliant on a specific workflow dependent on the Diesel CLI utility</li> <li>A lot of boilerplate code</li> <li>Multiple APIs available for doing the same thing</li> </ul> <p>Diesel supports procedural functions for CRUD functions as well as (mostly) equivalent methods on structs that implement Dsl traits. The Dsl API is more fluent </p> CRUD verb function method Create diesel::insert_into diesel::dsl::insert_into Delete diesel::delete diesel::dsl::delete?"},{"location":"Rust/Crates/Diesel/#prerequisites","title":"Prerequisites","text":"<p>Diesel has drivers for various DBMSes. Prerequisites for these have to be installed before attempting to install the corresponding features in Diesel CLI or compiling a Rust project using it.</p>  Arch Red Hat Ubuntu <pre><code>pacman -S postgresql\nsu - postgres -c 'initdb --pgdata /var/lib/postgres/data' # (1)\nsystemctl enable postgresql --now\n</code></pre> <ol> <li>On Arch, this step appears to be necessary before the postgresql service can be enabled. initdb requires a directory to be explicitly specified using --pgdata or alternatively the PGDATA environment variable.</li> </ol> <pre><code>dnf install libpq-devel mariadb-devel postgresql postgresql-server\npostgresql-setup --initdb # (1)\nsystemctl enable postgresql --now\n</code></pre> <ol> <li>This command facilitates initialization of the database cluster, which defaults to /var/lib/pgsql/data, similar to using initdb.</li> </ol> <pre><code>apt install libpq-dev\n</code></pre>"},{"location":"Rust/Crates/Diesel/#diesel-cli","title":"Diesel CLI","text":"Install Diesel CLI<pre><code>cargo install diesel_cli --no-default-features --features postgres sqlite # (1)\n</code></pre> <ol> <li>Without installing dependencies, the installation will fail upon calling /usr/bin/ld because it is unable to find \"-lpq\" (in the case of PostgreSQL).</li> </ol> .env<pre><code>DATABASE_URL=database.db # (1)\n</code></pre> <ol> <li>Because this is a relative path, Diesel will create the database in the working directory, wherever it may be. So absolute paths are recommended.</li> </ol> Create migrations directory and database specified in .env<pre><code>diesel setup\n</code></pre> diesel.toml<pre><code>[print_schema]\nfile = \"src/schema.rs\"\n</code></pre> schema.rs<pre><code>table! {\nstarships (registry) {\nregistry -&gt; Text,\nname -&gt; Text,\ncrew -&gt; Integer,\n}\n}\n</code></pre> <p>The schema can also be printed from the command-line <pre><code>diesel print-schema\n</code></pre></p>"},{"location":"Rust/Crates/Diesel/#migrations","title":"Migrations","text":"<p>Diesel facilitates the creation of migration scripts, reversible changes to the database's schema.  Named up.sql and down.sql, they must be manually edited by the user.</p> Migration commands<pre><code>diesel migration generate setup_tables # (1)\ndiesel migration list\ndiesel migration run\ndiesel migration revert # (2)\ndiesel migration redo\n</code></pre> <ol> <li>Example scripts: up.sql<pre><code>CREATE TABLE starships (\nregistry TEXT PRIMARY KEY NOT NULL,\nname TEXT NOT NULL,\ncrew INTEGER NOT NULL\n);\n</code></pre> down.sql<pre><code>DROP TABLE starships;\n</code></pre></li> <li>Because the migrations are reversible (via the down.sql script), the migration can be rolled back.</li> </ol> <p>When a migration is performed, the Diesel CLI will generate a schema.rs file in a directory set by diesel.toml.</p>"},{"location":"Rust/Crates/Diesel/Tasks/","title":"Tasks","text":""},{"location":"Rust/Crates/Diesel/Tasks/#to-do-app","title":"To-do app","text":"<pre><code>#[macro_use] extern crate diesel; // (1)\nuse diesel::pg::PgConnection;\nuse diesel::prelude::*;\nuse schema::tasks::dsl::*;\n\nmod schema {\ntable! { // (3)\ntasks (description) {\ndescription -&gt; Text,\n}\n}\n}\n\n#[derive(Queryable, Insertable, Debug)] // (4)\npub struct Task { // (6)\npub description: String,\n}\n\nfn main() {\nlet conn = get_connection().unwrap();\nlet todo = Task {\ndescription: String::from(\"Buy milk\"),\n};\nlet result = add_task(&amp;conn, &amp;todo).unwrap();\nprintln!(\"Added {:?}\", result);\nprintln!(\"All tasks: {:?}\", get_tasks(&amp;conn).unwrap());\n}\n\nfn get_connection() -&gt; ConnectionResult&lt;PgConnection&gt; { // (7)\ndotenv::dotenv().ok();\nPgConnection::establish(&amp;std::env::var(\"DATABASE_URL\").unwrap())\n}\n\nfn add_task(conn: &amp;PgConnection, todo: &amp;Task) -&gt; QueryResult&lt;Task&gt; { // (2)\ndiesel::insert_into(tasks) // (8)\n.values(todo).get_result(conn) // (5)\n}\n\nfn get_tasks(conn: &amp;PgConnection) -&gt; QueryResult&lt;Vec&lt;Task&gt;&gt; { // (9)\ntasks.load::&lt;Task&gt;(conn)\n}\n</code></pre> <ol> <li>For some reason, Diesel appears to require use of outdated syntax at the crate root (main.rs or lib.rs), without which the table! macro import in the schema is not resolved.</li> <li>Like ConnectionError, QueryResult is a convenience wrapper around Result: <pre><code>use diesel::result::Error;\n\nfn add_task(conn: &amp;PgConnection, todo: &amp;Task) -&gt; Result&lt;Task, Error&gt; { /* ... */ }\n</code></pre></li> <li>Normally found in src/schema.rs (which can be changed by editing diesel.toml), this is the output of the Diesel CLI when running migrations. This macro actually exposes a module with the table name (tasks in this case).</li> <li>This struct represents the model, or the language-native data structure into which the database's query results will be cast.  If the model is in a separate module (as it normally is), the Queryable and Insertable derives are made accessible not by including from the Diesel crate directly but by including the module generated by table!. models.rs<pre><code>use schema::tasks;\n#[derive(Queryable, Insertable)]\npub struct Task {\npub description: String,\n}\n</code></pre></li> <li>Thanks to the dsl import, the table field doesn't have to be accessed: <pre><code>fn get_tasks(conn: &amp;PgConnection) -&gt; QueryResult&lt;Vec&lt;Task&gt;&gt; {\ntasks.table.load::&lt;Task&gt;(conn)\n}\n</code></pre> There is also a get_results() function that returns a Vec in case of success. <pre><code>fn add_task(conn: &amp;PgConnection, todo: &amp;Task) -&gt; QueryResult&lt;Vec&lt;Task&gt;&gt; {\ndiesel::insert_into(tasks::table)\n.values(todo)\n.get_results(conn)\n}\n</code></pre></li> <li>The compiler will infer that the annotated struct is a record belonging to a table named after the plural of the struct's identifier (i.e. it will look for \"Tasks\", case insensitive). If the table does not have such a name it must be explicitly annotated with table_name. <pre><code>#[derive(Queryable, Insertable )]\n#[table_name = \"tasks\"]\npub struct Todo {\npub description: String,\n}\n</code></pre></li> <li>Like QueryResult, ConnectionResult is simply a convenience wrapper around Result: <pre><code>use diesel::result::ConnectionError;\n\nfn get_connection() -&gt; Result&lt;PgConnection, ConnectionError&gt; { /* ... */ }\n</code></pre></li> <li>Using the Dsl import exposes some minor syntactic sugars, otherwise: <pre><code>fn add_task(conn: &amp;PgConnection, todo: &amp;Task) -&gt; QueryResult&lt;Task&gt; {\ndiesel::insert_into(tasks::table)\n.values(todo).get_result(conn)\n}\n</code></pre></li> <li>Using the Dsl import exposes some minor syntactic sugars, otherwise: <pre><code>fn get_tasks(conn: &amp;PgConnection) -&gt; QueryResult&lt;Vec&lt;Task&gt;&gt; {\ntasks::table.load::&lt;Task&gt;(conn)\n}\n</code></pre></li> </ol>"},{"location":"Rust/Crates/Diesel/Tasks/#starships","title":"Starships","text":"main.rs<pre><code>#[macro_use] extern crate diesel;\nuse diesel::pg::PgConnection;\nuse diesel::prelude::*;\n\nmod models; // (1)\nuse models::Starship;\n\nmod schema; // (2)\nuse schema::starships;\n\nfn main() {\nlet conn = create_connection().unwrap();\nadd_item(&amp;conn, &amp;get_data()).unwrap();\n}\n\nfn add_item(conn: &amp;PgConnection, ship: &amp;Starship) -&gt; Result&lt;Starship, diesel::result::Error&gt; {\ndiesel::insert_into(starships::table)\n.values(ship)\n.get_result(conn)\n}\n\nfn create_connection() -&gt; Result&lt;PgConnection, diesel::result::ConnectionError&gt; {\ndotenv::dotenv().ok();\nlet url = &amp;std::env::var(\"DATABASE_URL\").unwrap();\nOk(PgConnection::establish(url)?)\n}\n\nfn get_data() -&gt; Starship {\nStarship {\nregistry: \"NCC-1700\".to_string(),\nname: \"USS Constitution\".to_string(),\ncrew: 204,\n}\n}\n</code></pre> <ol> <li>models.rs<pre><code>use crate::schema::starships;\n\n#[derive(Queryable, Insertable)]\npub struct Starship {\npub registry: String,\npub name: String,\npub crew: i32,\n}\n</code></pre></li> <li>schema.rs<pre><code>table! {\nstarships (registry) {\nregistry -&gt; Text,\nname -&gt; Text,\ncrew -&gt; Int4,\n}\n}\n</code></pre></li> </ol> <pre><code>#[macro_use] extern crate diesel;\nuse diesel::pg::PgConnection;\nuse diesel::prelude::*;\nuse diesel::result::QueryResult;\n\nmod models;\nuse models::Starship;\nmod schema; // (2)\nuse schema::starships::dsl::*;\n\nuse clap::{Args, Parser, Subcommand};\n\n#[derive(Parser)]\nstruct Cli {\n#[clap(subcommand)]\ncommand: Commands,\n}\n\n#[derive(Subcommand)]\nenum Commands {\nAdd(Starship),\nUpdate(StarshipFilter),\nRemove(StarshipFilter),\nList,\n}\n\n#[derive(Args)]\nstruct StarshipFilter {\n#[clap(short, long)]\nfilter: String\n}\n\nfn main() {\nlet app = Cli::parse();\nmatch app.command {\nCommands::Add(s)    =&gt; add_ship(&amp;s),\nCommands::List      =&gt; list_ships(),\nCommands::Remove(s) =&gt; remove_ship(&amp;s),\nCommands::Update(s) =&gt; update_ship(&amp;s),\n}\n}\n\nfn update_ship(s: &amp;StarshipFilter) {\nlet s = &amp;s.filter;\nlet conn = get_connection().unwrap();\n}\n\nfn remove_ship(s: &amp;StarshipFilter)  {\nlet s = &amp;s.filter;\nlet conn = get_connection().unwrap();\nlet result = diesel::delete(\nstarships.filter(registry.ilike(s))\n).get_result::&lt;Starship&gt;(&amp;conn)\n.expect(\"Record not found!\");\nprintln!(\"Removing {:?}\", result);\n}\n\nfn add_ship(s: &amp;Starship) {\nlet conn = get_connection().unwrap();\nprintln!(\"Adding {:?}\", s);\ns.insert_into(starships)\n.execute(&amp;conn)\n.unwrap();\n}\n\nfn list_ships() {\nprintln!(\"{:?}\", get_ships().unwrap());\n}\n\nfn get_connection() -&gt; ConnectionResult&lt;PgConnection&gt; {\ndotenv::dotenv().expect(\"Couldn't load .env file\");\nlet url = &amp;std::env::var(\"DATABASE_URL\").unwrap();\nPgConnection::establish(url)\n}\n\nfn get_ships() -&gt; QueryResult&lt;Vec&lt;Starship&gt;&gt; {\nlet conn = get_connection().unwrap();\nstarships\n.load::&lt;Starship&gt;(&amp;conn)\n}\n</code></pre> <ol> <li><pre><code>use crate::schema::starships;\nuse clap::Args;\n\n#[derive(Args,Debug, Queryable, Insertable, Identifiable, Clone)]\n#[primary_key(registry)]\npub struct Starship {\n#[clap(long, short)]\npub registry: String,\n#[clap(long, short)]\npub name: String,\n#[clap(long, short)]\npub crew: i32,\n}\n</code></pre></li> <li><pre><code>table! {\nstarships (registry) {\nregistry -&gt; Text,\nname -&gt; Text,\ncrew -&gt; Integer,\n}\n}\n</code></pre></li> </ol> <pre><code>#[macro_use] extern crate diesel;\nuse diesel::pg::PgConnection;\nuse diesel::prelude::*;\nuse diesel::result::QueryResult;\n\nmod models;\nuse models::Starship;\nmod schema;\nuse schema::starships::dsl::*;\n\nuse clap::{Args, Parser, Subcommand};\n\n#[derive(Parser)]\nstruct Cli {\n#[clap(subcommand)]\ncommand: Commands,\n}\n\n#[derive(Subcommand)]\nenum Commands {\nAdd(Starship),\nUpdate(StarshipFilter),\nRemove(StarshipFilter),\nList(OptionalStarshipFilter),\n}\n\n#[derive(Args)]\nstruct StarshipFilter {\n#[clap(short, long)]\nfilter: String\n}\n\n#[derive(Args)]\nstruct OptionalStarshipFilter {\n#[clap(short,long)]\nfilter: Option&lt;String&gt;\n}\n\nfn main() {\nlet app = Cli::parse();\nmatch app.command {\nCommands::Add(arg)        =&gt; add_ship(&amp;arg),\nCommands::List(arg)       =&gt; list_ships(&amp;arg),\nCommands::Remove(arg)     =&gt; remove_ship(&amp;arg),\nCommands::Update(arg)     =&gt; update_ship(&amp;arg),\n}\n}\n\nfn update_ship(s: &amp;StarshipFilter) {\nlet s = &amp;s.filter;\nlet conn = get_connection().unwrap();\n}\n\nfn remove_ship(s: &amp;StarshipFilter)  {\nlet s = &amp;s.filter;\nlet conn = get_connection().unwrap();\nlet result = diesel::delete(\nstarships.filter(registry.ilike(s))\n).get_result::&lt;Starship&gt;(&amp;conn)\n.expect(\"Record not found!\");\nprintln!(\"Removing {:?}\", result);\n}\n\nfn add_ship(s: &amp;Starship) {\nlet conn = get_connection().unwrap();\nprintln!(\"Adding {:?}\", s);\ns.insert_into(starships)\n.execute(&amp;conn)\n.unwrap();\n}\n\nfn list_ships(arg: &amp;OptionalStarshipFilter) {\nlet conn = get_connection().unwrap();\nmatch &amp;arg.filter {\nSome(s) =&gt; println!(\"{:?}\", starships.filter(registry.ilike(s)).load::&lt;Starship&gt;(&amp;conn).unwrap()),\nNone =&gt; println!(\"{:?}\", starships.load::&lt;Starship&gt;(&amp;conn).unwrap()),\n}\n}\n\nfn get_connection() -&gt; ConnectionResult&lt;PgConnection&gt; {\ndotenv::dotenv().expect(\"Couldn't load .env file\");\nlet url = &amp;std::env::var(\"DATABASE_URL\").unwrap();\nPgConnection::establish(url)\n}\n</code></pre>"},{"location":"Rust/Tasks/","title":"Boilerplate","text":""},{"location":"Rust/Tasks/#nightly-build","title":"Nightly build","text":"<p><pre><code>rustup install nightly\n</code></pre> The nightly build can be specified ad hoc or permanently for the crate</p> Ad hocPermanently <pre><code>cargo +nightly run\n</code></pre> <pre><code>rustup override set nightly\n</code></pre>"},{"location":"Rust/Tasks/#publishing","title":"Publishing","text":"<p>Some additional fields of the Cargo.toml are required before publishing: <pre><code>[package]\nname = \"mdrend\"\nversion = \"0.1.0\"\nedition = \"2018\"\nauthors= [\"Johnny Appleseed &lt;johnny@apple.com&gt;\"]\nlicense = \"MIT\"\nkeywords = [ \"Parse\", \"markdown\"]\nrepository = \"https://github.com/...\"\ndescription = \"Read a markdown file and return parsed HTML\"\n[dependencies]\nclap = \"2.34.0\"\nmaud = \"0.23.0\"\npulldown-cmark = \"0.8.0\"\n</code></pre></p> <pre><code>cargo login\ncargo publish\n</code></pre>"},{"location":"Rust/Tasks/Hello-World/","title":"Hello, World!","text":""},{"location":"Rust/Tasks/Hello-World/#parameterized","title":"Parameterized","text":"<pre><code>fn main() {\nlet name = String::from(match std::env::args().nth(1) { // (1)\nSome(s) =&gt; s,\n_ =&gt; \"World\";\n});\nprintln!(\"Hello, {}!\", name);\n}\n</code></pre> <ol> <li>if let is also possible, if more verbose. <pre><code>let mut name = String::new();\nif let Some(s) = std::env::args().nth(1) {\nname = s;\n} else {\nname = String::from(\"World\");\n}\n</code></pre></li> </ol>"},{"location":"Rust/Tasks/Hello-World/#interactive","title":"Interactive","text":"<p>The interactive implementation of Hello, World! allows us to apply the and_then() combinator to great effect.</p> <pre><code>fn main() {\nget_name().and_then(display_name);\n}\n\nfn get_name() -&gt; Result&lt;String, std::io::Error &gt; {\nlet mut name = String::new();\nstd::io::stdin().read_line(&amp;mut name)?;\nOk(name.trim().to_string())\n}\n\nfn display_name(name: String) -&gt; Result&lt;(), std::io::Error&gt; {\nprintln!(\"Hello, {}!\", name);\nOk(())\n}\n</code></pre>"},{"location":"Rust/Tasks/Hello-World/#modules","title":"Modules","text":"<pre><code>use input::get_name;\nuse output::display_name;\nfn main() -&gt; Result&lt;(), std::io::Error&gt; {\nget_name().and_then(display_name)?;\nOk(())\n}\n\npub mod input {\npub fn get_name() -&gt; Result&lt;String, std::io::Error&gt; {\nlet mut name = String::new();\nprintln!(\"What is your name? \");\nstd::io::stdin().read_line(&amp;mut name)?;\nOk(name.trim().to_string())\n}\n}\n\npub mod output {\npub fn display_name(name: String) -&gt; Result&lt;(), std::io::Error&gt; {\nprintln!(\"Hello, {}!\", name);\nOk(())\n}\n}\n</code></pre> <p>When separating modules into their own files, the filename of the module must match the name provided after mod. Folders can also be used, in which case the folder name must match.</p> main.rs<pre><code>mod input;\nmod output;\npub use input::get_name;\npub use output::display_name;\nfn main() -&gt; Result&lt;(), std::io::Error&gt; {\nget_name().and_then(display_name)?;\nOk(())\n}\n</code></pre> input.rs<pre><code>pub fn get_name() -&gt; Result&lt;String, std::io::Error&gt; {\nlet mut name = String::new();\nprintln!(\"What is your name? \");\nstd::io::stdin().read_line(&amp;mut name)?;\nOk(name.trim().to_string())\n}\n</code></pre> output.rs<pre><code>pub fn display_name(name: String) -&gt; Result&lt;(), std::io::Error&gt; {\nprintln!(\"Hello, {}!\", name);\nOk(())\n}\n</code></pre>"},{"location":"Rust/Tasks/Hello-World/#caesar-cipher","title":"Caesar cipher","text":"<p>''' rs pub mod encryptor {     pub trait Encryptable {         fn encrypt(&amp;self) -&gt; String;     }</p> <pre><code>pub struct Rot13(pub String);\n\nimpl Encryptable for Rot13 {\n    fn encrypt(&amp;self) -&gt; String {\n        self.0\n            .chars()\n            .map(|ch| match ch {\n                'a'..='m' | 'A'..='M' =&gt; (ch as u8 + 13) as char,\n                'n'..='z' | 'N'..='Z' =&gt; (ch as u8 - 13) as char,\n                _ =&gt; ch,\n            })\n            .collect()\n    }\n}\n</code></pre> <p>}</p> <p>use encryptor::Encryptable;</p> <p>fn main() {     println!(\"Input the string you want to encrypt:\");     let mut user_input = String::new();</p> <pre><code>std::io::stdin()\n    .read_line(&amp;mut user_input)\n    .expect(\"Cannot read input!\");\nprintln!(\n    \"Your encrypted string: {}\",\n    encryptor::Rot13(user_input).encrypt()\n);\n</code></pre> <p>} '''</p>"},{"location":"Rust/Tasks/Mathematics/","title":"Mathematics","text":""},{"location":"Rust/Tasks/Mathematics/#weight-on-mars","title":"Weight on Mars","text":"<pre><code>fn main() {\nlet mut input = String::new();\nprintln!(\"Enter weight in kilograms: \");\n\nstd::io::stdin().read_line(&amp;mut input);\n\nlet input: f32 = match input.trim().parse() {\nOk(num) =&gt; num,\nErr(_) =&gt; 0.0,\n};\n\nlet mars_weight = calculate_weight_on_mars(input);\nprintln!(\"Weight on Mars: {} kg\", &amp;mars_weight);\n}\n\nfn calculate_weight_on_mars(weight: f32) -&gt; f32 {\n(weight / 9.81) * 3.711\n}\n</code></pre>"},{"location":"Rust/Tasks/Mathematics/#fibonacci-sequence","title":"Fibonacci sequence","text":"RecursiveMemoized <pre><code>use std::collections::HashMap;\n\nfn fib(n: u64) -&gt; u64 {\nmatch n {\n0 | 1 =&gt; 1,\nn =&gt; fib(n - 1) + fib(n - 2)\n}\n}\n\nfn main() {\nlet n: u64 = std::env::args().nth(1).unwrap().parse().unwrap();\nfor i in 1..n {\nprintln!(\"{}: {}\", i, fib(i));\n}\n}\n</code></pre> <pre><code>use std::collections::HashMap;\n\nfn fib(n: u64, map: &amp;mut HashMap&lt;u64, u64&gt;) -&gt; u64 {\nmatch n {\n0 | 1 =&gt; 1,\nn =&gt; {\nif map.contains_key(&amp;n) {\n*map.get(&amp;n).unwrap()\n} else {\nlet val = fib(n-1, map) + fib(n-2, map);\nmap.insert(n, val);\nval\n}\n}\n}\n}\n\nfn main() {\nlet n: u64 = std::env::args().nth(1).unwrap().parse().unwrap();\nlet mut map = HashMap::new();\nfor i in 1..n {\nprintln!(\"{}: {}\", i, fib(i, &amp;mut map));\n}\n}\n</code></pre>"},{"location":"Rust/Tasks/Porting-grep/","title":"grep ports","text":"<p>The success of ripgrep has inspired many ports of other GNU utilities to Rust.</p> <p>Porting grep to Rust provides the opportunity to explore various ways of using iterators, evolving from a naive <code>for in</code> loop to the <code>filter()</code> iterator method using a closure.</p> Loop<pre><code>fn main() {\nlet mut results = Vec::new();\n\nfor line in contents.lines() {\nif line.contains(query) {\nresults.push(line);\n}\n}\nresults\n}\n</code></pre> filter<pre><code>fn main() {\ncontents.lines()\n.filter(|line| line.contains(query))\n.collect()\n}\n</code></pre>"},{"location":"Rust/Tasks/Porting-grep/#grep-lite","title":"grep-lite","text":"<p>This example begins with hard-coded strings and quickly develops the core logic of searching for a string. First regex (2), then a CLI framework is implemented (3).</p> <p>We take a slight digression to illustrate how file reading is done in Rust. First we produce a naive implementation (4) using a loop. A more expressive choice (5) is a <code>for in</code> loop iterating over the iterator returned by the BufReader's lines method.</p> <p>Finally, file opening is incorporated into the business logic of the application (6).  The search logic itself is abstracted into a function.  If the <code>-</code> argument is received from the command-line, STDIN is treated just as a file.</p> <p>Files are modeled with structs (7). <code>read()</code> models reading a file by cloning the File struct's data Vector,  then <code>reserve</code>ing that clone's length and appending its values to a buffer struct. <code>open</code> and <code>close</code> functions are inert stubs (8).</p> <p>Refactoring <code>read()</code> into a method on <code>File</code> and implementing the <code>new</code> method using an <code>impl</code> blocks is more idiomatic and readable (9).</p> <p><code>open()</code>, <code>close()</code>, and <code>read()</code> are refactored to use Results.  Also a rand function is used to model error generation on a random basis (10).</p> <p>Define a FileState enum (11). Implementing the Display trait allows us to use a standard template in a <code>println!</code> statement (12).</p> 123456789101112 <pre><code>// RIA 68\nfn main() {\nlet search_term = \"picture\";\nlet quote =\"Once upon a midnight dreary\\nWhile I pondered weak and weary\\nOver many a quaint and curious volume of forgotten lore\";\n\nfor line in quote.lines() {\nif line.contains(search_term) {\nprintln!(\"{}\", line);\n}\n}\n}\n</code></pre> <pre><code>// RIA 69\nuse regex::Regex;\nfn main() {\nlet re = Regex::new(\"picture\").unwrap();\nlet quote =\"Once upon a midnight dreary\\nWhile I pondered weak and weary\\nOver many a quaint and curious volume of forgotten lore\";\nfor line in quote.lines() {\nlet contains_substring = re.find(line);\nmatch contains_substring {\nSome(_) =&gt; println(\"{}\", line),\nNone =&gt; (),\n}\n}\n}\n</code></pre> <pre><code>// RIA 71-72\nuse regex::Regex;\nuse clap::{App,Arg};\nfn main() {\nlet args = App::new(\"grep-lite\")\n.version(\"0.1\")\n.about(\"searches for patterns\")\n.arg(Arg::with_name(\"pattern\")\n.help(\"The pattern to search for\")\n.takes_value(true)\n.required(true))\n.get_matches();\nlet pattern = args.value_of(\"pattern\").unwrap();\nlet re = Regex::new(\"picture\").unwrap();\nlet quote =\"Once upon a midnight dreary\\nWhile I pondered weak and weary\\nOver many a quaint and curious volume of forgotten lore\";\nfor line in quote.lines() {\nlet contains_substring = re.find(line);\nmatch contains_substring {\nSome(_) =&gt; println(\"{}\", line),\nNone =&gt; (),\n}\n}\n}\n</code></pre> <pre><code>// RIA 73\nuse std::fs::File;\nuse std::io::BufReader;\nuse std::io::prelude::*;\n\nfn main() {\nlet f = File::open(\"readme.md\").unwrap();\nlet mut reader = Bufreader::new(f);\n\nlet mut line = String::new();\n\nloop {\nlet len = reader.read_line(&amp;mut line)\n.unwrap();\n\nif len == 0 {\nbreak\n}\n\nprintln!(\"{} ({} bytes long)\", line, len);\n\nline.truncate(0);\n}\n}\n</code></pre> <pre><code>// RIA 73\nuse std::fs::File;\nuse std::io::BufReader;\nuse std::io::prelude::*;\n\nfn main() {\nlet f = File::open(\"readme.md\").unwrap();\nlet reader = BufReader::new(f);\n\nfor line_ in reader.lines() {\nlet line = line_.unwrap();\nprintln!(\"{} ({} bytes long)\", line, line.len());\n}\n}\n</code></pre> <pre><code>// RIA 74-75\nuse std::fs::File;\nuse std::io;\nuse std::io::BufReader;\nuse std::io::prelude::*;\nuse regex::Regex;\nuse clap::{App,Arg};\n\nfn process_lines&lt;T: BufRead + Sized&gt;(reader: T, re: Regex) {\nfor line_ in reader.lines() {\nlet line = line_.unwrap();\nmatch re.find(&amp;line) {\nSome(_) =&gt; println!(\"{}\", line),\nNone =&gt; (),)\n}\n}\n}\n\nfn main() {\nlet args = App::new(\"grep-lite\")\n.version(\"0.1\")\n.about(\"searches for patterns\")\n.arg(Arg::with_name(\"pattern\")\n.help(\"The pattern to search for\")\n.takes_value(true)\n.required(true))\n.arg(Arg::with_name(\"input\")\n.help(\"File to search\")\n.takes_value(true)\n.required(false))\n.get_matches();\n\nlet pattern = args.value_of(\"pattern\").unwrap();\nlet re = Regex::new(\"picture\").unwrap();\n\nlet input = args.value_of(\"input\").unwrap_or(\"-\");\n\nif input == \"-\" {\nlet stdin = io::stdin();\nlet reader = stdin.lock();\nprocess_lines(reader, re);\n} else {\nlet f = File::open(input).unwrap();\nlet reader = BufReader::new(f);\nprocess_lines(reader, re);\n}\n}\n</code></pre> <pre><code>// RIA 80\n#[derive(Debug)]\nstruct File {\nname: String,\ndata: Vec&lt;u8&gt;,\n}\n\nfn main() {\nlet f1 = File {\nname: String::from(\"f1.txt\"),\ndata: Vec:new(),\n};\n\nlet f1_name = &amp;f1.name;\nlet f1_length = &amp;f1.data.len();\n\nprintln!(\"{:?}\", f1);\nprintln!(\"{} is {} byes long\", f1_name, f1_length);\n}\n</code></pre> <pre><code>// RIA 82-83\n#![allow(unused_variables)]\n\n#[derive(Debug)]\nstruct File {\nname: String,\ndata: Vec&lt;u8&gt;,\n}\n\nfn read(\nf: &amp;File,\nsave_to: &amp;mut Vec&lt;u8&gt;,\n) -&gt; usize {\nlet mut tmp = f.data.clone();\nlet read_length = tmp.len();\nsave_to.reserve(read_length);\nsave_to.append(&amp;mut tmp);\nread_length\n}\nfn open(f: &amp;mut File) -&gt; bool { true }\n\nfn close(f: &amp;mut File) -&gt; bool { true }\n\nfn main() {\nlet mut f = File {\nname: String::from(\"2.txt\"),\ndata: vec![1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29],\n};\n\nlet mut buffer: Vec&lt;u8&gt; = vec![];\n\nopen(&amp;mut f);\nlet f_length = read(&amp;f2, &amp;mut buffer);\nclose (&amp;mut f);\n\nlet text = String::from_utf8_lossy(&amp;buffer);\n\nprintln!(\"{:?}\", f);\nprintln!(\"{} is {} bytes long\", &amp;f.name, f_length);\nprintln!(\"{}\", text);\n}\n</code></pre> <pre><code>// RIA 86\n#![allow(unused_variables)]\n\n#[derive(Debug)]\nstruct File {\nname: String,\ndata: Vec&lt;u8&gt;,\n}\n\nimpl File {\nfn new(name: &amp;str) -&gt; File {\nFile {\nname: String::from(name),\ndata: Vec::new(),\n}\n}\nfn new_with_data(\nname: &amp;str,\ndata: &amp;Vec&lt;u8&gt;,\n) -&gt; File {\nlet mut f = File::new(name);\nf.data = data.clone();\nf\n}\nfn read(\nself: &amp;File, save_to: &amp;mut Vec&lt;u8&gt;,\n) -&gt; usize {\nlet mut tmp = self.data.clone();\nlet read_length = tmp.len();\nsave_to.reserve(read_length);\nsave_to.append(&amp;mut tmp);\nread_length\n}\n}\nfn open(f: &amp;mut File) -&gt; bool { true }\n\nfn close(f: &amp;mut File) -&gt; bool { true }\n\nfn main() {\nlet f_data: Vec&lt;u8&gt; = vec![1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29];\nlet mut f = File::new_with_data(\"2.txt\", &amp;f_data);\nlet mut buffer: Vec&lt;u8&gt; = vec![];\n\nopen(&amp;mut f);\nlet f_length = f.read(&amp;mut buffer);\nclose(&amp;mut f);\n\nlet text = String::from_utf8_lossy(&amp;buffer);\n\nprintln!(\"{:?}\", f);\nprintln!(\"{} is {} bytes long\", &amp;f.name, f_length);\nprintln!(\"{}\", text);\n}\n</code></pre> <pre><code>// RIA 93-94\nuse rand::prelude::*;\n\nfn one_in(denominator: u32) -&gt; bool {\nthread_rng().gen_ratio(1, denominator)\n}\n\n#[derive(Debug)]\nstruct File {\nname: String,\ndata: Vec&lt;u8&gt;,\n}\n\nimpl File {\nfn new(name: &amp;str) -&gt; File {\nFile {\nname: String::from(name),\ndata: Vec::new(),\n}\n}\n\nfn new_with_data(name: &amp;str ,data: Vec&lt;u8&gt;) -&gt; File {\nlet mut f = File::new(name);\nf.data = data.clone();\nf\n}\n\nfn read(\nself: &amp;File,\nsave_to: &amp;mut Vec&lt;u8&gt;,\n) -&gt; Result&lt;usize, String&gt; {\nlet mut tmp = self.data.clone();\nlet read_length = tmp.len();\nsave_to.reserve(read_length);\nsave_to.append(&amp;mut tmp);\nOk(read_length)\n}\n}\n\nfn open(f: File) -&gt; Result&lt;File, String&gt; {\nif one_in(10_000) {\nlet err_mag = String::from(\"Permission denied\");\nreturn Err(err_msg);\n}\nOk(f)\n}\n\nfn close(f: File) -&gt; Result&lt;File, String&gt; {\nif one_in(100_000) {\nlet err_mag = String::from(\"Interrupted by signal!\");\nreturn Err(err_msg);\n}\nOk(f)\n}\n\nfn main() {\nlet f_data: Vec&lt;u8&gt; = vec![1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29];\nlet mut f = File::new_with_data(\"4.txt\", &amp;f_data);\n\nlet mut buffer: Vec&lt;u8&gt; = vec![];\n\nf = open(f).unwrap();\nlet f_length = f.read(&amp;mut buffer).unwrap();\nf = close(f).unwrap();\nlet text = String::from_utf8_lossy(&amp;buffer);\n\nprintln!(\"{:?}\", f);\nprintln!(\"{} is {} bytes long\", &amp;f.name, f_length);\nprintln!(\"{}\", text);\n}\n</code></pre> <pre><code>// RIA 97-98\n#[derive(Debug,PartialEq)]\nenum FileState {\nOpen,\nClosed,\n}\n#[derive(Debug)]\nstruct File {\nname: String,\ndata: Vec&lt;u8&gt;,\nstate: FileState,\n}\n\nimpl File {\nfn new(name: &amp;str) -&gt; File {\nFile {\nname: String::from(name),\ndata: Vec::new(),\nstate: FileState::Closed,\n}\n}\n\nfn read(\nself: &amp;File,\nsave_to: &amp;mut Vec&lt;u8&gt;,\n) -&gt; Result&lt;usize, String&gt; {\nlet mut tmp = self.data.clone();\nlet read_length = tmp.len();\nsave_to.reserve(read_length);\nsave_to.append(&amp;mut tmp);\nOk(read_length)\n}\n}\n\nfn open(mut f: File) -&gt; Result&lt;File, String&gt; {\nf.state = FileState::Open;\nOk(f)\n}\n\nfn close(mut f: File) -&gt; Result&lt;File, String&gt; {\nf.state = FileState::Closed;\nOk(f)\n}\n\nfn main() {\nlet f_data: Vec&lt;u8&gt; = vec![1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29];\nlet mut f = File::new(\"4.txt\");\nlet mut buffer: Vec&lt;u8&gt; = vec![];\n\nf = open(f).unwrap();\nlet f_length = f.read(&amp;mut buffer).unwrap();\nf = close(f).unwrap();\n\nlet text = String::from_utf8_lossy(&amp;buffer);\n\nprintln!(\"{:?}\", f);\nprintln!(\"{} is {} bytes long\", &amp;f.name, f_length);\nprintln!(\"{}\", text);\n}\n</code></pre> <pre><code>// RIA 101-102\n#![allow(dead_code)]\n\nuse std::fmt;\nuse std::fmt::{Display};\n\n#[derive(Debug,PartialEq)]\nenum FileState {\nOpen,\nClosed,\n}\n\nimpl Display for FileState {\nfn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\nmatch *self {\nFileState::Open =&gt; write!(f, \"OPEN\"),\nFileState::Closed =&gt; write!(f, \"CLOSED\"),\n}\n}\n}\n\nimpl Display for File {\nfn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result {\nwrite!(f, \"&lt;{} ({})&gt;\", self.name, self.state)\n}\n}\n\n// --snip--\n\nfn main() {\nprintln!(\"{:?}\", f);\nprintln!(\"{}\", f);\n}\n</code></pre>"},{"location":"Rust/Tasks/Porting-grep/#minigrep","title":"minigrep","text":"<p>From RPL p. 233-263</p> 12345678910111213 main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\nprintln!(\"{:?}\", args);\n}\n</code></pre> <p>Read any command line arguments passed, collecting into a vector.</p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet query = &amp;args[1];\nlet filename = &amp;args[2];\n\nprintln!(\"Searching for {}\", query);\nprintln!(\"In file {}\", filename);\n}\n</code></pre> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet query = &amp;args[1];\nlet filename = &amp;args[2];\n\nprintln!(\"Searching for {}\", query);\nprintln!(\"In file {}\", filename);\n\nlet contents = fs::read_to_string(filename)\n.expect(\"Somethign went wrong reading the file\");\n\nprintln!(\"With text:\\n{}\", contents);\n}\n</code></pre> <p><code>fs::read_to_string()</code> takes the filename, opens it, and returns a <code>Result&lt;String&gt;</code> of the file's contents.</p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet config = parse_config(&amp;args);\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nlet contents = std::fs::read_to_string(config.filename).expect(\"Couldn't read file\");\n\nprintln!(\"{}\", contents);\n}\n\nstruct Config {\nquery: String,\nfilename: String,\n}\nfn parse_config(args: &amp;[String]) -&gt; Config {\nlet query = args[1].clone();\nlet filename = args[2].clone();\nConfig { query, filename }\n}\n</code></pre> <p>Refactoring to abstract command-line argument parsing logic to its own function</p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet config = Config::new(&amp;args);\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nlet contents = std::fs::read_to_string(config.filename).expect(\"Couldn't read file\");\n\nprintln!(\"{}\", contents);\n}\n\nstruct Config {\nquery: String,\nfilename: String,\n}\n\nimpl Config {\nfn new(args: &amp;[String]) -&gt; Config {\nlet query = args[1].clone();\nlet filename = args[2].clone();\nConfig { query, filename }\n}\n}\n</code></pre> <p>Refactor the config parser into Config's constructor</p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet config = Config::new(&amp;args);\n\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nlet contents = std::fs::read_to_string(config.filename).expect(\"Couldn't read file\");\n\nprintln!(\"{}\", contents);\n}\n\nstruct Config {\nquery: String,\nfilename: String,\n}\n\nimpl Config {\nfn new(args: &amp;[String]) -&gt; Config {\nif args.len() &lt; 3 {\npanic!(\"Not enough args!\");\n}\nlet query = args[1].clone();\nlet filename = args[2].clone();\nConfig { query, filename }\n}\n}\n</code></pre> <p>Implement error message on invalid number of arguments </p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet config = Config::new(&amp;args).unwrap_or_else(|err| {\nprintln!(\"Problem parsing arguments: {}\", err);\nstd::process::exit(1);\n});\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nlet contents = std::fs::read_to_string(config.filename).expect(\"Couldn't read file\");\n\nprintln!(\"{}\", contents);\n}\n\nstruct Config {\nquery: String,\nfilename: String,\n}\n\nimpl Config {\nfn new(args: &amp;[String]) -&gt; Result&lt;Config, &amp;'static str&gt; {\nif args.len() &lt; 3 {\nreturn Err(\"not enough arguments\");\n}\nlet query = args[1].clone();\nlet filename = args[2].clone();\nOk(Config { query, filename })\n}\n}\n</code></pre> <p>Remove previous error message and incorporate error in the Err variant of a <code>Result&lt;T,E&gt;</code>. The argument passed to <code>unwrap_or_else()</code> is a closure.</p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet config = Config::new(&amp;args).unwrap_or_else(|err| {\nprintln!(\"Problem parsing arguments: {}\", err);\nstd::process::exit(1);\n});\n\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nrun(config);\n}\n\nfn run(config: Config) {\nlet contents = std::fs::read_to_string(config.filename)\n.expect(\"Couldn't read file\");\nprintln!(\"{}\", contents);\n}\nstruct Config {\nquery: String,\nfilename: String,\n}\n\nimpl Config {\nfn new(args: &amp;[String]) -&gt; Result&lt;Config, &amp;'static str&gt; {\nif args.len() &lt; 3 {\nreturn Err(\"not enough arguments\");\n}\nlet query = args[1].clone();\nlet filename = args[2].clone();\nOk(Config { query, filename })\n}\n}\n</code></pre> <p>Abstract program logic into <code>run()</code></p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet config = Config::new(&amp;args).unwrap_or_else(|err| {\nprintln!(\"Problem parsing arguments: {}\", err);\nstd::process::exit(1);\n});\n\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nrun(config).unwrap();\n}\n\nfn run(config: Config)  -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\nlet contents = std::fs::read_to_string(config.filename)?;\nprintln!(\"{}\", contents);\nOk(())\n}\nstruct Config {\nquery: String,\nfilename: String,\n}\n\nimpl Config {\nfn new(args: &amp;[String]) -&gt; Result&lt;Config, &amp;'static str&gt; {\nif args.len() &lt; 3 {\nreturn Err(\"not enough arguments\");\n}\nlet query = args[1].clone();\nlet filename = args[2].clone();\nOk(Config { query, filename })\n}\n}\n</code></pre> <p>Refactor <code>run()</code> to return a <code>Result&lt;T,E&gt;</code> in the <code>Ok</code> case and the trait object <code>Box&lt;dyn Error&gt;</code> for the error type. This allows various error types to be returned.</p> <p>Also, the <code>expect()</code> method is replaced by the <code>?</code> operator which returns the error type for the calling function to handle, rather than a boilerplate error message. </p> main.rs <pre><code>fn main() {\nlet args: Vec&lt;String&gt; = std::env::args().collect();\n\nlet config = Config::new(&amp;args).unwrap_or_else(|err| {\nprintln!(\"Problem parsing arguments: {}\", err);\nstd::process::exit(1);\n});\n\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nif let Err(e) = run(config) {\nprintln!(\"Application error: {}\", e);\nstd::process::exit(1);\n}\n}\n\nfn run(config: Config)  -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\nlet contents = std::fs::read_to_string(config.filename)?;\n\nprintln!(\"{}\", contents);\n\nOk(())\n}\n\nstruct Config {\nquery: String,\nfilename: String,\n}\n\nimpl Config {\nfn new(args: &amp;[String]) -&gt; Result&lt;Config, &amp;'static str&gt; {\nif args.len() &lt; 3 {\nreturn Err(\"not enough arguments\");\n}\nlet query = args[1].clone();\nlet filename = args[2].clone();\nOk(Config { query, filename })\n}\n}\n</code></pre> <p>Rather than <code>unwrap()</code>, we use <code>if let</code> to check for and handle errors from <code>run()</code>.</p> lib.rsmain.rs <pre><code>use std::fs;\nuse std::error::Error;\n\npub struct Config {\npub query: String,\npub filename: String,\n}\n\nimpl Config {\npub fn new(args: &amp;[String]) -&gt; Result&lt;Config, &amp;'static str&gt; {\nif args.len() &lt; 3 {\nreturn Err(\"not enough arguments\");\n}\nlet query = args[1].clone();\nlet filename = args[2].clone();\nOk(Config { query, filename })\n}\n}\n\npub fn run(config: Config)  -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\nlet contents = fs::read_to_string(config.filename)?;\n\nprintln!(\"{}\", contents);\n\nOk(())\n}\n</code></pre> <pre><code>use std::process;\nuse std::env;\n\nuse lib::run;\nuse lib::Config;\npub mod lib;\nfn main() {\nlet args: Vec&lt;String&gt; = env::args().collect();\n\nlet config = Config::new(&amp;args).unwrap_or_else(|err| {\nprintln!(\"Problem parsing arguments: {}\", err);\nprocess::exit(1);\n});\n\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nif let Err(e) = run(config) {\nprintln!(\"Application error: {}\", e);\n\nprocess::exit(1);\n}\n}\n</code></pre> <p>Abstract all elements except <code>main()</code> into a library module</p> lib.rsmain.rs <pre><code>use std::fs;\nuse std::error::Error;\n\npub struct Config {\npub query: String,\npub filename: String,\n}\n\nimpl Config {\npub fn new(args: &amp;[String]) -&gt; Result&lt;Config, &amp;'static str&gt; {\nif args.len() &lt; 3 {\nreturn Err(\"not enough arguments\");\n}\nlet query = args[1].clone();\nlet filename = args[2].clone();\nOk(Config { query, filename })\n}\n}\n\npub fn run(config: Config)  -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\nlet contents = fs::read_to_string(config.filename)?;\n\nprintln!(\"{}\", contents);\n\nOk(())\n}\n\npub fn search&lt;'a&gt;(query: &amp;str, contents: &amp;'a str) -&gt; Vec&lt;&amp;'a str&gt; {\nlet mut results = Vec::new();\nfor line in contents.lines() {\nif line.contains(query) {\nresults.push(line);\n}\n}\nresults\n}\n#[cfg(test)]\nmod tests {\nuse super::*;\n#[test]\nfn one_result() {\nlet query = \"duct\";\nlet contents= \"\\nRust:\\nsafe, fast, productive.\\nPick three.\";\nassert_eq!(\nvec![\"safe, fast, productive.\"],\nsearch(query, contents)\n)\n}\n}\n</code></pre> <pre><code>use std::process;\nuse std::env;\n\nuse lib::run;\nuse lib::Config;\n\npub mod lib;\n\nfn main() {\nlet args: Vec&lt;String&gt; = env::args().collect();\n\nlet config = Config::new(&amp;args).unwrap_or_else(|err| {\nprintln!(\"Problem parsing arguments: {}\", err);\nprocess::exit(1);\n});\n\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nif let Err(e) = run(config) {\nprintln!(\"Application error: {}\", e);\n\nprocess::exit(1);\n}\n}\n</code></pre> <p>Implement <code>search()</code> function and a unit test</p> lib.rsmain.rs <pre><code>use std::fs;\nuse std::error::Error;\n\npub struct Config {\npub query: String,\npub filename: String,\n}\n\nimpl Config {\npub fn new(mut args: std::env::Args) -&gt; Result&lt;Config, &amp;'static str&gt; {\nargs.next();\nlet query = match args.next() {\nSome(arg) =&gt; arg,\nNone =&gt; return Err(\"Didn't get a query string\"),\n};\nlet filename = match args.next() {\nSome(arg) =&gt; arg,\nNone =&gt; return Err(\"Didn't get a file name\")\n};\nOk(Config { query, filename })\n}\n}\n\npub fn run(config: Config)  -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\nlet contents = fs::read_to_string(config.filename)?;\n\nprintln!(\"{}\", contents);\n\nOk(())\n}\n\npub fn search&lt;'a&gt;(query: &amp;str, contents: &amp;'a str) -&gt; Vec&lt;&amp;'a str&gt; {\ncontents.lines()\n.filter(|line| line.contains(query))\n.collect()\n}\n\n#[cfg(test)]\nmod tests {\nuse super::*;\n\n#[test]\nfn one_result() {\nlet query = \"duct\";\nlet contents= \"\\nRust:\\nsafe, fast, productive.\\nPick three.\";\nassert_eq!(\nvec![\"safe, fast, productive.\"],\nsearch(query, contents)\n)\n}\n}\n</code></pre> <pre><code>use std::process;\nuse std::env;\n\nuse lib::run;\nuse lib::Config;\n\npub mod lib;\n\nfn main() {\nlet args: Vec&lt;String&gt; = env::args().collect();\n\nlet config = Config::new(&amp;args).unwrap_or_else(|err| {\nprintln!(\"Problem parsing arguments: {}\", err);\nprocess::exit(1);\n});\n\nprintln!(\"Searching for {} in file {}\", config.query, config.filename);\n\nif let Err(e) = run(config) {\nprintln!(\"Application error: {}\", e);\n\nprocess::exit(1);\n}\n}\n</code></pre> <p>Implementing iterators</p>"},{"location":"Rust/Tasks/To-Do/","title":"To-Do","text":""},{"location":"Rust/Tasks/To-Do/#vector-assembly","title":"Vector assembly","text":"<pre><code>use std::rc::Rc;\nuse std::cell::RefCell;\n\nfn main() {\nlet mut v: Vec&lt;String&gt; = Vec::new();\nloop {\nlet mut input: String = String::new();\nprintln!(\"Enter to-do list item ('q' to quit): \");\nstd::io::stdin().read_line(&amp;mut input).unwrap();\nmatch input.trim() {\n\"q\" =&gt; break,\ns =&gt; v.push(s.to_string()),\n}\n}\n\nfor i in v {\nprintln!(\"{}\", i);\n}\n}\n</code></pre>"},{"location":"Rust/Tasks/Transactions/","title":"Transactions","text":""},{"location":"Rust/Tasks/Transactions/#simple","title":"Simple","text":""},{"location":"Scripts/","title":"Video scripts","text":"<ul> <li> Discord.py master class</li> <li>Anki</li> <li>Audio</li> <li>C#</li> <li>Django</li> </ul>"},{"location":"Scripts/#articles","title":"Articles","text":"<ul> <li> Discord bot article</li> </ul>"},{"location":"Scripts/Anki/","title":"Anki","text":"<ul> <li>Tips for cramming: using cloze with Unbury</li> <li>Using CSS classes to simulate prompts and to visually identify CSS classes with environments, like Command Prompt or Ubuntu</li> <li>Use colors to set out various files in a project, i.e. Django</li> </ul>"},{"location":"Scripts/CSharp/","title":"CSharp","text":"<p>C# solution file is analogous (?) to a manage.py file in a Django application</p> <p> Django :</p> <p>What\u2019s the difference between a project and an app? An app is a Web application that does something \u2013 e.g., a Weblog system, a database of public records or a small poll app. A project is a collection of configuration and apps for a particular website. A project can contain multiple apps. An app can be in multiple projects.</p>"},{"location":"Scripts/Django/","title":"Django","text":"<p>Explaining conceptsF10</p> <p>Django is a web application framework written in Python.  Today I'm going to show you how to code a simple To-Do web application.  If you've found this video, that probably means you've already seen some of the many other popular YouTube tutorials that you how to do it. </p> <p>What I'll show you is how to integrate it with the Bulma CSS framework!</p>"},{"location":"Scripts/Django/#todo","title":"Todo","text":""},{"location":"Scripts/Django/#setup","title":"Setup","text":"<p>I'm going to assume you have a working installation of Python. </p> <ul> <li>Windows =&gt; Microsoft Store. </li> <li>If you're running Mac or Linux, you might already have a working Python installation, but if not there are many different ways of installing Python.</li> </ul> <p>Before we install Django we're going to set up a virtual environment.</p>"},{"location":"Scripts/Django/#venv","title":"Venv","text":"<p>Python only tolerates a single installed version of a package at any given point in time. This means that as you add packages to your installation, it's only a matter of time before you run into a conflict, where a package demands a  version of a dependency that conflicts with the one you have installed.</p> <p>The most common way to avoid this is by creating a virtual environment. A virtual environment is like a isolated copy of Python that is only activated when you need. Virtual environments let you install packages safely, keeping your system installation clutter-free.</p> <p>I have PowerShell open, and if you have a Windows computer you should have it too. I'm going to <code>cd</code> to the venv directory. This is the directory where I like to install all my virtual environments. But you're free to manage virtual environments however you choose. I run <code>ls</code> here and you can see I've already set up multiple virtual environments.</p> <p>Let's create a new virtual environment by running <code>python -m venv django</code>. After a few moments, the virtual environment will be created.</p> <p>Now let's run <code>ls</code> again, and we can see that this directory was created. Let's see what a virtual environment looks like.</p> <p>There are a few directories and a config file. If we inspect the config file <code>notepad pyvenv.cfg</code>, we see that it specifies the currently installed version of Python. It also points to the system installation of Python. If I run <code>Get-Command python</code> I can see that the system installation of Python points to this directory. Depending on how you installed Python, the directory that appears here may be different. And if you're watching this video in the future, your version of Python will be newer than this.</p> <p>The business end of the virtual environment is actually here, in Scripts. Let's navigate there and run <code>gci</code> again.</p> <p>Here we see activation scripts and some executable files. One of these is python.exe, which is the Python interpreter. We also have pip.exe.</p> <p>At the moment, this is just a directory - if we type python.exe we will be running the system installation of Python. I'll prove it.</p> <pre><code>gcm python | select source\n</code></pre> <pre><code>which python\n</code></pre> <p>In order to tell the system we want to use the virtual environment, we're going to run this activation script, Activate.ps1.</p> <p>Now we are in the virtual environment. We can confirm this by running <code>gcm python.exe</code>, and we can see that running Python now will run the interpreter that we just installed. What happens when we want to run <code>pip</code>? We can see that pip, too, now points to the version we just installed in the virtual environment. If we install a package now, it will be installed only to the virtual environment, and not the system installation.</p> <p>Let's install Django. <pre><code>pip install django\n</code></pre> In a few moments the installation will complete.</p> <p>We can confirm the installation completed by running <code>pip list</code>. Here is Django, version 3.xx. And if we run <code>gci</code> again, we can see that some new executable files have been installed to this directory.  But how can we be sure that Django wasn't installed to the system installation? We can exit the virtual environment by running <code>deactivate</code>.</p> <p>Now we have returned to the system installation of Python. We can confirm this again by running <code>gcm</code>. And now when we check the list of installed packages using <code>pip list</code>, we see that Django is not present. We successfully installed Django to the virtual environment alone, leaving our system installation untouched.</p> <p>This is the recommended way of installing Python packages.</p>"},{"location":"Scripts/Django/#project-skeleton","title":"Project skeleton","text":"Before we leave the virtual environment and start coding, let's take another look at the Scripts directory. One of the executables that has been installed is <code>django-admin.exe</code>. This is Django\u2019s command-line utility for administrative tasks.  <p>Other languages have similar utilities that are used to facilitate common administrative tasks, for example building out the skeleton of a new project, which you would do like this: <pre><code>django-admin startproject project\n</code></pre> This is all I'm going to use django-admin for in this course, but there is a lot you can do with it.</p> <p>Once the project has been created, let's go into the directory and peek around. As we can see, a Django project has a manage.py script and contains a nested directory with the same name as that of the project.</p> <p>The manage.py is actually what you will use to do a lot of administration for your web application. For example, we can run <code>python manage.py runserver</code> to start the web application. If we open a web browser to the address and port used by the server, we can see Django's default landing page. Let's close the server by pressing CtrlC</p> <p>Let's run another command <pre><code>python manage.py startapp application\n</code></pre> If we get the directory contents again, we see that, similar to the <code>django-admin</code> command we ran earlier, this command erects a directory of content. Let's take a look and see what it created.</p> <p>More Python scripts.. but what are these files for? Off the bat, we notice this directory has a urls.py. Is this similar to the urls.py created in the project directory?</p>"},{"location":"Scripts/Django/#project-structure","title":"Project structure","text":"<p>Django web apps are structured into projects and applications. It's important to understand the distinction, because it is not immediately obvious to a novice.</p> <ul> <li> <p>project describes a Django web application</p> <ul> <li>The project's root directory contains manage.py. </li> <li>The root directory contains a subdirectory with the same name as the root, but which contains other Python scripts, like urls.py and especially settings.py. </li> <li>This is called the project directory. </li> </ul> </li> <li> <p>An application refers to a Python package that provides some set of features. </p> <ul> <li>Applications are a component of projects. </li> <li>Application directories also contain a urls.py, but that's where the similarity ends.</li> </ul> </li> </ul> <p>For a person who's new to Django, this means that much of the core functionality of your project will actually be contained in an app, which can feel awkward at first. But bear with it for now.</p>"},{"location":"Scripts/Django/#settingspy","title":"settings.py","text":"<p>Before we move any further, let's open the project folder and go to settings.py. </p> <p>If we scroll down to <code>INSTALLED_APPS</code> we need to make sure we add the name of the application that we just created in quotes to the list. This list is what Django uses to construct its namespace. </p> <p>Let's also take a look at this token value  (<code>SECRET_KEY</code>) that is provided in plaintext. Because I'm guessing you're just learning Django and not about to deploy your web application to production, doing this is okay. But for production systems, this is a no-no. I'm going to show you an easy and simple it is to protect your secrest. But if you don't want to spend time on this section, feel free to use the time-codes to skip ahead.</p>"},{"location":"Scripts/Django/#model","title":"Model","text":"<p>In order to determine the shape of a web app's data, Django uses what is called a Model. If you're familiar with object-oriented programming, this will be the easiest part.</p> <p>Let's go into the application's models.py and create a Model. Models form the basis of how Django organizes data. </p> <p>models.py<pre><code>from django.db import models\n\nclass Task(models.Model):\n  title = models.CharField(max_length=50)\n  # done = models.BooleanField()\n  # created = models.DateTimeField(auto_now_add=True)\n</code></pre> We're subclassing <code>models.Model</code>, and the model defines a series of named fields which are instances of each of these classes. Some of these fields require specific attributes to be defined. For example, <code>CharField</code> requires a <code>max_length</code> attribute to be defined. </p> <p>Defining a model is not permanent, so let's stick with just the one title field. We'll add to it in a moment. Let's move on to the topic of migrations.</p> <p>When you make even the slightest to the models used in your web application's, Django requires you to perform what's called a migration. A migration keeps the web application's database consistent with the model. This is a two-step process from the command-line. <pre><code>python manage.py makemigrations\n</code></pre> This command analyzes the Model classes you've defined for the web application, and then it actually codes Python scripts for you to change the database accordingly. You'll find them in the migrations directory, see? </p> <p>To run these scripts, run <pre><code>python manage.py migrate\n</code></pre> Because this is the first time I ran a migration, it created a database for me from scratch, here. We can see that it's a SQLite database, a lightweight option that is used a lot in Python development. In fact, the Python Standard Library includes a SQLite module, so every Python installation is able to create and manipulate SQLite databases.</p> <p>How did Django know to produce an SQLite database, and not another? Let me show you.</p> <p>In the settings.py there is a dictionary named DATABASES</p> <p><pre><code>DATABASES = {\n  'default': {\n    'ENGINE': 'django.db.backends.sqlite3',\n    'NAME': BASE_DIR / 'db.sqlite3',\n  }\n}\n</code></pre> \"ENGINE\" specifies the driver to use with the database. Django supports four databases out of the box: PostgreSQL, MySQL, Oracle, and SQLite. The other 3 options are more involved and require a server to be set up, so if you ever want to use them, you'll have to define values for <code>HOST</code>, <code>PORT</code>, <code>USER</code>, and <code>PASSWORD</code> in this dictionary. But SQLite keeps the database in a local file - no need to mess with any of that. We don't have time for an in-depth discussion of SQLite, but what I will do is show you how we can quickly take a look at this database within VS Code.</p> <p>Open the Extensions Marketplace and search for sqlite. The top app, SQLite Explorer by \"alex\", is what we're looking for. Click the green install button. </p> <p>I already have this extension installed, so I'm going to return to the File Explorer. Now I right click on db.sqlite3 and select open database. Another section named SQlite explorer should open in the file explorer. If you installed SQLite Explorer but don't see this section, check the hamburger menu in the top right and make sure it's enabled.</p> <p>SQLite Explorer allows you to view the schema and content of SQLite tables. Let's expand it. Each of these is a table -- the file is the database. All of these tables comes from an application in our Django project, and all but one of them were automatically implemented. The one we created is here, at the top - application_task.</p> <p>When we expand the table, we see Django added an integer id field, as well as the field we defined. \"<code>varchar</code>\" is SQL's equivalent of a string, more or less. </p> <p>Let's go back to the code and make another change to the Model. We're going to add a value so we can mark completed tasks off our to-do list. <pre><code># models.py\nfrom django.db import models\n\nclass Task(models.Model):\n  title = models.CharField(max_length=50)\n  done = models.BooleanField(default=False)\n  # created = models.DateTimeField(auto_now_add=True)\n</code></pre> <code>BooleanField</code> doesn't require a <code>max_length</code>, but it does require a default value.</p> <p>We changed the model, so the database will have to be updated, which means we have to run another migration. Again we run <code>python manage.py makemigrations</code>, and we see a new migration script has been generated. Let's run it using <code>python manage.py migrate</code>. Once it's complete let's return to the SQLite Explorer. Now we see that our change has taken effect in the schema of the task. Let's go back and make one final addition. <pre><code># models.py\nfrom django.db import models\n\nclass Task(models.Model):\n  title = models.CharField(max_length=50)\n  done = models.BooleanField()\n  created = models.DateTimeField(auto_now_add=True)\n\n  # def __str__(self):\n  #   return self.title\n</code></pre> As you might guess, <code>DateTimeField</code> stores date and time information. The <code>auto_now_add</code> argument means that the web application will automatically associate the current date and time when a record is created. Let's make migrations and migrate one last time.</p>"},{"location":"Scripts/Django/#adding-data","title":"Adding data","text":"<p>Now the foundation of our web app - the data model - is complete. Too bad we have to wait until we code the rest of the web app to know what it looks like... wouldn't it be great if we could test out some data right away? Well, we can. Actually, there are several ways.</p> <p>The most Pythonic way is by running the Python interpreter. In the integrated terminal, when we run <code>python manage.py shell</code> we are greeted by a Python REPL. Let's import the model and instantiate a new task <pre><code>from app.models import Task\n\ntask = Task(title=\"Shop for milk\")\n</code></pre> Now we can run the <code>save</code> method on this task object: <code>task.save()</code>. And that will save the task created into the database.</p> <p>Another way is by running the command-line client for the database itself. By running <code>python manage.py dbshell</code>, we're taken into the SQLite client. We can run <code>.tables</code>, and we'll see all the available tables in the database. The output of this command should correspond exactly with the what we see in the SQLite explorer by opening the database.</p> <p>A deeper discussion of SQL syntax is beyond the scope of this video, but it wouldn't hurt to learn a couple of tricks. One SQL command that everyone know is <code>select * from</code>. We can run <code>select * from app_task;</code> and we can see that the task we added is in the database, and will be served by the web server.</p> <p>But a more typical way to add data during development is to do it through the admin portal. </p> <p>Let me show you what that is. Let's run <code>.exit</code> to leave the SQLite client. Now let's run the server and open a web browser to \"localhost/admin\". Every Django server has an admin application at this URL, by default. But it wants a login. How do we login to our own server? Let's stop the server and create a user so that we can login.</p> <pre><code>python manage.py createsuperuser\n</code></pre> <p>I'm going to create a superuser named Jasper. The prompt asks for an email address, but you can leave it blank. I enter a password, then confirm that password. And because Django can detect that it's not as complex as it should be, it asks me if I'm sure I want to set that as the password. I confirm. Now we can use those credentials to login to the admin site. </p> <p>Let's stop the webserver one last time and go into the app/admin.py file. Here I'm going to register the model we just created.  <pre><code>from .models import Task\n\nadmin.website.register(Task)\n</code></pre> This will make that model appear in the admin app, allowing us to manipulate the data through the web browser.</p> <p>Now we run the web server, refresh the admin site in the web browser, and we can see that the Task model appears in the admin dashboard. If I click on it, I can see the entry we created from the command-line. Let's create a new task here. And now our database has some data in it. Let's flesh out our web application some more.</p>"},{"location":"Scripts/Django/#view","title":"View","text":""},{"location":"Scripts/Django/#forms","title":"Forms","text":"<p>The <code>ModelForm</code> class can be used to quickly create a form from an existing model. <pre><code>from django.forms import ModelForm\n\nclass TaskForm(ModelForm):\n  class Meta:\n    model = Task\n    fields = '__all__'\n</code></pre> Alternatively, this class can be defined by instantiating the <code>modelform_factory</code> class generator. This can be placed within the views.py outside the view function for brevity, but it's typical to place this declaration within forms.py.  <pre><code># forms.py\nfrom django.forms.models import modelform_factory\nfrom .models import Task\nfrom django.forms.widgets import Input\n\nTaskForm = modelform_factory(Task, exclude=[])\n</code></pre> In either case, this subclass is instantiated in views.py and passed in with the context object views.py<pre><code>from .forms import TaskForm\nfrom .models import Task\n\ndef index(request):\n  tasks = Task.objects.all()\n  form = TaskForm()\n  context = {'form': form}\n  return render(request, 'website/list.html', context)\n</code></pre> Let's take a look at the <code>tasks</code> variable. This is called a <code>QuerySet</code>. </p> <p>The key of the context object where the form was placed can then simply be used in a template tag: <pre><code>&lt;form method=\"POST\"&gt;\n  {{form}}\n&lt;/form&gt;\n</code></pre> Without the <code>method=\"POST\"</code> attribute set in the tag, the form will not send a POST request.</p> <p>A single field of the form can be specified as well: <pre><code>&lt;form method=\"POST\"&gt;\n  {{form.title}}\n&lt;/form&gt;\n</code></pre> However, on the same page, the <code>csrf_token</code> must also be provided <pre><code>{% csrf_token %}\n</code></pre> If the token appears in the text of the page, that is because you have used the template tag mustaches <pre><code># Wrong!\n{{ csrf_token }}\n</code></pre></p>"},{"location":"Scripts/Django/#django-starships-gallery","title":"Django starships gallery","text":"<p>Now that we've learned the basics of Django, let's make another web app that will do something more interesting.</p> <p>So we'll return to PowerShell and create a new directory for a new project. We're still working with the same virtual environment, so no need to create a new one. <pre><code>django-admin startproject starships\npython manage.py startapp app\n</code></pre></p> <p>...</p> <p>Bulma is a popular web design framework. You've probably heard of Bootstrap, which reigns supreme in this space, but Bulma is often brought up as an alternative because it is CSS only, whereas Bootstrap does incorporate some JavaScript. Because Bulma is CSS only, incorporating it involves basically downloading the CSS file, which you can do from the website.</p> <p>Where do we put it? Well, CSS files are typically considered static content, so we make a new folder in our app directory named \"static\" and place it there. Now we create a base template</p> <pre><code>| {% load static %}\n&lt;!DOCTYPE html&gt;\nhtml(lang=\"en\")\n  head\nmeta(charset=\"UTF-8\")\n    meta(name=\"viewport\", content=\"width=device-width, initial-scale=1.0\")\n    link(rel=\"stylesheet\", href=\"{% static 'bulma.css'%}\")\n    title \ud83d\ude80\ud83d\udc0d Django Starships\n    style\n//- | .is-ancestor { flex-wrap: wrap; }\nbody\nsection.hero.is-primary\n.hero-body\n.container\nh1.title Starships\n    section.section \n.container {% block content %}{% endblock content%}\n</code></pre> <p>The content page, including  <pre><code>| {% extends 'dist/base.html' %}\n| {% load static %}\n| {% block content %}\n.tile.is-ancestor {% for ship in ships %}\n  .tile.is-parent.is-6\narticle.tile.is-child.notification.is-black\nh1.title {{ship.Name}}\n      h2.subtitle {{ship.Registry}}\n      img(src=\"{{ ship.Image.url }}\")\n  | {% endfor %} \n| {% endblock content %}\n</code></pre></p>"},{"location":"Scripts/Django/#basic-filter-table","title":"Basic filter table","text":"<p>Using list.js <pre><code>body\n.listy\ninput.search(type=\"text\")\n    ul.list\nli\np.name USS Enterprise\n        p.reg NCC-1701\n</code></pre> <pre><code>var options = { valueNames: ['name', 'reg'] };\nvar userList = new List('listy', options);\n</code></pre></p>"},{"location":"Scripts/Django/#bulma-filter-table","title":"Bulma filter table","text":"<p><pre><code>body\nsection.section\n.table-container#list\ninput.input.search(placeholder=\"Search\")\n      button.sort(data-sort=\"name\") Sort\n      table.table.is-bordered.is-striped.is-hoverable\nthead\ntr\nth Name\n            th Registry\n            th Crew\n            th Class\n        tbody.list\ntr\ntd.name USS Enterprise\n            td.reg NCC-1701\n            td.crew 204\n            td.cls Constitution\n</code></pre> <pre><code>var options = { valueNames: ['name', 'reg', 'cls'] };\nvar userList = new List('list', options);\n</code></pre></p>"},{"location":"Scripts/Django/#bulma-filter-tile-gallery","title":"Bulma filter tile gallery","text":"<p><pre><code>body\nsection.section\n.container#foo\ninput.search.input(type=\"text\")\n      .tile.is-ancestor.list\n.tile.is-parent.is-3\narticle.tile.is-child.notification.is-primary\nh1.name.subtitle USS Enterprise\n            p.reg NCC-1701\n            p.cls Constitution\n        .tile.is-parent.is-3\narticle.tile.is-child.notification.is-primary\nh1.name.subtitle USS Constitution\n            p.reg NCC-1700\n            p.cls Constitution\n</code></pre> <pre><code>var options = { valueNames: ['name', 'reg', 'cls'] };\nvar userList = new List('foo', options);\n</code></pre> Bulma tiles do not wrap by default <pre><code>.is-ancestor { flex-wrap: wrap; }\n</code></pre></p>"},{"location":"Scripts/Kusto/","title":"Kusto","text":"<p>If you're serious about learning Azure, you've gotta learn Kusto. </p> <p>Kusto is Microsoft's custom-built relational database query language, combining the functionality of SQL with the syntax of a shell language. </p> <p>It is a deep topic, but it's worth mastering if you're planning on doing data science or security in Azure. </p> <p>But like a lot of things worth mastering, getting started is a pain. That's where I'm going to help you.</p>"},{"location":"Scripts/Kusto/#setup","title":"Setup","text":"<p>The first thing you need to get started is an Azure account. If this is your first time signing up for an account, you'll be able to receive a $200 credit that will last 30 days.</p> <p>One of the main complications learning Kusto is that, as far as I know, there isn't a local client like sqlite that you can just download and start playing around with. There is the Kusto Explorer which is available for Windows only, but I'm not a big fan of it. </p> <p>Azure Data Studio has a Kusto extension. After installing it, you can connect to an ADX cluster.</p> <p>Now, what they do have is a Web UI at dataexplorer.azure.com which you.. don't even need an Azure account for! It's more or less publicly accessible as long as you login with a Microsoft account.</p> <p>Now you would think this would be the perfect place to play around with Kusto to start learning it, but if you go straight here you won't have any available data to run queries against.</p> <p>This layout is modeled on similar graphical applications put out by Microsoft like SQL Server Manager Studio where your data sources or connections are listed on the left sidebar, top pane is where you would compose your queries, and then the results would be displayed on the bottom pane.</p> <p>As we can see, there are no data connections available at the present time. So the first thing I'm going to show you, even though I'm not going to use it, is how to add the default \"Samples\" database that is used in every other tutorial and video you're going to find on this topic.</p> <p>Add connection &gt; help.kusto.windows.net, and it's available to the public so you should immediately see the connection show up and you can begin running queries, even though like I said I'm not going to use it for this video.</p> <p>This dataset includes tables on Covid19, US geospatial data, and of course the legendary StormEvents table which you will see everywhere somebody is trying to teach Kusto.</p> <p>But we're not going to go with the canned data that Microsoft provides because, frankly, it's boring and I can't learn with it. Unless you've already done a lot of data analysis, which I haven't, the results will probably seem frankly meaningless.</p> <p>We want to make our own data, or rather I'm going to give you some simple data to play with that you will be able to play with and engage with better. But to do that, we have to get into Azure and create our own Kusto cluster.</p> <p>The first thing we need to do is create a free Azure account. Now even though it says it's free, if you're signing in for the first time you will be expected to produce credit card information, so be ready for that.</p> <p>There are a couple of different ways that Kusto is used in Azure, for example Log Analytics workspaces. But this video is going to focus on just learning the syntax of the language itself, and for that we're going to be using Azure Data Explorer.</p> <p>There are many ways of going about this. Even though I typically opt for using a command-line interface, of which there are two available for Azure, Azure PowerShell and Azure CLI, today for the sake of simplicity I'm going to stick to the Azure website which is referred to as the Portal.</p> <p></p> <p>It will take a few minutes for the cluster to deploy. But once it does, we will be able to connect to it using the Data Explorer web ui by adding it as a source just like we did.</p> <p>Now that the database is up let's add some tables. </p> <p></p> <p><pre><code>.create table starships (name:string, class:string, registry:string, series:string);\n</code></pre> Ingest data <pre><code>.ingest into table starships 'https://raw.githubusercontent.com/jasper-zanjani/kusto/main/starships.csv' with (ignoreFirstRecord=true);\n</code></pre> If you make a mistake <pre><code>.drop table starships;\n</code></pre></p>"},{"location":"Scripts/Kusto/#joining-other-tables","title":"Joining other tables","text":"<pre><code>.create table classes (class:string, crew: int32);\n.ingest into table classes 'https://raw.githubusercontent.com/jasper-zanjani/kusto/main/classes.csv' with (ignoreFirstRecord=true);\n\n.create tables series (series:string, description:string);\n.ingest into table series 'https://raw.githubusercontent.com/jasper-zanjani/kusto/main/series.csv' with (ignoreFirstRecord=true);\n</code></pre> <p>There are a lot of different join flavors: leftouter, rightouter, fullouter, leftsemi, rightsemi, leftanti, rightanti...</p> <p>Joining with classes <pre><code>starships | join kind = inner (classes) on $left.class==$right.class\n| project name, crew;\n</code></pre></p>"},{"location":"Scripts/Kusto/#sqlbolt","title":"Sqlbolt","text":"<p>I love interactive tutorials, and one of my favorite tutorials has been sqlbolt.com.</p> <p>It is a very well-thought out site that takes you from topic to topic with interactive exercises in the browser to challenge what you learn every step of the way. </p> <p>Best of all, it's totally free, with no need even to sign up. </p> <p>In fact, I'm such a big fan when I decided to make this video I decided simply to adapt SQLbolt's lessons to Kusto.</p> <p>If you're interested in learning SQL, I can't recommend sqlbolt highly enough. </p>"},{"location":"Scripts/Labbing/","title":"Labbing to Learn Linux","text":"<p>So you've been on LinkedIn, looking for a job or just doomscrolling all the updates in everyone else's career. You happen upon people talking about Linux. What is it? Why is it useful? Or you decide to make a change and get into IT. However you came across it, you've made the decision to try to learn Linux.</p> <p>The </p>"},{"location":"Scripts/Rust/","title":"Rust","text":""},{"location":"Scripts/Rust/#rust-tutorial","title":"Rust tutorial","text":"<p>Introductory monologueF1</p>"},{"location":"Scripts/SQLite/","title":"SQLite","text":"<p>SQLite is a minimal, open-source database which supports standard relational database features.  It's part of the Python Standard Library and because of that, it's used in a lot of places.  And for Django web applications, it's the database of choice during development.</p>"},{"location":"Scripts/3rd/dylan_roof/","title":"Dylan roof","text":"<p>dylann roof was 21 years old and he believed in racial segregation. he also believed that the white-skinned people were superior to the dark skin ones.  Dylan ran a website called the last Rhodesian where he posted images of himself burning the Asdmerican flag or holding a pistol and posing proudly at sites connected to the Confederacy.</p> <p>At first he wanted to go into the projects and shoot African-American drug dealers, but he then decided that they might shoot back and he didn't want to risk dying before he could change the world.  he settles for the Emanuel African Methodist Episcopal Church in South Carolina.</p> <p>On June 17th 2015 Dylan roof pulled into that church and he sat in his car for some time. he had loaded 8 magazines of hollow point ammunition for his Glock 45 handgun. he wanted to have exactly 88 bullets because that number is the white nationalist code for Heil Hitler. Dylan then join the members of the congregation for a Bible study session that was planned for that night. he sat there for a few minutes working up the courage to attack. He then  out his gun telling the others that African-Americans were taking over their country, and he then open fire.  according to One Survivor,  roof tried to shoot himself but he had run out of ammunition.  he fled in his car he was arrested the following morning in North Carolina and brought in for interrogation</p> <p>Dylan roofs parents were in the middle of a divorce when he was born. his father Franklin was a carpenter and a contractor while his mother Amy serve drinks as a bartender. Dylan's birth would bring them back together but only for a short time. when Dylan was five his father would marry another woman named Paige and together they would give Dylan another sibling. Dylan would watch as his father constantly verbally and physically abused his stepmother on a daily basis</p> <p>at three years old Dylan received a haircut style called the bowl cut and for the remainder of his life he would make sure his hair would remain that way. He would begin to develop odd behaviors like obsessive compulsive disorder where he would fixate on any one thing and only that thing, and his family would have a hard time taking his attention away from it. he was also germaphobic, and would go out of his way to avoid any and all germs. in middle school he found that he enjoyed smoking marijuana and was even caught spending money on the drug.</p> <p>Dylan would attend almost a dozen different schools in his life and would even end up repeating the 9th grade before he decided to quit altogether. quitting school meant he would have a lot of free time and he would use that time to play video games and use drugs. he would live on and off between his biological mother and father maintaining this lifestyle until his father demanded he get a job as a landscaper, which Dylan did. aside from work Dylan continued to maintain his antisocial lifestyle. he would spend the majority of his free time locked in his room searching the internet or playing video games</p> <p>Dylan purchased the gun used in the shooting at a retail store in West Columbia using birthday money that was given to him. after showing it to his friends they would try and hide the weapon because they feared he would kill someone with it Dylan continue to post racist propaganda on the internet and was even talking to other white supremacist online. ironically it was his racist actions that would lead to him getting caught after the shooting</p> <p>after Dylan left the church he would drive almost 300 miles away. he was at a stoplight when a woman noticed his car with a three flag Confederate States of America bumper decoration. she then called the police, revealing his location. photos of him and his car we're all over television and the internet, so his car and him in it was like a beacon for all to see. Dylan was convicted of the murders and sentenced to death for his crimes</p> <p>On August 4th 2016 Dylan was assaulted by another inmate. the attacker was 25 year old African-American Dwayne Stafford who was awaiting trial for assault and robbery. Dwayne was able to sneak down to the protective custody unit where the two officers were watching Dylan just happened to be busy with other things. Dylan had bruising on his face and body but was not seriously injured strangely enough the next day Dwayne was released on bail.</p>"},{"location":"Scripts/Discord/Discord/","title":"Discord","text":"<ul> <li>Discord<ul> <li>Discord UI</li> <li>Creating a new Discord</li> <li>Creating a bot</li> <li>Set-up</li> <li>Visual Studio Code</li> <li>First bot</li> <li>Environment variable</li> <li>TextChannel hello-world</li> <li>DM hello-world</li> <li>Enriched hello-world</li> <li>Cogs</li> <li>Call-out to click video</li> <li>Inspection of <code>ctx</code> object</li> <li>Events</li> <li>Reaction role</li> <li><code>on_raw_reaction_add</code></li> <li><code>discord.utils.get</code></li> <li>Adding role</li> </ul> </li> <li>API</li> </ul> <p>If you're watching this video, odds are you need no introduction to Discord. Discord is an instant  messaging application with support for images and file sharing, custom emoji, and granular role- based access control. Just a few years ago, Discord might have been considered just one of many  messaging platforms, vying for the spotlight alongside Telegram, Viber, WhatsApp, Slack, and  Microsoft Teams. But today, Discord is the de facto communications platform for tech geeks,  YouTubers, and especially PC gamers and Twitch streamers. With Discord it is ridiculously easy to  start a free online community, populated with channels for text and voice communication, and you  can even host video streams. Most interesting of all, Discord exposes an API that is supported by  libraries that support the development of bots in a  ton of languages.</p> <p>Today I'm going to take you from zero to hero in one of these libraries, Discord.py! Let's get started!</p>"},{"location":"Scripts/Discord/Discord/#discord-ui","title":"Discord UI","text":"<p>I just created a fresh Discord account. All you need to provide is an email address for verification. The Discord logo at the top opens our private messages. We don't have any at the moment. We can  discover other public servers using the compass icon. We can also create our own server by clicking  on the plus button. As you can see I haven't joined any Discord servers, which would appear between  the compass and the plus icons.</p> <p>But let's change that right now and join the Discord.py server. This  is a Discord server run by the developers and maintainers of the discord.py library. I can find an  invite link from their GitHub page. I scroll to the bottom, click on the link and confirm that I  want to join the server. As you can see, the icon now appears on the left sidebar. Within a typical  Discord server, you usually find many TextChannels for chat, and a few VoiceChannels for audio  communication. These are found on the left sidebar, to the right of the list of joined servers. On the right sidebar you can find a list of all server members, organized by role.</p>"},{"location":"Scripts/Discord/Discord/#creating-a-new-discord","title":"Creating a new Discord","text":"<p>Let's create our own Discord by clicking on the plus icon.</p>"},{"location":"Scripts/Discord/Discord/#creating-a-bot","title":"Creating a bot","text":"<p>Let's open up a web browser and navigate to https://discordapp.com/developers</p> <ul> <li>token is a secret</li> <li>permissions</li> </ul>"},{"location":"Scripts/Discord/Discord/#set-up","title":"Set-up","text":"<p>Before we start coding, we're going to install a virtual environment. A virtual environment acts as a secondary installation of Python where we will install dependencies. It is considered a best practice to install packages like discord.py in virtual environments so that  you don't clutter up your system installation of Python with a bunch of packages of various versions that could cause you confusion down the road. How you do this is up to you, but I like to organize all my virtual environments into a single folder that I can then reference from multiple projects that are stored elsewhere. I start PowerShell and navigate to the correct folder. I create the virtual environment by invoking Python with <code>-m</code> followed by \"venv\", then the name of the virtual environment I want to create. <pre><code>python -m venv discord\n</code></pre> Now that it's created, before I activate it I inspect where the python command points to. <pre><code>Get-Command python | select Source\n</code></pre> This is the system installation of Python. I invoke the Activate script, which tells the system I want to use the virtual environment that was just created and changes the appearance of the prompt. <pre><code>.\\discord\\Scripts\\Activate.ps1\n</code></pre> Now I inspect how the system will interpret the <code>python</code> command and confirm that it does indeed point to the virtual environment. <pre><code>Get-Command python | select Source\n</code></pre> Now when I run Python, I'll be running the Python that was installed to this directory because I activated the virtual environment. The same goes for <code>pip</code>, which is Python's package manager. <pre><code>gcm pip | select Source\n</code></pre> I install the discord.py package into the virtual environment. <pre><code>pip install discord.py\n</code></pre> I can confirm the package was installed by running <pre><code>pip list\n</code></pre> I can leave the virtual environment by typing <pre><code>deactivate\n</code></pre> Now I have returned to the system installation of Python. If I check installed packages <pre><code>pip list\n</code></pre> We see that discord.py was installed only to the virtual environment, leaving our system installation clean.</p>"},{"location":"Scripts/Discord/Discord/#visual-studio-code","title":"Visual Studio Code","text":"<p>Now we are ready to start up our editor. For this video I'm going to use Visual Studio Code, which is available free of charge for multiple platforms, including Windows 10. I have the Python extension installed, and you should too if you're thinking of developing in Python. I start a new project folder to contain our work, and start a new Python script. <pre><code>import discord\n</code></pre> As we can see, attempting to import the discord.py package produces an error. That is because VS Code is still using the default system installation of Python. We already confirmed that we installed the discord.py package only to the virtual environment and not to the system installation. How do we tell VS Code to use the virtual environment?</p> <p>We can select the virtual environment's interpreter by clicking here. Once we select the correct interpreter, which is found in the same directory as the <code>activate</code> script, the error is resolved, and we're ready to hit the ground running.</p>"},{"location":"Scripts/Discord/Discord/#first-bot","title":"First bot","text":"<p>There are several ways of using the API exposed by the discord.py package. We will stick to the  easiest one by instantiating a <code>Bot</code> object. If you've never used a Discord bot, they typically  appear as another user, and their functionality is accessed by typing a keyword preceded by a  special character within a channel or DM, like <code>!help</code>. <code>command_prefix</code> indicates what these specials characters will be. You can specify more than one prefix by specifying a list of strings. Today, we will keep things simple and stick to a period. Finally, we invoke the <code>run</code> method of the newly instantiated <code>Bot</code> object and pass it the  token. <pre><code>from discord.ext.commands import Bot\n\nbot = Bot(command_prefix='.')\n\nbot.run(token)\n</code></pre> Let's run the script as-is. We don't get any feedback in the terminal, but if we check the Discord,  we see our bot is now online. We haven't defined any functionality for it yet, but we can type <code>.help</code> and we receive a help message. This is because the help message is automatically implemented for any  bot. Congratulations! You've created a completely useless Discord bot, hopefully the first of many!</p>"},{"location":"Scripts/Discord/Discord/#environment-variable","title":"Environment variable","text":"<p>If you're starting out learning coding, then it's important to learn good habits from the jump. And one of the most important habits is keeping secrets like a token out of your code.  In the previous example, I placed the literal token within my code, a practice known as hardcoding. This is a security issue, because anyone who sees this token will be able to use it and abuse it as they please.  Don't worry about my token here -- by the time you see this video it will have been changed long ago.</p> <p>One day you might decide to share your code, because you need help with it or want to  show off your achievement by uploading it to a public repository like GitHub. Unfortunately, hard-coded secrets left within code remains one of the biggest sources of data leaks, and even big companies and experienced developers are guilty of this rookie mistake. So how do we protect our secret token?</p> <p>One of the best ways of protecting secrets is by placing them in environment variables. Environment variables are values stored in memory and which can be accessed from Python. Let's open up the integrated terminal by hitting Ctrl`, which is the key directly to the left of the number 1 on US keyboards. </p> <p>As we can see, because we selected the virtual environment as our interpreter, the integrated terminal comes up with the virtual environment already loaded.</p> <p>Keep in mind in this video I'm using a Windows environment, so if you're using a Mac OS X or Linux computer, the terminal will look different.</p> <p>In PowerShell, environment variables can be viewed as a PowerShell drive, meaning it is treated like a virtual filesystem <pre><code>Set-Location Env:\\\nGet-ChildItem \n</code></pre> Our system already has many environment variables set up.  These environment variables provide information to programs on certain important locations. For example, <code>SystemRoot</code> points to the directory where our installation of Windows is located. My system has Windows installed to \"C:\\WINOWS\", and if you're running Windows yours probably does too. In PowerShell we can access the value of environment variable like so <pre><code>$Env:SystemRoot\n</code></pre> Because it's a location on the drive, we can navigate directly there by accessing the environment variable as an argument to another command. <pre><code>Set-Location $Env:SystemRoot\nGet-Location\n</code></pre> Let's start the Python interpreter and see how we can access environment variables within Python. <pre><code>python\n</code></pre> Now we import the <code>os</code> module, which is part of the Standard Library. The Standard Library is a collection of modules that are provided by default with every installation of Python. <pre><code>import os\n</code></pre> We can access environment variables by calling <code>os.getenv()</code>. Let's use this command to inspect the Windows installation directory. <pre><code>os.getenv('SystemRoot')\n</code></pre></p> <p>Now let's find out how to temporarily declare an environment variable and access it from the script. First we create a new file named \".env\". We open it up and we create a value <pre><code>TOKEN=...\n</code></pre> Let's install a new module <pre><code>pip install dotenv\n</code></pre> Now we place an import statement at the top of our Python script. And we can call a function  <pre><code>import dotenv\n\ndotenv.load_dotenv()\n</code></pre> When the script is run, this function call will load the \".env\" file and add the TOKEN value to the environment. Its value will be available as an environment variable.</p> <p>Let's try it out: <pre><code>import os, dotenv\n\ndotenv.load_dotenv()\ntoken = os.getenv('TOKEN')\nprint(token)\n</code></pre> As we can see we successfully loaded the .env file, then accessed its value as an environment variable. However, once the script has completed execution and we exit the interpreter, the TOKEN variable is no longer available <pre><code>$Env:TOKEN\n</code></pre> This is how we can protect secrets at the measly cost of nothing more than 2 additional lines of code. This has the added benefit that we will be able to use the same .env file for any additional Python scripts we compose in this directory.</p> <p>Let's compose  <pre><code># import discord\nimport os, dotenv\nfrom discord.ext.commands import Bot\n\ndotenv.load_dotenv()\ntoken=os.getenv('TOKEN')\n\nclient= Bot(command_prefix='.')\n\n# ...\n\nclient.run(token)\n</code></pre></p>"},{"location":"Scripts/Discord/Discord/#textchannel-hello-world","title":"TextChannel hello-world","text":"<p>These expressions preceded by the <code>@</code> sign are called decorators. A deeper discussion of what decorators do is outside the scope of this video, but it's enough to say that they add functionality to any functions they decorate. And in discord.py in particular, they will tie together all the code you write. <code>ctx.send</code> equivalent to <code>print</code> <pre><code>@client.command()\nasync def hello(ctx):\n  await ctx.send(f'Hello world!')\n</code></pre></p>"},{"location":"Scripts/Discord/Discord/#dm-hello-world","title":"DM hello-world","text":"<pre><code>@client.command()\nasync def hello(ctx):\n  user = ctx.author\n  await user.send('Hey handsome')\n</code></pre>"},{"location":"Scripts/Discord/Discord/#enriched-hello-world","title":"Enriched hello-world","text":"<p>Embed: enriched message - URLs are automatically put into links <pre><code>@client.command()\nasync def hello(ctx):\n  user = ctx.message.author.name\n  emoji = random.choice([':grin:', ':smiling_face_with_3_hearts:', ':smirk:'])\n  embed=discord.Embed(\n    title=f\"Hello {user}!\", \n    description=f\"Thank you for the attention {emoji}\",\n    color=discord.Color.teal())\n  await ctx.send(embed=embed)\n</code></pre></p>"},{"location":"Scripts/Discord/Discord/#cogs","title":"Cogs","text":"<p>When you're developing something from scratch or learning something new, your code can get messy  very quickly. It's always a good idea to keep your code as tidy and clean as possible.  You can definitely do this using the standard Python imports and modules. This shouldn't be much of an issue since we're defining procedural functions which have nothing  to do with one another logically. The discord.py library offers a way to do that in what are called \"Cogs\", which not only organize and modularize your code but offer a way to group your commands into command groups. </p> <p><pre><code>from discord.ext import commands\nimport dotenv\nimport os\n\ndotenv.load_dotenv()\ntoken = os.getenv('TOKEN')\n\nclient = commands.Bot(command_prefix='.')\n\nclient.load_extension('cogs.Example')\n\nif __name__ == \"__main__\":\n  client.run(token)\n</code></pre> The way the cog file itself is designated by using the directory name and filename separated by period is the same convention used in  Django . <pre><code>from discord.ext import commands\n\nclass Example(commands.Cog):\n  def __init__(self, client):\n    self.client = client\n\n  @commands.command()\n  async def ping(self, ctx):\n    await ctx.send('pong')\n</code></pre></p>"},{"location":"Scripts/Discord/Discord/#call-out-to-click-video","title":"Call-out to click video","text":"<p>If the use of these command decorators strikes you as bizarre and you feel that it would help you to see them being used in a different context, another video I recently made should help you out. In it, I go over the <code>Click</code> package, which allows you to create command-line utilities in Python  using decorators that look and act a whole lot like these ones.</p>"},{"location":"Scripts/Discord/Discord/#inspection-of-ctx-object","title":"Inspection of <code>ctx</code> object","text":"<p>Listing channels on a Discord server <pre><code>@commands.command()\nasync def channels(self, ctx):\n  channels = [c.name for c in ctx.guild.channels if type(c) is discord.TextChannel]\n</code></pre> Snitch command <pre><code>@commands.command()\nasync def dmowner(self, ctx):\n  user_id = ctx.guild.owner_id\n  user = self.client.get_user(user_id)\n  print(user_id)\n  await user.send(f'This guy {ctx.author.name} is creeping me out... Betta handle dat!')\n</code></pre></p>"},{"location":"Scripts/Discord/Discord/#events","title":"Events","text":"<p>Event handler functions conventionally have names beginning with \"on\", i.e. <code>on_load</code> - <code>@commands.Cog.listener()</code> vs. <code>@client.event</code> vs. <code>on_ready(self)</code> (class-based)</p> <p><pre><code>@client.event\nasync def on_ready():\n  print(f\"Logged in as {client.user.name}\")\n</code></pre> <pre><code>@commands.Cog.listener()\nasync def on_ready(self):\n  print(f\"Logged in as {self.client.user.name}\")\n</code></pre></p>"},{"location":"Scripts/Discord/Discord/#reaction-role","title":"Reaction role","text":"<p>So we've established a broad-based understanding of the features exposed in the discord.py API: - commands defined using the <code>command()</code> decorator - event handlers that use the <code>event</code> decorator and which override the API's built-in events  - <code>Context</code>  objects that are passed to commands upon invocation from the message window. Context objects, in turn, expose a   - <code>send</code> method that we can use to send messages back to the <code>TextChannel</code> where the command originated   - Using the <code>author</code> attribute of a Context object, we can send direct messages. - <code>Embed</code> objects for richer message content - Cogs to organize and modularize commands - Most importantly, we learned about the <code>Bot</code> object itself, which accepts the token we get from the Discord developer portal, and how to keep that token secure.</p> <p>Let's implement a practical project that will allow us to bring these lessons home. One of the most common features that Discord guild maintainers want to implement is a bot that will automatically assign roles to members based on an emoji reaction, or a \"reaction role\". In Discord these are often used to force members to indicate agreement to a code of conduct or to assign fun roles based on the individual's personal interests.</p> <ul> <li>First we need to adjust the permissions of the bot by assigning it the \"Manage roles\" permission. We can do this through the developer portal, but it's easier to do it in the Discord server itself</li> <li>We right-click on our Discord server and open server settings</li> <li>Let's go to the Roles section and click on Chatty Cathy</li> <li>We scroll down until we find the Manage Roles permission</li> <li>We grant Chatty Cathy the permission to manage roles</li> <li>We also need to actually create a role that Chatty Cathy will assign to a user. We can also do this in server settings.</li> <li>We also need to make sure the bot's role is placed physically above that of the role to be assigned.</li> <li>Discord roles are arranged like a totem pole in this way, such that roles can only be assigned by higher roles.</li> <li>Finally we can write some code.</li> </ul>"},{"location":"Scripts/Discord/Discord/#on_raw_reaction_add","title":"<code>on_raw_reaction_add</code>","text":"<p>Let's go back to Visual Studio Code where we will create a new event handler in main.py for the ON RAW REACTION ADD event. This event, unlike the <code>on_ready</code> event will be passed a PAYLOAD argument.. <pre><code>@bot.event\nasync def on_raw_reaction_add(payload):\n  pass\n</code></pre> </p> <p>The Payload argument is similar in concept to a Context object. It is not as rich in information. A payload does expose a few useful properties that we will need if we want to implement the functionality of a reaction role.</p> <p>Where a Context object exposes a Guild object, a Payload object exposes only a guild_id. Where a Context object exposes a Channel object, a Payload object exposes only a channel_id. Where a Context object exposes a Message object, a Payload object exposes only a message_id. This means that we have to implement additional query logic in order to retrieve these objects from the ID numbers alone.</p> Context RawReactionActionEvent Guild <code>guild_id</code> Channel <code>channel_id</code> Message <code>message_id</code> <p></p> <p><pre><code>@client.event\nasync def on_raw_reaction_add(payload):\n  print(\"Message ID:\",payload.message_id)\n  print(\"Channel ID:\", payload.channel_id)\n  print('Guild ID:',payload.guild_id)\n  print('Emoji:', payload.emoji.name)\n</code></pre> Let's run it in the integrated terminal and see how it responds. After a moment, the <code>on_ready</code> event handlers fire, and the bot is running. Let's open Discord, react to a message, then examine the output in the terminal. The event handler worked!</p> <p>Now let's see what the significance of this output is. Let's open Discord again, copy the message URL, and compare it to the output in the terminal. As we can see, - The first number indicates the Discord server, or Guild as it is referred to in the Discord API - The second number indicates the channel ID - The third number indicates the message ID</p> <p>Now let's create a new channel. This is where new Discord server members will have to go to be granted the Turtles role. <pre><code>Respond with :thumbs_up:\n</code></pre> And let's give it a reaction. As we can see, the event handler will be triggered when members perform emoji reactions to any message in any <code>TextChannel</code> on our Discord server.</p> <p>Now we're ready to complete the implementation of the role reaction</p>"},{"location":"Scripts/Discord/Discord/#discordutilsget","title":"<code>discord.utils.get</code>","text":"<p>In order to retrieve the object from the object id, we're going to use the <code>discord.utils.get</code> function. <code>discord.utils.get</code> takes the sequence to be queried first, and we can pass the guild_id into the id keyword argument. <pre><code>guild = discord.utils.get(client.guilds, id=payload.guild_id)\n</code></pre> Now that we have a guild object, we can use this same <code>get</code> function to get the role that we want to assign. <pre><code>role = discord.utils.get(guild.roles, name='Turtles')\n</code></pre> Now we can retrieve the member object for the user that actually provided the emoji reaction <pre><code>member = discord.utils.get(guild.members, id=payload.user_id)\n</code></pre> Finally, a method exposed by the member object allows us to add the role. <pre><code>await member.add_roles(role)\n</code></pre> Let's fire up our bot in the integrated terminal. The <code>on_ready</code> events fired, and we're up and running. Let's switch over to Discord. We can see that my username in Discord is not green. I do have a crown, because I am the Guild owner, but I do not have the Turtles role yet. </p> <p>I put a thumbs up on the message, and I can see that now my name is green. Our reaction role bot worked!</p> <p>For some objects, in particular <code>Guild</code>, the Client object exposes a specific method: <pre><code>guild = client.get_guild(payload.guild_id)\n</code></pre> <code>discord.utils.find</code> uses a syntax similar to the Python builtin <code>filter</code> function, where a lambda function is defined, then the sequence of items across which it will be executed.</p> <p>So for example, let's start a Python interpreter in the terminal. Let's make a list of numbers from 0 through 9. <pre><code>l = range(10)\n</code></pre> We can use the filter command to find only even numbers: <pre><code>list(filter(lambda x: x % 2 == 0, l)) # [0,2,4,6,8]\n</code></pre> What we're doing here is that we're iterating over this sequence of elements and executing this lambda function by passing each element through this expression. If the expression returns true, then that element makes it through. If the expression evaluates as false, that value is filtered.</p> <p><code>discord.utils.find</code> uses an identical syntax, but instead of returning multiple values, it returns only one. So we can use it to retrieve the guild object from the guild_id <pre><code>guild = discord.utils.find(lambda g : g.id == payload.guild_id, client.guilds)\n</code></pre> A deeper discussion of lambdas is outside the scope of this video, and because the syntax can be confusing to someone who's not familiar with the topic, I'm actually going to comment out this line.</p>"},{"location":"Scripts/Discord/Discord/#adding-role","title":"Adding role","text":"<p><code>Member.add_roles</code> method takes a role object <pre><code>@client.event\nasync def on_raw_reaction_add(payload):\n  if payload.message_id == 751854496748929065 and payload.emoji.name == u\"\\U0001F44D\":\n    guild = get(client.guilds, id=payload.guild_id)\n</code></pre></p>"},{"location":"Scripts/Discord/Discord/#api","title":"API","text":"<ul> <li>Context</li> <li>Guild</li> <li>Message<ul> <li>Author</li> </ul> </li> <li></li> <li>Client</li> <li>guilds</li> <li>Guild</li> <li>channels</li> <li>roles</li> <li>members</li> <li><code>id</code></li> <li>Payload</li> <li>Member</li> <li>Emoji</li> <li><code>message_id</code></li> <li><code>channel_id</code></li> <li><code>guild_id</code></li> </ul>"}]}